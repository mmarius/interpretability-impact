SubmissionNumber#=%=#22
FinalPaperTitle#=%=#Phrase-Based & Neural Unsupervised Machine Translation
ShortPaperTitle#=%=#
NumberOfPages#=%=#
CopyrightSigned#=%=#
JobTitle#==#
Organization#==#
Abstract#==#Machine translation systems achieve near human-level performance on some languages, yet their effectiveness strongly relies on the availability of large amounts of bitexts, which hinders their applicability to the majority of language pairs. This work investigates how to learn to translate when having access to only large monolingual corpora in each language. We propose two model variants, a neural and a phrase-based model. Both versions leverage automatic generation of parallel data by backtranslating with a backward model operating in the other direction, and the denoising effect of a language model trained on the target side. These models are significantly better than methods from the literature, while being simpler and having fewer hyper-parameters. On the widely used WMT’14 English-French and WMT’16 German-English benchmarks, our models respectively obtain 27.1 and 23.6 BLEU points without using a single parallel sentence, outperforming the state of the art by more than 11 BLEU points.
Author{1}{Firstname}#=%=#Guillaume
Author{1}{Lastname}#=%=#Lample
Author{1}{Email}#=%=#guillaume.lample@gmail.com
Author{1}{Affiliation}#=%=#Carnegie Mellon University
Author{2}{Firstname}#=%=#Myle
Author{2}{Lastname}#=%=#Ott
Author{2}{Email}#=%=#myleott@gmail.com
Author{2}{Affiliation}#=%=#Facebook
Author{3}{Firstname}#=%=#Alexis
Author{3}{Lastname}#=%=#Conneau
Author{3}{Email}#=%=#aconneau@fb.com
Author{3}{Affiliation}#=%=#FAIR Paris/University Le Mans
Author{4}{Firstname}#=%=#Ludovic
Author{4}{Lastname}#=%=#Denoyer
Author{4}{Email}#=%=#ludovic.denoyer@lip6.fr
Author{4}{Affiliation}#=%=#University Pierre et Marie Curie
Author{5}{Firstname}#=%=#Marc'Aurelio
Author{5}{Lastname}#=%=#Ranzato
Author{5}{Email}#=%=#ranzato@fb.com
Author{5}{Affiliation}#=%=#Facebook AI Research

==========