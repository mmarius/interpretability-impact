{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af602986-4766-46cd-83da-71f57253d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import networkx as nx\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import rc\n",
    "from matplotlib import colormaps\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed971ff-83a3-4419-8c68-b28494d0d8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>semantic_scholar_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main.1004</td>\n",
       "      <td>AnswerFact: Fact Checking in Product Question ...</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.188</td>\n",
       "      <td>Product-related question answering platforms n...</td>\n",
       "      <td>4c61df1b4b9a164fec1a34587b4fffae029cd18c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main.1006</td>\n",
       "      <td>Knowledge-Grounded Dialogue Generation with Pr...</td>\n",
       "      <td>Dialog and Interactive Systems</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.272</td>\n",
       "      <td>We study knowledge-grounded dialogue generatio...</td>\n",
       "      <td>3447a432f724aa36595643446acda5b78943db19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main.1009</td>\n",
       "      <td>BiST: Bi-directional Spatio-Temporal Reasoning...</td>\n",
       "      <td>Dialog and Interactive Systems</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.145</td>\n",
       "      <td>Video-grounded dialogues are very challenging ...</td>\n",
       "      <td>f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main.1010</td>\n",
       "      <td>A Knowledge-Aware Sequence-to-Tree Network for...</td>\n",
       "      <td>NLP Applications</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.579</td>\n",
       "      <td>With the advancements in natural language proc...</td>\n",
       "      <td>24ed85ad966823868c1694a19385d01c6ad71008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main.1011</td>\n",
       "      <td>Knowledge Association with Hyperbolic Knowledg...</td>\n",
       "      <td>Information Extraction</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.460</td>\n",
       "      <td>Capturing associations for knowledge graphs (K...</td>\n",
       "      <td>3d61a28b9429fc8f7047fc379a0134a3765edbcb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0  main.1004  AnswerFact: Fact Checking in Product Question ...   \n",
       "1  main.1006  Knowledge-Grounded Dialogue Generation with Pr...   \n",
       "2  main.1009  BiST: Bi-directional Spatio-Temporal Reasoning...   \n",
       "3  main.1010  A Knowledge-Aware Sequence-to-Tree Network for...   \n",
       "4  main.1011  Knowledge Association with Hyperbolic Knowledg...   \n",
       "\n",
       "                             area source  year  \\\n",
       "0              Question Answering  EMNLP  2020   \n",
       "1  Dialog and Interactive Systems  EMNLP  2020   \n",
       "2  Dialog and Interactive Systems  EMNLP  2020   \n",
       "3                NLP Applications  EMNLP  2020   \n",
       "4          Information Extraction  EMNLP  2020   \n",
       "\n",
       "                               doi  \\\n",
       "0  10.18653/v1/2020.emnlp-main.188   \n",
       "1  10.18653/v1/2020.emnlp-main.272   \n",
       "2  10.18653/v1/2020.emnlp-main.145   \n",
       "3  10.18653/v1/2020.emnlp-main.579   \n",
       "4  10.18653/v1/2020.emnlp-main.460   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Product-related question answering platforms n...   \n",
       "1  We study knowledge-grounded dialogue generatio...   \n",
       "2  Video-grounded dialogues are very challenging ...   \n",
       "3  With the advancements in natural language proc...   \n",
       "4  Capturing associations for knowledge graphs (K...   \n",
       "\n",
       "                        semantic_scholar_id  \n",
       "0  4c61df1b4b9a164fec1a34587b4fffae029cd18c  \n",
       "1  3447a432f724aa36595643446acda5b78943db19  \n",
       "2  f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16  \n",
       "3  24ed85ad966823868c1694a19385d01c6ad71008  \n",
       "4  3d61a28b9429fc8f7047fc379a0134a3765edbcb  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/cl_papers.csv\", sep=\",\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75309bed-2f9f-4134-85e5-ed230282bbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/miniconda3/envs/interpretability-impact/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/tom/miniconda3/envs/interpretability-impact/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a0569fdee349adb10ac20eecbb37d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from classifier import is_interpretability_title_and_abstract, is_mt_title_and_abstract, is_dialogue_title_and_abstract, is_ie_title_and_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc16f1a6-eb92-4ee4-ad33-bb687c3a979f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185384"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_path = '../citationgraph/graph.json'\n",
    "zip_path = '../citationgraph/graph.zip'\n",
    "\n",
    "if not os.path.exists(json_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.dirname(zip_path))\n",
    "    print(\"ZIP file extracted.\")\n",
    " \n",
    "with open(json_path) as f:\n",
    "    graph_json = json.load(f)\n",
    "    G = nx.cytoscape_graph(graph_json)\n",
    "\n",
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a1085e-8d36-4149-baa3-8fa2fcc4b9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185384"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_nodes = []\n",
    "\n",
    "for node in G.nodes():\n",
    "  if 'ie_prediction' not in G.nodes[node] or G.nodes[node]['ie_prediction'] is None:\n",
    "      missing_nodes.append(node)\n",
    "len(missing_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63b6b07-c435-4b5f-8e14-f6f5dab2eab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba976785aeeb403d92c90c36420dd1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching papers: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 371/371 [09:31<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "from utils import chunk_list, API_KEY\n",
    "import requests\n",
    "\n",
    "def get_dois(paper_ids: list[str]):\n",
    "    chunk_size = 500\n",
    "    all_papers = []\n",
    "\n",
    "    for chunk in tqdm(chunk_list(paper_ids, chunk_size), desc=\"Fetching papers\", total=(1 + len(paper_ids) // chunk_size)):\n",
    "        url = 'https://api.semanticscholar.org/graph/v1/paper/batch'\n",
    "        fields = \"externalIds,abstract,title\"\n",
    "\n",
    "        response = requests.post(url,\n",
    "                                 headers={\"x-api-key\": API_KEY},\n",
    "                                 params={\"fields\": fields},\n",
    "                                 json={\"ids\": chunk})\n",
    "\n",
    "        for paper_dict in response.json():\n",
    "            if paper_dict is None:\n",
    "                all_papers.append(None)\n",
    "                continue\n",
    "\n",
    "            if 'DOI' in paper_dict['externalIds']:\n",
    "                doi = paper_dict['externalIds']['DOI']\n",
    "            else:\n",
    "                doi = None\n",
    "            abstract = paper_dict['abstract']\n",
    "            title = paper_dict['title']\n",
    "            all_papers.append({ 'doi': doi, 'abstract': abstract, 'title': title})\n",
    "\n",
    "    return all_papers\n",
    "\n",
    "papers = get_dois(missing_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691f6f3c-3c5f-4025-a119-525dd7414961",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_to_title_and_abstract = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7ee2cd-19bf-45ff-9efd-914acc05769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ssid, paper in zip(missing_nodes, papers):\n",
    "    if paper is not None:\n",
    "        abstract = paper['abstract']\n",
    "        title = paper['title']\n",
    "        if title is not None and abstract is not None:\n",
    "            doi_to_title_and_abstract[ssid] = { 'title': title, 'abstract': abstract }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "875c63a9-8326-423d-b9d3-6a0e445268eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142470"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_to_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75f5f30c-4631-4a11-909e-bbee65d8d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_doi = {}\n",
    "doi_to_id = {}\n",
    "for paper, ssid in zip(papers, missing_nodes):\n",
    "    if paper is not None:\n",
    "        doi = paper['doi']\n",
    "        if doi:\n",
    "            id_to_doi[ssid] = doi\n",
    "            doi_to_id[doi] = ssid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4ccc7bc-3051-4ccc-acfe-16868859072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyalex\n",
    "\n",
    "pyalex.config.email = \"tomvergara@uc.cl\"\n",
    "pyalex.config.max_retries = 1\n",
    "pyalex.config.retry_backoff_factor = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8175968-e9f2-440f-9a60-661d7ef5a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 142414/142414 [00:00<00:00, 1883381.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for doi in tqdm(doi_to_id.keys()):\n",
    "    if doi not in doi_to_title_and_abstract and doi in prev:\n",
    "        doi_to_title_and_abstract[doi] = prev[doi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d227353-9970-40cf-9b7b-a130179759be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doi in tqdm(doi_to_id.keys()):\n",
    "    if doi not in doi_to_title_and_abstract:\n",
    "        try:\n",
    "            paper = pyalex.Works()['https://doi.org/' + doi]\n",
    "            title = paper['title']\n",
    "            abstract = paper['abstract']\n",
    "            if title and abstract:\n",
    "                doi_to_title_and_abstract[doi] = { 'title': title, 'abstract': abstract }\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97f1a8-8e43-43c0-bf6d-fcb7635ea94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doi_to_title_and_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2ef60-da17-4a71-872e-12ccaaee773a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff96ee19-1f90-471b-a048-04f13fee0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doi, paper in doi_to_title_and_abstract.items():\n",
    "    title = paper['title']\n",
    "    abstract = paper['abstract']\n",
    "    if abstract is None:\n",
    "        print('aaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dbe3bf2-097d-4a8f-a0c6-c3062df53d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 185384/185384 [51:42<00:00, 59.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for node in tqdm(G.nodes()):\n",
    "    if 'ie_prediction' not in G.nodes[node] or G.nodes[node]['ie_prediction'] is None:\n",
    "        if node in id_to_doi:\n",
    "            doi = id_to_doi[node]\n",
    "            if doi in doi_to_title_and_abstract:\n",
    "                \n",
    "                abstract = doi_to_title_and_abstract[doi]['abstract']\n",
    "                title = doi_to_title_and_abstract[doi]['title']\n",
    "                ie = is_ie_title_and_abstract(title, abstract)\n",
    "                G.nodes[node]['ie_prediction'] = ie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd99b68a-41f1-486a-9b9a-7e1e8cd254f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 185384/185384 [00:00<00:00, 275082.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16949"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "for node in tqdm(G.nodes()):\n",
    "    if 'ie_prediction' in G.nodes[node] and G.nodes[node]['ie_prediction'] is not None:\n",
    "        n += 1\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eceafa48-3179-40e3-86b0-56c13f927e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 185384/185384 [00:00<00:00, 1186388.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125521"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "for node in tqdm(G.nodes()):\n",
    "    if 'ie_prediction' not in G.nodes[node] or G.nodes[node]['ie_prediction'] is None:\n",
    "        if node in id_to_doi: \n",
    "            n += 1\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "815d0d81-4236-463c-84cd-9b80d5369672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142470"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_to_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "64a0cb62-d695-425f-b49a-9646d052424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_json = nx.cytoscape_data(G)\n",
    "with open('../citationgraph/graph.json', 'w') as f:\n",
    "    json.dump(G_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c28d5445-5546-42a0-8923-81caf87d556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../citationgraph/abstracts.json', 'w') as f:\n",
    "    json.dump(doi_to_title_and_abstract, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c665b9-8c47-451d-bc17-530585d5b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../citationgraph/abstracts.json', 'r') as f:\n",
    "    prev = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db8d2054-5c41-42e3-8bd0-b18c6d38f767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10.1016/j.cogsys.2021.09.001': {'title': 'Vector Semiotic Model for Visual Question Answering',\n",
       "  'abstract': 'In this paper, we propose a Vector Semiotic Model as a possible solution to the symbol grounding problem in the context of Visual Question Answering. The Vector Semiotic Model combines the advantages of a Semiotic Approach implemented in the Sign-Based World Model and Vector Symbolic Architectures. The Sign-Based World Model represents information about a scene depicted on an input image in a structured way and grounds abstract objects in an agent’s sensory input. We use the Vector Symbolic Architecture to represent the elements of the Sign-Based World Model on a computational level. Properties of a high-dimensional space and operations defined for high-dimensional vectors allow encoding the whole scene into a high-dimensional vector with the preservation of the structure. That leads to the ability to apply explainable reasoning to answer an input question. We conducted experiments are on a CLEVR dataset and show results comparable to the state of the art. The proposed combination of approaches, first, leads to the possible solution of the symbol-grounding problem and, second, allows expanding current results to other intelligent tasks (collaborative robotics, embodied intellectual assistance, etc.).'},\n",
       " '10.1016/j.neucom.2023.126878': {'title': 'Dialog generation model based on variational Bayesian knowledge retrieval method',\n",
       "  'abstract': 'For dialog generation models that introduce external knowledge, the key challenge lies in how to select the relevant knowledge. The existing common method is to directly use a retriever to fetch knowledge according to the prior distribution that is only conditioned on dialog history. In fact, the response also contains crucial information that is helpful for knowledge retrieval. If we can make use of it and conduct posterior retrieval of relevant knowledge according to both dialog history and response, the selected knowledge will be more relevant to the dialog. Therefore, this paper proposes a dialog generation model (DG-VBKR) based on variational Bayesian knowledge retrieval method, which consists of two modules: knowledge retrieval and dialog generation. During the training process, both a prior knowledge retriever and a posterior knowledge retriever are trained simultaneously, and the prior knowledge retriever is guided by the posterior knowledge retriever. Specifically, the KL Divergence is used to measure the difference between the retrieval results of the two retrievers and make the trained prior knowledge retriever achieve a similar effect to the posterior knowledge retriever. In addition, this paper constructs four versions of the proposed model by using GPT-2, BART, TransformerDecoder, and TransformerEnc−Dec in dialog generation module. The experimental results show that the DG-VBKR model achieves certain improvements on several metrics compared to the baseline models. Among them, the GPT-2 version model with the best performance has improved by 7.0% on the PPL metric compared with the model using only prior knowledge retrieval. This indicates that the DG-VBKR model can effectively select knowledge related to the dialog to generate high-quality responses.'},\n",
       " '10.1016/j.patrec.2023.05.034': {'title': 'Dicer: Dialogue-Centric Representation for Knowledge-Grounded Dialogue through Contrastive Learning',\n",
       "  'abstract': 'Knowledge-grounded dialogue is a task that utilizes external knowledge to generate appropriate and fluent responses to statements. Owing to the relevance of generating responses based on relevant knowledge in diverse fields, the knowledge selection task has been spotlighted. In this study, we propose a novel selection model that applies contrastive-learning with negative sampling loss to create dialogue-centric representation of knowledge. A two-part loss is considered knowledge selection loss and topic prediction loss. The former increases the similarity between content representations of related knowledge and dialogue history, while the latter increases the similarity between their topic representations. The proposed model was evaluated on two well-known datasets,Wizard of Wikipedia and Holl-E, in terms of the knowledge-grounded dialogue task exhibiting remarkable improvement over previously proposed methods on both knowledge selection and response generation tasks.'},\n",
       " '10.1038/s41598-023-29213-8': {'title': 'Knowledge grounded medical dialogue generation using augmented graphs',\n",
       "  'abstract': \"Smart healthcare systems that make use of abundant health data can improve access to healthcare services, reduce medical costs and provide consistently high-quality patient care. Medical dialogue systems that generate medically appropriate and human-like conversations have been developed using various pre-trained language models and a large-scale medical knowledge base based on Unified Medical Language System (UMLS). However, most of the knowledge-grounded dialogue models only use local structure in the observed triples, which suffer from knowledge graph incompleteness and hence cannot incorporate any information from dialogue history while creating entity embeddings. As a result, the performance of such models decreases significantly. To address this problem, we propose a general method to embed the triples in each graph into large-scalable models and thereby generate clinically correct responses based on the conversation history using the recently recently released MedDialog(EN) dataset. Given a set of triples, we first mask the head entities from the triples overlapping with the patient's utterance and then compute the cross-entropy loss against the triples' respective tail entities while predicting the masked entity. This process results in a representation of the medical concepts from a graph capable of learning contextual information from dialogues, which ultimately aids in leading to the gold response. We also fine-tune the proposed Masked Entity Dialogue (MED) model on smaller corpora which contain dialogues focusing only on the Covid-19 disease named as the Covid Dataset. In addition, since UMLS and other existing medical graphs lack data-specific medical information, we re-curate and perform plausible augmentation of knowledge graphs using our newly created Medical Entity Prediction (MEP) model. Empirical results on the MedDialog(EN) and Covid Dataset demonstrate that our proposed model outperforms the state-of-the-art methods in terms of both automatic and human evaluation metrics.\"},\n",
       " '10.1016/j.artint.2023.103874': {'title': 'Search-engine-augmented dialogue response generation with cheaply supervised query production',\n",
       "  'abstract': 'Knowledge-aided dialogue response generation aims at augmenting chatbots with relevant external knowledge in the hope of generating more informative responses. The majority of previous work assumes that the relevant knowledge is given as input or retrieved from a static pool of knowledge. However, this assumption violates the real-world situation, where knowledge is continually updated and a chatbot has to dynamically retrieve useful knowledge. We propose a dialogue model that can access the vast and dynamic information from any search engine for response generation. As the core module, a query producer is used to generate queries from a dialogue context to interact with a search engine. We design a training algorithm using cheap noisy supervision for the query producer, where the signals are obtained by comparing retrieved articles with the next dialogue response. As the result, the query producer is adjusted without any human annotation of gold queries, making it easily transferable to other domains and search engines. Experiments show that our query producer can achieve R@1 and R@5 rates of 62.4% and 74.8% for retrieving gold knowledge, and the overall model generates better responses over strong knowledge-aided baselines using BART and other typical systems.'},\n",
       " '10.1016/j.eswa.2022.118775': {'title': 'Towards personalized persuasive dialogue generation for adversarial task oriented dialogue setting',\n",
       "  'abstract': 'In recent years, task-oriented virtual assistants have gained huge popularity and demand in both research and industry communities. The primary aim of a task-oriented dialogue agent is to assist end-users in accomplishing a task successfully and satisfactorily. Existing virtual agents have acquired proficiency in assisting users in solving simple tasks such as restaurant bookings. However, they operate under the deterministic presumption that end-users will have a servable task objective, which makes them inadequate under adversarial situations such as goal unavailability. On the other hand, human agents accomplish users’ tasks even in many goal unavailability scenarios by persuading them towards a similar goal to the user’s proposed task. Motivated by the limitation, the current work proposes and builds a novel transformer-based context-aware personalized persuasive virtual assistant (CoPersUasive VA), which also serves end-users in task unavailability situations. The proposed CoPersUasive VA recognizes goal conflicts through user sentiment and identifies an appropriate persuasion strategy using ongoing dialogue context and user personality. Depending on users’ proposed goals, it finds a similar servable goal and persuades them with the identified persuasion strategy. The obtained experimental results and detailed post-analysis firmly establish that the proposed model effectively enhances the capability of task-oriented virtual assistants to deal with the task failures caused by goal unavailability. The obtained findings also suggest the crucial role of dialogue context in identifying an appropriate and appealing persuasion strategy. The proposed CoPersUasive model could easily be adapted to any other domain by fine-tuning the model on an underlying task. Furthermore, we developed a personalized persuasive multi-intent conversational dialogue corpus annotated with intent, slot, sentiment, and dialogue act for electronic domain.2'},\n",
       " '10.1016/j.neucom.2022.05.012': {'title': 'Global and local interaction matching model for knowledge-grounded response selection in retrieval-based chatbots',\n",
       "  'abstract': 'Knowledge-grounded response selection, the task of selecting a proper response from a set of response candidates given the conversation context and its background knowledge, is important for building intelligent dialogue systems. Challenges for the task mainly lie in how to interact between the context and the knowledge, and how to match between the response and the context-knowledge pair. Existing work mainly focuses on exploiting global or local interaction matching information, and hence cannot fully utilize the information. In this paper, we propose a global and local interaction matching model (GLIMM) that matches a response with the context-knowledge pair from global and local views. For global interaction matching, GLIMM takes the context and the knowledge as long sequences. For local interaction matching, GLIMM treats each context utterance and knowledge sentence separately. GLIMM integrates information from two different views that could provide complementary information for each other. Experiments on two datasets show that the proposed model outperforms the state-of-the-art baselines.'},\n",
       " '10.1016/j.aiopen.2022.02.001': {'title': 'Learning towards conversational AI: A survey',\n",
       "  'abstract': 'Recent years have witnessed a surge of interest in the field of open-domain dialogue. Thanks to the rapid development of social media, large dialogue corpus from the Internet builds up a fundamental premise for data-driven dialogue model. The breakthrough in neural network also brings new ideas to researchers in AI and NLP. A great number of new techniques and methods therefore came into being. In this paper, we review some of the most representative works in recent years and divide existing prevailing frameworks for a dialogue model into three categories. We further analyze the trend of development for open-domain dialogue and summarize the goal of an open-domain dialogue system in two aspects, informative and controllable. The methods we review in this paper are selected according to our unique perspectives and by no means complete. Rather, we hope this servery could benefit NLP community for future research in open-domain dialogue.'},\n",
       " '10.1016/J.NEUCOM.2021.08.131': {'title': 'Towards information-rich, logical dialogue systems with knowledge-enhanced neural models',\n",
       "  'abstract': 'Dialogue systems have made massive promising progress contributed by deep learning techniques and have been widely applied in our life. However, existing end-to-end neural models suffer from the problem of tending to generate uninformative and generic responses because they cannot ground dialogue context with background knowledge. In order to solve this problem, many researchers begin to consider combining external knowledge in dialogue systems, namely knowledge-enhanced dialogue systems. The challenges of knowledge-enhanced dialogue systems include how to select the appropriate knowledge from large-scale knowledge bases, how to read and understand extracted knowledge, and how to integrate knowledge into responses generation process. Combined with external knowledge, dialogue systems can deeply understand the dialogue context, and generate more informative and logical responses. This survey gives a comprehensive review of knowledge-enhanced dialogue systems, summarizes research progress to solve these challenges and proposes some open issues and research directions.'},\n",
       " '10.1016/J.IPM.2021.102605': {'title': 'Pattern and content controlled response generation',\n",
       "  'abstract': 'Controllable response generation is an attractive and valuable task to the success of conversational systems. However, controlling both pattern and content of the response has not been well studied in existing models since they are mainly based on matching mechanisms. To tackle the problem, we first design a pattern model to automatically learn and extract speech patterns from words. The pattern is then integrated into the encoder–decoder model to control the response pattern. Second, a sentence sampling algorithm is built to directly insert or delete words in the generated response, so that the content is controlled. In this two-stage framework, the response could be explicitly controlled by the pattern and content, without any human annotation of the post-response dataset. Experiments show the proposed framework achieves better performance in response controllability than the state-of-the-art. • We develop a framework that tackles the task of controllable response generation, where diverse patterns and content are considered in the response generation. • A pattern model is devised to automatically analyze the sets of keywords of all the patterns and to capture a pattern distribution for each pattern. • To control content of the response, we employ a sentence sampling algorithm to directly perform local operations (word insertion and deletion) on the response.'},\n",
       " '10.1007/978-3-030-88480-2_36': {'title': 'Knowledge-Grounded Dialogue with Reward-Driven Knowledge Selection',\n",
       "  'abstract': 'Knowledge-grounded dialogue is a task of generating a fluent and informative response based on both conversation context and a collection of external knowledge, in which knowledge selection plays an important role and attracts more and more research interest. However, most existing models either select only one knowledge or use all knowledge for responses generation. The former may lose valuable information in discarded knowledge, while the latter may bring a lot of noise. At the same time, many approaches need to train the knowledge selector with knowledge labels that indicate ground-truth knowledge, but these labels are difficult to obtain and require a large number of manual annotations. Motivated by these issues, we propose Knoformer, a dialogue response generation model based on reinforcement learning, which can automatically select one or more related knowledge from the knowledge pool and does not need knowledge labels during training. Knoformer is evaluated on two knowledge-guided conversation datasets, and achieves state-of-the-art performance.'},\n",
       " '10.1007/s10462-022-10248-8': {'title': 'Recent advances in deep learning based dialogue systems: a systematic survey',\n",
       "  'abstract': 'Dialogue systems are a popular natural language processing (NLP) task as it is promising in real-life applications. It is also a complicated task since many NLP tasks deserving study are involved. As a result, a multitude of novel works on this task are carried out, and most of them are deep learning based due to their outstanding performance. In this survey, we mainly focus on the deep learning based dialogue systems. We comprehensively review state-of-the-art research outcomes in dialogue systems and analyze them from two angles: model type and system type. Specifically, from the angle of model type, we discuss the principles, characteristics, and applications of different models that are widely used in dialogue systems. This will help researchers acquaint these models and see how they are applied in state-of-the-art frameworks, which is rather helpful when designing a new dialogue system. From the angle of system type, we discuss task-oriented and open-domain dialogue systems as two streams of research, providing insight into the hot topics related. Furthermore, we comprehensively review the evaluation methods and datasets for dialogue systems to pave the way for future research. Finally, some possible research trends are identified based on the recent research outcomes. To the best of our knowledge, this survey is the most comprehensive and up-to-date one at present for deep learning based dialogue systems, extensively covering the popular techniques. We speculate that this work is a good starting point for academics who are new to the dialogue systems or those who want to quickly grasp up-to-date techniques in this area.'},\n",
       " '10.1007/978-3-030-77964-1_10': {'title': 'Exemplar Guided Latent Pre-trained Dialogue Generation',\n",
       "  'abstract': 'Pre-trained models with latent variables have been proved to be an effective method in the diverse dialogue generation. However, the latent variables in current models are finite and uninformative, making the generated responses lack diversity and informativeness. In order to address this problem, we propose an exemplar guided latent pre-trained dialogue generation model to sample the latent variables from a continuous sentence embedding space, which can be controlled by the exemplar sentences. The proposed model contains two parts: exemplar seeking and response generation. First, the exemplar seeking builds a sentence graph based on the given dataset and seeks an enlightened exemplar from the graph. Next, the response generation constructs informative latent variables based on the exemplar and generates diverse responses with latent variables. Experiments show that the model can effectively improve the propriety and diversity of responses and achieve state-of-the-art performance.'},\n",
       " '10.1016/j.knosys.2022.108550': {'title': 'Leveraging speaker-aware structure and factual knowledge for faithful dialogue summarization',\n",
       "  'abstract': 'Currently, sequence/graph-to-sequence models for abstractive dialogue summarization are being studied extensively. However, previous methods strive to integrate complex events spanning multiple utterances, and the generated summaries are often filled with incorrect facts. In this study, we first utilize the speaker-aware structure to model the information interaction process in the dialogue, which shows an excellent ability to settle the cross-sentence dependency. Then, we incorporate the factual representations via a dual-copy decoder to obtain summaries conditioned on both the tokens from source sequences and the factual knowledge from our designed fact graph, which enhances the factual consistency for dialogue summarization. We also propose some fact-level factual consistency metrics. Adequate experimental results demonstrate that our model outperforms the state-of-the-art baselines by a significant margin on the SAMSum and DialSumm datasets. A comprehensive analysis also proves the effectiveness of our model. Furthermore, human judges confirm that the outputs of our model contain more informative and faithful information.'},\n",
       " '10.1007/s11263-018-1116-0': {'title': 'Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering',\n",
       "  'abstract': 'The problem of visual question answering (VQA) is of significant importance both as a challenging research question and for the rich set of applications it enables. In this context, however, inherent structure in our world and bias in our language tend to be a simpler signal for learning than visual modalities, resulting in VQA models that ignore visual information, leading to an inflated sense of their capability. We propose to counter these language priors for the task of VQA and make vision (the V in VQA) matter! Specifically, we balance the popular VQA dataset (Antol et al., in: ICCV, 2015) by collecting complementary images such that every question in our balanced dataset is associated with not just a single image, but rather a pair of similar images that result in two different answers to the question. Our dataset is by construction more balanced than the original VQA dataset and has approximately twice the number of image-question pairs. Our complete balanced dataset is publicly available at http://visualqa.org/ as part of the 2nd iteration of the VQA Dataset and Challenge (VQA v2.0). We further benchmark a number of state-of-art VQA models on our balanced dataset. All models perform significantly worse on our balanced dataset, suggesting that these models have indeed learned to exploit language priors. This finding provides the first concrete empirical evidence for what seems to be a qualitative sense among practitioners. We also present interesting insights from analysis of the participant entries in VQA Challenge 2017, organized by us on the proposed VQA v2.0 dataset. The results of the challenge were announced in the 2nd VQA Challenge Workshop at the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017. Finally, our data collection protocol for identifying complementary images enables us to develop a novel interpretable model, which in addition to providing an answer to the given (image, question) pair, also provides a counter-example based explanation. Specifically, it identifies an image that is similar to the original image, but it believes has a different answer to the same question. This can help in building trust for machines among their users.'},\n",
       " '10.1007/978-3-319-46448-0_31': {'title': 'Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding',\n",
       "  'abstract': 'Computer vision has a great potential to help our daily lives by searching for lost keys, watering flowers or reminding us to take a pill. To succeed with such tasks, computer vision methods need to be trained from real and diverse examples of our daily dynamic scenes. While most of such scenes are not particularly exciting, they typically do not appear on YouTube, in movies or TV broadcasts. So how do we collect sufficiently many diverse but boring samples representing our lives? We propose a novel Hollywood in Homes approach to collect such data. Instead of shooting videos in the lab, we ensure diversity by distributing and crowdsourcing the whole process of video creation from script writing to video recording and annotation. Following this procedure we collect a new dataset, Charades, with hundreds of people recording videos in their own homes, acting out casual everyday activities. The dataset is composed of 9,848 annotated videos with an average length of 30 s, showing activities of 267 people from three continents. Each video is annotated by multiple free-text descriptions, action labels, action intervals and classes of interacted objects. In total, Charades provides 27,847 video descriptions, 66,500 temporally localized intervals for 157 action classes and 41,104 labels for 46 object classes. Using this rich data, we evaluate and provide baseline results for several tasks including action recognition and automatic description generation. We believe that the realism, diversity, and casual nature of this dataset will present unique challenges and new opportunities for computer vision community.'},\n",
       " '10.1007/s11263-016-0966-6': {'title': 'VQA: Visual Question Answering',\n",
       "  'abstract': 'We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer. Mirroring real-world scenarios, such as helping the visually impaired, both the questions and answers are open-ended. Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions. Moreover, VQA is amenable to automatic evaluation, since many open-ended answers contain only a few words or a closed set of answers that can be provided in a multiple-choice format. We provide a dataset containing $$\\\\sim $$ 0.25 M images, $$\\\\sim $$ 0.76 M questions, and $$\\\\sim $$ 10 M answers ( www.visualqa.org ), and discuss the information it provides. Numerous baselines and methods for VQA are provided and compared with human performance. Our VQA demo is available on CloudCV ( http://cloudcv.org/vqa ).'},\n",
       " '10.1016/j.ipm.2023.103585': {'title': 'Number-enhanced representation with hierarchical recursive tree decoding for math word problem solving',\n",
       "  'abstract': 'Automatic solving math word problems (MWPs) is a number-intensive application in natural language processing (NLP). However, these existing methods are far from achieving acceptable levels of numeracy learning. As a result, the performance of these models is limited for mathematical reasoning. In addition, the mainstream tree decoder suffers from early-stage information loss, resulting in an unsatisfactory performance for complex problems with more operators. In this paper, we propose NERHRT (Number-Enhanced Representation with Hierarchical Recursive Tree Decoding), a simple yet effective number embedding method that produces the numerical reasoning via the decimal notation-based embedding and a dual-direction graph attention network. In addition, a hierarchical recursive tree-structured decoder is introduced to aggregate information from all ancestor nodes. Experiments show that our approach obtains the best performance on four popular benchmark datasets, and beats the state-of-the-art models with a large margin.'},\n",
       " '10.1016/j.mlwa.2023.100506': {'title': 'Solving math word problems concerning systems of equations with GPT models',\n",
       "  'abstract': 'Researchers have been interested in developing AI tools to help students learn various mathematical subjects. One challenging set of tasks for school students is learning to solve math word problems. We explore how recent advances in natural language processing, specifically the rise of powerful transformer based models, can be applied to help math learners with such problems. Concretely, we evaluate the use of GPT-3, GPT-3.5, and GPT-4, all transformer models with billions of parameters recently released by OpenAI, for three related challenges pertaining to math word problems corresponding to systems of two linear equations. The three challenges are classifying word problems, extracting equations from word problems, and generating word problems. For the first challenge, we define a set of problem classes and find that GPT models generally result in classifying word problems with an overall accuracy around 70%. There is one class that all models struggle about, namely the \"item and property\" class, which significantly lowered the value. For the second challenge, our findings align with researchers\\' expectation: newer models are better at extracting equations from word problems. The highest accuracy we get from fine-tuning GPT-3 with 1000 examples (78%) is surpassed by GPT-4 given only 20 examples (79%). For the third challenge, we again find that GPT-4 outperforms the other two models. It is able to generate problems with accuracy ranging from 76.7% to 100%, depending on the problem type.'},\n",
       " '10.1007/s10489-022-04253-1': {'title': 'Goal selection and feedback for solving math word problems',\n",
       "  'abstract': 'Solving Math Word Problems (MWPs) automatically is a challenging task for AI-tutoring in online education. Most of the existing State-Of-The-Art (SOTA) neural models for solving MWPs use Goal-driven Tree-structured Solver (GTS) as their decoders. However, owing to the defects of the tree-structured recurrent neural networks, GTS can not obtain the information of all generated nodes in each decoding time step. Therefore, the performance for long math expressions is not satisfactory enough. To address such limitations, we propose a Goal Selection and Feedback (GSF) decoding module. In each time step of GSF, we firstly feed the latest result back to all goal vectors through goal feedback operation, and then the goal selection operation based on attention mechanism is designed for generate the new goal vector. Not only can the decoder collect the historical information from all generated nodes through goal selection operation, but also these generated nodes are always updated timely by goal feedback operation. In addition, a Multilayer Fusion Network (MFN) is proposed to provide a better representation of each hidden state during decoding. Combining the ELECTRA language model with our novel decoder, experiments on the Math23k, Ape-clean, and MAWPS datasets show that our model outperforms the SOTA baselines, especially on the MWPs of complex samples with long math expressions. The ablation study and case study further verify that our model can better solve the samples with long expressions, and the proposed components are indeed able to help enhance the performance of the model.'},\n",
       " '10.1007/s11633-022-1351-2': {'title': 'Clause-level Relationship-aware Math Word Problems Solver',\n",
       "  'abstract': 'Automatically solving math word problems, which involves comprehension, cognition, and reasoning, is a crucial issue in artificial intelligence research. Existing math word problem solvers mainly work on word-level relationship extraction and the generation of expression solutions while lacking consideration of the clause-level relationship. To this end, inspired by the theory of two levels of process in comprehension, we propose a novel clause-level relationship-aware math solver (CLRSolver) to mimic the process of human comprehension from lower level to higher level. Specifically, in the lower-level processes, we split problems into clauses according to their natural division and learn their semantics. In the higher-level processes, following human′s multi-view understanding of clause-level relationships, we first apply a CNN-based module to learn the dependency relationships between clauses from word relevance in a local view. Then, we propose two novel relationship-aware mechanisms to learn dependency relationships from the clause semantics in a global view. Next, we enhance the representation of clauses based on the learned clause-level dependency relationships. In expression generation, we develop a tree-based decoder to generate the mathematical expression. We conduct extensive experiments on two datasets, where the results demonstrate the superiority of our framework.'},\n",
       " '10.3758/BF03207654': {'title': 'Understanding and solving arithmetic word problems: A computer simulation',\n",
       "  'abstract': 'In this paper, I describe a computer program, WORDPRO, which simulates the psychological processes involved when third-grade children understand and solve simple arithmetic word problems. Both the implementation of the program and its performance on a set of sample problems are presented. WORDPRO is a useful research tool in that it demonstrates the sufficiency of the theory upon which it is based, assists in communicating that theory to other researchers, and provides a sources of empirical predictions for experimental tests of the theory.'},\n",
       " '10.1016/j.engappai.2024.108451': {'title': 'Embedding-based entity alignment between multi-source temporal knowledge graphs',\n",
       "  'abstract': 'The goal of entity alignment is to identify entities in two multi-source knowledge graphs (KGs) that represent the same real-world object. Recent researches on multi-source entity alignment mainly concentrate on static KGs. In fact, temporal KGs have become valuable resources for numerous artificial intelligence applications, and entity alignment between multi-source temporal KGs is becoming more and more important. Current entity alignment models cannot support temporal tasks and fail to deal with the attributes with low literal similarity that share the same semantics through attribute embedding. Therefore, we propose a RDF (Resource Description Framework)-based model for representing temporal KGs, and an embedding-based entity alignment method for multi-source temporal KGs. This method computes for the similarity of temporal information and generates aligned attribute pairs in the predicate alignment module. We design an interactive module to make matched attributes and the matched entities help to find each other based on aligned attribute pairs. This module can calculate the similarity of attributes with low literal similarity. After getting the structure similarity of the structure embedding module, the final entity alignment result of temporal KGs is produced by the calculation of a binary linear regression function. Experimental results demonstrate that our proposed model outperforms existing approaches significantly.'},\n",
       " '10.1016/j.eij.2023.100414': {'title': 'Knowledge graph completion method based on hyperbolic representation learning and contrastive learning',\n",
       "  'abstract': \"Knowledge graph completion employs existing triples to deduce missing data, thereby enriching and enhancing graph completeness. Recent research has revealed that using hyperbolic representation learning in knowledge graph completion yields superior expressive and generalization capabilities. However, the long-tail problem and the presence of hyperbolic metrics make it challenging to effectively learn low-frequency entities or relations, resulting in embedding space distortion and impacting the original semantic relationships. Therefore, this paper proposes a knowledge graph completion method (Att-CL) that integrates hyperbolic representation learning and contrastive learning. In this approach, knowledge is embedded into a hyperbolic space, and samples with limited hierarchical characteristics and insufficient feature information are enhanced by introducing adversarial noise. The loss function of the embedded samples is backpropagated into embedding vectors, perturbations are adjusted in the gradient direction to promote smoothness and locality, and hyperparameters are introduced for fine-tuning the adversarial strength in the construction of adversarial samples for data augmentation to enhance model robustness. To mitigate data distortion due to hyperbolic metrics, a penalty term is introduced in the contrastive loss function to control the distances of the embedding vectors from the origin, thereby reducing the impact of the metrics and further improving the model's completion ability. Experimental results on the WN18RR and FB15K-237 benchmark datasets demonstrate significant improvements in metrics such as MRR, Hits@1, and Hits@3 compared to traditional knowledge graph completion models, providing ample evidence of the model's effectiveness.\"},\n",
       " '10.1016/j.knosys.2023.110631': {'title': 'Entity alignment for temporal knowledge graphs via adaptive graph networks',\n",
       "  'abstract': 'The temporal entity alignment task aims to discover entities with the same meaning but belonging to different temporal knowledge graphs (KGs). Most existing entity alignment studies mainly focus on static entity alignment, while temporal entity alignment has not received enough attention. However, entity alignment containing temporal information is more in line with real-world application scenarios, and applying static entity alignment models directly to temporal KGs usually does not achieve satisfactory performance because many events (entities) in the knowledge graph will change with time. Therefore, we propose an adaptive graph network (AGN) for entity alignment between temporal KGs. Specifically, we use a time-aware graph attention network model as an encoder to aggregate the features and temporal relationships of neighboring nodes. To adapt to various temporal knowledge graphs, we design a training scheme with adaptive relative error loss minimization, which aims to provide relative positions of entities in vector space for model optimization. Furthermore, we propose an adaptive fine-tuning distance algorithm based on supervised information, which aims to adaptively fine-tune the locations of entities in the vector space for the entity alignment similarity measure. Our proposed AGN model can be naturally extended to entity alignment datasets across multiple temporal knowledge graphs. We evaluate our proposed model via temporal knowledge graphs on public datasets and our newly proposed noisy dataset. We also demonstrate the advantages of the AGN model through extensive experiments, which achieves state-of-the-art performance on the temporal knowledge graph dataset.'},\n",
       " '10.1016/j.knosys.2024.111590': {'title': 'Lorentz equivariant model for knowledge-enhanced hyperbolic collaborative filtering',\n",
       "  'abstract': 'Introducing prior auxiliary information from the knowledge graph (KG) to assist the user–item graph can improve the comprehensive performance of the recommender system. Many recent studies have shown that the ensemble properties of hyperbolic spaces fit the scale-free and hierarchical characteristics exhibited in the above two types of graphs well. Therefore, hyperbolic-based recommender systems have achieved a series of outstanding performances. However, in existing hyperbolic methods, equivariance is not considered. Thus, they cannot generalize symmetric features under given transformations, which seriously limits the capability of the model. Moreover, they cannot balance preserving the heterogeneity and mining the high-order entity information to users across two graphs. To fill these gaps, we propose a rigorous Lorentz group equivariant knowledge-enhanced collaborative filtering (LECF) model. Innovatively, we jointly update the attribute embeddings (containing the high-order entity signals from the KG) and hyperbolic embeddings (the distance between hyperbolic embeddings reveals the recommendation tendency) via the LECF layer with Lorentz Equivariant Transformation. Moreover, we propose Hyperbolic Sparse Attention Mechanism to sample the most informative neighboring nodes. Lorentz equivariance is strictly maintained throughout the entire model, and enforcing equivariance is proven necessary experimentally. Extensive experiments on three real-world datasets demonstrate that the proposed LECF remarkably outperforms state-of-the-art methods.'},\n",
       " '10.1016/j.ins.2023.02.050': {'title': 'HyGGE: Hyperbolic graph attention network for reasoning over knowledge graphs',\n",
       "  'abstract': 'Recently, hyperbolic embedding has successfully demonstrated its superiority over Euclidean analogues in representing hierarchical data. As the scale-free network that usually exhibits rich hierarchical structures, knowledge graphs naturally become a field where hyperbolic embedding shows its talents. Furthermore, hyperbolic embedding is also an expected solution to comprehensively reproduce the semantic features and underlying structures of KGs in the embedding space, which will significantly optimize the interpretability and performance of embedding models. However, most of the several existing hyperbolic studies only individually learn semantic information indicated by triples individually, making the embedding space relatively one-sided and simplified. In addition, many issues that limit reasoning performance are still ignored and unresolved in the context of hyperbolic geometry, like the response to complex relations and relation patterns. Motivated by these concerns, we propose the hyperbolic embedding model for KG reasoning, HyGGE. It is based on an innovative hyperbolic graph attention network. Furthermore, the response to complex relations, which is a well-known problem that constrains reasoning performance is also discussed in HyGGE. On the one hand, the focus on neighborhood structures and relation features makes up for the singularity that the embedding space is completely induced by triples individually, thereby optimizing the expressiveness of the embedding space. On the other hand, they cooperate with the effect of hyperbolic geometry to capture hierarchical features contained in local structures, and thus giving the hyperbolic embedding a fuller play to its advantages. Extensive experiments have validated the effectiveness and advantages of HyGGE.'},\n",
       " '10.1016/j.knosys.2022.109451': {'title': 'Learning knowledge graph embeddings by deep relational roto-reflection',\n",
       "  'abstract': 'Embedding methods map entities and relations to low-dimensional vectors and then use a scoring function to predict missing links for knowledge graph completion. Most of the existing deep embedding methods are primarily based on planner convolution, which generates less expressive feature maps that limit the predictive performance. In this paper, we propose a group convolution and hypernetwork-based neural embedding model named, DeepER for knowledge graph completion. DeepER utilizes rotation and reflection transformations of group convolution to produce more expressive feature maps for entities and relations. Furthermore, it introduces a relation-specific roto-reflection of head entities via hypernetwork architecture to preserve the relation-specific information in the embeddings while keeping the rotation and reflection properties of the relations. In addition, we introduce a multimodal extension of DeepER that includes visual and structured information in the embedding vectors of entities. Experimental results demonstrate that DeepER outperforms 20 existing methods on knowledge graph completion benchmarks, consisting of both structured and multimodal datasets.'},\n",
       " '10.1016/J.AIOPEN.2021.02.002': {'title': 'A comprehensive survey of entity alignment for knowledge graphs',\n",
       "  'abstract': 'Knowledge Graphs (KGs), as a structured human knowledge, manage data in an ease-of-store, recognizable, and understandable way for machines and provide a rich knowledge base for different artificial intelligence applications. However, current multi-source KGs have heterogeneity and complementarity, and it is necessary to fuse heterogeneous knowledge from different data sources or different languages into a unified and consistent KG. Entity alignment aims to find equivalence relations between entities in different knowledge graphs but semantically represent the same real-world object, which is the most fundamental and essential technology in knowledge fusion. This paper investigated almost all the latest knowledge graph representations learning and entity alignment methods and summarized their core technologies and features from different aspects. Our full investigation gives a comprehensive outlook on several promising research directions for future work. We also provide an efficient and efficiency entity alignment toolkit to help researchers quickly start their own entity alignment models.'},\n",
       " '10.1007/978-3-030-90888-1_24': {'title': 'HyperJOIE: Two-View Hyperbolic Knowledge Graph Embedding with Entities and Concepts Jointly',\n",
       "  'abstract': 'Knowledge graphs have two views: an entity graph in the instance view and a concept graph in the ontology view. Recent studies reveal that modeling the two graphs jointly can benefit the understanding to either one. However, the existing work has flaws on both modelling the hierarchical structures in the Euclidean space, and capturing the deep cross-view interaction between an entity and its corresponding concept. In this paper, we propose to explore hyperbolic space for two-view knowledge graph embedding, which provides more effective and efficient embedding learning mechanism, especially for hierarchical structured knowledge. We also propose to capture the deep cross-view interaction between an entity and its corresponding concept through modeling local structure information from intra-view neighbor nodes with hyperbolic attention mechanism. Finally, we propose to maintain the structural correspondence between the concept graph and the entity graph by first encoding two graphs with the same embedding model respectively and then aligning the two graphs with a hyperbolic transformation. Our empirical study conducted on two benchmark data collections proves that our model outperforms several state-of-the-art two-view knowledge graph embedding models.'},\n",
       " '10.1007/978-3-030-30793-6_35': {'title': 'TransEdge: Translating Relation-Contextualized Embeddings for Knowledge Graphs',\n",
       "  'abstract': 'Learning knowledge graph (KG) embeddings has received increasing attention in recent years. Most embedding models in literature interpret relations as linear or bilinear mapping functions to operate on entity embeddings. However, we find that such relation-level modeling cannot capture the diverse relational structures of KGs well. In this paper, we propose a novel edge-centric embedding model TransEdge, which contextualizes relation representations in terms of specific head-tail entity pairs. We refer to such contextualized representations of a relation as edge embeddings and interpret them as translations between entity embeddings. TransEdge achieves promising performance on different prediction tasks. Our experiments on benchmark datasets indicate that it obtains the state-of-the-art results on embedding-based entity alignment. We also show that TransEdge is complementary with conventional entity alignment methods. Moreover, it shows very competitive performance on link prediction.'},\n",
       " '10.1007/978-3-030-49461-2_12': {'title': 'Hyperbolic Knowledge Graph Embeddings for Knowledge Base Completion',\n",
       "  'abstract': 'Learning embeddings of entities and relations existing in knowledge bases allows the discovery of hidden patterns in them. In this work, we examine the contribution of geometrical space to the task of knowledge base completion. We focus on the family of translational models, whose performance has been lagging. We extend these models to the hyperbolic space so as to better reflect the topological properties of knowledge bases. We investigate the type of regularities that our model, dubbed HyperKG, can capture and show that it is a prominent candidate for effectively representing a subset of Datalog rules. We empirically show, using a variety of link prediction datasets, that hyperbolic space allows to narrow down significantly the performance gap between translational and bilinear models and effectively represent certain types of rules.'},\n",
       " '10.1007/978-3-319-68288-4_37': {'title': 'Cross-Lingual Entity Alignment via Joint Attribute-Preserving Embedding',\n",
       "  'abstract': 'Entity alignment is the task of finding entities in two knowledge bases (KBs) that represent the same real-world object. When facing KBs in different natural languages, conventional cross-lingual entity alignment methods rely on machine translation to eliminate the language barriers. These approaches often suffer from the uneven quality of translations between languages. While recent embedding-based techniques encode entities and relationships in KBs and do not need machine translation for cross-lingual entity alignment, a significant number of attributes remain largely unexplored. In this paper, we propose a joint attribute-preserving embedding model for cross-lingual entity alignment. It jointly embeds the structures of two KBs into a unified vector space and further refines it by leveraging attribute correlations in the KBs. Our experimental results on real-world datasets show that this approach significantly outperforms the state-of-the-art embedding approaches for cross-lingual entity alignment and could be complemented with methods based on machine translation.'},\n",
       " '10.1007/978-3-319-93417-4_38': {'title': 'Modeling Relational Data with Graph Convolutional Networks',\n",
       "  'abstract': 'Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to handle the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved through the use of an R-GCN encoder model to accumulate evidence over multiple inference steps in the graph, demonstrating a large improvement of 29.8% on FB15k-237 over a decoder-only baseline.'},\n",
       " '10.1007/978-3-642-41335-3_32': {'title': 'Type Inference on Noisy RDF Data',\n",
       "  'abstract': 'Type information is very valuable in knowledge bases. However, most large open knowledge bases are incomplete with respect to type information, and, at the same time, contain noisy and incorrect data. That makes classic type inference by reasoning difficult. In this paper, we propose the heuristic link-based type inference mechanism SDType, which can handle noisy and incorrect data. Instead of leveraging T-box information from the schema, SDType takes the actual use of a schema into account and thus is also robust to misused schema elements.'},\n",
       " '10.1007/978-3-642-10871-6_23': {'title': 'Overcoming Schema Heterogeneity between Linked Semantic Repositories to Improve Coreference Resolution',\n",
       "  'abstract': 'Schema heterogeneity issues often represent an obstacle for discovering coreference links between individuals in semantic data repositories. In this paper we present an approach, which performs ontology schema matching in order to improve instance coreference resolution performance. A novel feature of the approach is its use of existing instance-level coreference links defined in third-party repositories as background knowledge for schema matching techniques. In our tests of this approach we obtained encouraging results, in particular, a substantial increase in recall in comparison with existing sets of coreference links.'},\n",
       " '10.1080/00029890.1993.11990430': {'title': 'Hyperbolic Geometry on a Hyperboloid',\n",
       "  'abstract': '(1993). Hyperbolic Geometry on a Hyperboloid. The American Mathematical Monthly: Vol. 100, No. 5, pp. 442-455.'},\n",
       " '10.1007/978-1-4471-3987-4': {'title': 'Hyperbolic Geometry',\n",
       "  'abstract': 'The geometry of the hyperbolic plane has been an active and fascinating field of mathematical inquiry for most of the past two centuries. This book provides a self-contained introduction to the subjec'},\n",
       " '10.1016/j.ipm.2024.103668': {'title': 'Dialogue summarization enhanced response generation for multi-domain task-oriented dialogue systems',\n",
       "  'abstract': 'Task-oriented dialogue systems (TOD) are blossoming with the advances in pre-trained language models (PrLM). Recently, research on PrLM-based multi-domain TOD has arisen with many outstanding outcomes. However, three challenges still need to be thoroughly studied. First, most current works regard dialogue state tracking as a generative problem supervised by concatenated slot-value sequences, impairing the models’ domain adaption because of the discrepancy between PrLM’s natural text inputs and spliced slot-value spans. Second, most existing works seldom specifically consider how to deal with long and involved dialogue history caused by multiple task domains. Third, few studies are concerned with enhancing the model’s reasoning ability to handle intricate contexts. To alleviate these issues, we propose a dialogue summarization enhanced response generation framework for multi-domain TOD. Specifically, we offer a novel summarization model that employs the query and the generated summarization from the previous turn to obtain beneficial information for the current turn, which is then combined with the entire dialogue history to produce the final summary. Then, the generated dialogue summarization is fed to the response decoder as dialogue states and key dialogue histories through the designed dynamic fusion mechanism to yield responses. Experimental results indicate that the proposed model for response generation task outperforms the baseline models in both automatic and human evaluations on two public datasets.'},\n",
       " '10.1016/j.knosys.2023.110927': {'title': 'Mutually improved response generation and dialogue summarization for multi-domain task-oriented dialogue systems',\n",
       "  'abstract': 'With the development of pre-trained language models (PrLM), the research of PrLM-based multi-domain task-oriented dialogue systems (TOD) has attracted growing attention and has achieved great progress. However, most current studies suffer from two problems. First, they model dialogue state tracking as an independent subtask supervised by slot-value pairs, resulting in poor adaptability when transferring to new task domains. Second, these studies ignore the fact that not all dialogue histories are valuable for the ensuing turns as they increase in length. To tackle these two issues, we propose a simple and novel framework to explore multi-domain TOD by jointly training response generation and dialogue summarization with PrLM as the backbone. Specifically, first, we use fluent text generated by the dialogue summarization model to replace formatted dialogue states, treating the dialogue state identification task as a natural language generation task, which allows dialogue state tracking to be easily extended to new task domains. Second, dialogue summarization removes redundant and useless information from the current dialogue process and is fed into the response decoder enabling the system to focus on crucial details in long dialogues. Furthermore, we employ a dialogue chunk detector to assist the dialogue summarization model and design a fusion mechanism to dynamically integrate helpful dialogue summarization into the response generation process. Experimental results show that the proposed model achieves state-of-the-art performance in both automatic and human evaluations on two public datasets and demonstrate that the joint framework can benefit both tasks from each other.'},\n",
       " '10.1016/j.knosys.2022.110069': {'title': 'Multi-task learning with graph attention networks for multi-domain task-oriented dialogue systems',\n",
       "  'abstract': 'A task-oriented dialogue system (TOD) is an important application of artificial intelligence. In the past few years, works on multi-domain TODs have attracted increased research attention and have seen much progress. A main challenge of such dialogue systems is finding ways to deal with cross-domain slot sharing and dialogue act temporal planning. However, existing studies seldom consider the models’ reasoning ability over the dialogue history; moreover, existing methods overlook the structure information of the ontology schema, which makes them inadequate for handling multi-domain TODs. In this paper, we present a multi-task learning framework equipped with graph attention networks (GATs) to probe the above two challenges. In the method, we explore a dialogue state GAT consisting of a dialogue context subgraph and an ontology schema subgraph to alleviate the cross-domain slot sharing issue. We further construct a GAT-enhanced memory network using the updated nodes in the ontology subgraph to filter out the irrelevant nodes to acquire the needed dialogue states. For dialogue act temporal planning, a similar GAT and corresponding memory network are proposed to obtain fine-grained dialogue act representation. Moreover, we design an entity detection task to improve the capability of soft gate, which determines whether the generated tokens are from the vocabulary or knowledge base. In the training phase, four training tasks are combined and optimized simultaneously to facilitate the response generation process. The experimental results for automatic and human evaluations show that the proposed model achieves superior results compared to the state-of-the-art models on the MultiWOZ 2.0 and MultiWOZ 2.1 datasets.'},\n",
       " '10.1016/j.knosys.2022.109873': {'title': 'Hard-style Selective Context Utilization for dialogue generation based on what user just said',\n",
       "  'abstract': 'Dialogue is a process of information exchanging, where global background is stable while local focuses are transiting. Thus, at the ongoing dialogue turn, there are both relevant and irrelevant semantics existing in dialogue contexts. How to filter out noises and selectively utilize context can pave the way to successful dialogue generation. Current work on dialogue context utilization either processes contexts as vanilla monologue text ignoring dynamic conversation flows, or depends on weighted strategies to fuse all contexts where irrelevant utterances cannot be filter out even may overwhelm relevant ones. To deal with this, this paper proposes a Hard-style Selective Context Utilization method (HardSCU). We first define and measure the information density of the last utterance (query) of a dialogue, marking it as “strong” or “weak”. For a dialogue with strong query, HardSCU directly inputs the query into a RNN-based or T5-based encoder–decoder framework to generate a response; for a dialogue with weak query, HardSCU conducts a selective context utilization for dialogue generation, where a semantic interaction module introduces relevant semantics of context to enrich the query and the co-reference relations existing in dialogue are extracted to promote the learning process of response decoder. Extensive experiments on two benchmark conversation corpora verify that our HardSCU method can outperform competitive baselines on generating appropriate responses for chit-chat-bots with yielding strong robustness to the variations of dialogue lengths.'},\n",
       " '10.1007/BFb0020217': {'title': 'Kernel principal component analysis',\n",
       "  'abstract': 'A new method for performing a nonlinear form of Principal Component Analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in highdimensional feature spaces, related to input space by some nonlinear map; for instance the space of all possible d-pixel products in images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.'},\n",
       " '10.1016/j.ipm.2023.103297': {'title': 'Joint reasoning with knowledge subgraphs for Multiple Choice Question Answering',\n",
       "  'abstract': 'Humans are able to reason from multiple sources to arrive at the correct answer. In the context of Multiple Choice Question Answering (MCQA), knowledge graphs can provide subgraphs based on different combinations of questions and answers, mimicking the way humans find answers. However, current research mainly focuses on independent reasoning on a single graph for each question–answer pair, lacking the ability for joint reasoning among all answer candidates. In this paper, we propose a novel method KMSQA, which leverages multiple subgraphs from the large knowledge graph ConceptNet to model the comprehensive reasoning process. We further encode the knowledge graphs with shared Graph Neural Networks (GNNs) and perform joint reasoning across multiple subgraphs. We evaluate our model on two common datasets: CommonsenseQA (CSQA) and OpenBookQA (OBQA). Our method achieves an exact match score of 74.53% on CSQA and 71.80% on OBQA, outperforming all eight baselines.'},\n",
       " '10.1016/j.dib.2023.109535': {'title': 'A data package for abstractive opinion summarization, title generation, and rating-based sentiment prediction for airline reviews',\n",
       "  'abstract': \"Customer reviews are valuable resources containing customer opinions and sentiments toward the product. The reviews are informative but can be quite lengthy or may contain repetitive information calling for opinion summarization systems that retain only the significant opinion information from the review. Abstractive summarization is a form of text summarization that generates a summary mimicking a human-written summary [1]. When pretrained language models are finetuned for abstractive review summarization, there usually occurs a problem known as the 'domain shift', because the source and target domains exhibit data from varying distributions [2]. This issue results in performance degradation of the model at the target end. This paper contributes a data package comprising of an annotated abstractive summarization dataset (annotated_abs_summ) of airline reviews having 500 reviews and abstractive summary pairs, a dataset (review_titles_data) consisting of 7079 reviews and review title pairs for review title generatioon or domain adaptive training [3] to address the domain shift problem for abstractive opinion summarization and, an annotated reviews dataset (annotated_sentiment) for rating-based sentiment classification. All datasets have been collected from the Skytrax Review Portal via web scraping using Python programming language. The datasets have several potential use cases. The abstractive summarization dataset can serve as a benchmark dataset for airline review summarization. The dataset for domain adaptive training can be used as a standalone dataset for review title generation. The dataset for sentiment analysis is multipurpose having columns like user rating and recommendation value, that can be used for statistical analysis like finding correlation between these data items as well as for other Natural Language Processing (NLP) tasks like predicting rating or recommendation value from the customer reviews. The datasets can be extended using various data augmentation techniques [4,5]. Moreover, the datasets are related and can be collectively used to develop a multi-task learning model [6] for better learning efficiency and improved performance.\"},\n",
       " '10.1016/j.ipm.2022.103138': {'title': 'AsU-OSum: Aspect-augmented unsupervised opinion summarization',\n",
       "  'abstract': 'Opinion summarization can facilitate user’s decision-making by mining the salient review information. However, due to the lack of sufficient annotated data, most of the early works are based on extractive methods, which restricts the performance of opinion summarization. In this work, we aim to improve the informativeness of opinion summarization to provide better guidance to users. We consider the setting with only reviews without corresponding summaries, and propose an aspect-augmented model for unsupervised abstractive opinion summarization, denoted as AsU-OSum. We first employ an aspect-based sentiment analysis system to extract opinion phrases from reviews. Then, we construct a heterogeneous graph consisting of reviews and opinion clusters as nodes, which is used to enhance the Transformer-based encoder–decoder framework. Furthermore, we design a novel cascaded attention mechanism to prompt the decoder to pay more attention to the aspects that are more likely to appear in summary. During training, we introduce a sentiment accuracy reward that further enhances the learning ability of our model. We conduct comprehensive experiments on the Yelp , Amazon , and Rotten Tomatoes datasets. Automatic evaluation results show that our model is competitive and performs better than the state-of-the-art (SOTA) models on some ROUGE metrics. Human evaluation results further verify that our model can generate more informative summaries and reduce redundancy.'},\n",
       " '10.1016/j.jjimei.2024.100238': {'title': 'Airline reviews processing: Abstractive summarization and rating-based sentiment classification using deep transfer learning',\n",
       "  'abstract': 'Opinion summarization and sentiment classification are key processes for understanding, analyzing, and leveraging information from customer opinions. The rapid and ceaseless increase in big data of reviews on e-commerce platforms, social media, or review portals becomes a stimulus for the automation of these processes. In recent years, deep transfer learning has opted to solve many challenging tasks in Natural Language Processing (NLP) relieving the hassles of exhaustive training and the requirement of extensive labelled datasets. In this work, we propose frameworks for Abstractive Summarization (ABS) and Sentiment Analysis (SA) of airline reviews using Pretrained Language Models (PLM). The abstractive summarization model goes through two finetuning stages, the first one, for domain adaptation and the second one, for final task learning. Several studies in the literature empirically demonstrate that review rating has a positive correlation with sentiment valence. For the sentiment classification framework, we used the rating value as a signal to determine the review sentiment, and the model is built on top of BERT (Bidirectional Encoder Representations from Transformers) architecture. We evaluated our models comprehensively with multiple metrics. Our results indicate competitive performance of the models in terms of most of the evaluation metrics.'},\n",
       " '10.1016/J.ASEJ.2014.04.011': {'title': 'Sentiment analysis algorithms and applications: A survey',\n",
       "  'abstract': \"Sentiment Analysis (SA) is an ongoing field of research in text mining field. SA is the computational treatment of opinions, sentiments and subjectivity of text. This survey paper tackles a comprehensive overview of the last update in this field. Many recently proposed algorithms' enhancements and various SA applications are investigated and presented briefly in this survey. These articles are categorized according to their contributions in the various SA techniques. The related fields to SA (transfer learning, emotion detection, and building resources) that attracted researchers recently are discussed. The main target of this survey is to give nearly full image of SA techniques and the related fields with brief details. The main contributions of this paper include the sophisticated categorizations of a large number of recent articles and the illustration of the recent trend of research in the sentiment analysis and its related areas.\"},\n",
       " '10.1007/s10579-023-09709-5': {'title': 'Introducing the 3MT_French dataset to investigate the timing of public speaking judgements',\n",
       "  'abstract': 'Abstract In most public speaking datasets, judgements are given after watching the entire performance, or on thin slices randomly selected from the presentations, without focusing on the temporal location of these slices. This does not allow to investigate how people’s judgements develop over time during presentations. This contrasts with primacy and recency theories, which suggest that some moments of the speech could be more salient than others and contribute disproportionately to the perception of the speaker’s performance. To provide novel insights on this phenomenon, we present the 3MT_French dataset. It contains a set of public speaking annotations collected on a crowd-sourcing platform through a novel annotation scheme and protocol. Global evaluation, persuasiveness, perceived self-confidence of the speaker and audience engagement were annotated on different time windows (i.e., the beginning, middle or end of the presentation, or the full video). This new resource will be useful to researchers working on public speaking assessment and training. It will allow to fine-tune the analysis of presentations under a novel perspective relying on socio-cognitive theories rarely studied before in this context, such as first impressions and primacy and recency theories. An exploratory correlation analysis on the annotations provided in the dataset suggests that the early moments of a presentation have a stronger impact on the judgements.'},\n",
       " '10.1016/j.cognition.2006.10.010': {'title': 'It’s the way that you, er, say it: Hesitations in speech affect language comprehension',\n",
       "  'abstract': 'Everyday speech is littered with disfluency, often correlated with the production of less predictable words (e.g., Beattie & Butterworth [Beattie, G., & Butterworth, B. (1979). Contextual probability and word frequency as determinants of pauses in spontaneous speech. Language and Speech, 22, 201–211.]). But what are the effects of disfluency on listeners? In an ERP experiment which compared fluent to disfluent utterances, we established an N400 effect for unpredictable compared to predictable words. This effect, reflecting the difference in ease of integrating words into their contexts, was reduced in cases where the target words were preceded by a hesitation marked by the word er. Moreover, a subsequent recognition memory test showed that words preceded by disfluency were more likely to be remembered. The study demonstrates that hesitation affects the way in which listeners process spoken language, and that these changes are associated with longer-term consequences for the representation of the message.'},\n",
       " '10.1016/S0010-0277(02)00017-3': {'title': 'Using uh and um in spontaneous speaking',\n",
       "  'abstract': 'The proposal examined here is that speakers use uh and um to announce that they are initiating what they expect to be a minor (uh), or major (um), delay in speaking. Speakers can use these announcements in turn to implicate, for example, that they are searching for a word, are deciding what to say next, want to keep the floor, or want to cede the floor. Evidence for the proposal comes from several large corpora of spontaneous speech. The evidence shows that speakers monitor their speech plans for upcoming delays worthy of comment. When they discover such a delay, they formulate where and how to suspend speaking, which item to produce (uh or um), whether to attach it as a clitic onto the previous word (as in \"and-uh\"), and whether to prolong it. The argument is that uh and um are conventional English words, and speakers plan for, formulate, and produce them just as they would any word.'},\n",
       " '10.1142/S1793351X16500045': {'title': 'Deep Learning',\n",
       "  'abstract': 'Deep learning is a branch of machine learning that tries to model high-level abstractions of data using multiple layers of neurons consisting of complex structures or non-liner transformations. With the increase of the amount of data and the power of computation, neural networks with more complex structures have attracted widespread attention and been applied to various fields. This paper provides an overview of deep learning in neural networks including popular architecture models and training algorithms.'},\n",
       " '10.1145/3616855.3635777': {'title': 'TTC-QuAli: A Text-Table-Chart Dataset for Multimodal Quantity Alignment',\n",
       "  'abstract': 'In modern documents, numerical information is often presented using multimodal formats such as text, tables, and charts. However, the heterogeneity of these sources poses a challenge for machines attempting to jointly read and understand the numerical semantics conveyed through text, tables, and charts. In this paper, we introduce a multimodal dataset called Text-Table-Chart Quantity Alignment (TTC-QuAli). This dataset is designed to facilitate a new task that involves linking related quantities across text, tables, and charts. TTC-QuAli is a comprehensive dataset that contains 4,498 quantities in text, aligned with 1,086 chart images and 1,503 tables from real-world statistical reports. It is the first dataset to provide high-quality annotations for linking quantities across multiple modalities, and it includes challenging composite (aggregated/calculated) quantity linking. To address the challenge of bridging representation gaps between different modalities and capturing their shared contextual semantic meaning, we introduce ConTTC, a novel transformer-based cross-modal contrastive learning architecture. This is the first architecture to jointly model text, tables, and charts, and contrastive learning is employed for multimodal quantity linking towards unified representation learning. Our experiments demonstrate that TTC-QuAli presents a significant challenge for existing baselines and serves as a valuable benchmark for future research. Experiment results show that ConTTC significantly outperforms all baseline methods.'},\n",
       " '10.1007/978-3-031-20059-5_27': {'title': 'Classification-Regression for Chart Comprehension',\n",
       "  'abstract': 'Chart question answering (CQA) is a task used for assessing chart comprehension, which is fundamentally different from understanding natural images. CQA requires analyzing the relationships between the textual and the visual components of a chart, in order to answer general questions or infer numerical values. Most existing CQA datasets and models are based on simplifying assumptions that often enable surpassing human performance. In this work, we address this outcome and propose a new model that jointly learns classification and regression. Our language-vision setup uses co-attention transformers to capture the complex real-world interactions between the question and the textual elements. We validate our design with extensive experiments on the realistic PlotQA dataset, outperforming previous approaches by a large margin, while showing competitive performance on FigureQA. Our model is particularly well suited for realistic questions with out-of-vocabulary answers that require regression.'},\n",
       " '10.1007/978-3-030-58577-8_8': {'title': 'Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks',\n",
       "  'abstract': 'Large-scale pre-training methods of learning cross-modal representations on image-text pairs are becoming popular for vision-language tasks. While existing methods simply concatenate image region features and text features as input to the model to be pre-trained and use self-attention to learn image-text semantic alignments in a brute force manner, in this paper, we propose a new learning method Oscar (Object-Semantics Aligned Pre-training), which uses object tags detected in images as anchor points to significantly ease the learning of alignments. Our method is motivated by the observation that the salient objects in an image can be accurately detected, and are often mentioned in the paired text. We pre-train an Oscar model on the public corpus of 6.5 million text-image pairs, and fine-tune it on downstream tasks, creating new state-of-the-arts on six well-established vision-language understanding and generation tasks (The code and pre-trained models are released: https://github.com/microsoft/Oscar).'},\n",
       " '10.1007/978-3-319-71249-9_9': {'title': 'Scatteract: Automated Extraction of Data from Scatter Plots',\n",
       "  'abstract': 'Charts are an excellent way to convey patterns and trends in data, but they do not facilitate further modeling of the data or close inspection of individual data points. We present a fully automated system for extracting the numerical values of data points from images of scatter plots. We use deep learning techniques to identify the key components of the chart, and optical character recognition together with robust regression to map from pixels to the coordinate system of the chart. We focus on scatter plots with linear scales, which already have several interesting challenges. Previous work has done fully automatic extraction for other types of charts, but to our knowledge this is the first approach that is fully automatic for scatter plots. Our method performs well, achieving successful data extraction on 89% of the plots in our test set.'},\n",
       " '10.1007/s11263-016-0981-7': {'title': 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations',\n",
       "  'abstract': 'Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in an image. When asked “What vehicle is the person riding?”, computers will need to identify the objects in an image as well as the relationships riding(man, carriage) and pulling(horse, carriage) to answer correctly that “the person is riding a horse-drawn carriage.” In this paper, we present the Visual Genome dataset to enable the modeling of such relationships. We collect dense annotations of objects, attributes, and relationships within each image to learn these models. Specifically, our dataset contains over 108K images where each image has an average of $$35$$ objects, $$26$$ attributes, and $$21$$ pairwise relationships between objects. We canonicalize the objects, attributes, relationships, and noun phrases in region descriptions and questions answer pairs to WordNet synsets. Together, these annotations represent the densest and largest dataset of image descriptions, objects, attributes, relationships, and question answer pairs.'},\n",
       " '10.1007/978-3-030-45442-5_21': {'title': 'ANTIQUE: A Non-factoid Question Answering Benchmark',\n",
       "  'abstract': 'Considering the widespread use of mobile and voice search, answer passage retrieval for non-factoid questions plays a critical role in modern information retrieval systems. Despite the importance of the task, the community still feels the significant lack of large-scale non-factoid question answering collections with real questions and comprehensive relevance judgments. In this paper, we develop and release a collection of 2,626 open-domain non-factoid questions from a diverse set of categories. The dataset, called ANTIQUE, contains 34k manual relevance annotations. The questions were asked by real users in a community question answering service, i.e., Yahoo! Answers. Relevance judgments for all the answers to each question were collected through crowdsourcing. To facilitate further research, we also include a brief analysis of the data as well as baseline results on both classical and neural IR models.'},\n",
       " '10.1016/j.knosys.2024.111762': {'title': 'Uncertainty-Aware Contrastive Learning for semi-supervised named entity recognition',\n",
       "  'abstract': 'Named entity recognition (NER) based on deep neural networks has shown competitive performance when trained on large-scale human-annotated data. However, they face challenges in low-resource settings, where the available labeled data are scarce. A typical solution is pseudo-labeling which assigns pseudo-labels to the certain (i.e., high confidence) tokens of unlabeled sentences while discards the uncertain (i.e., low confidence) ones. But there still have two potential challenges: (1) discarding the uncertain tokens leads to low utilization of unlabeled data; (2) the intrinsic quality-quantity trade-off issue of pseudo-labeling with confidence threshold. In this work, we propose an innovative method named Uncertainty-Aware Contrastive Learning (UACL) for semi-supervised named entity recognition. Specifically, UACL first utilizes a Gaussian-based class-wise token separation mechanism to dynamically distinguish certain and uncertain tokens, which can self-adaptively adjust the confidence threshold to balance the quantity and quality of pseudo-labeled certain tokens. Then we perform pseudo-supervised learning based on certain tokens and contrastive learning based on uncertain ones, which not only improves the utilization of unlabeled data, but also provides uncertainty-aware guidance information for model training. Furthermore, our method leverages uncertain tokens to optimize token representation, leading to improving performance. The extensive experimental results on four benchmarks demonstrate that the performance of our proposed approach surpasses that of previously leading low-resource baselines.'},\n",
       " '10.1016/j.infsof.2022.107021': {'title': 'Using clarification questions to improve software developers’ Web search',\n",
       "  'abstract': 'Recent research indicates that Web queries written by software developers are not very successful in retrieving relevant results, performing measurably worse compared to general purpose Web queries. Most approaches up to this point have addressed this problem with software engineering-specific automated query reformulation techniques, which work without developer involvement but are limited by the content of the original query. In other words, these techniques automatically improve the existing query but cannot contribute new, previously unmentioned, concepts. In this paper, we propose a technique to guide software developers in manually improving their own Web search queries. We examine a conversational approach that follows unsuccessful queries with a clarification question aimed at eliciting additional query terms, thus providing to the developer a clear dimension along which the query could be improved. We describe a set of clarification questions derived from a corpus of software developer queries and a neural approach to recommending them for a newly issued query. Our evaluation indicates that the recommendation technique is accurate, predicting a valid clarification question 80% of the time and outperforms simple baselines, as well as, state-of-the-art Learning To Rank (LTR) baselines. As shown in the experimental results, the described approach is capable at recommending appropriate clarification questions to software developers and considered useful by a sample of developers ranging from novices to experienced professionals.'},\n",
       " '10.1016/j.aiopen.2022.03.001': {'title': 'Data augmentation approaches in natural language processing: A survey',\n",
       "  'abstract': 'As an effective strategy, data augmentation (DA) alleviates data scarcity scenarios where deep learning techniques may fail. It is widely applied in computer vision then introduced to natural language processing and achieves improvements in many tasks. One of the main focuses of the DA methods is to improve the diversity of training data, thereby helping the model to better generalize to unseen testing data. In this survey, we frame DA methods into three categories based on the diversity of augmented data, including paraphrasing, noising, and sampling. Our paper sets out to analyze DA methods in detail according to the above categories. Further, we also introduce their applications in NLP tasks as well as the challenges. Some helpful resources are provided in the appendix.'},\n",
       " '10.1016/j.ipm.2024.103657': {'title': 'CoTea: Collaborative teaching for low-resource named entity recognition with a divide-and-conquer strategy',\n",
       "  'abstract': 'Low-resource named entity recognition (NER) aims to identify entity mentions when training data is scarce. Recent approaches resort to distant data with manual dictionaries for improvement, but such dictionaries are not always available for the target domain and have limited coverage of entities, which may introduce noise. In this paper, we propose a novel Collaborative Teaching (CoTea) framework for low-resource NER with a few supporting labeled examples, which can automatically augment training data and reduce label noise. Specifically, CoTea utilizes the entities in the supporting labeled examples to retrieve entity-related unlabeled data heuristically and then generates accurate distant labels with a novel mining-refining iterative mechanism. For optimizing distant labels, the mechanism mines potential entities from non-entity tokens with a recognition teacher and then refines entity labels with another prompt-based discrimination teacher in a divide-and-conquer manner. Experimental results on two benchmark datasets demonstrate that CoTea outperforms state-of-the-art baselines in low-resource settings and achieves 85% and 65% performance levels of the best high-resource baseline methods by merely utilizing about 2% of labeled data.'},\n",
       " '10.4236/jcc.2023.1112003': {'title': 'A Knowledge-Integrate Cross-Domain Data Generation Method for Aspect and Opinion Co-Extraction',\n",
       "  'abstract': 'To address the difficulty of training high-quality models in some specific domains due to the lack of fine-grained annotation resources, we propose in this paper a knowledge-integrated cross-domain data generation method for unsupervised domain adaptation tasks. Specifically, we extract domain features, lexical and syntactic knowledge from source-domain and target-domain data, and use a masking model with an extended masking strategy and a re-masking strategy to obtain domain-specific data that remove domain-specific features. Finally, we improve the sequence generation model BART and use it to generate high-quality target domain data for the task of aspect and opinion co-extraction from the target domain. Experiments were performed on three conventional English datasets from different domains, and our method generates more accurate and diverse target domain data with the best results compared to previous methods.'},\n",
       " '10.1016/j.eswa.2024.123742': {'title': 'MGCoT: Multi-Grained Contextual Transformer for table-based text generation',\n",
       "  'abstract': 'Recent advances in Transformer have led to the revolution of table-based text generation. However, most existing Transformer-based architectures ignore the rich contexts among input tokens distributed in multi-level units (e.g., cell, row, or column), leading to sometimes unfaithful text generation that fails to establish accurate association relationships and misses vital information. In this paper, we propose Multi-Grained Contextual Transformer (MGCoT), a novel architecture that fully capitalizes on the multi-grained contexts among input tokens and thus strengthens the capacity of table-based text generation. The key primitive, Multi-Grained Contexts (MGCo) module, involves two components: a local context sub-module that adaptively gathers neighboring tokens to form the token-wise local context features, and a global context sub-module that consistently aggregates tokens from a broader range to form the shared global context feature. The former aims at modeling the short-range dependencies that reflect the salience of tokens within similar fine-grained unit (e.g., cell and row) attending to the query token, while the latter aims at capturing the long-range dependencies that reflect the significance of each token within similar coarse-grained unit (e.g., multiple rows or columns). Based on the fused multi-grained contexts, MGCoT can flexibly and holistically model the content of a table across multi-level structures. On three benchmark datasets, ToTTo, FeTaQA, and Tablesum, MGCoT outperforms strong baselines by a large margin on the quality of the generated texts, demonstrating the effectiveness of multi-grained context modeling. Our source codes are available at https://anonymous.4open.science/r/MGCoT-3BED.'},\n",
       " '10.1016/j.csl.2023.101482': {'title': 'Evaluating factual accuracy in complex data-to-text',\n",
       "  'abstract': 'It is essential that data-to-text Natural Language Generation (NLG) systems produce texts which are factually accurate. We examine accuracy issues in the task of generating summaries of basketball games, including what accuracy means in this context, how accuracy errors can be detected by human annotators, as well as the types of accuracy mistakes made by both neural NLG systems and human authors. We also look at the effectiveness of automatic metrics in measuring factual accuracy.'},\n",
       " '10.1016/j.ipm.2022.103048': {'title': 'Hierarchical template transformer for fine-grained sentiment controllable generation',\n",
       "  'abstract': 'Existing methods for text generation usually fed the overall sentiment polarity of a product as an input into the seq2seq model to generate a relatively fluent review. However, these methods cannot express more fine-grained sentiment polarity. Although some studies attempt to generate aspect-level sentiment controllable reviews, the personalized attribute of reviews would be ignored. In this paper, a hierarchical template-transformer model is proposed for personalized fine-grained sentiment controllable generation, which aims to generate aspect-level sentiment controllable reviews with personalized information. The hierarchical structure can effectively learn sentiment information and lexical information separately. The template transformer uses a part of speech (POS) template to guide the generation process and generate a smoother review. To verify our model, we used the existing model to obtain a corpus named FSCG-80 from Yelp, which contains 800K samples and conducted a series of experiments on this corpus. Experimental results show that our model can achieve up to 89.93% aspect-sentiment control accuracy and generate more fluent reviews.'},\n",
       " '10.1007/s10618-021-00801-4': {'title': 'Controlling hallucinations at word level in data-to-text generation',\n",
       "  'abstract': 'Abstract Data-to-Text Generation (DTG) is a subfield of Natural Language Generation aiming at transcribing structured data in natural language descriptions. The field has been recently boosted by the use of neural-based generators which exhibit on one side great syntactic skills without the need of hand-crafted pipelines; on the other side, the quality of the generated text reflects the quality of the training data, which in realistic settings only offer imperfectly aligned structure-text pairs. Consequently, state-of-art neural models include misleading statements –usually called hallucinations—in their outputs. The control of this phenomenon is today a major challenge for DTG, and is the problem addressed in the paper. Previous work deal with this issue at the instance level: using an alignment score for each table-reference pair. In contrast, we propose a finer-grained approach, arguing that hallucinations should rather be treated at the word level. Specifically, we propose a Multi-Branch Decoder which is able to leverage word-level labels to learn the relevant parts of each training instance. These labels are obtained following a simple and efficient scoring procedure based on co-occurrence analysis and dependency parsing. Extensive evaluations, via automated metrics and human judgment on the standard WikiBio benchmark, show the accuracy of our alignment labels and the effectiveness of the proposed Multi-Branch Decoder. Our model is able to reduce and control hallucinations, while keeping fluency and coherence in generated texts. Further experiments on a degraded version of ToTTo show that our model could be successfully used on very noisy settings.'},\n",
       " '10.1007/978-3-319-58347-1_10': {'title': 'Domain-Adversarial Training of Neural Networks',\n",
       "  'abstract': 'We introduce aRe-identification representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transferDomain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behavior can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new Gradient Reversal Layer. The resulting augmented architecture can be trained using standard backpropagation, and can thus be implemented with little effort using any of the deep learning packages. We demonstrate the success of our approach for image classification, where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.'},\n",
       " '10.1007/s10791-008-9066-8': {'title': 'A comparison of extrinsic clustering evaluation metrics based on formal constraints',\n",
       "  'abstract': 'There is a wide set of evaluation metrics available to compare the quality of text clustering algorithms. In this article, we define a few intuitive formal constraints on such metrics which shed light on which aspects of the quality of a clustering are captured by different metric families. These formal constraints are validated in an experiment involving human assessments, and compared with other constraints proposed in the literature. Our analysis of a wide range of metrics shows that only BCubed satisfies all formal constraints. We also extend the analysis to the problem of overlapping clustering, where items can simultaneously belong to more than one cluster. As Bcubed cannot be directly applied to this task, we propose a modified version of Bcubed that avoids the problems found with other metrics.'},\n",
       " '10.1002/9781119487142.ch8': {'title': 'Speech to Text',\n",
       "  'abstract': \"Researchers have noted that audio files can be preprocessed into an unstructured data stream that can then be used in much the same way as a regular text corpus for analytic processing. To illustrate the speech-to-text-to-analytics process, this chapter presents a case study that processes consumer audio feedback. Apart from the categorical predictions made on the audio content that develops a rough persona of the feedback providers' demographics, further analysis can be made on the audio content. The audio feedback is converted to text, several text analytics models can be implemented and executed on the textual content. Since the audio data is consumer feedback, the chapter provides information on extracting the associated sentiment of the feedback and try to extract the latent topic of the discussion for the feedback received.\"},\n",
       " '10.1016/j.asoc.2015.01.070': {'title': 'A framework for multi-document abstractive summarization based on semantic role labelling',\n",
       "  'abstract': 'We propose a framework for abstractive summarization of multi-documents, which aims to select contents of summary not from the source document sentences but from the semantic representation of the source documents. In this framework, contents of the source documents are represented by predicate argument structures by employing semantic role labeling. Content selection for summary is made by ranking the predicate argument structures based on optimized features, and using language generation for generating sentences from predicate argument structures. Our proposed framework differs from other abstractive summarization approaches in a few aspects. First, it employs semantic role labeling for semantic representation of text. Secondly, it analyzes the source text semantically by utilizing semantic similarity measure in order to cluster semantically similar predicate argument structures across the text; and finally it ranks the predicate argument structures based on features weighted by genetic algorithm (GA). Experiment of this study is carried out using DUC-2002, a standard corpus for text summarization. Results indicate that the proposed approach performs better than other summarization systems.'},\n",
       " '10.1007/s40747-023-01064-w': {'title': 'A bilateral context and filtering strategy-based approach to Chinese entity synonym set expansion',\n",
       "  'abstract': 'Abstract Entity synonyms play a significant role in entity-based tasks. Previous approaches use linguistic syntax, distributional, and semantic features to expand entity synonym sets from text corpora. Due to the flexibility and complexity of the Chinese language expression, the aforementioned approaches are still difficult to expand entity synonym sets robustly from Chinese text, because these approaches fail to track holistic semantics among entities and suffer from error propagation. This paper introduces an approach for expanding Chinese entity synonym sets based on bilateral context and filtering strategy. Specifically, the approach consists of two novel components. First, a bilateral-context-based Siamese network classifier is proposed to determine whether a new entity should be inserted into the existing entity synonym set. The classifier tracks the holistic semantics of bilateral contexts and is capable of imposing soft holistic semantic constraints to improve synonym prediction. Second, a filtering-strategy-based set expansion algorithm is presented to generate Chinese entity synonym sets. The filtering strategy enhances semantic and domain consistencies to filter out wrong synonym entities, thereby mitigating error propagation. Experimental results on two Chinese real-world datasets demonstrate that the proposed approach is effective and outperforms the selected existing state-of-the-art approaches to the Chinese entity synonym set expansion task.'},\n",
       " '10.1016/j.eswa.2023.119966': {'title': 'Synonym recognition from short texts: A self-supervised learning approach',\n",
       "  'abstract': 'Synonyms refer to different expressions for the same entity in the text and affect entity-centric text mining research performance. Therefore, synonym recognition has become a promising research topic in recent years. However, most existing approaches are based on structured, semi-structured, or long text, and only a few studies have tackled synonym recognition in short texts on social networks. Synonyms recognition in short texts confronts several research challenges. First, there are a large number of unlabeled synonyms in the short texts. Second, many new words will appear in short text on social networks. Therefore, in this paper, we propose a self-supervised learning method to recognize synonyms in short texts, which consists of two steps. First, we use a clustering algorithm to generate a pseudo-label for expression. Second, we input the co-occurrence information and the character information of the expressions into a deep-learning model to obtain the feature representation of the expression. The two steps are executed iteratively until the algorithm converges. To demonstrate the effectiveness of the proposed method, we conducted extensive experiments on a real short-text dataset, and the results suggest the effectiveness of our proposal.'},\n",
       " '10.1007/978-3-030-67664-3_37': {'title': 'FUSE: Multi-faceted Set Expansion by Coherent Clustering of Skip-Grams',\n",
       "  'abstract': 'Set expansion aims to expand a small set of seed entities into a complete set of relevant entities. Most existing approaches assume the input seed set is unambiguous and completely ignore the multi-faceted semantics of seed entities. As a result, given the seed set {\"Canon\", \"Sony\", \"Nikon\"}, previous models return one mixed set of entities that are either Camera Brands or Japanese Companies. In this paper, we study the task of multi-faceted set expansion, which aims to capture all semantic facets in the seed set and return multiple sets of entities, one for each semantic facet. We propose an unsupervised framework, FUSE, which consists of three major components: (1) facet discovery module: identifies all semantic facets of each seed entity by extracting and clustering its skip-grams, and (2) facet fusion module: discovers shared semantic facets of the entire seed set by an optimization formulation, and (3) entity expansion module: expands each semantic facet by utilizing a masked language model with pre-trained BERT models. Extensive experiments demonstrate that FUSE can accurately identify multiple semantic facets of the seed set and generate quality entities for each facet.'},\n",
       " '10.1007/978-3-319-71249-9_18': {'title': 'SetExpan: Corpus-Based Set Expansion via Context Feature Selection and Rank Ensemble',\n",
       "  'abstract': 'Corpus-based set expansion (i.e., finding the “complete” set of entities belonging to the same semantic class, based on a given corpus and a tiny set of seeds) is a critical task in knowledge discovery. It may facilitate numerous downstream applications, such as information extraction, taxonomy induction, question answering, and web search. To discover new entities in an expanded set, previous approaches either make one-time entity ranking based on distributional similarity, or resort to iterative pattern-based bootstrapping. The core challenge for these methods is how to deal with noisy context features derived from free-text corpora, which may lead to entity intrusion and semantic drifting. In this study, we propose a novel framework, SetExpan, which tackles this problem, with two techniques: (1) a context feature selection method that selects clean context features for calculating entity-entity distributional similarity, and (2) a ranking-based unsupervised ensemble method for expanding entity set based on denoised context features. Experiments on three datasets show that SetExpan is robust and outperforms previous state-of-the-art methods in terms of mean average precision. Code related to this chapter is available at: https://github.com/mickeystroller/SetExpan Data related to this chapter are available at: https://goo.gl/1suS3Z'},\n",
       " '10.1007/978-3-319-73013-4_9': {'title': 'Fighting with the Sparsity of Synonymy Dictionaries for Automatic Synset Induction',\n",
       "  'abstract': 'Graph-based synset induction methods, such as MaxMax and Watset, induce synsets by performing a global clustering of a synonymy graph. However, such methods are sensitive to the structure of the input synonymy graph: sparseness of the input dictionary can substantially reduce the quality of the extracted synsets. In this paper, we propose two different approaches designed to alleviate the incompleteness of the input dictionaries. The first one performs a pre-processing of the graph by adding missing edges, while the second one performs a post-processing by merging similar synset clusters. We evaluate these approaches on two datasets for the Russian language and discuss their impact on the performance of synset induction methods. Finally, we perform an extensive error analysis of each approach and discuss prominent alternative methods for coping with the problem of the sparsity of the synonymy dictionaries.'},\n",
       " '10.1007/978-3-319-25007-6_25': {'title': 'TabEL: Entity Linking in Web Tables',\n",
       "  'abstract': 'Web tables form a valuable source of relational data. The Web contains an estimated 154 million HTML tables of relational data, with Wikipedia alone containing 1.6 million high-quality tables. Extracting the semantics of Web tables to produce machine-understandable knowledge has become an active area of research. A key step in extracting the semantics of Web content is entity linking (EL): the task of mapping a phrase in text to its referent entity in a knowledge base (KB). In this paper we present TabEL, a new EL system for Web tables. TabEL differs from previous work by weakening the assumption that the semantics of a table can be mapped to pre-defined types and relations found in the target KB. Instead, TabEL enforces soft constraints in the form of a graphical model that assigns higher likelihood to sets of entities that tend to co-occur in Wikipedia documents and tables. In experiments, TabEL significantly reduces error when compared to current state-of-the-art table EL systems, including a $$75\\\\%$$ error reduction on Wikipedia tables and a $$60\\\\%$$ error reduction on Web tables. We also make our parsed Wikipedia table corpus and test datasets publicly available for future work.'},\n",
       " '10.1007/s10579-013-9249-9': {'title': 'ECO and Onto.PT: a flexible approach for creating a Portuguese wordnet automatically',\n",
       "  'abstract': 'A wordnet is an important tool for developing natural language processing applications for a language. However, most wordnets are handcrafted by experts, which limits their growth. In this article, we propose an automatic approach to create wordnets by exploiting textual resources, dubbed ECO. After extracting semantic relation instances, identified by discriminating textual patterns, ECO discovers synonymy clusters, used as synsets, and attaches the remaining relations to suitable synsets. Besides introducing each step of ECO, we report on how it was implemented to create Onto.PT, a public lexical ontology for Portuguese. Onto.PT is the result of the automatic exploitation of Portuguese dictionaries and thesauri, and it aims to minimise the main limitations of existing Portuguese lexical knowledge bases.'},\n",
       " '10.1016/j.ipm.2024.103716': {'title': '3SHNet: Boosting image–sentence retrieval via visual semantic–spatial self-highlighting',\n",
       "  'abstract': 'In this paper, we propose a novel visual Semantic-Spatial Self-Highlighting Network (termed 3SHNet) for high-precision, high-efficiency and high-generalization image–sentence retrieval. 3SHNet highlights the salient identification of prominent objects and their spatial locations within the visual modality, thus allowing the integration of visual semantics–spatial interactions and maintaining independence between two modalities. This integration effectively combines object regions with the corresponding semantic and position layouts derived from segmentation to enhance the visual representation. And the modality-independence guarantees efficiency and generalization. Additionally, 3SHNet utilizes the structured contextual visual scene information from segmentation to conduct the local (region-based) or global (grid-based) guidance and achieve accurate hybrid-level retrieval. Extensive experiments conducted on MS-COCO and Flickr30K benchmarks substantiate the superior performances, inference efficiency and generalization of the proposed 3SHNet when juxtaposed with contemporary state-of-the-art methodologies. Specifically, on the larger MS-COCO 5K test set, we achieve 16.3%, 24.8%, and 18.3% improvements in terms of rSum score, respectively, compared with the state-of-the-art methods using different image representations, while maintaining optimal retrieval efficiency. Moreover, our performance on cross-dataset generalization improves by 18.6%.'},\n",
       " '10.1007/978-3-030-01261-8_23': {'title': 'Cross-Modal and Hierarchical Modeling of Video and Text',\n",
       "  'abstract': 'Visual data and text data are composed of information at multiple granularities. A video can describe a complex scene that is composed of multiple clips or shots, where each depicts a semantically coherent event or action. Similarly, a paragraph may contain sentences with different topics, which collectively conveys a coherent message or story. In this paper, we investigate the modeling techniques for such hierarchical sequential data where there are correspondences across multiple modalities. Specifically, we introduce hierarchical sequence embedding (hse), a generic model for embedding sequential data of different modalities into hierarchically semantic spaces, with either explicit or implicit correspondence information. We perform empirical studies on large-scale video and paragraph retrieval datasets and demonstrated superior performance by the proposed methods. Furthermore, we examine the effectiveness of our learned embeddings when applied to downstream tasks. We show its utility in zero-shot action recognition and video captioning.'},\n",
       " '10.1007/978-3-030-01225-0_13': {'title': 'Stacked Cross Attention for Image-Text Matching',\n",
       "  'abstract': 'In this paper, we study the problem of image-text matching. Inferring the latent semantic alignment between objects or other salient stuff (e.g. snow, sky, lawn) and the corresponding words in sentences allows to capture fine-grained interplay between vision and language, and makes image-text matching more interpretable. Prior work either simply aggregates the similarity of all possible pairs of regions and words without attending differentially to more and less important words or regions, or uses a multi-step attentional process to capture limited number of semantic alignments which is less interpretable. In this paper, we present Stacked Cross Attention to discover the full latent alignments using both image regions and words in a sentence as context and infer image-text similarity. Our approach achieves the state-of-the-art results on the MS-COCO and Flickr30K datasets. On Flickr30K, our approach outperforms the current best methods by 22.1% relatively in text retrieval from image query, and 18.2% relatively in image retrieval with text query (based on Recall@1). On MS-COCO, our approach improves sentence retrieval by 17.8% relatively and image retrieval by 16.6% relatively (based on Recall@1 using the 5K test set). Code has been made available at: ( https://github.com/kuanghuei/SCAN ).'},\n",
       " '10.1007/s11263-016-0965-7': {'title': 'Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models',\n",
       "  'abstract': 'The Flickr30k dataset has become a standard benchmark for sentence-based image description. This paper presents Flickr30k Entities, which augments the 158k captions from Flickr30k with 244k coreference chains, linking mentions of the same entities across different captions for the same image, and associating them with 276k manually annotated bounding boxes. Such annotations are essential for continued progress in automatic image description and grounded language understanding. They enable us to define a new benchmark for localization of textual entity mentions in an image. We present a strong baseline for this task that combines an image-text embedding, detectors for common objects, a color classifier, and a bias towards selecting larger objects. While our baseline rivals in accuracy more complex state-of-the-art models, we show that its gains cannot be easily parlayed into improvements on such tasks as image-sentence retrieval, thus underlining the limitations of current methods and the need for further research.'},\n",
       " '10.1007/978-3-319-10602-1_48': {'title': 'Microsoft COCO: Common Objects in Context',\n",
       "  'abstract': 'We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.'},\n",
       " '10.1007/s11263-013-0658-4': {'title': 'A Multi-View Embedding Space for Modeling Internet Images, Tags, and Their Semantics',\n",
       "  'abstract': 'This paper investigates the problem of modeling Internet images and associated text or tags for tasks such as image-to-image search, tag-to-image search, and image-to-tag search (image annotation). We start with canonical correlation analysis (CCA), a popular and successful approach for mapping visual and textual features to the same latent space, and incorporate a third view capturing high-level image semantics, represented either by a single category or multiple non-mutually-exclusive concepts. We present two ways to train the three-view embedding: supervised, with the third view coming from ground-truth labels or search keywords; and unsupervised, with semantic themes automatically obtained by clustering the tags. To ensure high accuracy for retrieval tasks while keeping the learning process scalable, we combine multiple strong visual features and use explicit nonlinear kernel mappings to efficiently approximate kernel CCA. To perform retrieval, we use a specially designed similarity function in the embedded space, which substantially outperforms the Euclidean distance. The resulting system produces compelling qualitative results and outperforms a number of two-view baselines on retrieval tasks on three large-scale Internet image datasets.'},\n",
       " '10.1016/j.ymeth.2024.04.005': {'title': 'AlpaPICO: Extraction of PICO Frames from Clinical Trial Documents Using LLMs',\n",
       "  'abstract': 'In recent years, there has been a surge in the publication of clinical trial reports, making it challenging to conduct systematic reviews. Automatically extracting Population, Intervention, Comparator, and Outcome (PICO) from clinical trial studies can alleviate the traditionally time-consuming process of manually scrutinizing systematic reviews. Existing approaches of PICO frame extraction involves supervised approach that relies on the existence of manually annotated data points in the form of BIO label tagging. Recent approaches, such as In-Context Learning (ICL), which has been shown to be effective for a number of downstream NLP tasks, require the use of labeled examples. In this work, we adopt ICL strategy by employing the pretrained knowledge of Large Language Models (LLMs), gathered during the pretraining phase of an LLM, to automatically extract the PICO-related terminologies from clinical trial documents in unsupervised set up to bypass the availability of large number of annotated data instances. Additionally, to showcase the highest effectiveness of LLM in oracle scenario where large number of annotated samples are available, we adopt the instruction tuning strategy by employing Low Rank Adaptation (LORA) to conduct the training of gigantic model in low resource environment for the PICO frame extraction task. More specifically, both of the proposed frameworks utilize AlpaCare as base LLM which employs both few-shot in-context learning and instruction tuning techniques to extract PICO-related terms from the clinical trial reports. We applied these approaches to the widely used coarse-grained datasets such as EBM-NLP, EBM-COMET and fine-grained datasets such as EBM-NLPrev and EBM-NLPh. Our empirical results show that our proposed ICL-based framework produces comparable results on all the version of EBM-NLP datasets and the proposed instruction tuned version of our framework produces state-of-the-art results on all the different EBM-NLP datasets. Our project is available at https://github.com/shrimonmuke0202/AlpaPICO.git.'},\n",
       " '10.1016/j.ipm.2023.103539': {'title': 'Retrieval Contrastive Learning for Aspect-Level Sentiment Classification',\n",
       "  'abstract': 'Aspect-Level Sentiment Classification (ALSC) aims to assign specific sentiments to a sentence toward different aspects, which is one of the crucial challenges in the field of Natural Language Processing (NLP). Despite numerous approaches being proposed and obtaining prominent results, the majority of them focus on leveraging the relationships between the aspect and opinion words in a single instance while ignoring correlations with other instances, which will make models inevitably become trapped in local optima due to the absence of a global viewpoint. Instance representation derived from a single instance, on the one hand, the contained information is insufficient due to the lack of descriptions from other perspectives; on the other hand, its stored knowledge is redundant since the inability to filter extraneous content. To obtain a polished instance representation, we developed a Retrieval Contrastive Learning (RCL) framework to subtly extract intrinsic knowledge across instances. RCL consists of two modules: (a) obtaining retrieval instances by sparse retriever and dense retriever, and (b) extracting and learning the knowledge of the retrieval instances by using Contrastive Learning (CL). To demonstrate the superiority of RCL, five ALSC models are employed to conduct comprehensive experiments on three widely-known benchmarks. Compared with the baselines, ALSC models achieve substantial improvements when trained with RCL. Especially, ABSA-DeBERTa with RCL obtains new state-of-the-art results, which outperform the advanced methods by 0.92%, 0.23%, and 0.47% in terms of Macro F1 gains on Laptops, Restaurants, and Twitter, respectively.'},\n",
       " '10.1016/j.jss.2024.111982': {'title': 'RRGcode: Deep hierarchical search-based code generation',\n",
       "  'abstract': 'Retrieval-augmented code generation strengthens the generation model by using a retrieval model to select relevant code snippets from a code corpus. The synergy between retrieval and generation ensures that the generated code closely corresponds to the intended functionality. Existing methods simply feed the retrieved results to the generation model. However, if the retrieval corpus contains erroneous or sub-optimal code examples, there is a risk that the model may replicate these mistakes in the generated code. To tackle these problems, we propose RRGcode(Retrieval, Re-ranking, and Generation for code generation), a deep hierarchical search-based code generation framework that fine-tunes initial retrieved code rankings, reducing the risk of replicating errors from the retrieval corpus and enhancing the generation of higher-quality, more reliable code. Specifically, it first retrieves relevant code candidates from a large code corpus. Then, a re-ranking model reconstructs the search space through a detailed semantic comparison between code candidates and the query, ensuring that only the most relevant and accurate candidates are considered. Finally, the re-ranked top-K codes, along with the query, serve as input for the code generation model. Extensive experiments are conducted to evaluate the effectiveness of generated code by RRGcode, demonstrating state-of-the-art performance in code generation tasks.'},\n",
       " '10.1016/j.eswa.2023.122177': {'title': 'Chinese legal judgment prediction via knowledgeable prompt learning',\n",
       "  'abstract': \"In recent years, applying AI techniques in the legal field has attracted researchers' attention. In particular, Legal Judgment Prediction (LJP), which aims to predict accusations based on given case description texts, has attracted much attention from the natural language processing community. However, most of the existing LJP methods are data-intensive. As we know, data annotation in the legal field is expensive. Prompt learning is a recently prevalent methodology, which often achieves surprising results in few-shot or even zero-shot scenarios. We propose a novel method for Chinese LJP based on prompt learning called KnowPrompt4LJP. The method aligns the Chinese LJP task with the pre-training task of a Pre-trained Language Model (PLM) via a prompt template to stimulate the PLM's recall of learned knowledge. In addition, the well-designed prompt template can enhance the PLM's understanding of the Chinese LJP task. We also use an external knowledge base to extract keyword information from the Chinese case description texts and incorporate it into the prompt template, thus enhancing the guidance of the prompt template to the PLM. Experimental results on CAIL2018, a high-quality Chinese LJP competition dataset, show that KnowPrompt4LJP achieves far better results than the baselines in zero-shot, few-shot, and full-size training data scenarios. KnowPrompt4LJP can achieve a macro F1 value of 0.70 in the low-resource scenario, which is comparable to the baselines' results in the data-rich scenario. In the scenario of using full-size training data, KnowPrompt4LJP can achieve a macro F1 value of 0.81.\"},\n",
       " '10.1016/j.knosys.2023.110826': {'title': 'A divide and conquer framework for Knowledge Editing',\n",
       "  'abstract': 'As Pre-trained language models (LMs) play an important role in various Natural Language Processing (NLP) tasks, it is becoming increasingly important to make sure the knowledge learned from LMs is valid and correct. Unlike conventional knowledge bases, LMs implicitly memorize knowledge in their parameters, which makes it harder to correct if some knowledge is incorrectly inferred or obsolete. The task of Knowledge Editing is to correct errors in language models, avoiding the expensive overhead associated with retraining the model from scratch. While existing methods have shown some promising results, they fail on multi-edits as they ignore the conflicts between these edits. In the paper, we propose a novel framework to divide-and-conquer edits with parallel Editors. Specifically, we design explicit and implicit multi-editor models to learn diverse editing strategies in terms of dynamic structure and dynamic parameters respectively, which allows solving the conflict data in an efficient end-to-end manner. Our main findings are: (i) State of the art Knowledge Editing methods with multiple editing capability, such as MEND and ENN, can hardly outperform the fine-tuning method; (ii) Our proposed models outperform the fine-tuning method over the two widely used datasets for Knowledge Editing; (iii) Additional analytical experiments verify that our approach can learn diverse editing strategies, thus better adapting to multiple editing than state-of-the-art methods.'},\n",
       " '10.1007/s10579-023-09677-w': {'title': 'Fine-tuning language models to recognize semantic relations',\n",
       "  'abstract': 'Abstract Transformer-based pre-trained Language Models (PLMs) have emerged as the foundations for the current state-of-the-art algorithms in most natural language processing tasks, in particular when applied to context rich data such as sentences or paragraphs. However, their impact on the tasks defined in terms of abstract individual word properties, not necessary tied to their specific use in a particular sentence, has been inadequately explored, which is a notable research gap. Addressing this gap is crucial for advancing our understanding of natural language processing. To fill this void, we concentrate on classification of semantic relations: given a pair of concepts (words or word sequences) the aim is to identify the semantic label to describe their relationship. E.g. in the case of the pair green/colour , “is a” is a suitable relation while “part of”, “property of”, and “opposite of” are not suitable. This classification is independent of a particular sentence in which these concepts might have been used. We are first to incorporate a language model into both existing approaches to this task, namely path-based and distribution-based methods. Our transformer-based approaches exhibit significant improvements over the state-of-the-art and come remarkably close to achieving human-level performance on rigorous benchmarks. We are also first to provide evidence that the standard datasets over-state the performance due to the effect of “lexical memorisation.” We reduce this effect by applying lexical separation. On the new benchmark datasets, the algorithmic performance remains significantly below human-level, highlighting that the task of semantic relation classification is still unresolved, particularly for language models of the sizes commonly used at the time of our study. We also identify additional challenges that PLM-based approaches face and conduct extensive ablation studies and other experiments to investigate the sensitivity of our findings to specific modelling and implementation choices. Furthermore, we examine the specific relations that pose greater challenges and discuss the trade-offs between accuracy and processing time.'},\n",
       " '10.1016/j.ipm.2023.103374': {'title': 'A BERT-based deontic logic learner',\n",
       "  'abstract': \"In recent years, large-scale Pre-trained Language Models (PLMs) like BERT have achieved state-of-the-art results on many NLP tasks. We explore whether BERT understands deontic logic which is important for the fields of legal AI and digital government. We measure BERT's understanding of deontic logic through the Deontic Modality Classification (DMC) task. Experiments show that without fine-tuning or fine-tuning with only a small amount of data, BERT cannot achieve good performance on the DMC task. Therefore, we propose a new method for BERT fine-tuning and prediction, called DeonticBERT. The method incorporates heuristic knowledge from deontic logic theory as an inductive bias into BERT through a template function and a mapping between category labels and predicted words, to steer BERT understand the DMC task. This can also stimulate BERT to recall the deontic logic knowledge learned in pre-training. We use an English dataset widely used as well as a Chinese dataset we constructed to conduct experiments. Experimental results show that on the DMC task, DeonticBERT can achieve 66.9% and 91% accuracy under zero-shot and few-shot conditions, respectively, far exceeding other baselines. This demonstrates that DeonticBERT does enable BERT to understand deontic logic and can handle related tasks without using much fine-tuning data. Our research helps facilitate applying large-scale PLMs like BERT into legal AI and digital government.\"},\n",
       " '10.1007/s11633-023-1416-x': {'title': 'The Life Cycle of Knowledge in Big Language Models: A Survey',\n",
       "  'abstract': 'Knowledge plays a critical role in artificial intelligence. Recently, the extensive success of pre-trained language models (PLMs) has raised significant attention about how knowledge can be acquired, maintained, updated and used by language models. Despite the enormous amount of related studies, there is still a lack of a unified view of how knowledge circulates within language models throughout the learning, tuning, and application processes, which may prevent us from further understanding the connections between current progress or realizing existing limitations. In this survey, we revisit PLMs as knowledge-based systems by dividing the life circle of knowledge in PLMs into five critical periods, and investigating how knowledge circulates when it is built, maintained and used. To this end, we systematically review existing studies of each period of the knowledge life cycle, summarize the main challenges and current limitations, and discuss future directions.'},\n",
       " '10.1007/s11633-022-1410-8': {'title': 'Large-scale Multi-modal Pre-trained Models: A Comprehensive Survey',\n",
       "  'abstract': 'Abstract With the urgent demand for generalized deep models, many pre-trained big models are proposed, such as bidirectional encoder representations (BERT), vision transformer (ViT), generative pre-trained transformers (GPT), etc. Inspired by the success of these models in single domains (like computer vision and natural language processing), the multi-modal pre-trained big models have also drawn more and more attention in recent years. In this work, we give a comprehensive survey of these models and hope this paper could provide new insights and helps fresh researchers to track the most cutting-edge works. Specifically, we firstly introduce the background of multi-modal pre-training by reviewing the conventional deep learning, pre-training works in natural language process, computer vision, and speech. Then, we introduce the task definition, key challenges, and advantages of multi-modal pre-training models (MM-PTMs), and discuss the MM-PTMs with a focus on data, objectives, network architectures, and knowledge enhanced pre-training. After that, we introduce the downstream tasks used for the validation of large-scale MM-PTMs, including generative, classification, and regression tasks. We also give visualization and analysis of the model parameters and results on representative downstream tasks. Finally, we point out possible research directions for this topic that may benefit future works. In addition, we maintain a continuously updated paper list for large-scale pre-trained multi-modal big models: https://github.com/wangxiao5791509/MultiModal_BigModels_Survey .'},\n",
       " '10.1016/j.knosys.2024.111542': {'title': 'DSTEA: Improving Dialogue State Tracking via Entity Adaptive pre-training',\n",
       "  'abstract': 'Dialogue State Tracking (DST) is critical for comprehensively interpreting user and system utterances, thereby forming the cornerstone of efficient dialogue systems. Despite past research efforts focused on enhancing DST performance through alterations to the model structure or integrating additional features like graph relations, they often require additional pre-training with external dialogue corpora. In this study, we propose DSTEA, improving Dialogue State Tracking via Entity Adaptive pre-training, which can enhance the encoder through by intensively training key entities in dialogue utterances. DSTEA identifies these pivotal entities from input dialogues utilizing four different methods: ontology information, named-entity recognition, the spaCy toolkit, and the flair library. Subsequently, it employs selective knowledge masking to train the model effectively. Remarkably, DSTEA only requires pre-training without the direct infusion of extra knowledge into the DST model. This approach results in substantial performance improvements of four robust DST models on MultiWOZ 2.0, 2.1, and 2.2, with joint goal accuracy witnessing an increase of up to 2.69% (from 52.41% to 55.10%). Comparative experiments considering various entity types and different entity adaptive pre-training configurations, such as masking strategy and masking rate, further validated the efficacy of DSTEA.'},\n",
       " '10.1007/978-3-031-44696-2_35': {'title': 'Knowledgeable Salient Span Mask for Enhancing Language Models as Knowledge Base',\n",
       "  'abstract': 'Pre-trained language models (PLMs) like BERT have made significant progress in various downstream NLP tasks. However, by asking models to do cloze-style tests, recent work finds that PLMs are short in acquiring knowledge from unstructured text. To understand the internal behaviour of PLMs in retrieving knowledge, we first define knowledge-baring (K-B) tokens and knowledge-free (K-F) tokens for unstructured text and ask professional annotators to label some samples manually. Then, we find that PLMs are more likely to give wrong predictions on K-B tokens and attend less attention to those tokens inside the self-attention module. Based on these observations, we develop two solutions to help the model learn more knowledge from unstructured text in a fully self-supervised manner. Experiments on knowledge-intensive tasks show the effectiveness of the proposed methods. To our best knowledge, we are the first to explore fully self-supervised learning of knowledge in continual pre-training.'},\n",
       " '10.1016/j.gltp.2022.03.014': {'title': 'Fake news detection on Hindi news dataset',\n",
       "  'abstract': 'With the increase in social networks, more number of people are creating and sharing information than ever before, many of them have no relevance to reality. Due to this, fake news for various political and commercial purposes are spreading quickly. Online newspaper has made it challenging to identify trustworthy news sources. In this work, Hindi news articles from various news sources are collected. Preprocessing, feature extraction, classification and prediction processes are discussed in detail. Different machine learning algorithms such as Naïve Bayes, logistic regression and Long Short-Term Memory (LSTM) are used to detect the fake news. The preprocessing step includes data cleaning, stop words removal, tokenizing and stemming. Term frequency inverse document frequency(TF-IDF) is used for feature extraction. Naïve Bayes, logistic regression and LSTM classifiers are used and compared for fake news detection with probability of truth. It is observed that among these three classifiers, LSTM achieved best accuracy of 92.36%.'},\n",
       " '10.1007/978-3-031-15931-2_19': {'title': 'Eliciting Knowledge from Pretrained Language Models for Prototypical Prompt Verbalizer',\n",
       "  'abstract': 'Recent advances on prompt-tuning cast few-shot classification tasks as a masked language modeling problem. By wrapping input into a template and using a verbalizer which constructs a mapping between label space and label word space, prompt-tuning can achieve excellent results in few-shot scenarios. However, typical prompt-tuning needs a manually designed verbalizer which requires domain expertise and human efforts. And the insufficient label space may introduce considerable bias into the results. In this paper, we focus on eliciting knowledge from pretrained language models and propose a prototypical prompt verbalizer for prompt-tuning. Labels are represented by prototypical embeddings in the feature space rather than by discrete words. The distances between the embedding at the masked position of input and prototypical embeddings are used as classification criterion. To address the problem of random initialization of parameters in zero-shot settings, we elicit knowledge from pretrained language models to form initial prototypical embeddings. Our method optimizes models by contrastive learning. Extensive experimental results on several many-class text classification datasets with low-resource settings demonstrate the effectiveness of our approach compared with other verbalizer construction methods. Our implementation is at https://github.com/Ydongd/prototypical-prompt-verbalizer .'},\n",
       " '10.1007/978-3-030-88480-2_61': {'title': 'Exploring Generalization Ability of Pretrained Language Models on Arithmetic and Logical Reasoning',\n",
       "  'abstract': 'To quantitatively and intuitively explore the generalization ability of pre-trained language models (PLMs), we have designed several tasks of arithmetic and logical reasoning. We both analyse how well PLMs generalize when the test data is in the same distribution as the train data and when it is different, for the latter analysis, we have also designed a cross-distribution test set other than the in-distribution test set. We conduct experiments on one of the most advanced and publicly released generative PLM - BART. Our research finds that the PLMs can easily generalize when the distribution is the same, however, it is still difficult for them to generalize out of the distribution.'},\n",
       " '10.1016/j.aiopen.2021.08.002': {'title': 'Pre-trained models: Past, present and future',\n",
       "  'abstract': 'Large-scale pre-trained models (PTMs) such as BERT and GPT have recently achieved great success and become a milestone in the field of artificial intelligence (AI). Owing to sophisticated pre-training objectives and huge model parameters, large-scale PTMs can effectively capture knowledge from massive labeled and unlabeled data. By storing knowledge into huge parameters and fine-tuning on specific tasks, the rich knowledge implicitly encoded in huge parameters can benefit a variety of downstream tasks, which has been extensively demonstrated via experimental verification and empirical analysis. It is now the consensus of the AI community to adopt PTMs as backbone for downstream tasks rather than learning models from scratch. In this paper, we take a deep look into the history of pre-training, especially its special relation with transfer learning and self-supervised learning, to reveal the crucial position of PTMs in the AI development spectrum. Further, we comprehensively review the latest breakthroughs of PTMs. These breakthroughs are driven by the surge of computational power and the increasing availability of data, towards four important directions: designing effective architectures, utilizing rich contexts, improving computational efficiency, and conducting interpretation and theoretical analysis. Finally, we discuss a series of open problems and research directions of PTMs, and hope our view can inspire and advance the future study of PTMs.'},\n",
       " '10.1038/s42256-022-00458-8': {'title': 'Large pre-trained language models contain human-like biases of what is right and wrong to do',\n",
       "  'abstract': 'Artificial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, GPT-2 and GPT-3. Using them as pre-trained models and fine-tuning them for specific tasks, researchers have extended the state of the art for many natural language processing tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on unfiltered text corpora suffer from degenerated and biased behaviour. While this is well established, we show here that recent LMs also contain human-like biases of what is right and wrong to do, reflecting existing ethical and moral norms of society. We show that these norms can be captured geometrically by a ‘moral direction’ which can be computed, for example, by a PCA, in the embedding space. The computed ‘moral direction’ can rate the normativity (or non-normativity) of arbitrary phrases without explicitly training the LM for this task, reflecting social norms well. We demonstrate that computing the ’moral direction’ can provide a path for attenuating or even preventing toxic degeneration in LMs, showcasing this capability on the RealToxicityPrompts testbed. Large language models identify patterns in the relations between words and capture their relations in an embedding space. Schramowski and colleagues show that a direction in this space can be identified that separates ‘right’ and ‘wrong’ actions as judged by human survey participants.'},\n",
       " '10.1186/s40537-020-00392-9': {'title': 'Deep Learning applications for COVID-19',\n",
       "  'abstract': 'This survey explores how Deep Learning has battled the COVID-19 pandemic and provides directions for future research on COVID-19. We cover Deep Learning applications in Natural Language Processing, Computer Vision, Life Sciences, and Epidemiology. We describe how each of these applications vary with the availability of big data and how learning tasks are constructed. We begin by evaluating the current state of Deep Learning and conclude with key limitations of Deep Learning for COVID-19 applications. These limitations include Interpretability, Generalization Metrics, Learning from Limited Labeled Data, and Data Privacy. Natural Language Processing applications include mining COVID-19 research for Information Retrieval and Question Answering, as well as Misinformation Detection, and Public Sentiment Analysis. Computer Vision applications cover Medical Image Analysis, Ambient Intelligence, and Vision-based Robotics. Within Life Sciences, our survey looks at how Deep Learning can be applied to Precision Diagnostics, Protein Structure Prediction, and Drug Repurposing. Deep Learning has additionally been utilized in Spread Forecasting for Epidemiology. Our literature review has found many examples of Deep Learning systems to fight COVID-19. We hope that this survey will help accelerate the use of Deep Learning for COVID-19 research.'},\n",
       " '10.1007/978-3-031-43415-0_35': {'title': 'Efficient Fine-Tuning Large Language Models for Knowledge-Aware Response Planning',\n",
       "  'abstract': 'Large Language Models (LLMs) have shown impressive emergent language capabilities, especially in applications with high ambiguity, such as language reasoning and knowledge consolidation. However, previous work explores the use of LLMs for acquiring information using either parametric or external knowledge, which might lead to serious issues such as hallucination. Toward solving these issues, we present a novel approach of knowledge-aware response planning (KARP) and propose a novel framework that employs (i) a knowledge retriever to obtain relevant information from web documents or databases for a given user query, and (ii) a robust fine-tuning strategy for LLMs to exploit the retrieved external knowledge for planning a final response. Experimental results show that our proposed framework can provide natural, concise answers for open-domain questions with high accuracy.'},\n",
       " '10.48550/arXiv.2312.09979': {'title': 'LoRAMoE: Revolutionizing Mixture of Experts for Maintaining World Knowledge in Language Model Alignment',\n",
       "  'abstract': 'Supervised fine-tuning (SFT) is a crucial step for large language models (LLMs), enabling them to align with human instructions and enhance their capabilities in downstream tasks. Increasing instruction data substantially is a direct solution to align the model with a broader range of downstream tasks or notably improve its performance on a specific task. However, we find that large-scale increases in instruction data can damage the world knowledge previously stored in LLMs. To address this challenge, we propose LoRAMoE, a novelty framework that introduces several low-rank adapters (LoRA) and integrates them by using a router network, like a plugin version of Mixture of Experts (MoE). It freezes the backbone model and forces a portion of LoRAs to focus on leveraging world knowledge to solve downstream tasks, to alleviate world knowledge-edge forgetting. Experimental results show that, as the instruction data increases, LoRAMoE can significantly improve the ability to process downstream tasks, while maintaining the world knowledge stored in the LLM.'},\n",
       " '10.1007/978-3-030-95481-9_3': {'title': 'Modelling Symbolic Knowledge Using Neural Representations',\n",
       "  'abstract': 'Symbolic reasoning and deep learning are two fundamentally different approaches to building AI systems, with complementary strengths and weaknesses. Despite their clear differences, however, the line between these two approaches is increasingly blurry. For instance, the neural language models which are popular in Natural Language Processing are increasingly playing the role of knowledge bases, while neural network learning strategies are being used to learn symbolic knowledge, and to develop strategies for reasoning more flexibly with such knowledge. This blurring of the boundary between symbolic and neural methods offers significant opportunities for developing systems that can combine the flexibility and inductive capabilities of neural networks with the transparency and systematic reasoning abilities of symbolic frameworks. At the same time, there are still many open questions around how such a combination can best be achieved. This paper presents an overview of recent work on the relationship between symbolic knowledge and neural representations, with a focus on the use of neural networks, and vector representations more generally, for encoding knowledge.'},\n",
       " '10.1007/s10462-023-10414-6': {'title': 'Video description: A comprehensive survey of deep learning approaches',\n",
       "  'abstract': 'Abstract Video description refers to understanding visual content and transforming that acquired understanding into automatic textual narration. It bridges the key AI fields of computer vision and natural language processing in conjunction with real-time and practical applications. Deep learning-based approaches employed for video description have demonstrated enhanced results compared to conventional approaches. The current literature lacks a thorough interpretation of the recently developed and employed sequence to sequence techniques for video description. This paper fills that gap by focusing mainly on deep learning-enabled approaches to automatic caption generation. Sequence to sequence models follow an Encoder–Decoder architecture employing a specific composition of CNN, RNN, or the variants LSTM or GRU as an encoder and decoder block. This standard-architecture can be fused with an attention mechanism to focus on a specific distinctiveness, achieving high quality results. Reinforcement learning employed within the Encoder–Decoder structure can progressively deliver state-of-the-art captions by following exploration and exploitation strategies. The transformer mechanism is a modern and efficient transductive architecture for robust output. Free from recurrence, and solely based on self-attention, it allows parallelization along with training on a massive amount of data. It can fully utilize the available GPUs for most NLP tasks. Recently, with the emergence of several versions of transformers, long term dependency handling is not an issue anymore for researchers engaged in video processing for summarization and description, or for autonomous-vehicle, surveillance, and instructional purposes. They can get auspicious directions from this research.'},\n",
       " '10.1038/s42256-023-00624-6': {'title': 'Multimodal learning with graphs',\n",
       "  'abstract': 'Artificial intelligence for graphs has achieved remarkable success in modelling complex systems, ranging from dynamic networks in biology to interacting particle systems in physics. However, the increasingly heterogeneous graph datasets call for multimodal methods that can combine different inductive biases — assumptions that algorithms use to make predictions for inputs they have not encountered during training. Learning on multimodal datasets is challenging because the inductive biases can vary by data modality and graphs might not be explicitly given in the input. To address these challenges, graph artificial intelligence methods combine different modalities while leveraging cross-modal dependencies through geometric relationships. Diverse datasets are combined using graphs and fed into sophisticated multimodal architectures, specified as image-intensive, knowledge-grounded and language-intensive models. Using this categorization, we introduce a blueprint for multimodal graph learning, use it to study existing methods and provide guidelines to design new models. One of the main advances in deep learning in the past five years has been graph representation learning, which enabled applications to problems with underlying geometric relationships. Increasingly, such problems involve multiple data modalities and, examining over 160 studies in this area, Ektefaie et al. propose a general framework for multimodal graph learning for image-intensive, knowledge-grounded and language-intensive problems.'},\n",
       " '10.1007/978-3-031-20059-5_32': {'title': 'The Abduction of Sherlock Holmes: A Dataset for Visual Abductive Reasoning',\n",
       "  'abstract': 'Humans have remarkable capacity to reason abductively and hypothesize about what lies beyond the literal content of an image. By identifying concrete visual clues scattered throughout a scene, we almost can’t help but draw probable inferences beyond the literal scene based on our everyday experience and knowledge about the world. For example, if we see a “20 mph” sign alongside a road, we might assume the street sits in a residential area (rather than on a highway), even if no houses are pictured. Can machines perform similar visual reasoning? We present Sherlock, an annotated corpus of 103K images for testing machine capacity for abductive reasoning beyond literal image contents. We adopt a free-viewing paradigm: participants first observe and identify salient clues within images (e.g., objects, actions) and then provide a plausible inference about the scene, given the clue. In total, we collect 363K (clue, inference) pairs, which form a first-of-its-kind abductive visual reasoning dataset. Using our corpus, we test three complementary axes of abductive reasoning. We evaluate the capacity of models to: i) retrieve relevant inferences from a large candidate corpus; ii) localize evidence for inferences via bounding boxes, and iii) compare plausible inferences to match human judgments on a newly-collected diagnostic corpus of 19K Likert-scale judgments. While we find that fine-tuning CLIP-RN50 $$\\\\,\\\\times \\\\,$$ 64 with a multitask objective outperforms strong baselines, significant headroom exists between model performance and human agreement. Data, models, and leaderboard available at http://visualabduction.com/ .'},\n",
       " '10.1007/978-3-030-58610-2_24': {'title': 'ViTAA: Visual-Textual Attributes Alignment in Person Search by Natural Language',\n",
       "  'abstract': 'Person search by natural language aims at retrieving a specific person in a large-scale image pool that matches given textual descriptions. While most of the current methods treat the task as a holistic visual and textual feature matching one, we approach it from an attribute-aligning perspective that allows grounding specific attribute phrases to the corresponding visual regions. We achieve success as well as a performance boost by a robust feature learning that the referred identity can be accurately bundled by multiple attribute cues. To be concrete, our Visual-Textual Attribute Alignment model (dubbed as ViTAA) learns to disentangle the feature space of a person into sub-spaces corresponding to attributes using a light auxiliary attribute segmentation layer. It then aligns these visual features with the textual attributes parsed from the sentences via a novel contrastive learning loss. We validate our ViTAA framework through extensive experiments on tasks of person search by natural language and by attribute-phrase queries, on which our system achieves state-of-the-art performances. Codes and models are available at https://github.com/Jarr0d/ViTAA.'},\n",
       " '10.1007/978-3-030-58589-1_23': {'title': 'VQA-LOL: Visual Question Answering Under the Lens of Logic',\n",
       "  'abstract': 'Logical connectives and their implications on the meaning of a natural language sentence are a fundamental aspect of understanding. In this paper, we investigate whether visual question answering (VQA) systems trained to answer a question about an image, are able to answer the logical composition of multiple such questions. When put under this Lens of Logic, state-of-the-art VQA models have difficulty in correctly answering these logically composed questions. We construct an augmentation of the VQA dataset as a benchmark, with questions containing logical compositions and linguistic transformations (negation, disjunction, conjunction, and antonyms). We propose our Lens of Logic (LOL) model which uses question-attention and logic-attention to understand logical connectives in the question, and a novel Fréchet-Compatibility Loss, which ensures that the answers of the component questions and the composed question are consistent with the inferred logical operation. Our model shows substantial improvement in learning logical compositions while retaining performance on VQA. We suggest this work as a move towards robustness by embedding logical connectives in visual understanding.'},\n",
       " '10.1016/j.patrec.2022.05.021': {'title': 'Diverse video captioning through latent variable expansion',\n",
       "  'abstract': 'Automatically describing video content with text description is challenging but important task, which has been attracting a lot of attention in computer vision community. Previous works mainly strive for the accuracy of the generated sentences, while ignoring the sentences diversity, which is inconsistent with human behavior. In this paper, we aim to caption each video with multiple descriptions and propose a novel framework. Concretely, for a given video, the intermediate latent variables of conventional encode-decode process are utilized as input to the conditional generative adversarial network (CGAN) with the purpose of generating diverse sentences. We adopt different Convolutional Neural Networks (CNNs) as our generator that produces descriptions conditioned on latent variables and discriminator that assesses the quality of generated sentences. Simultaneously, a novel DCE metric is designed to assess the diverse captions. We evaluate our method on the benchmark datasets, where it demonstrates its ability to generate diverse descriptions and achieves superior results against other state-of-the-art methods.'},\n",
       " '10.1007/978-3-030-58621-8_20': {'title': 'Procedure Planning in Instructional Videos',\n",
       "  'abstract': 'In this paper, we study the problem of procedure planning in instructional videos, which can be seen as a step towards enabling autonomous agents to plan for complex tasks in everyday settings such as cooking. Given the current visual observation of the world and a visual goal, we ask the question “What actions need to be taken in order to achieve the goal?”. The key technical challenge is to learn structured and plannable state and action spaces directly from unstructured videos. We address this challenge by proposing Dual Dynamics Networks (DDN), a framework that explicitly leverages the structured priors imposed by the conjugate relationships between states and actions in a learned plannable latent space. We evaluate our method on real-world instructional videos. Our experiments show that DDN learns plannable representations that lead to better planning performance compared to existing planning approaches and neural network policies.'},\n",
       " '10.1007/978-3-030-01216-8_35': {'title': 'Textual Explanations for Self-Driving Vehicles',\n",
       "  'abstract': 'Deep neural perception and control networks have become key components of self-driving vehicles. User acceptance is likely to benefit from easy-to-interpret textual explanations which allow end-users to understand what triggered a particular behavior. Explanations may be triggered by the neural controller, namely introspective explanations, or informed by the neural controller’s output, namely rationalizations. We propose a new approach to introspective explanations which consists of two parts. First, we use a visual (spatial) attention model to train a convolutional network end-to-end from images to the vehicle control commands, i.e., acceleration and change of course. The controller’s attention identifies image regions that potentially influence the network’s output. Second, we use an attention-based video-to-text model to produce textual explanations of model actions. The attention maps of controller and explanation model are aligned so that explanations are grounded in the parts of the scene that mattered to the controller. We explore two approaches to attention alignment, strong- and weak-alignment. Finally, we explore a version of our model that generates rationalizations, and compare with introspective explanations on the same video segments. We evaluate these models on a novel driving dataset with ground-truth human explanations, the Berkeley DeepDrive eXplanation (BDD-X) dataset. Code is available at https://github.com/JinkyuKimUCB/explainable-deep-driving .'},\n",
       " '10.1007/s11263-017-1033-7': {'title': 'Uncovering the Temporal Context for Video Question Answering',\n",
       "  'abstract': 'In this work, we introduce Video Question Answering in the temporal domain to infer the past, describe the present and predict the future. We present an encoder–decoder approach using Recurrent Neural Networks to learn the temporal structures of videos and introduce a dual-channel ranking loss to answer multiple-choice questions. We explore approaches for finer understanding of video content using the question form of “fill-in-the-blank”, and collect our Video Context QA dataset consisting of 109,895 video clips with a total duration of more than 1000 h from existing TACoS, MPII-MD and MEDTest 14 datasets. In addition, 390,744 corresponding questions are generated from annotations. Extensive experiments demonstrate that our approach significantly outperforms the compared baselines.'},\n",
       " '10.1007/978-3-319-46448-0_49': {'title': 'Grounding of Textual Phrases in Images by Reconstruction',\n",
       "  'abstract': 'Grounding (i.e. localizing) arbitrary, free-form textual phrases in visual content is a challenging problem with many applications for human-computer interaction and image-text reference resolution. Few datasets provide the ground truth spatial localization of phrases, thus it is desirable to learn from data with no or little grounding supervision. We propose a novel approach which learns grounding by reconstructing a given phrase using an attention mechanism, which can be either latent or optimized directly. During training our approach encodes the phrase using a recurrent network language model and then learns to attend to the relevant image region in order to reconstruct the input phrase. At test time, the correct attention, i.e., the grounding, is evaluated. If grounding supervision is available it can be directly applied via a loss over the attention mechanism. We demonstrate the effectiveness of our approach on the Flickr 30k Entities and ReferItGame datasets with different levels of supervision, ranging from no supervision over partial supervision to full supervision. Our supervised variant improves by a large margin over the state-of-the-art on both datasets.'},\n",
       " '10.1007/978-3-030-88483-3_10': {'title': 'CUSTOM: Aspect-Oriented Product Summarization for E-Commerce',\n",
       "  'abstract': 'Product summarization aims to automatically generate product descriptions, which is of great commercial potential. Considering the customer preferences on different product aspects, it would benefit from generating aspect-oriented customized summaries. However, conventional systems typically focus on providing general product summaries, which may miss the opportunity to match products with customer interests. To address the problem, we propose CUSTOM, aspect-oriented product summarization for e-commerce, which generates diverse and controllable summaries towards different product aspects. To support the study of CUSTOM and further this line of research, we construct two Chinese datasets, i.e., SMARTPHONE and COMPUTER, including 76,279/49,280 short summaries for 12,118/11,497 real-world commercial products, respectively. Furthermore, we introduce EXT, an extraction-enhanced generation framework for CUSTOM, where two famous sequence-to-sequence models are implemented in this paper. We conduct extensive experiments on the two proposed datasets for CUSTOM and show results of two famous baseline models and EXT, which indicates that EXT can generate diverse, high-quality, and consistent summaries (https://github.com/JD-AI-Research-NLP/CUSTOM).'},\n",
       " '10.1016/J.COMPIND.2021.103449': {'title': 'Exploiting knowledge graphs in industrial products and services: A survey of key aspects, challenges, and future perspectives',\n",
       "  'abstract': 'The rapid development of information and communication technologies has enabled a value co-creation paradigm for developing industrial products and services, where massive heterogeneous data and multidisciplinary knowledge are generated and leveraged. In this context, Knowledge Graph (KG) emerges as a promising tool to elicit, fuse, process, and utilize numerous entities and relationships embedded in products and services, as well as their stakeholders. Nevertheless, to the best of the authors’ knowledge, there is scarcely any comprehensive and thorough discussion about making full use of KG’s potentials to solve pain points of product development and service innovation in the industry. Aiming to fill this gap, this paper conducted a systematic survey of KG exploitations in industrial products and services and the customizations towards higher adaptability to practices. The authors selected 119 representative papers (up to 10/03/2021) together with other 29 supplementary works to summarize the technical and practical efforts and discuss the current challenges of exploiting KG in industrial products and services. Meantime, this work also highlights enhancing KG’s availability and boosting its productivity in industrial products and services development as the core future perspectives to explore. It is hoped that this work can provide a basis for the explorations and implementations of KG-supported industrial product and services development, and attract more open discussions to the exploitation of KG-enabled industrial information systems.'},\n",
       " '10.1007/s10844-022-00774-w': {'title': 'The detection of mental health conditions by incorporating external knowledge',\n",
       "  'abstract': 'Mental health conditions have become a growing problem; it increases the likelihood of premature death for patients, and imposes a high economic burden on the world. However, some studies have shown that if patients are detected and treated early, the social impact and economic costs of mental illness can be reduced. With the popularity of social media, people are sharing their feelings on it, which allows data from social media to be used to study mental health conditions. However, past research had been limited to the optimization of the model or using different types of data available on social media, resulting in models that only rely on data to make decisions. Moreover, people judge things not only by the data collected, but also by background knowledge. Therefore, we considered the diagnostic process of doctors and combined the knowledge of psychological screening tools and diagnostic criteria into the model. In addition, we also tested the effect of combining general knowledge. We retrieve the top m most relevant knowledge segments for each user’s post, and then put both into the prediction model. Experimental results show that our method outperforms previous studies, and the F1-score is increased more than 10% in some situations. Moreover, because the knowledge segments are automatically retrieved, our method does not require additional manual labeling, and the knowledge set can be freely adjusted. These show that our method can help detect mental health conditions and can be continuously optimized in practice.'},\n",
       " '10.1016/j.eswa.2022.117588': {'title': 'Cross-document attention-based gated fusion network for automated medical licensing exam',\n",
       "  'abstract': 'One of the applications of machine-learning in the medical industry is to automatically learn knowledge from medical textbooks and transfer medical knowledge into diagnosis abilities. Because of complex nature of medical issues, the learning process usually requires multiple knowledge documents to form a comprehensive reasoning chain for diagnosis, which increases the difficulty of the automatic learning process. Existing models for multiple document comprehension either concatenate multiple documents together for inference or reason on every document independently. In this paper, we propose a Co-Attention-based Multi-document Inference (CAMI) framework for better reasoning over multiple documents. The proposed framework makes use of not only the attentional information among questions, answers and support documents but also the complementary attentional information across different documents. In addition, a gated fusion network is designed to fuse the cross-document information. The proposed model outperforms the state-of-the-art methods on Chinese National Medical Licensing Examination (CNMLE) dataset, ClinicQA, which contains 27,432 plain text documents and 13,827 CNMLE questions. We intend to make it publicly available as the first clinical OpenQA dataset. • A CAMI frame is proposed to tackle the OpenQA medical MRC tasks. • The proposed CDCA could extract the attentional information across documents. • The proposed HGFN could dynamically fuse information from multiple documents. • The proposed ClinicQA is the first public dataset to evaluate clinical diagnosis ability. • The proposed method greatly outperforms SOTA openQA medical MRC models.'},\n",
       " '10.1007/978-3-031-18315-7_16': {'title': 'TCM-SD: A Benchmark for Probing Syndrome Differentiation via Natural Language Processing',\n",
       "  'abstract': 'Traditional Chinese Medicine (TCM) is a natural, safe, and effective therapy that has spread and been applied worldwide. The unique TCM diagnosis and treatment system requires a comprehensive analysis of a patient’s symptoms hidden in the clinical record written in free text. Prior studies have shown that this system can be informationized and intelligentized with the aid of artificial intelligence (AI) technology, such as natural language processing (NLP). However, existing datasets are not of sufficient quality nor quantity to support the further development of data-driven AI technology in TCM. Therefore, in this paper, we focus on the core task of the TCM diagnosis and treatment system—syndrome differentiation (SD)—and we introduce the first public large-scale benchmark for SD, called TCM-SD. Our benchmark contains 54,152 real-world clinical records covering 148 syndromes. Furthermore, we collect a large-scale unlabelled textual corpus in the field of TCM and propose a domain-specific pre-trained language model, called ZY-BERT. We conducted experiments using deep neural networks to establish a strong performance baseline, reveal various challenges in SD, and prove the potential of domain-specific pre-trained language model. Our study and analysis reveal opportunities for incorporating computer science and linguistics knowledge to explore the empirical validity of TCM theories.'},\n",
       " '10.1002/ctd2.29': {'title': 'Prostate cancer management with lifestyle intervention: From knowledge graph to Chatbot',\n",
       "  'abstract': 'Abstract Background Personal lifestyle is an important cause of prostate cancer (PCa), hence establishing a corresponding knowledge graph (KG) and a chatbot is a convenient way for preventing and assessing risks. The chatbot based on a KG of PCa‐associated lifestyles will be helpful to PCa management, then save health care resources in the ageing society. Results Based on our established knowledge base, we define entities and corresponding relationships to construct the PCa‐associated lifestyles KG for visualization by importing the triples into the Neo4j graph server. The dialogue system uses the Flask framework to determine the classification of questions through entity recognition and relationship extraction and later uses the query template to search the answers from the PCa‐associated lifestyles KG. The PCa‐associated lifestyles KG contains 11 types of entities and 14 types of relationships, the total number of nodes and links is 21 546 and 66 493, respectively. Also, the entity “Lifestyle”, “Paper”, “Baseline” and “Outcome” contain multiple attributes. The established chatbot can answer 12 types of basic questions and predict the probability of a certain lifestyle resulting in a certain PCa. The chatbot is available at http://sysbio.org.cn:5000/Pca/chatbot . Conclusion A chatbot based on PCa‐associated lifestyles KG was constructed to help researchers, physicians or patients learn more about PCa lifestyle management interactively.'},\n",
       " '10.1016/j.neucom.2021.06.076': {'title': 'SKR-QA: Semantic ranking and knowledge revise for multi-choice question answering',\n",
       "  'abstract': 'Knowledge has long been cosnsidered a crucial part of natural language understanding. Many knowledge bases have been constructed, but none of them will ever be complete. Nevertheless, we argue that complete knowledge already exists in natural language. Most previous work on question answering retrieved such knowledge using traditional statistical methods, and consequently, the knowledge retrieved contained co-occurring phrases and could not provide guidance for model understanding and reasoning. Therefore, in addition to demonstrating the effectiveness of natural language knowledge in machine understanding, this study presents a novel knowledge retrieval approach that evaluates the importance of knowledge from a semantic perspective. Furthermore, we propose a knowledge revise mechanism that allows the model to revise the retrieved knowledge from local and global perspectives. We demonstrate our Semantic-rank-and-Knowledge-Revise-based Question Answering (SKR-QA) approach on two challenging multi-choice question and answering tasks: ARC–Challenge and OpenbookQA. Compared with the previous State-of-the-Art (SOTA) models, our work achieves consistent improvements. Moreover, the knowledge obtained by our method is more conducive to machine understanding, thus providing certain interpretability.'},\n",
       " '10.1007/978-3-030-43887-6_64': {'title': 'Pre-trained Language Model for Biomedical Question Answering',\n",
       "  'abstract': 'The recent success of question answering systems is largely attributed to pre-trained language models. However, as language models are mostly pre-trained on general domain corpora such as Wikipedia, they often have difficulty in understanding biomedical questions. In this paper, we investigate the performance of BioBERT, a pre-trained biomedical language model, in answering biomedical questions including factoid, list, and yes/no type questions. BioBERT uses almost the same structure across various question types and achieved the best performance in the 7th BioASQ Challenge (Task 7b, Phase B). BioBERT pre-trained on SQuAD or SQuAD 2.0 easily outperformed previous state-of-the-art models. BioBERT obtains the best performance when it uses the appropriate pre-/post-processing strategies for questions, passages, and answers.'},\n",
       " '10.1186/s12859-015-0564-6': {'title': 'An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition',\n",
       "  'abstract': 'This article provides an overview of the first BIOASQ challenge, a competition on large-scale biomedical semantic indexing and question answering (QA), which took place between March and September 2013. BIOASQ assesses the ability of systems to semantically index very large numbers of biomedical scientific articles, and to return concise and user-understandable answers to given natural language questions by combining information from biomedical articles and ontologies.The 2013 BIOASQ competition comprised two tasks, Task 1a and Task 1b. In Task 1a participants were asked to automatically annotate new PUBMED documents with MESH headings. Twelve teams participated in Task 1a, with a total of 46 system runs submitted, and one of the teams performing consistently better than the MTI indexer used by NLM to suggest MESH headings to curators. Task 1b used benchmark datasets containing 29 development and 282 test English questions, along with gold standard (reference) answers, prepared by a team of biomedical experts from around Europe and participants had to automatically produce answers. Three teams participated in Task 1b, with 11 system runs. The BIOASQ infrastructure, including benchmark datasets, evaluation mechanisms, and the results of the participants and baseline methods, is publicly available.A publicly available evaluation infrastructure for biomedical semantic indexing and QA has been developed, which includes benchmark datasets, and can be used to evaluate systems that: assign MESH headings to published articles or to English questions; retrieve relevant RDF triples from ontologies, relevant articles and snippets from PUBMED Central; produce \"exact\" and paragraph-sized \"ideal\" answers (summaries). The results of the systems that participated in the 2013 BIOASQ competition are promising. In Task 1a one of the systems performed consistently better from the NLM\\'s MTI indexer. In Task 1b the systems received high scores in the manual evaluation of the \"ideal\" answers; hence, they produced high quality summaries as answers. Overall, BIOASQ helped obtain a unified view of how techniques from text classification, semantic indexing, document and passage retrieval, question answering, and text summarization can be combined to allow biomedical experts to obtain concise, user-understandable answers to questions reflecting their real information needs.'},\n",
       " '10.1007/978-3-319-24471-6_3': {'title': 'BioASQ: A Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering',\n",
       "  'abstract': 'BioASQ is a series of challenges that aims to assess the performance of information systems in supporting two tasks that are central to the biomedical question answering process: (a) the indexing of large volumes of unlabelled data, primarily scientific articles, with biomedical concepts, (b) the processing of biomedical questions and the generation of answers and supporting material. In this paper, the main results of the first two BioASQ challenges are presented.'},\n",
       " '10.1016/j.patcog.2024.110294': {'title': 'Progressive modality-complement aggregative multitransformer for domain multi-modal neural machine translation',\n",
       "  'abstract': 'Domain-specific Multi-modal Neural Machine Translation (DMNMT) aims to translate domain-specific sentences from a source language to a target language by incorporating text-related visual information. Generally, domain-specific text-image data often complement each other and have the potential to collaboratively enhance the representation of domain-specific information. Unfortunately, there is a considerable modality gap between image and text in data format and semantic expression, which leads to distinctive challenges in domain-text translation tasks. Narrowing the modality gap and improving domain-aware representation are two critical challenges in DMNMT. To this end, this paper proposes a progressive modality-complement aggregative MultiTransformer, which aims to simultaneously narrow the modality gap and capture domain-specific multi-modal representation. We first adopt a bidirectional progressive cross-modal interactive strategy to effectively narrow the text-to-text, text-to-visual, and visual-to-text semantics in the multi-modal representation space by integrating visual and text information layer-by-layer. Subsequently, we introduce a modality-complement MultiTransformer based on progressive cross-modal interaction to extract the domain-related multi-modal representation, thereby enhancing machine translation performance. Experiment results on the Fashion-MMT and Multi-30k datasets are conducted, and the results show that the proposed approach outperforms the compared state-of-the-art (SOTA) methods on the En-Zh task in E-commerce domain, En-De, En-Fr and En-Cs tasks of Multi-30k in general domain. The in-depth analysis confirms the validity of the proposed modality-complement MultiTransformer and bidirectional progressive cross-modal interactive strategy for DMNMT.'},\n",
       " '10.1016/j.phycom.2023.102253': {'title': 'Filtered data augmentation approach based on model competence evaluation',\n",
       "  'abstract': 'The scale of parallel corpus plays an important role in training high-quality neural machine translation models. In order to expand the scale of parallel corpus in low-resource scenarios, researchers have proposed a series of data augmentation approaches, in which the most representative work is the back-translation. The back-translation approach uses a basic translation model to translate the target monolingual corpus into the source language, and then combines it into a pseudo parallel corpus to expand the training data. Due to the simple and efficient data expansion strategies, the back-translation approach becomes the mainstream data augmentation approach of neural machine translation. However, in low-resource scenarios, only low-precision basic translation models can be used. The pseudo-parallel corpus translated by this model contains low-quality sentence pairs, which inevitably introduces noises and leads to negative impacts to translation procedure. To improve the performance of low-resource neural machine translation, we propose a filtered data augmentation method based on the model competence evaluation, which can effectively improve the quality of training data by using both the filtered back-translation and dynamic evaluation of translation model capabilities. Comparative experiments show that the proposed approach can improve the quality of training data and the performance of low-resource neural machine translation.'},\n",
       " '10.1016/j.knosys.2023.110838': {'title': 'A commonsense-infused language-agnostic learning framework for enhancing prediction of political bias in multilingual news headlines',\n",
       "  'abstract': 'Predicting the political bias of news headlines is a challenging task that becomes even more challenging in a multilingual setting with low-resource languages. To deal with this, we propose to utilise Inferential Commonsense Knowledge via a Translate-Retrieve-Translate strategy to introduce a learning framework. To begin with, we use the translate-retrieve-translate strategy to acquire inferential knowledge in the target language. We then employ an attention mechanism to emphasise important inferences. We finally integrate the attended inferences into a multilingual, pre-trained language model for the task of bias prediction. To evaluate the effectiveness of our framework, we present a dataset of over 62.6K multilingual news headlines annotated with their respective political biases in five low-resource European languages. We evaluate several state-of-the-art multilingual pre-trained language models since their performance tends to vary across languages (low or high resource). Evaluation results demonstrate that our proposed framework is effective regardless of the models employed. Overall, the best-performing model trained with only headlines shows 0.90 accuracy and F1 and a 0.83 Jaccard score. With attended knowledge in our framework, the same model shows an increase in 2.2% accuracy and F1 and a 3.6% Jaccard score. Extending our experiments to individual languages reveals that the models we analyse for Slovenian perform significantly worse than other languages in our dataset. To investigate this, we assess the effect of translation quality on prediction performance. It indicates that the disparity in performance is most likely due to poor translation quality. We release our dataset and scripts at https://github.com/Swati17293/KG-Multi-Bias for future research. Our framework has the potential to benefit journalists, social scientists, news producers, and consumers.'},\n",
       " '10.1016/j.knosys.2022.109861': {'title': 'PU-GEN: Enhancing generative commonsense reasoning for language models with human-centered knowledge',\n",
       "  'abstract': 'Generative commonsense reasoning refers to the ability of a language model to generate a sentence with a given concept-set based on compositional generalization and commonsense reasoning. In the CommonGen challenge, which evaluates the capability of generative commonsense reasoning, language models continue to exhibit low performances and struggle to leverage knowledge representation from humans. Therefore, we propose PU-GEN to leverage human-centered knowledge in language models to enhance compositional generalization and commonsense reasoning considering the human language generation process. To incorporate human-centered knowledge, PU-GEN reinterprets two linguistic philosophies from Wittgenstein: picture theory and use theory. First, we retrieve scene knowledge to reflect picture theory such that a model can describe a general situation as if it were being painted. Second, we extend relational knowledge to consider use theory for understanding various contexts. PU-GEN demonstrates superior performance in qualitative and quantitative evaluations over baseline models in CommonGen and generates convincing evidence for CommonsenseQA. Moreover, it outperforms the state-of-the-art model used in the previous CommonGen challenge.'},\n",
       " '10.1016/j.artint.2022.103740': {'title': 'ASER: Towards large-scale commonsense knowledge acquisition via higher-order selectional preference over eventualities',\n",
       "  'abstract': 'Commonsense knowledge acquisition and reasoning have long been a core artificial intelligence problem. However, in the past, there has been a lack of scalable methods to collect commonsense knowledge. In this paper, we propose to develop principles for collecting commonsense knowledge based on selectional preference, which is a common phenomenon in human languages that has been shown to be related to semantics. We generalize the definition of selectional preference from one-hop linguistic syntactic relations to higher-order relations over linguistic graphs. Unlike previous commonsense knowledge definitions (e.g., ConceptNet), the selectional preference (SP) knowledge only relies on statistical distributions over linguistic graphs, which can be efficiently and accurately acquired from the unlabeled corpora with modern tools, rather than human-defined relations. As a result, acquiring SP knowledge is a much more scalable way of acquiring commonsense knowledge. Following this principle, we develop a large-scale eventuality (a linguistic term covering activity, state, and event)-based knowledge graph ASER, where each eventuality is represented as a dependency graph, and the relation between them is a discourse relation defined in shallow discourse parsing. The higher-order selectional preference over collected linguistic graphs reflects various kinds of commonsense knowledge. For example, dogs are more likely to bark than cats as the eventuality \"dog barks\" appears 14,998 times in ASER while \"cat barks\" only appears 6 times. \"Be hungry\" is more likely to be the reason rather than result of \"eat food\" as the edge 〈\"be hungry,\" Cause, \"eat food\"〉 appears in ASER while 〈\"eat food,\" Cause, \"be hungry\"〉 does not. Moreover, motivated by the observation that humans understand events by abstracting the observed events to a higher level and can thus transfer their knowledge to new events, we propose a conceptualization module on top of the collected knowledge to significantly boost the coverage of ASER. In total, ASER contains 648 million edges between 438 million eventualities. After conceptualization with Probase, a selectional preference based concept-instance relational knowledge base, our concept graph contains 15 million conceptualized eventualities and 224 million edges between them. Detailed analysis is provided to demonstrate its quality. All the collected data, APIs, and tools that can help convert collected SP knowledge into the format of ConceptNet are available at https://github.com/HKUST-KnowComp/ASER.'},\n",
       " '10.1016/J.KNOSYS.2021.107347': {'title': 'Dimensions of commonsense knowledge',\n",
       "  'abstract': 'Commonsense knowledge is essential for many AI applications, including those in natural language processing, visual processing, and planning. Consequently, many sources that include commonsense knowledge have been designed and constructed over the past decades. Recently, the focus has been on large text-based sources, which facilitate easier integration with neural (language) models and application to textual tasks, typically at the expense of the semantics of the sources and their harmonization. Efforts to consolidate commonsense knowledge have yielded partial success, with no clear path towards a comprehensive solution. We aim to organize these sources around a common set of dimensions of commonsense knowledge. We survey a wide range of popular commonsense sources with a special focus on their relations. We consolidate these relations into 13 knowledge dimensions. This consolidation allows us to unify the separate sources and to compute indications of their coverage, overlap, and gaps with respect to the knowledge dimensions. Moreover, we analyze the impact of each dimension on downstream reasoning tasks that require commonsense knowledge, observing that the temporal and desire/goal dimensions are very beneficial for reasoning on current downstream tasks, while distinctness and lexical knowledge have little impact. These results reveal preferences for some dimensions in current evaluation, and potential neglect of others.'},\n",
       " '10.1016/J.ARTINT.2018.07.007': {'title': 'Explanation in artificial intelligence: Insights from the social sciences',\n",
       "  'abstract': \"There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a ‘good’ explanation. There exist vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations to the explanation process. This paper argues that the field of explainable artificial intelligence can build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.\"},\n",
       " '10.1016/j.tins.2013.07.001': {'title': 'Sugar for the brain: the role of glucose in physiological and pathological brain function',\n",
       "  'abstract': 'The mammalian brain depends upon glucose as its main source of energy, and tight regulation of glucose metabolism is critical for brain physiology. Consistent with its critical role for physiological brain function, disruption of normal glucose metabolism as well as its interdependence with cell death pathways forms the pathophysiological basis for many brain disorders. Here, we review recent advances in understanding how glucose metabolism sustains basic brain physiology. We synthesize these findings to form a comprehensive picture of the cooperation required between different systems and cell types, and the specific breakdowns in this cooperation that lead to disease.'},\n",
       " '10.1016/j.tics.2006.08.004': {'title': 'The structure and function of explanations',\n",
       "  'abstract': \"Generating and evaluating explanations is spontaneous, ubiquitous and fundamental to our sense of understanding. Recent evidence suggests that in the course of an individual's reasoning, engaging in explanation can have profound effects on the probability assigned to causal claims, on how properties are generalized and on learning. These effects follow from two properties of the structure of explanations: explanations accommodate novel information in the context of prior beliefs, and do so in a way that fosters generalization. The study of explanation thus promises to shed light on core cognitive issues, such as learning, induction and conceptual representation. Moreover, the influence of explanation on learning and inference presents a challenge to theories that neglect the roles of prior knowledge and explanation-based reasoning. Generating and evaluating explanations is spontaneous, ubiquitous and fundamental to our sense of understanding. Recent evidence suggests that in the course of an individual's reasoning, engaging in explanation can have profound effects on the probability assigned to causal claims, on how properties are generalized and on learning. These effects follow from two properties of the structure of explanations: explanations accommodate novel information in the context of prior beliefs, and do so in a way that fosters generalization. The study of explanation thus promises to shed light on core cognitive issues, such as learning, induction and conceptual representation. Moreover, the influence of explanation on learning and inference presents a challenge to theories that neglect the roles of prior knowledge and explanation-based reasoning.\"},\n",
       " '10.1007/978-3-319-77182-3_7': {'title': 'Explanation Scaffolds Causal Learning and Problem Solving in Childhood',\n",
       "  'abstract': 'Explanation provides a window into what children know and scaffolds causal learning. Here we review research on the contributions of explanation to causal knowledge acquisition and problem solving. We discuss evidence that generating explanations enhances children’s understanding of causal mechanisms and increases their persistence and skill in applying new knowledge to novel contexts. In this way, explanation operates as a tool for learning and is particularly effective in the context of explaining inconsistent or ambiguous information. Explanation also enhances problem solving by allowing children to articulate their knowledge, a process which makes gaps in their current knowledge salient. The process of generating and requesting explanations facilitates the transmission of information and often occurs during interactions with others. We discuss the social context of explanation and the implications for belief revision and for building new knowledge. Explanation works in tandem with discovery-oriented behaviors like question asking and exploration to drive causal learning and improve problem solving.'},\n",
       " '10.1007/978-981-99-7022-3_23': {'title': 'Prompting GPT-3.5 for Text-to-SQL with De-semanticization and Skeleton Retrieval',\n",
       "  'abstract': 'Text-to-SQL is a task that converts a natural language question into a structured query language (SQL) to retrieve information from a database. Large language models (LLMs) work well in natural language generation tasks, but they are not specifically pre-trained to understand the syntax and semantics of SQL commands. In this paper, we propose an LLM-based framework for Text-to-SQL which retrieves helpful demonstration examples to prompt LLMs. However, questions with different database schemes can vary widely, even if the intentions behind them are similar and the corresponding SQL queries exhibit similarities. Consequently, it becomes crucial to identify the appropriate SQL demonstrations that align with our requirements. We design a de-semanticization mechanism that extracts question skeletons, allowing us to retrieve similar examples based on their structural similarity. We also model the relationships between question tokens and database schema items (i.e., tables and columns) to filter out scheme-related information. Our framework adapts the range of the database schema in prompts to balance length and valuable information. A fallback mechanism allows for a more detailed schema to be provided if the generated SQL query fails. Ours outperforms state-of-the-art models and demonstrates strong generalization ability on three cross-domain Text-to-SQL benchmarks.'},\n",
       " '10.1007/s10796-022-10295-0': {'title': 'Knowledge Graph and Deep Learning-based Text-to-GraphQL Model for Intelligent Medical Consultation Chatbot',\n",
       "  'abstract': \"Abstract Text-to-GraphQL (Text2GraphQL) is a task that converts the user's questions into Graph + QL (Query Language) when a graph database is given. That is a task of semantic parsing that transforms natural language problems into logical expressions, which will bring more efficient direct communication between humans and machines. The existing related work mainly focuses on Text-to-SQL tasks, and there is no available semantic parsing method and data set for the graph database. In order to fill the gaps in this field to serve the medical Human–Robot Interactions (HRI) better, we propose this task and a pipeline solution for the Text2GraphQL task. This solution uses the Adapter pre-trained by “the linking of GraphQL schemas and the corresponding utterances” as an external knowledge introduction plug-in. By inserting the Adapter into the language model, the mapping between logical language and natural language can be introduced faster and more directly to better realize the end-to-end human–machine language translation task. In the study, the proposed Text2GraphQL task model is mainly constructed based on an improved pipeline composed of a Language Model, Pre-trained Adapter plug-in, and Pointer Network. This enables the model to copy objects' tokens from utterances, generate corresponding GraphQL statements for graph database retrieval, and builds an adjustment mechanism to improve the final output. And the experiments have proved that our proposed method has certain competitiveness on the counterpart datasets (Spider, ATIS, GeoQuery, and 39.net) converted from the Text2SQL task, and the proposed method is also practical in medical scenarios.\"},\n",
       " '10.1007/978-3-030-73197-7_19': {'title': 'An Interactive NL2SQL Approach with Reuse Strategy',\n",
       "  'abstract': \"This paper studies a recently proposed task that maps contextual natural language questions to SQL queries in a multi-turn interaction. Instead of synthesizing an SQL query in an end-to-end way, we propose a new model which first generates an SQL grammar tree, called Tree-SQL, as the intermediate representation, and then infers an SQL query from the Tree-SQL with domain knowledge. For semantic dependency among context-dependent questions, we propose a reuse strategy that assigns a probability for each sub-tree of historical Tree-SQLs. On the challenging contextual Text-to-SQL benchmark SParC ( https://yale-lily.github.io/sparc ) with the 'value selection' task which includes values in queries, our approach achieves SOTA accuracy of 48.5% in question execution accuracy and 21.6% in interaction execution accuracy. In addition, we experimentally demonstrate the significant improvements on the reuse strategy.\"},\n",
       " '10.1007/978-3-030-86517-7_21': {'title': 'An Optimized NL2SQL System for Enterprise Data Mart',\n",
       "  'abstract': \"Natural language interfaces to databases is a growing field that enables end users to interact with relational databases without technical database skills. These interfaces solve the problem of synthesizing SQL queries based on natural language input from the user. There are considerable research interests around the topic but there are few systems to date that are deployed on top of an active enterprise data mart. We present our NL2SQL system designed for the banking sector, which can generate a SQL query from a user's natural language question. The system is comprised of the NL2SQL model we developed, as well as the data simulation and the adaptive feedback framework to continuously improve model performance. The architecture of this NL2SQL model is built on our research on WikiSQL data, which we extended to support multitable scenarios via our unique table expand process. The data simulation and the feedback loop help the model continuously adjust to linguistic variation introduced by the domain specific knowledge.\"},\n",
       " '10.1007/978-3-030-88244-0_10': {'title': 'COMBINE: A Pipeline for SQL Generation from Natural Language',\n",
       "  'abstract': 'Accessing data stored in relational databases requires an understanding of the database schema and mainly a query language such as SQL, which, while powerful, is difficult to master. In this sense, recent researches try to approach systems to facilitate this task, in particular by making Text-to-SQL models that attempt to map a question in Natural Language (NL) to the corresponding SQL query. In this paper, we present COMBINE, a pipeline for SQL generation from NL, in which we combine two existing models, RATSQL (We used the version RATSQL v3+BERT; paper’s url: arxiv.org/abs/1911.04942.) and BRIDGE (We used the version BRIDGE v1+BERT; paper’s url: aclweb.org/anthology/2020.findings-emnlp.438/.), that are based on recent advances in Deep Learning (DL) for Natural Language Processing (NLP). Our model is evaluated on the Spider challenge, using Exact Matching Accuracy (EMA) and Execution Accuracy (EA) metrics. Our experimental evaluation demonstrates that COMBINE outperforms the two used models in the same challenge, and at the time of writing, achieving the state of the art in EA with 70%, and competitive result in EMA with 71.4%, on Spider Dev Set.'},\n",
       " '10.1007/978-3-319-00065-7_28': {'title': 'Learning to Parse Natural Language Commands to a Robot Control System',\n",
       "  'abstract': 'As robots become more ubiquitous and capable of performing complex tasks, the importance of enabling untrained users to interact with them has increased. In response, unconstrained natural-language interaction with robots has emerged as a significant research area. We discuss the problem of parsing natural language commands to actions and control structures that can be readily implemented in a robot execution system. Our approach learns a parser based on example pairs of English commands and corresponding control language expressions. We evaluate this approach in the context of following route instructions through an indoor environment, and demonstrate that our system can learn to translate English commands into sequences of desired actions, while correctly capturing the semantic intent of statements involving complex control structures. The procedural nature of our formal representation allows a robot to interpret route instructions online while moving through a previously unknown environment.'},\n",
       " '10.1016/j.patcog.2024.110511': {'title': 'Memory-Adaptive Vision-and-Language Navigation',\n",
       "  'abstract': 'Vision-and-Language Navigation (VLN) requests an agent to navigate in 3D environments following given instructions, where history is critical for decision-making in dynamic navigation process. Particularly, a memory bank storing histories is widely used in existing methods to incorporate with multimodel representations in current scenes for better decision-making. However, by weighting each history with a simple scalar, those methods cannot purely utilize the informative cues that co-exist with detrimental contents in each history, thereby inevitably introducing noises into decision-making. To that end, we propose a novel Memory-Adaptive Model (MAM) that can dynamically restrain the detrimental contents in histories for retaining contents that benefit navigation only. Specifically, two key modules, Visual and Textual Adaptive Modules, are designed to restrain history noises based on scene-related vision and text, respectively. A Reliability Estimator Module is further introduced to refine above adaptation operations. Our experiments on the widely used RxR and R2R datasets show that MAM outperforms its baseline method by 4.0%/2.5% and 2%/1% on the validation unseen/test split, respectively, wrt the SR metric.'},\n",
       " '10.1016/j.knosys.2024.111437': {'title': 'Adaptive knowledge distillation and integration for weakly supervised referring expression comprehension',\n",
       "  'abstract': \"Weakly supervised referring expression comprehension (REC) aims to ground target objects in images according to given referring expressions, while the mappings between image regions and referring expressions are unavailable during the model training phase. Existing models typically reconstruct the multimodal relationships to ground targets by utilizing off-the-shelf information, and ignore to further exploit helpful knowledge to enhance the model performance. To address this issue, we propose an adaptive knowledge distillation architecture to enrich the predominant pattern of weakly supervised REC and transfer the target-aware and interaction-aware knowledge from a pre-trained teacher grounder to enhance the grounding performance of the student model. Specifically, in order to encourage the teacher to impart more reliable knowledge, we present a Knowledge Confidence-Based Adaptive Temperature (KCAT) learning approach to learn optimal temperatures to transfer the target-aware and interaction-aware knowledge with higher prediction confidence. Moreover, to urge the student to absorb more helpful knowledge, we introduce a Student Competency-Based Adaptive Weight (SCAW) learning strategy to dynamically integrate the distilled target-aware and interaction-aware knowledge to enhance the student's grounding certainty. We conduct extensive experiments on three benchmark datasets, RefCOCO, RefCOCO+, and RefCOCOg, to validate the proposed approach. Experimental results demonstrate that our approach achieves superior performance over state-of-the-art methods with the aid of adaptive knowledge distillation and integration. The code and trained models are available at: https://github.com/dami23/WREC_AdaptiveKD.\"},\n",
       " '10.1016/j.knosys.2023.110785': {'title': 'Coarse-to-fine fusion for language grounding in 3D navigation',\n",
       "  'abstract': 'We present a new network whereby an agent navigates in the 3D environment to find a target object according to a language-based instruction. Such a task is challenging because the agent has to understand the instruction correctly and takes a series of actions to locate a target among others without colliding with obstacles. The essence of our proposed network consists of a coarse-to-fine fusion model to fuse language and vision and an autoencoder to encode visual information effectively. Then, an asynchronous reinforcement learning algorithm is used to coordinate detailed actions to complete the navigation task. Extensive evaluation using three different levels of the navigation task in the 3D Vizdoom environment suggests that our model outperforms the state-of-the-art. To see if the proposed network can deal with a real-world 3D environment for the navigation task, it is combined with Rec-BERT, which is based on REVERIE. The result suggests that it performs better, especially for unseen cases, and it is also useful to visualize what and when the agent pays attention to while it navigates in a complex indoor environment.'},\n",
       " '10.1007/978-3-031-20074-8_18': {'title': 'A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility',\n",
       "  'abstract': 'Vision-language navigation (VLN), in which an agent follows language instruction in a visual environment, has been studied under the premise that the input command is fully feasible in the environment. Yet in practice, a request may not be possible due to language ambiguity or environment changes. To study VLN with unknown command feasibility, we introduce a new dataset Mobile app Tasks with Iterative Feedback (MoTIF), where the goal is to complete a natural language command in a mobile app. Mobile apps provide a scalable domain to study real downstream uses of VLN methods. Moreover, mobile app commands provide instruction for interactive navigation, as they result in action sequences with state changes via clicking, typing, or swiping. MoTIF is the first to include feasibility annotations, containing both binary feasibility labels and fine-grained labels for why tasks are unsatisfiable. We further collect follow-up questions for ambiguous queries to enable research on task uncertainty resolution. Equipped with our dataset, we propose the new problem of feasibility prediction, in which a natural language instruction and multimodal app environment are used to predict command feasibility. MoTIF provides a more realistic app dataset as it contains many diverse environments, high-level goals, and longer action sequences than prior work. We evaluate interactive VLN methods using MoTIF, quantify the generalization ability of current approaches to new app environments, and measure the effect of task feasibility on navigation performance.'},\n",
       " '10.1007/978-3-031-20059-5_22': {'title': 'Multimodal Transformer with Variable-Length Memory for Vision-and-Language Navigation',\n",
       "  'abstract': 'Vision-and-Language Navigation (VLN) is a task that an agent is required to follow a language instruction to navigate to the goal position, which relies on the ongoing interactions with the environment during moving. Recent Transformer-based VLN methods have made great progress benefiting from the direct connections between visual observations and language instructions via the multimodal cross-attention mechanism. However, these methods usually represent temporal context as a fixed-length vector by using an LSTM decoder or using manually designed hidden states to build a recurrent Transformer. Considering a single fixed-length vector is often insufficient to capture long-term temporal context, in this paper, we introduce Multimodal Transformer with Variable-length Memory (MTVM) for visually-grounded natural language navigation by modeling the temporal context explicitly. Specifically, MTVM enables the agent to keep track of the navigation trajectory by directly storing activations in the previous time step in a memory bank. To further boost the performance, we propose a memory-aware consistency loss to help learn a better joint representation of temporal context with random masked instructions. We evaluate MTVM on popular R2R and CVDN datasets. Our model improves Success Rate on R2R test set by 2% and reduces Goal Process by 1.5 m on CVDN test set. Code is available at: https://github.com/clin1223/MTVM .'},\n",
       " '10.1007/978-3-031-44696-2_36': {'title': 'A Text-Image Pair Is Not Enough: Language-Vision Relation Inference with Auxiliary Modality Translation',\n",
       "  'abstract': 'The semantic relations between language and vision modalities become more and more vital since they can effectively facilitate downstream multi-modal tasks. Although several approaches have been proposed to handle language-vision relation inference (LVRI), they normally rely on the limited information of the posted text-image pair. In this paper, to extend the information width of the original input, we introduce a concept of modality translation and propose the auxiliary modality translation framework (AMT) for LVRI. Specifically, the original input and the text pair (original and generated) are passed into two separate multi-layer bidirectional transformer structures respectively. The different linguistic and visual hybrid features are extracted and subsequently feed into a feature fusion module followed by a classifier. Systematic experiments and extensive analysis demonstrate the effectiveness of our approach with auxiliary modality translation.'},\n",
       " '10.1007/978-3-031-20059-5_18': {'title': 'Learning Disentanglement with Decoupled Labels for Vision-Language Navigation',\n",
       "  'abstract': 'Vision-and-Language Navigation (VLN) requires an agent to follow complex natural language instructions and perceive the visual environment for real-world navigation. Intuitively, we find that instruction disentanglement for each viewpoint along the agent’s path is critical for accurate navigation. However, most methods only utilize the whole complex instruction or inaccurate sub-instructions due to the lack of accurate disentanglement as an intermediate supervision stage. To address this problem, we propose a new Disentanglement framework with Decoupled Labels (DDL) for VLN. Firstly, we manually extend the benchmark dataset Room-to-Room with landmark- and action-aware labels in order to provide fine-grained information for each viewpoint. Furthermore, to enhance the generalization ability, we propose a Decoupled Label Speaker module to generate pseudo-labels for augmented data and reinforcement training. To fully use the proposed fine-grained labels, we design a Disentangled Decoding Module to guide discriminative feature extraction and help alignment of multi-modalities. To reveal the generality of our proposed method, we apply it on a LSTM-based model and two recent Transformer-based models. Extensive experiments on two VLN benchmarks (i.e., R2R and R4R) demonstrate the effectiveness of our approach, achieving better performance than previous state-of-the-art methods.'},\n",
       " '10.1007/978-3-031-20059-5_16': {'title': 'ASSISTER: Assistive Navigation via Conditional Instruction Generation',\n",
       "  'abstract': 'We introduce a novel vision-and-language navigation (VLN) task of learning to provide real-time guidance to a blind follower situated in complex dynamic navigation scenarios. Towards exploring real-time information needs and fundamental challenges in our novel modeling task, we first collect a multi-modal real-world benchmark with in-situ Orientation and Mobility (O &M) instructional guidance. Subsequently, we leverage the real-world study to inform the design of a larger-scale simulation benchmark, thus enabling comprehensive analysis of limitations in current VLN models. Motivated by how sighted O &M guides seamlessly and safely support the awareness of individuals with visual impairments when collaborating on navigation tasks, we present ASSISTER, an imitation-learned agent that can embody such effective guidance. The proposed assistive VLN agent is conditioned on navigational goals and commands for generating instructional sentences that are coherent with the surrounding visual scene, while also carefully accounting for the immediate assistive navigation task. Altogether, our introduced evaluation and training framework takes a step towards scalable development of the next generation of seamless, human-like assistive agents.'},\n",
       " '10.1007/978-3-030-89820-5_3': {'title': 'Question Answering for Visual Navigation in Human-Centered Environments',\n",
       "  'abstract': 'In this paper, we propose an HISNav VQA dataset – a challenging dataset for a Visual Question Answering task that is aimed at the needs of Visual Navigation in human-centered environments. The dataset consists of images of various room scenes that were captured using the Habitat virtual environment and of questions important for navigation tasks using only visual information. We also propose a baseline for a HISNav VQA dataset, a Vector Semiotic Architecture, and demonstrate its performance. The Vector Semiotic Architecture is a combination of a Sign-Based World Model and Vector Symbolic Architectures. The Sign-Based World Model allows representing various aspects of an agent’s knowledge, and Vector Symbolic Architectures serve on a low computational level. The Vector Semiotic Architecture addresses the symbol grounding problem that plays an important role in the Visual Question Answering Task.'},\n",
       " '10.1007/978-3-030-58604-1_7': {'title': 'Beyond the Nav-Graph: Vision-and-Language Navigation in Continuous Environments',\n",
       "  'abstract': 'We develop a language-guided navigation task set in a continuous 3D environment where agents must execute low-level actions to follow natural language navigation directions. By being situated in continuous environments, this setting lifts a number of assumptions implicit in prior work that represents environments as a sparse graph of panoramas with edges corresponding to navigability. Specifically, our setting drops the presumptions of known environment topologies, short-range oracle navigation, and perfect agent localization. To contextualize this new task, we develop models that mirror many of the advances made in prior settings as well as single-modality baselines. While some transfer, we find significantly lower absolute performance in the continuous setting – suggesting that performance in prior ‘navigation-graph’ settings may be inflated by the strong implicit assumptions. Code at jacobkrantz.github.io/vlnce .'},\n",
       " '10.1007/978-3-030-58586-0_25': {'title': 'Environment-Agnostic Multitask Learning for Natural Language Grounded Navigation',\n",
       "  'abstract': 'Recent research efforts enable study for natural language grounded navigation in photo-realistic environments, e.g., following natural language instructions or dialog . However, existing methods tend to overfit training data in seen environments and fail to generalize well in previously unseen environments. To close the gap between seen and unseen environments, we aim at learning a generalized navigation model from two novel perspectives: (1) we introduce a multitask navigation model that can be seamlessly trained on both Vision-Language Navigation (VLN) and Navigation from Dialog History (NDH) tasks, which benefits from richer natural language guidance and effectively transfers knowledge across tasks; (2) we propose to learn environment-agnostic representations for the navigation policy that are invariant among the environments seen during training, thus generalizing better on unseen environments. Extensive experiments show that environment-agnostic multitask learning significantly reduces the performance gap between seen and unseen environments, and the navigation agent trained so outperforms baselines on unseen environments by 16% (relative measure on success rate) on VLN and 120% (goal progress) on NDH. Our submission to the CVDN leaderboard establishes a new state-of-the-art for the NDH task on the holdout test set. Code is available at https://github.com/google-research/valan .'},\n",
       " '10.1007/978-3-030-58558-7_38': {'title': 'Connecting Vision and Language with Localized Narratives',\n",
       "  'abstract': 'We propose Localized Narratives, a new form of multimodal image annotations connecting vision and language. We ask annotators to describe an image with their voice while simultaneously hovering their mouse over the region they are describing. Since the voice and the mouse pointer are synchronized, we can localize every single word in the description. This dense visual grounding takes the form of a mouse trace segment per word and is unique to our data. We annotated 849k images with Localized Narratives: the whole COCO, Flickr30k, and ADE20K datasets, and 671k images of Open Images, all of which we make publicly available. We provide an extensive analysis of these annotations showing they are diverse, accurate, and efficient to produce. We also demonstrate their utility on the application of controlled image captioning.'},\n",
       " '10.1007/s11263-015-0816-y': {'title': 'ImageNet Large Scale Visual Recognition Challenge',\n",
       "  'abstract': 'The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.'},\n",
       " '10.1016/j.cognition.2014.03.016': {'title': 'Mapping spatial frames of reference onto time: A review of theoretical accounts and empirical findings',\n",
       "  'abstract': 'When speaking and reasoning about time, people around the world tend to do so with vocabulary and concepts borrowed from the domain of space. This raises the question of whether the cross-linguistic variability found for spatial representations, and the principles on which these are based, may also carry over to the domain of time. Real progress in addressing this question presupposes a taxonomy for the possible conceptualizations in one domain and its consistent and comprehensive mapping onto the other-a challenge that has been taken up only recently and is far from reaching consensus. This article aims at systematizing the theoretical and empirical advances in this field, with a focus on accounts that deal with frames of reference (FoRs). It reviews eight such accounts by identifying their conceptual ingredients and principles for space-time mapping, and it explores the potential for their integration. To evaluate their feasibility, data from some thirty empirical studies, conducted with speakers of sixteen different languages, are then scrutinized. This includes a critical assessment of the methods employed, a summary of the findings for each language group, and a (re-)analysis of the data in view of the theoretical questions. The discussion relates these findings to research on the mental time line, and explores the psychological reality of temporal FoRs, the degree of cross-domain consistency in FoR adoption, the role of deixis, and the sources and extent of space-time mapping more generally.'},\n",
       " '10.1016/j.cognition.2010.12.009': {'title': 'Plasticity of human spatial cognition: Spatial language and cognition covary across cultures',\n",
       "  'abstract': 'The present paper explores cross-cultural variation in spatial cognition by comparing spatial reconstruction tasks by Dutch and Namibian elementary school children. These two communities differ in the way they predominantly express spatial relations in language. Four experiments investigate cognitive strategy preferences across different levels of task-complexity and instruction. Data show a correlation between dominant linguistic spatial frames of reference and performance patterns in non-linguistic spatial memory tasks. This correlation is shown to be stable across an increase of complexity in the spatial array. When instructed to use their respective non-habitual cognitive strategy, participants were not easily able to switch between strategies and their attempts to do so impaired their performance. These results indicate a difference not only in preference but also in competence and suggest that spatial language and non-linguistic preferences and competences in spatial cognition are systematically aligned across human populations.'},\n",
       " '10.1016/S0010-0277(01)00127-5': {'title': 'Spatial language and spatial representation: a cross-linguistic comparison',\n",
       "  'abstract': \"We examined the relationship between spatial language and spatial memory by comparing native English, Japanese, and Korean speakers' naming of spatial locations and their spatial memory for the same set of locations. We focused on two kinds of spatial organization: axial structure of the reference object, and contact/support with respect to its surface. The results of two language (naming) tasks showed similar organization across the three language groups in terms of axial structure, but differences in organization in terms of contact/support. In contrast, the results of two memory tasks were the same across language groups for both axial structure and contact/support. Moreover, the relationship between spatial language and spatial memory in the two sets of tasks did not show a straightforward isomorphism between the two systems. We conclude that spatial language and spatial memory engage the same kinds of spatial properties, suggesting similarity in the foundations of the two systems. However, the two systems appear to be partially independent: the preservation of particular spatial properties was not mandatory across languages, nor across memory tasks, and cross-linguistic differences in spatial language did not lead to differences in the non-linguistic encoding of location. We speculate that the similarity in linguistic and non-linguistic representations of space may emerge as a functional consequence of negotiating the spatial world.\"},\n",
       " '10.1007/s11063-024-11515-1': {'title': 'Multi-channels Prototype Contrastive Learning with Condition Adversarial Attacks for Few-shot Event Detection',\n",
       "  'abstract': 'Abstract Few-shot Event Detection (FSED) is a sub-task of Event Detection that aims to accurately identify event types with limited training instances and enable smooth transfer to newly-emerged event types. Recently, the dominant works have used the prototypical network to accomplish this task and employ contrastive learning to alleviate the issue of semantically-close categories. Nevertheless, these methods still suffer from two serious problems: (1) inadequate learning of prototype representations resulting from limited training data; (2) hard-easy sample imbalance and categories imbalance caused by the large number of non-trigger word(\"O\" tags) in the token-level classification task. To address the problems, this paper proposes the Multi-channels Prototype and Contrastive learning method with Conditional Adversarial attack, which introduces the improved multi-channels prototype and contrastive networks to alleviate the categories and hard-easy samples imbalance. Moreover, we devise a constrained adversarial attack to improve the problem of limited training data. Extensive experimental results show that our model performs better than other FSED methods. All the code and data will be available for online public access.'},\n",
       " '10.1016/j.knosys.2024.111410': {'title': 'Temporal relation extraction with contrastive prototypical sampling',\n",
       "  'abstract': 'Temporal relation extraction aims to infer the temporal order of either two events in the document. Because of the nature of events in real life, severe imbalanced temporal relation classes exist in the temporal relation extraction task. Even though various methods have been proposed to improve the overall performance, the accuracy of these methods on minority temporal classes is limited. In this work, we present a contrastive prototypical learning architecture to address this problem, which explicitly models the spatial similarity between instances in the embedding space so that instances from minority classes can be distinguished from the large classes. To make it compatible with current temporal relation extraction settings, we propose a novel sampling memory queue-based method so that the architecture can be applied to a limited batch size scenario. We further design a context encoding layer that incorporates both contextualized information and linguistic features such as tense information and dependency. Our extensive experiments on TimeBank-Dense, TDDiscourse, and MATRES datasets demonstrate that our model can significantly improve the performance of minority relation classes and, therefore increase the overall learning ability.'},\n",
       " '10.1016/j.ipm.2023.103469': {'title': 'Syntax-based dynamic latent graph for event relation extraction',\n",
       "  'abstract': 'This paper focuses on extracting temporal and parent–child relationships between news events in social news. Previous methods have proved that syntactic features are valid. However, most previous methods directly use the static outcomes parsed by syntactic parsing tools, but task-irrelevant or erroneous parses will inevitably degrade the performance of the model. In addition, many implicit higher-order connections that are directly related and critical to tasks are not explicitly exploited. In this paper, we propose a novel syntax-based dynamic latent graph model (SDLG) for this task. Specifically, we first apply a syntactic type-enhanced attention mechanism to assign different weights to different connections in the parsing results, which helps to filter out noisy connections and better fuse the information in the syntactic structures. Next, we introduce a dynamic event pair-aware induction graph to mine the task-related latent connections. It constructs a potential attention matrix to complement and correct the supervised syntactic features, using the semantics of the event pairs as a guide. Finally, the latent graph, together with the syntactic information, is fed into the graph convolutional network to obtain an improved representation of the event to complete relational reasoning. We have conducted extensive experiments on four public benchmarks, MATRES, TCR, HiEve and TB-Dense. The results show that our model outperforms the state-of-the-art model by 0.4%, 1.5%, 3.0% and 1.3% in F1 scores on the four datasets, respectively. Finally, we provide detailed analyses to show the effectiveness of each proposed component.'},\n",
       " '10.1016/j.neunet.2023.04.020': {'title': 'PIPER: A logic-driven deep contrastive optimization pipeline for event temporal reasoning',\n",
       "  'abstract': 'Event temporal relation extraction is an important task for information extraction. The existing methods usually rely on feature engineering and require post-process to achieve optimization, though inconsistent optimization may occur in the post-process module and main neural network due to their independence. Recently, a few works start to incorporate the temporal logic rules into the neural network and achieve joint optimization. However, these methods still suffer from two shortcomings: (1) Although the joint optimization is applied, the differences between rules are neglected in the unified design of rule losses and further the interpretability and flexibility of the design of model are reduced. (2) Because of lacking abundant syntactic connections between events and rule-match features, the performance of the model may be suppressed by the inefficient interaction in training between features and rules. To tackle these issues, this paper proposes PIPER, a logic-driven deep contrastive optimization pipeline for event temporal reasoning. Specifically, we apply joint optimization (including multi-stage and single-stage joint paradigms) by combining independent rule losses (i.e., flexibility) to make PIPER more interpretable. Also, by proposing a hierarchical graph distillation network to obtain more abundant syntactic information, the designed rule-match features can effectively aid in the interaction between low-level features and high-level rules during training. The final experiments on TB-Dense and MATRES demonstrate that the proposed model can achieve competitive performance compared with the recent advances.'},\n",
       " '10.1061/(asce)cp.1943-5487.0001014': {'title': 'Hierarchical Representation and Deep Learning–Based Method for Automatically Transforming Textual Building Codes into Semantic Computable Requirements',\n",
       "  'abstract': 'Most of the existing automated compliance checking (ACC) systems are unable to fully automatically convert building-code requirements, especially requirements that have hierarchically complex semantic and syntactic structures, into computer-processable forms. The state-of-the-art rule-based ACC methods that are able to deal with complex requirements are based on information extraction and transformation rules, which are inflexible when applied to different types of regulatory documents. More research is thus needed to develop a flexible method to automatically process and understand requirements to support the downstream tasks in ACC systems, such as information matching and compliance reasoning. To address this need, this paper proposes (1) a new representation of requirements, the requirement hierarchy, and (2) a deep learning-based method to automatically extract semantic relations between words from building-code sentences, which are used to transform the sentences into such hierarchies. The proposed method was evaluated using a corpus of sentences from multiple regulatory documents. It achieved high semantic relation and requirement hierarchy extraction performance.'},\n",
       " '10.1016/j.eswa.2024.123921': {'title': 'Self-supervised commonsense knowledge learning for document-level relation extraction',\n",
       "  'abstract': 'Compared to sentence-level relation extraction, practical document-level relation extraction (DocRE) is a more challenging task for which multi-entity problems need to be resolved. It aims at extracting relationships between two entities over multiple sentences at once while taking into account significant cross-sentence features. Learning long-distance semantic relation representation across sentences in a document, however, is a widespread and difficult task. To address the above issues, we propose a novel Self-supervised Commonsense-enhanced DocRE approach, named as SCDRE, bypassing the need for external knowledge. The methodology begins by harnessing self-supervised learning to capture the commonsense knowledge pertaining to each entity within an entity pair, drawing insights from the commonsense entailed text. This acquired knowledge subsequently serves as the foundation for transforming cross-sentence entity pairs into alias counterparts achieved by the coreference commonsense replacement. The focus then shifts to semantic relation representation learning, applied to these alias entity pairs. Through a process of entity pair rich attention fusion, these alias pairs are seamlessly and automatically translated back into the target entity pairs. This innovation harnesses self-supervised learning and contextual commonsense to distinguish SCDRE as a unique and self-contained approach, promising an enhanced ability to extract relationships from documents. We examine our model on three publicly accessible datasets, DocRED, DialogRE and MPDD, and the results show that it performs significantly better than strong baselines by 2.03% F1, and commonsense knowledge has an important contribution to the DocRE by the ablation experimental analysis.'},\n",
       " '10.1007/978-3-031-18315-7_12': {'title': 'Improving Event Temporal Relation Classification via Auxiliary Label-Aware Contrastive Learning',\n",
       "  'abstract': 'Event Temporal Relation Classification (ETRC) is crucial to natural language understanding. In recent years, the mainstream ETRC methods may not take advantage of lots of semantic information contained in golden temporal relation labels, which is lost by the discrete one-hot labels. To alleviate the loss of semantic information, we propose learning Temporal semantic information of the golden labels by Auxiliary Contrastive Learning (TempACL). Different from traditional contrastive learning methods, which further train the PreTrained Language Model (PTLM) with unsupervised settings before fine-tuning on target tasks, we design a supervised contrastive learning framework and make three improvements. Firstly, we design a new data augmentation method that generates augmentation data via matching templates established by us with golden labels. Secondly, we propose patient contrastive learning and design three patient strategies. Thirdly we design a label-aware contrastive learning loss function. Extensive experimental results show that our TempACL effectively adapts contrastive learning to supervised learning tasks which remain a challenge in practice. TempACL achieves new state-of-the-art results on TB-Dense and MATRES and outperforms the baseline model with up to 5.37% $$F_1$$ on TB-Dense and 1.81% $$F_1$$ on MATRES.'},\n",
       " '10.1007/978-3-031-17120-8_20': {'title': 'TEMPLATE: TempRel Classification Model Trained with Embedded Temporal Relation Knowledge',\n",
       "  'abstract': 'In recent years, the mainstream Temporal Relation (TempRel) classification methods may not take advantage of the large amount of semantic information contained in golden TempRel labels, which is lost by the traditional discrete one-hot labels. To solve this problem, we propose a new approach that can make full use of golden TempRel label information and make the model perform better. Firstly we build a TempRel Classification (TC) model, which consists of a RoBERTa and a Classifier. Secondly, we establish fine-grained templates to automatically generate sentences to enrich golden TempRel label information and build an Enhanced Data-set. Thirdly we use the Enhanced Data-set to train the Knowledge Encoder, which has the same structure as the TC model, and get embedded knowledge. Finally, we get a TC model Trained with EMbedded temPoral reLATion knowldgE (TEMPLATE) using our designed Cosine balanced MSE loss function. Extensive experimental results show that our approach achieves new state-of-the-art results on TB-Dense and MATRES and outperforms the TC model trained with only traditional cross entropy loss function with up to 5.51% $$F_1$$ on TB-Dense and 2.02% $$F_1$$ on MATRES.'},\n",
       " '10.1007/978-3-030-10997-4_1': {'title': 'Neural Article Pair Modeling for Wikipedia Sub-article Matching',\n",
       "  'abstract': 'Nowadays, editors tend to separate different subtopics of a long Wiki-pedia article into multiple sub-articles. This separation seeks to improve human readability. However, it also has a deleterious effect on many Wikipedia-based tasks that rely on the article-as-concept assumption, which requires each entity (or concept) to be described solely by one article. This underlying assumption significantly simplifies knowledge representation and extraction, and it is vital to many existing technologies such as automated knowledge base construction, cross-lingual knowledge alignment, semantic search and data lineage of Wikipedia entities. In this paper we provide an approach to match the scattered sub-articles back to their corresponding main-articles, with the intent of facilitating automated Wikipedia curation and processing. The proposed model adopts a hierarchical learning structure that combines multiple variants of neural document pair encoders with a comprehensive set of explicit features. A large crowdsourced dataset is created to support the evaluation and feature extraction for the task. Based on the large dataset, the proposed model achieves promising results of cross-validation and significantly outperforms previous approaches. Large-scale serving on the entire English Wikipedia also proves the practicability and scalability of the proposed model by effectively extracting a vast collection of newly paired main and sub-articles. Code related to this paper is available at: https://github.com/muhaochen/subarticle .'},\n",
       " '10.1016/j.eswa.2023.122699': {'title': 'Query-focused summarization with the context-graph information fusion transformer',\n",
       "  'abstract': 'Query-Focused Summarization (QFS) is a system that understands important information from a long document and generates them as a summary that can responds to the query. In QFS, how to properly utilize query information to generate a summary is a challenging problem. Existing Transformer-based QFS models, which is attending all words in the concatenation of a query and a document, result in inaccurate concentration on some unimportant words and they consequently cannot generate a good query-focused summary. This study proposes a Query-attentive Semantic Graph (QSG) that assists in identifying words related to the query, and a novel QFS model that generates a query-focused summary by appropriately fusing the contextual information of the language model with the structural information of QSG. In addition, we propose a novel personalized PageRank based graph neural network that computes each node’s importance score for the query inside QSG and utilizes it for node representation calculation. Experimental results on two QFS benchmarks show that the performance of the proposed model outperforms the simple Transformer-based model by large margins, as well as other state-of-the-art QFS.'},\n",
       " '10.1007/978-3-031-02141-1': {'title': 'Learning to Rank for Information Retrieval and Natural Language Processing',\n",
       "  'abstract': 'Learning to rank refers to machine learning techniques for training the model in a ranking task. Learning to rank is useful for many applications in information retrieval, natural language processing,'},\n",
       " '10.3115/1220835': {'title': 'Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics -',\n",
       "  'abstract': 'It is with pleasure that we preface the publications of the 2006 Human Language Technology conference --- North American chapter of the Association for Computational Linguistics annual meeting (HLTNAACL 2006). The conference has a number of formats by which refereed work can be presented: full papers, short papers (either as a talk or poster), and demonstrations. As befits this multi-disciplinary conference, papers were submitted across the three topics of computational linguistics, information retrieval and speech recognition. This year, 257 full papers were submitted and 62 accepted (25% acceptance rate), 127 short papers submitted and 52 accepted (41% rate). It is pleasing to report that these numbers mark a strong increase in submissions compared to the last HLT NAACL conference run in 2004.The selection of the high quality submissions in these proceedings was the product of a two tiered reviewing system. The three PC chairs selected 28 senior program committee (PC) members, who are internationally recognized for their subject expertise. This group constituted the top tier of the PC. Each of the members selected a group of reviewers to review both the full and short submitted papers. The complete PC numbered around 250. Three reviewers and one senior PC person were assigned per paper. Reviewing was double blinded. The senior PC oversaw the reviewing process, helped resolve any disputes, and at the end produced, for each paper, an overview of the reviewers\\' comments along with a preliminary decision on whether the submission should be accepted or not. These decisions formed the basis of discussion at a program committee meeting. Separate PC meetings were held for full and short papers. For full, a one day meeting was held at IBM Research Watson, NY; for short papers, a telephone conference call was held between the three PC chairs.The senior PC also nominated candidates for best paper and best student paper, the two selected for the prizes were chosen by the PC chairs working in conjunction with the senior PCs. The papers that won were \"Probabilistic Context-Free Grammar Induction Based on Structural Zeros\" by Mehryar Mohri and Brian Roark and \"Prototype-Driven Learning for Sequence Models\" by Aria Haghighi and Dan Klein. Congratulations to them both.'},\n",
       " '10.7232/jkiie.2022.48.2.235': {'title': 'KoBERTSEG: Local Context Based Topic Segmentation Using KoBERT',\n",
       "  'abstract': 'Topic segmentation refers to the work of separating a document consisting of several topics into unit documents, such as paragraphs, with one single topic. Topic segmentation has been considered as one of main preprocessing step prior to performing natural language processing tasks, such as document summary or document classification. This paper proposes a Korean BERT-based news article segmentation method aiming at separating a single news article, in which multiple subjects exist, into news segments, each of which contains a single subject. The proposed model has the advantage of being able to capture a wider range of semantic relationships compared to existing topic segmentation studies by borrowing a structure proposed for document summarization. Experimental results on a Korean news article dataset show that the proposed method outperform the benchmark models for topic segmentation. In addition, we also show that the proposed method can be used for practical news clip summarization task, supporting the possibility of implementing the application service based on Korean topic segmentation model.'},\n",
       " '10.1007/978-3-319-76941-7_14': {'title': 'Attention-Based Neural Text Segmentation',\n",
       "  'abstract': 'Text segmentation plays an important role in various Natural Language Processing (NLP) tasks like summarization, context understanding, document indexing and document noise removal. Previous methods for this task require manual feature engineering, huge memory requirements and large execution times. To the best of our knowledge, this paper is the first one to present a novel supervised neural approach for text segmentation. Specifically, we propose an attention-based bidirectional LSTM model where sentence embeddings are learned using CNNs and the segments are predicted based on contextual information. This model can automatically handle variable sized context information. Compared to the existing competitive baselines, the proposed model shows a performance improvement of $$\\\\sim $$ 7% in WinDiff score on three benchmark datasets.'},\n",
       " '10.1023/A:1007506220214': {'title': 'Statistical Models for Text Segmentation',\n",
       "  'abstract': 'This paper introduces a new statistical approach to automatically partitioning text into coherent segments. The approach is based on a technique that incrementally builds an exponential model to extract features that are correlated with the presence of boundaries in labeled training text. The models use two classes of features: topicality features that use adaptive language models in a novel way to detect broad changes of topic, and cue-word features that detect occurrences of specific words, which may be domain-specific, that tend to be used near segment boundaries. Assessment of our approach on quantitative and qualitative grounds demonstrates its effectiveness in two very different domains, Wall Street Journal news articles and television broadcast news story transcripts. Quantitative results on these domains are presented using a new probabilistically motivated error metric, which combines precision and recall in a natural and flexible way. This metric is used to make a quantitative assessment of the relative contributions of the different feature types, as well as a comparison with decision trees and previously proposed text segmentation algorithms.'},\n",
       " '10.1140/epjds/s13688-016-0093-1': {'title': 'The emotional arcs of stories are dominated by six basic shapes',\n",
       "  'abstract': 'Advances in computing power, natural language processing, and digitization of text now make it possible to study a culture\\'s evolution through its texts using a \"big data\" lens. Our ability to communicate relies in part upon a shared emotional experience, with stories often following distinct emotional trajectories and forming patterns that are meaningful to us. Here, by classifying the emotional arcs for a filtered subset of 1,327 stories from Project Gutenberg\\'s fiction collection, we find a set of six core emotional arcs which form the essential building blocks of complex emotional trajectories. We strengthen our findings by separately applying Matrix decomposition, supervised learning, and unsupervised learning. For each of these six core emotional arcs, we examine the closest characteristic stories in publication today and find that particular emotional arcs enjoy greater success, as measured by downloads.'},\n",
       " '10.1007/978-3-642-24583-1_22': {'title': 'When Was It Written? Automatically Determining Publication Dates',\n",
       "  'abstract': 'Automatically determining the publication date of a document is a complex task, since a document may contain only few intra-textual hints about its publication date. Yet, it has many important applications. Indeed, the amount of digitized historical documents is constantly increasing, but their publication dates are not always properly identified via OCR acquisition. Accurate knowledge about publication dates is crucial for many applications, e.g. studying the evolution of documents topics over a certain period of time. In this article, we present a method for automatically determining the publication dates of documents, which was evaluated on a French newspaper corpus in the context of the DEFT 2011 evaluation campaign. Our system is based on a combination of different individual systems, relying both on supervised and unsupervised learning, and uses several external resources, e.g. Wikipedia, Google Books Ngrams, and etymological background knowledge about the French language. Our system detects the correct year of publication in 10% of the cases for 300-word excerpts and in 14% of the cases for 500-word excerpts, which is very promising given the complexity of the task.'},\n",
       " '10.1176/appi.ajp.2009.09091369': {'title': 'The Great Gatsbyby F. Scott Fitzgerald. New York, Scribner, 2004, 192 pp., $14.00.',\n",
       "  'abstract': 'Back to table of contents Previous article Next article Book ForumFull AccessThe Great GatsbyJOE WESTERMEYER M.D.,JOE WESTERMEYER M.D.Search for more papers by this author,Published Online:1 Dec 2009https://doi.org/10.1176/appi.ajp.2009.09091369AboutSectionsPDF/EPUB ToolsAdd to favoritesDownload CitationsTrack Citations ShareShare onFacebookTwitterLinked InEmail A few years ago a colleague from my internship days suggested rereading classics not read since high school, college, or our twenties. F. Scott Fitzgerald held a personal interest for me, both then and now. We both spent our adolescence and early adulthood in St. Paul (although he four decades before me). For almost a half century, I have lived on the same street where he once lived in an apartment with his mother. Several decades ago, when many of his age-mates were still alive, gossip of his youthful carousing—not yet available in print—was heard. I knew that he “hung around” (or tried to) with a wealthy crowd in a suburb—a group to which he had none of the credentials for membership (wrong ethnicity, religion, ancestry, etc.). Consequently I came to my first reading of Gatsby with considerable personal awareness of its author. The lead character, Gatsby (obviously a cipher for Fitzgerald himself), was trying to acquire a woman clearly outside of his class-bound reach. For me, as a young single man at that time, the futility of courting in the leisure class reverberated from these pages. Although Gatsby had achieved wealth (or at least access to money, as had Fitzgerald), he could not buy his way into the 1920s Americana elite. From Fitzgerald’s perspective, it was clear that the novel’s hero could not diminish, overcome, or even undermine, much less destroy this class-based structure. On the contrary, even the mere effort to join the ascribed (rather than achieved) class of inherited wealth and power not only would fail ultimately but could be deadly. On a more global level for me at this first reading, Fitzgerald taught through Gatsby (and his own tragic life) that one’s sights were best set within the social and ethnic realities of one’s time and place. My rereading of Gatsby a half century later did not diminish these earlier lessons, although by 2009, I have made my choices and experienced successes and failures ensuing from these choices. Class never posed the huge obstacle for me that it did for Fitzgerald, perhaps because I took his lesson to heart and found means of circumventing it. I suspect that my society (as I experience and perceive it) is less class-ridden than it was 50 years ago. However, I might not feel the same way were I a member of the American underclass (poor, minimal education, limited prospects, lack of familiarity with society as it exists and functions). On this second reading, I discovered several elements of the book that I had, amazingly, either not emphasized or had in the meantime forgotten. One of these key features was Gatsby’s upper Midwestern origins as a rural, northern European Lutheran, whose family name was Gatz. Fitzgerald had his novel’s hero changing his ethnicity by changing his name and abandoning his ethnic origins. Since my initial reading long predated my own formal education in anthropology and later studies of ethnicity, I may have been oblivious to the import of this information. Or perhaps I suppressed Gatsby’s several regional-ethnic-class similarities to my own. In any event, Gatsby, unprepared for life in the elite class, repeatedly misread people and events. By contrast, his protagonist Tom was in his element, read people and events accurately, and reacted toward his own survival.Second, I had forgotten that Gatsby was a decorated combat veteran of World War I, who had seen harsh battle. Fitzgerald—not a combat veteran—cogently described in Gatsby certain behavioral and social scars characteristic of combat veterans, probably through observing World War I veterans who were about his age and of his time. Although Fitzgerald’s description of Gatsby would not justify a diagnosis of posttraumatic stress disorder, Gatsby manifests many characteristics of surviving combat veterans: his social isolation and loneliness, his abandoning of his society’s ethics, his overinvesting in a single, unlikely goal (regaining Daisy, now Tom’s wife). Since my early reading, I spent two years in the midst of war (in Laos, as a general physician and surgeon), returned to the United States to treat veterans with posttraumatic maladies as a psychiatry resident, then worked with refugees for two decades and currently work with veterans. The consequences of war and trauma, as they existed in Gatsby’s values and decisions, were unmistakable, graphic, and even overwhelming in my later reading.Third, I saw Gatsby’s protagonist, Tom, a compleat member of the moneyed elite, in an entirely new light. Years earlier, in my eyes, he was a brigand and worse. He cheated on his wife, treated his concubine and assorted underlings deplorably, lied, and set a murderer falsely on Gatsby’s trail. Fifty years later, I saw him—despite his many flaws—as protecting his family’s integrity, deftly avoiding a cuckold-murderer, accreting to the wealth inherited to him, and building his network of loyal indentured supporters. At the end, he held the field, with his life, his family, and his holdings intact. He remained true to his class and to his version of the Ivy League code. It is amazing that Fitzgerald, verbally denigrating Tom (through Nick, our guide in the novel), nonetheless permits Tom total victory over Gatsby. Parenthetically, Tom—in his dealings with everyone—reminded me of the challenging VIP (very important patient) that we can encounter in our physician role.Fourth and last, Gatsby’s funeral reflected his devastated social network: four people attended the event. Mansell Pattison’s network schema suggests that Gatsby was a seriously deranged individual, in the range of a Skid Row alcoholic, an institutionalized psychotic, or a disabled borderline, whose efforts at resolution had run their course (1, 2). Gatsby’s murderer may well have saved him from death at his own hand—another too-frequent end among war heroes. This return to Gatsby heightened my regard for Fitzgerald’s ability to describe elements of the human condition. He skillfully wove a tale of postcombat tragedy in a man escaping (rather than finding resolve in) his roots. Gatsby was a tragic hero for an entire generation trying to recover from World War I (and later rediscovered after World War II and the Korean and Vietnam conflicts). This second reading also provided insights into my own changes over a half century, wrought by my work and historical circumstance. Although Gatsby’s exploits in war cover only a few pages of this book, for me they redefined Fitzgerald’s Gatsby as a tragic novel on postwar maladjustment, set against the backdrop of class and ethnicity—and not only a commentary on class struggle and ethnic escape. St. Paul, Minn.The author reports no financial relationships with commercial interests.Book review accepted for publication October 2009 (doi: 10.1176/appi.ajp.2009.09091369).References1. Pattison EM: Social system psychotherapy. Am J Psychother 1973; 27:396–409Google Scholar2. Westermeyer J, Pattison EM: Social networks and mental illness in a peasant society. Schizophr Bull 1981; 7:125–134Google Scholar FiguresReferencesCited byDetailsCited byNone Volume 166Issue 12 December, 2009Pages 1415-1416THE AMERICAN JOURNAL OF PSYCHIATRY December 2009 Volume 166 Number 12 Metrics PDF download History Published online 1 December 2009 Published in print 1 December 2009'},\n",
       " '10.1007/11573548_86': {'title': 'Emotional Sequencing and Development in Fairy Tales',\n",
       "  'abstract': \"Affect is a transient phenomenon, with emotions tending to blend and interact over time [4]. This paper discusses emotional distributions in child-directed texts. It provides statistical evidence for the relevance of emotional sequencing, and evaluates trends of emotional story development, based on annotation statistics on 22 Grimms' fairy tales which form part of a larger on-going text-annotation project that is also introduced. The study is motivated by the need for exploring features for text-based emotion prediction at the sentence-level, for use in expressive text-to-speech synthesis of children's stories.\"},\n",
       " '10.1007/s10579-005-7882-7': {'title': 'Temporal and Event Information in Natural Language Text',\n",
       "  'abstract': 'In this paper, we discuss the role that temporal information plays in natural language text, specifically in the context of question answering systems. We define a descriptive framework with which we can examine the temporally sensitive aspects of natural language queries. We then investigate broadly what properties a general specification language would need, in order to mark up temporal and event information in text. We present a language, TimeML, which attempts to capture the richness of temporal and event related information in language, while demonstrating how it can play an important part in the development of more robust question answering systems.'},\n",
       " '10.1016/0004-3702(72)90040-9': {'title': 'A model for temporal references and its application in a question answering program',\n",
       "  'abstract': 'A formal model is presented which represents the structure underlying temporal references in natural language. Serving as a framework for analysis of tenses, time relation, and other references to time in language, the model consists of a partially ordered set, called “time” and successively defined concepts such as “time-segment”, “duration”, “time-segment relation”, “tense”, “reference time”, and “tense marker”. This model is justified by making informal arguments, by giving English language examples, and by showing that it is a generalization of several other systems. A computer question answering program, “Chronos”, which uses the concepts of tense and time-segment relations, illustrates and supports the validity of the model. Chronos is shown to be a simple program which nevertheless can understand most of the temporal meaning in a sentence.'},\n",
       " '10.1016/j.ijar.2024.109128': {'title': 'Enriching Interactive Explanations with Fuzzy Temporal Constraint Networks',\n",
       "  'abstract': \"Humans often use expressions with vague terms which play a fundamental role for effective communication. These expressions are successfully modeled with fuzzy technology, but they are not usually integrated yet with Natural Language Processing models and techniques. Large-scale pre-trained language models yield excellent results in many language tasks, but they have some drawbacks such as their lack of transparency and thorough temporal reasoning capabilities. Therefore, the use of such models may provoke inconsistent or incorrect dialogues in the context of conversational agents which were aimed at providing users of intelligent systems with interactive explanations. In this paper, we propose a model for fuzzy temporal reasoning to overcome some inconsistencies detected in pre-trained language models in a specific application domain of a conversational agent carefully designed for providing users with explanations which are endowed with a good balance between naturalness and fidelity. More precisely, starting from a knowledge graph that provides an intuitive representation of the entities and relations in the application domain, we describe how to map the temporal information onto a fuzzy temporal constraint network. This formalism allows to represent imprecise temporal information and provides mechanisms for checking consistency in conversations. In addition, as a proof of concept, we have developed TimeVersa, a conversational agent which integrates the proposed model into an application domain (i.e., a virtual assistant for tourists) that requires handling imprecise temporal constraints. We illustrate in a use case how the agent can identify temporal inconsistencies and answer queries related to temporal information properly. Results after a user study report that users' perception of consistency is significantly higher in a conversation with TimeVersa than in a similar conversation using the well-known GPT-3 Large Language Model, when vague temporal information is involved. The proposed approach is a step forward for developing conversational agents operating in application domains that require temporal reasoning under uncertainty.\"},\n",
       " '10.62036/isd.2023.46': {'title': 'Ontology-Based Dialogue System for Domain-Specific Knowledge Acquisition',\n",
       "  'abstract': 'Building task-oriented dialogue systems for solving specific tasks within companies represents a challenging research objective especially when the specific expertise of the company is not yet machine-readable formalized. Aiming to collect the specific knowledge in a company-scope knowledge graph, we design the architecture of a dialog system integrating the natural language processing modules with the specific concepts described in the domain ontology and the com- pany’s graph of instances. The described system helps growing the knowledge graph with the specific company data, while also providing the NLP building blocks for a future dialog system specifically tuned for the requirements of the target company processes.'},\n",
       " '10.1016/j.asoc.2022.109873': {'title': 'A semantic relation-aware deep neural network model for end-to-end conversational recommendation',\n",
       "  'abstract': 'Conversational recommendation system (CRS) aims at recommending appropriate items to the user through a multi-turn conversation. The end-to-end CRS is a type of CRS that models the recommendation task and the conversation task simultaneously which has attracted more and more attention in recent years. At the same time, knowledge graph and Transformer are incorporated into the end-to-end CRS to generate better recommendations and better responses to the user, which makes the CRS have state-of-the-art performance. It is known that there exist semantic relations in a conversation. However, we observe that existing end-to-end CRSs in general ignore the semantic relations in the conversation and therefore would likely hinder the performance of CRSs. Motivated by this, we propose a gated cross- and self-attention based CRS utilizing semantic relation information (ASR) model, which can explicitly model and utilize the semantic relations in a conversation. To the best of our knowledge, we are the first to advocate for modelling and utilizing the semantic relations in the end-to-end CRS, which could help to improve the performance of the CRS. Furthermore, to mitigate the class-imbalance problem that most end-to-end CRSs face, we propose a new negative sampling method which could make the proposed CRS learn better. Moreover, we design a Transformer-based dialogue module integrating the semantic relations in a conversation to generate more diversified and precise responses. Extensive experiments on widely used benchmark datasets demonstrate that the proposed ASR model achieves state-of-the-art results in both recommendation and conversation tasks.'},\n",
       " '10.1016/J.NEUCOM.2021.07.039': {'title': 'Grabbing the Long Tail: A data normalization method for diverse and informative dialogue generation',\n",
       "  'abstract': 'Recent neural models have shown significant progress in dialogue generation. Among those models, most of them are based on language models, yielding the generation word by word according to the previous context. Due to the inherent mechanism in language models, as well as the most frequently used cross-entropy function (making the distribution of generations approximate that of training data continuously), trained generation models inevitably tend to generate frequent words in training datasets, leading to low diversity and poor informativeness issues. By investigating a few mainstream dialogue generation models, we find that the probable cause is the intrinsic Long Tail Phenomenon in linguistics. To address these issues of low diversity and poor informativeness, we explore and analyze a large corpus from Wikipedia, and then propose an efficient frequency-based data normalization method, i.e., Log Normalization. Furthermore, we explore another two methods, Mutual Normalization and Log-Mutual Normalization, to eliminate the mutual information effect. In order to validate the effectiveness of the proposed methods, we conduct extensive experiments on three datasets with different subjects, including social media, film subtitles, and online customer service. Compared with the vanilla transformers, generation models augmented with our proposed methods achieve significant improvements in generated responses, in terms of both diversity and informativeness. Specifically, the unigram and bigram diversity in the responses are improved by 8.5%–14.1% and 19.7%–25.8% on the three datasets, respectively. The informativeness (defined as amounts of nouns and verbs) is increased by 13.1%–31.0% and 30.4%–59.0%, respectively. Moreover, our methods can be adapted to new generation models efficiently and effectively, with their model-agnostic characteristics.'},\n",
       " '10.1007/s00778-022-00747-z': {'title': 'A benchmark and comprehensive survey on knowledge graph entity alignment via representation learning',\n",
       "  'abstract': 'In the last few years, the interest in knowledge bases has grown exponentially in both the research community and the industry due to their essential role in AI applications. Entity alignment is an important task for enriching knowledge bases. This paper provides a comprehensive tutorial-type survey on representative entity alignment techniques that use the new approach of representation learning. We present a framework for capturing the key characteristics of these techniques, propose a benchmark addressing the limitation of existing benchmark datasets, and conduct extensive experiments using our benchmark. The framework gives a clear picture of how various techniques work. The experiments yield important results about the empirical performance of the techniques and how various factors affect the performance. One important observation not stressed by previous work is that techniques making good use of attribute triples and relation predicates as features stand out as winners. We are also the first to investigate the question of how to perform entity alignments on large-scale knowledge graphs such as the full Wikidata and Freebase (in Experiment 5).'},\n",
       " '10.1007/978-981-19-5538-9_15': {'title': 'Dialogue Management as Graph Transformations',\n",
       "  'abstract': 'We present ongoing work on a new dialogue management framework using graphs as core representation for the current dialogue state. Dialogue management tasks such as state tracking and action selection are framed as sequences of graph transformations that repeatedly update this graph based on incoming observations. Those graph transformations are expressed using a graph query language, making it possible to specify all dialogue management operations through a unified, declarative syntax. We argue that graphs are particularly well suited to model the dialogue state of complex, open-ended domains. In contrast to traditional dialogue state representations that are limited to fixed, predefined slots, graphs can naturally express dialogue domains with rich relational structures and variable numbers of entities to track. We describe how dialogue state tracking and action selection can be modelled in such graph-centric view of dialogue management, using either handcrafted rules or data-driven models. We also briefly discuss how to account for some aspects of dialogue management such as uncertainties, incremental inputs and contextual knowledge. Finally, we describe a proof-of-concept study of this dialogue management framework in a human–robot interaction scenario.'},\n",
       " '10.1016/j.specom.2009.01.008': {'title': 'Example-based dialog modeling for practical multi-domain dialog system',\n",
       "  'abstract': 'This paper proposes a generic dialog modeling framework for a multi-domain dialog system to simultaneously manage goal-oriented and chat dialogs for both information access and entertainment. We developed a dialog modeling technique using an example-based approach to implement multiple applications such as car navigation, weather information, TV program guidance, and chatbot. Example-based dialog modeling (EBDM) is a simple and effective method for prototyping and deploying of various dialog systems. This paper also introduces the system architecture of multi-domain dialog systems using the EBDM framework and the domain spotting technique. In our experiments, we evaluate our system using both simulated and real users. We expect that our approach can support flexible management of multi-domain dialogs on the same framework.'},\n",
       " '10.1016/j.csl.2006.06.008': {'title': 'Partially observable Markov decision processes for spoken dialog systems',\n",
       "  'abstract': 'In a spoken dialog system, determining which action a machine should take in a given situation is a difficult problem because automatic speech recognition is unreliable and hence the state of the conversation can never be known with certainty. Much of the research in spoken dialog systems centres on mitigating this uncertainty and recent work has focussed on three largely disparate techniques: parallel dialog state hypotheses, local use of confidence scores, and automated planning. While in isolation each of these approaches can improve action selection, taken together they currently lack a unified statistical framework that admits global optimization. In this paper we cast a spoken dialog system as a partially observable Markov decision process (POMDP). We show how this formulation unifies and extends existing techniques to form a single principled framework. A number of illustrations are used to show qualitatively the potential benefits of POMDPs compared to existing techniques, and empirical results from dialog simulations are presented which demonstrate significant quantitative gains. Finally, some of the key challenges to advancing this method – in particular scalability – are briefly outlined.'},\n",
       " '10.1007/s41060-024-00550-9': {'title': 'An overview of sentence ordering task',\n",
       "  'abstract': 'Abstract The sentence ordering task aims to organize complex, unordered sentences into readable text. This improves accuracy, validity, and reliability in various natural language processing domains, including automatic text generation, text summarization, and machine translation. We begin by analyzing and summarizing the sentence ordering algorithm from two perspectives: the input data approach and the implementation technique approach. Based on the different ways of input data formats, they are classified into pointwise, pairwise, and listwise, and the advantages, disadvantages and representative algorithmic features of each are discussed. Based on the different implementation technologies, we classify them into sentence ordering algorithms based on learning to rank and deep learning, and the core ideas, typical algorithms and research progress of these two categories of methods were specifically explained. We summarize the datasets and evaluation metrics of currently commonly used sentence ordering tasks. Additionally, we analyze the problems and challenges of sentence ordering tasks and look forward to the future direction of this field.'},\n",
       " '10.1016/j.knosys.2022.108453': {'title': 'Local and global context-based pairwise models for sentence ordering',\n",
       "  'abstract': \"Sentence Ordering refers to the task of rearranging a set of sentences into the appropriate coherent order. For this task, most previous approaches have explored global context-based end-to-end methods using Sequence Generation techniques. In this paper, we put forward a set of robust local and global context-based pairwise ordering strategies, leveraging which our prediction strategies outperform all previous works in this domain. Our proposed encoding method utilizes the paragraph's rich global contextual information to predict the pairwise order using novel transformer architectures. Analysis of the two proposed decoding strategies helps better explain error propagation in pairwise models. This approach is the most accurate pure pairwise model and our encoding strategy also significantly improves the performance of other recent approaches that use pairwise models, including the previous state-of-the-art, demonstrating the research novelty and generalizability of this work. Additionally, we show how the pre-training task for ALBERT helps it to significantly outperform BERT, despite having considerably lesser parameters. The extensive experimental results, architectural analysis and ablation studies demonstrate the effectiveness and superiority of the proposed models compared to the previous state-of-the-art, besides providing a much better understanding of the functioning of pairwise models.\"},\n",
       " '10.5715/jnlp.31.134': {'title': '言語モデルを用いた漢詩文の返り点付与と書き下し文生成',\n",
       "  'abstract': '近年の自然言語処理の研究は,現代語を中心に行われ,多くのタスクで高い性能を達成している.一方,古文やそれに関連するタスクにはほとんど注意が払われてこなかった.漢文は約 2000 年前の弥生時代に中国から日本に伝えられたと推測されており,それ以降日本文学に多大な影響を与えた.現在においても大学入学共通テストの国語において漢文は 200 点の内 50 点を占めている.しかし,中国にある豊富な言語資源に比べ,日本にある漢文の書き下し文資源は非常に少ない.この問題を解決するために,本研究は漢詩文を対象とし,白文と書き下し文からなる漢文訓読データセットを構築する.そして,漢文理解において重要視される返り点付与,書き下し文生成の二つのタスクに対し,言語モデルを用いて精度向上を試みる.また,人間の評価結果と比較することで,最適な自動評価指標について議論する.データセットとコードは https://github.com/nlp-waseda/Kanbun-LM で公開している.'},\n",
       " '10.1007/s11263-022-01611-x': {'title': 'Curriculum Learning: A Survey',\n",
       "  'abstract': 'Training machine learning models in a meaningful order, from the easy samples to the hard ones, using curriculum learning can provide performance improvements over the standard training approach based on random data shuffling, without any additional computational costs. Curriculum learning strategies have been successfully employed in all areas of machine learning, in a wide range of tasks. However, the necessity of finding a way to rank the samples from easy to hard, as well as the right pacing function for introducing more difficult data can limit the usage of the curriculum approaches. In this survey, we show how these limits have been tackled in the literature, and we present different curriculum learning instantiations for various tasks in machine learning. We construct a multi-perspective taxonomy of curriculum learning approaches by hand, considering various classification criteria. We further build a hierarchical tree of curriculum learning methods using an agglomerative clustering algorithm, linking the discovered clusters with our taxonomy. At the end, we provide some interesting directions for future work.'},\n",
       " '10.1016/j.procs.2023.08.154': {'title': 'Curriculum Compositional Continual Learning for Neural Machine Translation',\n",
       "  'abstract': 'Current trends in language modelling leverage large language models pre-trained on a huge corpus of data to achieve state of the art results on several NLP tasks. On the other hand, humans acquire language from small amount of data using cognitive principles. Recently, a continual learning approach using compositionality to disentangle the syntax and semantics of an input sentence for downstream sequence to sequence tasks was proposed. In this work, we show how curriculum learning can be incorporated with this framework to improve performance. More specifically, first, we show that using the model of interest with reduced hidden size as the auxiliary model to generate curriculum is not necessarily optimal and second, we propose a novel variant of the one best score approach for curriculum learning where, a sequence to sequence model is used as the auxiliary model to generate the conditional probabilities of word predictions (proxy for difficulty) and consequently used this to generate a curriculum. Results on a variety of translation tasks, demonstrate the superiority of the proposed approach compared to several baselines, enabling the improvement of sentence accuracy with respect to knowledge transfer and catastrophic-forgetting both by at least a significant margin of 35% with respect to the best performing baseline on the English-French translation task.'},\n",
       " '10.1007/s10115-022-01767-5': {'title': 'Tailoring and evaluating the Wikipedia for in-domain comparable corpora extraction',\n",
       "  'abstract': 'Abstract We propose a language-independent graph-based method to build à-la-carte article collections on user-defined domains from the Wikipedia. The core model is based on the exploration of the encyclopedia’s category graph and can produce both mono- and multilingual comparable collections. We run thorough experiments to assess the quality of the obtained corpora in 10 languages and 743 domains. According to an extensive manual evaluation, our graph model reaches an average precision of $$84\\\\%$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mrow> <mml:mn>84</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> on in-domain articles, outperforming an alternative model based on information retrieval techniques. As manual evaluations are costly, we introduce the concept of domainness and design several automatic metrics to account for the quality of the collections. Our best metric for domainness shows a strong correlation with human judgments, representing a reasonable automatic alternative to assess the quality of domain-specific corpora. We release the toolkit with the implementation of the extraction methods, the evaluation measures and several utilities.'},\n",
       " '10.1016/0010-0277(93)90058-4': {'title': 'Learning and development in neural networks: the importance of starting small',\n",
       "  'abstract': \"It is a striking fact that in humans the greatest learning occurs precisely at that point in time--childhood--when the most dramatic maturational changes also occur. This report describes possible synergistic interactions between maturational change and the ability to learn a complex domain (language), as investigated in connectionist networks. The networks are trained to process complex sentences involving relative clauses, number agreement, and several types of verb argument structure. Training fails in the case of networks which are fully formed and 'adultlike' in their capacity. Training succeeds only when networks begin with limited working memory and gradually 'mature' to the adult state. This result suggests that rather than being a limitation, developmental restrictions on resources may constitute a necessary prerequisite for mastering certain complex domains. Specifically, successful learning may depend on starting small.\"},\n",
       " '10.1016/j.datak.2023.102265': {'title': 'Towards deep understanding of graph convolutional networks for relation extraction',\n",
       "  'abstract': 'Relation extraction aims at identifying semantic relations between pairs of named entities from unstructured texts and is considered an essential prerequisite for many downstream tasks in natural language processing (NLP). Owing to the ability in expressing complex relationships and interdependency, graph neural networks (GNNs) have been gradually used to solve the relation extraction problem and have achieved state-of-the-art results. However, the designs of GNN-based relation extraction methods are mostly based on empirical intuition, heuristic, and experimental trial-and-error. A clear understanding of why and how GNNs perform well in relation extraction tasks is lacking. In this study, we investigate three well-known GNN-based relation extraction models, CGCN, AGGCN, and SGCN, and aim to understand the underlying mechanisms of the extractions. In particular, we provide a visual analytic to reveal the dynamics of the models and provide insight into the function of intermediate convolutional layers. We determine that entities, particularly subjects and objects in them, are more important features than other words for relation extraction tasks. With various masking strategies, the significance of entity type to relation extraction is recognized. Then, from the perspective of the model architecture, we find that graph structure modeling and aggregation mechanisms in GCN do not significantly affect the performance improvement of GCN-based relation extraction models. The above findings are of great significance in promoting the development of GNNs. Based on these findings, an engineering oriented MLP-based GNN relation extraction model is proposed to achieve a comparable performance and greater efficiency.'},\n",
       " '10.1016/j.neunet.2023.10.053': {'title': 'Improving few-shot relation extraction through semantics-guided learning',\n",
       "  'abstract': 'Few-shot relation extraction (few-shot RE) aims to recognize relations between the entity pair in a given text by utilizing very few annotated instances. As a simple yet efficient approach, prototype network-based methods often directly incorporate relation information to enhance prototype representation or leverage contrastive learning to mitigate prediction confusion. Despite achieving good results, the above methods are still susceptible to false judgments of outlier samples and confusion of similar classes. To address these issues, we propose a novel Semantics-Guided Learning (SemGL) method that more effectively utilizes relation information to enhance both the representations of instances and prototypes for improving the performance of few-shot RE. First, SemGL employs the prompt encoder to encode various prompt templates of instances and relation information and obtains more accurate semantic representations of instances, instance prototypes, and concept prototypes via the prompt enhancement from large language models. Then, SemGL introduces a novel technique called relation graph learning, which leverages concept prototypes to cluster homogeneous instances together, emphasizing relation-specific features of concrete instances. Simultaneously, SemGL employs instance-level contrastive learning between instance prototypes and support instances to distinguish between intra-class instances and inter-class instances to promote shared features among intra-class instances. Additionally, prototype-level contrastive learning leverages concept prototypes to pull closer relation-specific features of the concept prototype and shared features of the instance prototype from the same relation. Finally, SemGL utilizes new relation prototypes that integrate interpretable features of concept prototypes and shared features of instance prototypes for prediction. Experimental results on two publicly available few-shot RE datasets demonstrate the effectiveness and efficiency of SemGL in introducing relation information, with particularly promising results for the domain adaptation challenge task.'},\n",
       " '10.1016/j.neunet.2023.11.062': {'title': 'Document-level Relation Extraction with Relation Correlations',\n",
       "  'abstract': 'Document-level relation extraction faces two often overlooked challenges: long-tail problem and multi-label problem. Previous work focuses mainly on obtaining better contextual representations for entity pairs, hardly address the above challenges. In this paper, we analyze the co-occurrence correlation of relations, and introduce it into the document-level relation extraction task for the first time. We argue that the correlations can not only transfer knowledge between data-rich relations and data-scarce ones to assist in the training of long-tailed relations, but also reflect semantic distance guiding the classifier to identify semantically close relations for multi-label entity pairs. Specifically, we use relation embedding as a medium, and propose two co-occurrence prediction sub-tasks from both coarse- and fine-grained perspectives to capture relation correlations. Finally, the learned correlation-aware embeddings are used to guide the extraction of relational facts. Substantial experiments on two popular datasets (i.e., DocRED and DWIE) are conducted, and our method achieves superior results compared to baselines. Insightful analysis also demonstrates the potential of relation correlations to address the above challenges. The data and code are released at https://github.com/RidongHan/DocRE-Co-Occur.'},\n",
       " '10.1145/3640771.3640779': {'title': 'CLPLM-EE: Contrastive Learning Pre-training Model for Event Extraction In New Domain',\n",
       "  'abstract': 'The event extraction task recognizes events in natural language text and extracts the event triggers and arguments. The majority of existing methods that based on closed domains have poor generalization and are difficult to extend to new domains. As a result, event extraction models for new domains requires general event knowledge learned from large amounts of unsupervised data. Fortunately, existing studies have shown that a contrastive pre-training model for information extraction can better obtain prior knowledge from large unannotated data. However, such methods have insufficient perception of event structure, have not learnt enough about event representations, and thier contrastive learning methods used to construct negative samples lead to semantic conflicts. To adress the above problem, we propose CLPLM-EE, a contrastive pre-training MODEL for event extraction in new domians. CLPLM-EE contains has an encoder with event semantics and event structure awareness to learn the most common knowledge of the event. In addition, CLPLM-EE learns high-quality event representations by eliminating false negative samples and using a weighting mechanism to avoid the semantic conflicts generated in Contrastive learning pre-training.'},\n",
       " '10.1016/j.eswa.2023.121971': {'title': 'Hyperplane projection network for few-shot relation classification',\n",
       "  'abstract': 'Recently meta-learning-based few-shot learning methods have been widely used for relation classification. Previous work reveals that meta-learning performs poorly in scenarios where the edge probability distribution of the target domain dataset appears to be significantly different from the source domain. In this paper, we enhance the meta-learning framework with high-dimensional semantic feature extraction and hyperplane projection metrics for meta-tasks. First, we enhance the focus of BERT on entity words by adding entity markers and vector pooling. After that, the high-dimensional semantic features of the support set are extracted and transformed into hyperplanes. Finally, we obtain the classification results by calculating the projection distance between the query sample and the hyperplane. In addition, we design a auxiliary function with a plane correction factor, which can better amplify the plane spacing and reduce the degree of category confusion, which is important for solving the problem of metric spatial loss. Experiments on two real-world few-shot datasets show that our model HPN is more effective in classifying few-shot relations in the same domain and domain-adapted scenarios. And HPN is more stable on NOTA tasks.'},\n",
       " '10.1016/j.eswa.2023.121866': {'title': 'Unleashing the power of context: Contextual association network with cross-task attention for joint relational extraction',\n",
       "  'abstract': 'Extraction of entities and their relationships remains a challenge in information extraction tasks such as opinion recognition and event detection. Research efforts has been dedicated to training named entity recognition (NER) models and relation extraction (RE) models simultaneously, in order to leverage the semantic associations among such sub-tasks to improve their performance. However, how to reasonably capture the interdependence between these two sub-tasks is still not clear. Well trained joint extraction models often do not generalize well to examples from wide sources due to that existing strategies may overly rely on shallow heuristics via entity mentions and fail to make enough use of contextual associations among such sub-tasks. With this in mind, we propose a novel contextual association network for joint relational extraction (called CARE) with cross-task attention mechanism, which makes use of the correlated contextual information produced by the NER and RE sub-tasks explicitly, and achieves significantly better performance comparing with the state-of-the-art models. We use experimental results on four publicly available datasets to test the efficacy of our proposed model. Experimental results demonstrate that the proposed mechanism can use the semantic information produced by NER and RE sub-tasks to boost one another in a complementary way.'},\n",
       " '10.1016/j.neunet.2023.10.025': {'title': 'Adaptive class augmented prototype network for few-shot relation extraction',\n",
       "  'abstract': 'Relation extraction is one of the most essential tasks of knowledge construction, but it depends on a large amount of annotated data corpus. Few-shot relation extraction is proposed as a new paradigm, which is designed to learn new relationships between entities with merely a small number of annotated instances, effectively mitigating the cost of large-scale annotation and long-tail problems. To generalize to novel classes not included in the training set, existing approaches mainly focus on tuning pre-trained language models with relation instructions and developing class prototypes based on metric learning to extract relations. However, the learned representations are extremely sensitive to discrepancies in intra-class and inter-class relationships and hard to adaptively classify the relations due to biased class features and spurious correlations, such as similar relation classes having closer inter-class prototype representation. In this paper, we introduce an adaptive class augmented prototype network with instance-level and representation-level augmented mechanisms to strengthen the representation space. Specifically, we design the adaptive class augmentation mechanism to expand the representation of classes in instance-level augmentation, and class augmented representation learning with Bernoulli perturbation context attention to enhance the representation of class features in representation-level augmentation and explore adaptive debiased contrastive learning to train the model. Experimental results have been demonstrated on FewRel and NYT-25 under various few-shot settings, and the proposed model has improved accuracy and generalization, especially for cross-domain and different hard tasks.'},\n",
       " '10.1016/j.csl.2023.101574': {'title': 'Document-level relation extraction with entity mentions deep attention',\n",
       "  'abstract': 'Document-level Relation Extraction(DocRE) aims to extract relations between entities from documents. In contrast to sentence-level relation extraction, it requires extracting semantic relations from multiple sentences. It is necessary to further improve the performance of the above algorithm in order to extract document-level relation. Therefore, the DocRE algorithms have to deal with more complex entity structure relationships and the need to unite semantic relationships between different sentences when reasoning about relationships between entities. The proposed algorithms fail to infer relationships between entities when dealing with complex entity structure relationships. In this paper, we propose an entity mentions deep attention framework that efficiently infers entity relationships through entity structure and contextual information. Firstly, a structural dependency module of entities is designed to achieve interaction between different mentions of the entity. Secondly, a deep contextual attention component proposed to enrich the semantic information between entities by entity-related contexts. Finally, we use a distance mapping component to solve the problem of entity pairs that are far away from each other. According to our implementation results, our model outperforms the state-ofthe-art models on three public datasets DocRED, DGA, and CDR.'},\n",
       " '10.1016/j.csl.2023.101580': {'title': 'A lightweight approach based on prompt for few-shot relation extraction',\n",
       "  'abstract': 'Few-shot relation extraction (FSRE) aims to predict the relation between two entities in a sentence using a few annotated samples. Many works solve the FSRE problem by training complex models with a huge number of parameters, which results in longer processing times to obtain results. Some recent works focus on introducing relation information into Prototype Networks in various ways. However, most of these methods obtain entity and relation representations by fine-tuning large pre-trained language models. This implies that a copy of the complete pre-trained model needs to be saved after fine-tuning for each specific task, leading to a shortage of computing and space resources. To address this problem, in this paper, we introduce a light approach that utilizes prompt-learning to assist in fine-tuning model by adjusting fewer parameters. To obtain a better prototype of relation, we design a new enhanced fusion module to fuse relation information and original prototype. We conduct extensive experiments on the common FSRE datasets FewRel 1.0 and FewRel 2.0 to varify the advantages of our method, the results show that our model achieves state-of-the-art performance.'},\n",
       " '10.1016/j.iswa.2023.200244': {'title': 'A survey on Relation Extraction',\n",
       "  'abstract': 'With the advent of the Internet, the daily production of digital text in the form of social media, emails, blogs, news items, books, research papers, and Q&A forums has increased significantly. This unstructured or semi-structured text contains a huge amount of information. Information Extraction (IE) can extract meaningful information from text sources and present it in a structured format. The sub-tasks of IE include Named Entity Recognition (NER), Event Extraction, Relation Extraction (RE), Sentiment Extraction, Opinion Extraction, Terminology Extraction, Reference Extraction, and so on. One way to represent information in the text is in the form of entities and relations representing links between entities. The Entity Extraction task identifies entities from the text, and the Relation Extraction (RE) task can identify relationships between those entities. Many NLP applications can benefit from relational information derived from natural language, including Structured Search, Knowledge Base (KB) population, Information Retrieval, Question-Answering, Language Understanding, Ontology Learning, etc. This survey covers (1) basic concepts of Relation Extraction; (2) various Relation Extraction methodologies; (3) Deep Learning techniques for Relation Extraction; and (4) different datasets that can be used to evaluate the RE system.'},\n",
       " '10.2139/ssrn.4391750': {'title': 'Time Expression as Update Operations: Normalizing Time Expressions Via a Distantly Supervised Neural Semantic Parser',\n",
       "  'abstract': 'Existing approaches to normalize time expressions highly rely on expert-engineered rules or grammars, which are labor-intensive and difficult to scale to different scenarios. In this article, we formulate a novel idea to model the semantics of time expression as update operations. We use the update semantics-based representation to model the normalization task as predicting an operation sequence from a given natural language sequence, which is compatible with the popular Seq2Seq scheme in deep learning.We propose a distantly supervised neural parsing approach DNPTime for parsing the time expressions. DNPTime parses recognized expressions into executable operations to obtain normalized values. Specifically, DNPTime uses the intermediate results from the automatic rule generation approach ARTime to construct distant supervision samples for fine-tuning T5 models.Experimental results show that DNPTime gives the best average performances on different benchmarks with fewer human interventions.'},\n",
       " '10.1007/s11280-023-01142-6': {'title': 'Phrase-level attention network for few-shot inverse relation classification in knowledge graph',\n",
       "  'abstract': 'Relation classification aims to recognize semantic relation between two given entities mentioned in the given text. Existing models have performed well on the inverse relation classification with large-scale datasets, but their performance drops significantly for few-shot learning. In this paper, we propose a Phrase-level Attention Network, function words adaptively enhanced attention framework (FAEA+), to attend class-related function words by the designed hybrid attention for few-shot inverse relation classification in Knowledge Graph. Then, an instance-aware prototype network is present to adaptively capture relation information associated with query instances and eliminate intra-class redundancy due to function words introduced. We theoretically prove that the introduction of function words will increase intra-class differences, and the designed instance-aware prototype network is competent for reducing redundancy. Experimental results show that FAEA+ significantly improved over strong baselines on two few-shot relation classification datasets. Moreover, our model has a distinct advantage in solving inverse relations, which outperforms state-of-the-art results by 16.82% under a 1-shot setting in FewRel1.0.'},\n",
       " '10.1016/j.eswa.2023.120435': {'title': 'A novel pipelined end-to-end relation extraction framework with entity mentions and contextual semantic representation',\n",
       "  'abstract': \"The mainstream method of end-to-end relation extraction is to jointly extract entities and relations by sharing span representation, which, however, may cause feature conflict. The advent of advanced pre-trained models enhances the ability to learn span semantic representation and allows the breaking of the dominance of joint models. We argue the benefits of using separate encoders for entity recognition and relation classification and propose a novel pipelined end-to-end relation extraction framework. By adopting attention mechanisms, the framework has the ability to fuse contextual semantic representation, which is missed in other pipelined models. By introducing explicit entity mentions, the framework is able to capture entities' location information and type information, which are difficult to utilize in joint models. Several elaborate tricks are integrated into the training process of the framework to further improve its performance. Our experiments show that our method increases the state-of-the-art relation F1-score on CoNLL04, ADE and SciERC datasets to 75.6% (+1.2%), 85.0% (+1.2%), 43.9% (+2.3%), respectively, indicating that our pipelined approach is promising in end-to-end relation extraction.\"},\n",
       " '10.1016/j.neucom.2023.03.005': {'title': 'Semantic piecewise convolutional neural network with adaptive negative training for distantly supervised relation extraction',\n",
       "  'abstract': 'Distantly Supervised Relation Extraction (DSRE) aligns existing knowledge bases with unstructured text to extract relation facts, and its automatically generated training data is inevitably noisy. Most existing works identify and reduce the impact of noise by enhancing semantic features. However, they only consider the semantic information in a single instance and ignore the semantic information between different instances. In this work, we propose a Semantic Piecewise Convolutional Neural Network (SPCNN), which uses the similarity between different entity pairs as semantic information to improve relation extraction. Specifically, to learn better semantic vector representations, we combine position features with entity pair features and entity similarity features in a high-dimensional space respectively, and generating two different semantic-aware representations. Then we unify these two representations to form a high-quality bag representation for training. Moreover, we design an Adaptive Negative Training (ANT) strategy, which facilitates the network to further exploit the rich semantic features to reduce the interference of noisy labels. Extensive experimental results on a large-scale benchmark dataset show that our method significantly outperforms other baselines.'},\n",
       " '10.1016/j.knosys.2023.110471': {'title': 'A joint training network for learning more distinguishable relation features in relation classification',\n",
       "  'abstract': 'Relation classification is an important task in natural language processing, which aims to predict the semantic relation between a given entity pair in a sentence. There are datasets, like TACRED, that contain a large number of “no_relation” type samples. Most existing methods treat “no_relation” and normal relation types equally, and directly apply the softmax function over all relation types. In this paper, we propose a novel joint training network to learn more distinguishable relation features for relation classification. Specially, we convert the original multi-class classification problem into two joint optimized modules, binary classification of whether a relation is “no_relation” and multi-class classification of normal relation types. To further differentiate between similar normal relation types, we introduce a self-supervised contrastive learning method to learn more distinguishable features for them. We jointly optimize the above modules. Experimental results agree well with our design intention and demonstrate that our joint training network not only achieves superior performance against existing competitive models, but also is robust to “no_relation” problem.'},\n",
       " '10.1016/j.patrec.2023.02.012': {'title': 'Relational distance and document-level contrastive pre-training based relation extraction model',\n",
       "  'abstract': 'Document-level relation extraction has multi-entity and multi-mention compared to sentence-level, existing sentence-level relation extraction models cannot meet the requirements of document-level relation extraction. Existing graph-based document-level models usually design points and edges manually, which often introduces man-made noise; while the Transformer-based models cannot deeply solve the difficulties such as coreference resolution by designing pre-training tasks or other methods. In this paper, we propose a new Relational Distance and Document-level Contrastive Pre-training (RDDCP) based relation extraction model, which achieves coreference resolution by simple and effective mention replacement; we also introduce the concept of relational distance to achieve document-level contrastive pre-training, and find the most likely relational mention pairs from the plural mention pairs existing in the document-level dataset for contrastive learning; for the relation information in distant mentions ignored by the relational distance, we quantified the distances as weights and incorporated the information with weights into the embedding representation of entities. Each entity presents different entity embedding representations in different entity pairs. We conducted experiments on three popular datasets and the RDDCP model outperformed GAIN, SSAN and ATLOP as well as other baseline models in terms of performance and time complexity.'},\n",
       " '10.1016/j.knosys.2022.109470': {'title': 'Cost-effective CNNs-based prototypical networks for few-shot relation classification across domains',\n",
       "  'abstract': 'This paper studies few-shot relation classification under domain shift, which is quite a challenging inductive task in practice. Previous work focusing on few-shot relation classification usually adopted prototypical networks, whose performance dramatically dropped when adapting to diverse domains. Some researches introduced large pretrained language models, which consume massive time and computation resources. To address the above issues, we propose cost-effective CNNs-based prototypical networks in this paper. Specifically, a multichannel encoder (MCE) is adopted to capture general domain invariant features respectively from the entity and the context, then they are aggregated according to relation classes. When encoding the context, we propose an attention mechanism based on the dependency trees of sentences to effectively select helpful grams. To get further improvements, we leverage the unlabeled data from the target domain by pseudo-labeling and introduce a method to select instances with high confidence via information entropy. We conducted experiments on two public datasets: FewRel 2.0 and FewTAC. The results demonstrate that our approaches not only largely enhance the effectiveness of original prototypical networks, but also achieve competitive results with large pretrained models with faster speeds and much fewer computational costs.'},\n",
       " '10.1007/s00500-022-07195-5': {'title': 'Relationship classification based on dependency parsing and the pretraining model',\n",
       "  'abstract': 'As an important part of information extraction, relationship extraction aims to extract the relationships between given entities from natural language text. Based on the pretraining model R-BERT, this paper proposes an entity relationship extraction method that integrates an entity dependency path and pretraining model, which generates a dependency parse tree by dependency parsing, obtains the dependency path of an entity pair via a given entity, and uses an entity dependency path to exclude information such as modifier chunks and useless entities in sentences. This model has achieved good F1 value performance on the SemEval2010 Task 8 dataset. Experiments on datasets show that dependency parsing can provide context information for models and improve performance.'},\n",
       " '10.1016/J.INS.2021.05.045': {'title': 'Classifier-adaptation knowledge distillation framework for relation extraction and event detection with imbalanced data',\n",
       "  'abstract': 'Fundamental information extraction tasks, such as relation extraction and event detection, suffer from a data imbalance problem. To alleviate this problem, existing methods rely mostly on well-designed loss functions to reduce the negative influence of imbalanced data. However, this approach requires additional hyper-parameters and limits scalability. Furthermore, these methods can only benefit specific tasks and do not provide a unified framework across relation extraction and event detection. In this paper, a Classifier-Adaptation Knowledge Distillation (CAKD) framework is proposed to address these issues, thus improving relation extraction and event detection performance. The first step is to exploit sentence-level identification information across relation extraction and event detection, which can reduce identification errors caused by the data imbalance problem without relying on additional hyper-parameters. Moreover, this sentence-level identification information is used by a teacher network to guide the baseline model’s training by sharing its classifier. Like an instructor, the classifier improves the baseline model’s ability to extract this sentence-level identification information from raw texts, thus benefiting overall performance. Experiments were conducted on both relation extraction and event detection using the Text Analysis Conference Relation Extraction Dataset (TACRED) and Automatic Content Extraction (ACE) 2005 English datasets, respectively. The results demonstrate the effectiveness of the proposed framework.'},\n",
       " '10.1016/j.aiopen.2022.11.003': {'title': 'PTR: Prompt Tuning with Rules for Text Classification',\n",
       "  'abstract': 'Recently, prompt tuning has been widely applied to stimulate the rich knowledge in pre-trained language models (PLMs) to serve NLP tasks. Although prompt tuning has achieved promising results on some few-class classification tasks, such as sentiment classification and natural language inference, manually designing prompts is cumbersome. Meanwhile, generating prompts automatically is also difficult and time-consuming. Therefore, obtaining effective prompts for complex many-class classification tasks still remains a challenge. In this paper, we propose to encode the prior knowledge of a classification task into rules, then design sub-prompts according to the rules, and finally combine the sub-prompts to handle the task. We name this Prompt Tuning method with Rules “PTR”. Compared with existing prompt-based methods, PTR achieves a good trade-off between effectiveness and efficiency in building prompts. We conduct experiments on three many-class classification tasks, including relation classification, entity typing, and intent classification. The results show that PTR outperforms both vanilla and prompt tuning baselines, indicating the effectiveness of utilizing rules for prompt tuning. The source code of PTR is available at https://github.com/thunlp/PTR.'},\n",
       " '10.1016/J.ESWA.2021.114853': {'title': 'Joint extraction of entities and overlapping relations using source-target entity labeling',\n",
       "  'abstract': 'Joint extraction of entities and overlapping relations has attracted considerable attention in recent research. Existing relation extraction methods rely on a training set that is labeled by the distant supervision method for supervised relation extraction. However, the drawbacks of these methods are that large-scale unlabeled data cannot be used and the quality of labeled data cannot be guaranteed. Moreover, owing to the relatively complex overlapping relations, it is difficult to perform joint entity-relation extraction accurately. In this study, we propose an end-to-end neural network model (BERT-JEORE) for the joint extraction of entities and overlapping relations. First, we use the BERT-based parameter-sharing layer to capture the joint features of entities and overlapping relations. Then, we implement the source-target BERT model to assign entity labels to each token in a sentence, thereby expanding the amount of labeled data and improving their quality. Finally, we design a three-step overlapping relations extraction model and use it to predict the relations between all entity pairs. Experiments conducted on two public datasets show that BERT-JEORE achieves the best current performance and outperforms the baseline models by a significant margin. Further analysis shows that our model can effectively capture different types of overlapping relational triplets in a sentence.'},\n",
       " '10.1007/978-3-031-18315-7_7': {'title': 'Abstains from Prediction: Towards Robust Relation Extraction in Real World',\n",
       "  'abstract': 'Supervised learning is a classic paradigm of relation extraction (RE). However, a well-performing model can still confidently make arbitrarily wrong predictions when exposed to samples of unseen relations. In this work, we propose a relation extraction method with rejection option to improve robustness to unseen relations. To enable the classifier to reject unseen relations, we introduce contrastive learning techniques and carefully design a set of class-preserving transformations to improve the discriminability between known and unseen relations. Based on the learned representation, inputs of unseen relations are assigned a low confidence score and rejected. Off-the-shelf open relation extraction (OpenRE) methods can be adopted to discover the potential relations in these rejected inputs. In addition, we find that the rejection can be further improved via readily available distantly supervised data. Experiments on two public datasets prove the effectiveness of our method capturing discriminative representations for unseen relation rejection.'},\n",
       " '10.1007/978-3-030-84186-7_13': {'title': 'From Learning-to-Match to Learning-to-Discriminate: Global Prototype Learning for Few-shot Relation Classification',\n",
       "  'abstract': 'Few-shot relation classification has attracted great attention recently, and is regarded as an effective way to tackle the long-tail problem in relation classification. Most previous works on few-shot relation classification are based on learning-to-match paradigms, which focus on learning an effective universal matcher between the query and one target class prototype based on inner-class support sets. However, the learning-to-match paradigm focuses on capturing the similarity knowledge between query and class prototype, while fails to consider discriminative information between different candidate classes. Such information is critical especially when target classes are highly confusing and domain shifting exists between training and testing phases. In this paper, we propose the Global Transformed Prototypical Networks (GTPN), which learns to build a few-shot model to directly discriminate between the query and all target classes with both inner-class local information and inter-class global information. Such learning-to-discriminate paradigm can make the model concentrate more on the discriminative knowledge between all candidate classes, and therefore leads to better classification performance. We conducted experiments on standard FewRel benchmarks. Experimental results show that GTPN achieves very competitive performance on few-shot relation classification and reached the best performance on the official leaderboard of FewRel 2.0 ( https://thunlp.github.io/2/fewrel2_da.html ).'},\n",
       " '10.1007/978-3-030-88480-2_23': {'title': 'Entity-Aware Relation Representation Learning for Open Relation Extraction',\n",
       "  'abstract': 'Open relation extraction aims at extracting novel relations from open-domain corpora. However, most recent works typically treat entities and tokens equally while encoding sentences, without taking full advantage of the guiding role of entities in representation learning. In this work, we propose the Entity-Aware Relation Representation learning framework for open relation extraction and establish the new state-of-the-art on standard benchmarks. It gives more attention to entities when learning representations by leveraging an entity-aware attention mechanism. And we further propose a pair-wise contrastive loss to learn relation representations effectively in terms of alignment and uniformity. Extensive experimental results show that our framework achieves significant improvements compared to state-of-the-art models.'},\n",
       " '10.1007/978-3-642-53917-6_21': {'title': 'Convolution Neural Network for Relation Extraction',\n",
       "  'abstract': 'Deep Neural Network has been applied to many Natural Language Processing tasks. Instead of building hand-craft features, DNN builds features by automatic learning, fitting different domains well. In this paper, we propose a novel convolution network, incorporating lexical features, applied to Relation Extraction. Since many current deep neural networks use word embedding by word table, which, however, neglects semantic meaning among words, we import a new coding method, which coding input words by synonym dictionary to integrate semantic knowledge into the neural network. We compared our Convolution Neural Network (CNN) on relation extraction with the state-of-art tree kernel approach, including Typed Dependency Path Kernel and Shortest Dependency Path Kernel and Context-Sensitive tree kernel, resulting in a 9% improvement competitive performance on ACE2005 data set. Also, we compared the synonym coding with the one-hot coding, and our approach got 1.6% improvement. Moreover, we also tried other coding method, such as hypernym coding, and give some discussion according the result.'},\n",
       " '10.1007/978-3-642-15939-8_10': {'title': 'Modeling Relations and Their Mentions without Labeled Text',\n",
       "  'abstract': 'Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision. Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation. Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with. We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB. We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base. When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31% error reduction.'},\n",
       " '10.1007/3-540-60925-3_51': {'title': 'Learning information extraction patterns from examples',\n",
       "  'abstract': 'A growing population of users want to extract a growing variety of information from on-line texts. Unfortunately, current information extraction systems typically require experts to hand-build dictionaries of extraction patterns for each new type of information to be extracted. This paper presents a system that can learn dictionaries of extraction patterns directly from user-provided examples of texts and events to be extracted from them. The system, called LIEP, learns patterns that recognize relationships between key constituents based on local syntax. Sets of patterns learned by LIEP for a sample extraction task perform nearly at the level of a hand-built dictionary of patterns.'},\n",
       " '10.1016/S0079-7421(08)60536-8': {'title': 'Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem',\n",
       "  'abstract': 'Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.'},\n",
       " '10.1007/s10489-022-03692-0': {'title': 'CookDial: a dataset for task-oriented dialogs grounded in procedural documents',\n",
       "  'abstract': 'This work presents a new dialog dataset, CookDial, that facilitates research on task-oriented dialog systems with procedural knowledge understanding. The corpus contains 260 human-to-human task-oriented dialogs in which an agent, given a recipe document, guides the user to cook a dish. Dialogs in CookDial exhibit two unique features: (i) procedural alignment between the dialog flow and supporting document; (ii) complex agent decision-making that involves segmenting long sentences, paraphrasing hard instructions and resolving coreference in the dialog context. In addition, we identify three challenging (sub)tasks in the assumed task-oriented dialog system: (1) User Question Understanding, (2) Agent Action Frame Prediction, and (3) Agent Response Generation. For each of these tasks, we develop a neural baseline model, which we evaluate on the CookDial dataset. We publicly release the CookDial dataset, comprising rich annotations of both dialogs and recipe documents, to stimulate further research on domain-specific document-grounded dialog systems.'},\n",
       " '10.1016/j.iswa.2023.200251': {'title': 'Continual learning for predictive maintenance: Overview and challenges',\n",
       "  'abstract': 'Deep learning techniques have become one of the main propellers for solving engineering problems effectively and efficiently. For instance, Predictive Maintenance methods have been used to improve predictions of when maintenance is needed on different machines and operative contexts. However, deep learning methods are not without limitations, as these models are normally trained on a fixed distribution that only reflects the current state of the problem. Due to internal or external factors, the state of the problem can change, and the performance decreases due to the lack of generalization and adaptation. Contrary to this stationary training set, real-world applications change their environments constantly, creating the need to constantly adapt the model to evolving scenarios. To aid in this endeavor, Continual Learning methods propose ways to constantly adapt prediction models and incorporate new knowledge after deployment. Despite the advantages of these techniques, there are still challenges to applying them to real-world problems. In this work, we present a brief introduction to predictive maintenance, non-stationary environments, and continual learning, together with an extensive review of the current state of applying continual learning in real-world applications and specifically in predictive maintenance. We then discuss the current challenges of both predictive maintenance and continual learning, proposing future directions at the intersection of both areas. Finally, we propose a novel way to create benchmarks that favor the application of continuous learning methods in more realistic environments, giving specific examples of predictive maintenance.'},\n",
       " '10.1016/j.knosys.2022.108657': {'title': 'Incorporate opinion-towards for stance detection',\n",
       "  'abstract': 'Stance detection can help gain different perspectives into important events, e.g., whether people are in favor of or against certain claim. Most previous work use sentiment information to assist in stance detection. However, they do not consider the critical opinion-towards information, i.e. whether the opinions are aimed at target or other objects. In this work, we incorporate opinion-towards information into a multi-task learning model to facilitate our proposed model for better understanding the sentiment information, which effectively improves the performance of stance detection. In particular, we have constructed a novel label relation matrix which constrains two auxiliary tasks in multi-task learning: (1) sentiment classification, and (2) opinion-towards classification. Our extensive experimental results on three publicly available benchmark datasets demonstrate the effectiveness of the proposed model. In addition, we show the importance of opinion-towards information for stance detection through ablation study and visualization analysis.'},\n",
       " '10.1016/J.KNOSYS.2019.02.008': {'title': 'Semi-supervised Aspect-level Sentiment Classification Model based on Variational Autoencoder',\n",
       "  'abstract': 'Aspect-level sentiment classification aims to predict the sentiment of a text in different aspects and it is a fine-grained sentiment analysis task. Recent work exploits an Attention-based Long Short-Term Memory Network to perform aspect-level sentiment classification. Most previous work are based on supervised learning that needs a large number of labeled samples, but the problem is that only a limited subset of data samples are labeled in practical applications. To solve this problem, we propose a novel Semi-supervised Aspect Level Sentiment Classification Model based on Variational Autoencoder (AL-SSVAE) for semi-supervised learning in the aspect-level sentiment classification. The AL-SSVAE model inputs a given aspect to an encoder a decoder based on a variational autoencoder (VAE), and it also has an aspect level sentiment classifier. It enables the attention mechanism to deal with different parts of a text when different aspects are taken as input as previous methods. Due to that the sentiment polarity of a word is usually sensitive to the given aspect, a single vector for a word is problematic. Therefore, we propose the aspect-specific word embedding learning from a topical word embeddings model to express a word and also append the corresponding sentiment vector into the word input vector. We compare our AL-SSVAE model with several recent aspect-level sentiment classification models on the SemEval 2016 dataset. The experimental results indicate that the proposed model is able to capture more accurate semantics and sentiment for the given aspect and obtain better performance on the task of the aspect level sentiment classification. Moreover, the AL-SSVAE model is able to learn with the semi-supervised mode in the aspect level sentiment classification, which enables it to learn efficiently using less labeled data.'},\n",
       " '10.1016/j.knosys.2018.11.018': {'title': 'Semi-supervised dimensional sentiment analysis with variational autoencoder',\n",
       "  'abstract': 'Dimensional sentiment analysis (DSA) aims to compute real-valued sentiment scores of texts in multiple dimensions such as valence and arousal. Existing methods for DSA are usually based on supervised learning. However, it is expensive and time-consuming to annotate sufficient samples for training. In this paper, we propose a semi-supervised approach for DSA based on the variational autoencoder model. Our model consists of three modules: an encoding module to encode sentences into hidden vectors, a sentiment prediction module to predict the sentiment scores of sentences, and a decoding module that takes the outputs of the preceding two modules as input and reconstructs the input sentences. In our approach, the sentiment prediction module is encouraged to accurately predict sentiment scores of both labeled and unlabeled texts to help the decoding module reconstruct such texts more accurately. Thus, our approach can exploit useful information in unlabeled data. Experimental results on three benchmark datasets show that our approach can effectively improve the performance of DSA with considerably less labeled data.'},\n",
       " '10.1016/j.patcog.2018.04.007': {'title': 'Variational inference based bayes online classifiers with concept drift adaptation',\n",
       "  'abstract': 'We present VIGO, a novel online Bayesian classifier for both binary and multiclass problems. In our model, variational inference for multivariate distribution technique is exploited to approximate the class conditional probability density functions of data in an online manner. To handle concept drift that could arise in streaming data, we develop 2 new adaptive methods based on VIGO, which we called VIGOw and VIGOd. While VIGOw naturally adapts to any kind of changing environments, VIGOd maximises the benefit of a static environment as long as it does not detect any change. Extensive experiments on big/medium real-world/synthetic datasets demonstrate the superior performance of our algorithms over many state-of-the-art methods in the literature.'},\n",
       " '10.1007/978-3-319-67008-9_29': {'title': 'Sentiment Classification over Opinionated Data Streams Through Informed Model Adaptation',\n",
       "  'abstract': 'Opinionated data streams are very popular data paradigms nowadays as more and more users share their opinions online about almost everything from products to persons, brands and ideas. One of the key challenges for opinionated stream mining is dealing with concept drifts in the underlying stream population by building learners that adapt to such concept changes. Ageing is a typical way of adapting to change in a stream environment as it potentially allows us to discard outdated information from the learning models and focus on the most recent information. Most of the existing approaches follow a fixed ageing strategy which remains the same over the whole stream; for example, a fixed window size in the sliding window model or a fixed ageing factor in the damped window model. This implies that we forget at the same rate over the whole course of the stream, which is counterintuitive given the volatile nature of the stream. What is more intuitive is to forget faster in times of change so as to adapt to new data and to forget slower, or in other words, to remember more, in times of stability. In this work, we propose an informative-adaptation-to-change approach where we first detect changes in the underlying data stream and then we tune the ageing factor of the ageing-based Multinomial Naive Bayes (MNB) classifier based on the detected change. Except for the up-to-date classifier our method also outputs the points of change in the stream, therefore offering more insights to the final users.'},\n",
       " '10.1016/j.patcog.2014.07.028': {'title': 'EWMA model based shift-detection methods for detecting covariate shifts in non-stationary environments',\n",
       "  'abstract': 'Dataset shift is a very common issue wherein the input data distribution shifts over time in non-stationary environments. A broad range of real-world systems face the challenge of dataset shift. In such systems, continuous monitoring of the process behavior and tracking the state of shift are required in order to decide about initiating adaptive corrections in a timely manner. This paper presents novel methods for covariate shift-detection tests based on a two-stage structure for both univariate and multivariate time-series. The first stage works in an online mode and it uses an exponentially weighted moving average (EWMA) model based control chart to detect the covariate shift-point in non-stationary time-series. The second stage validates the shift-detected by first stage using the Kolmogorov–Smirnov statistical hypothesis test (K–S test) in the case of univariate time-series and the Hotelling T-Squared multivariate statistical hypothesis test in the case of multivariate time-series. Additionally, several orthogonal transformations and blind source separation algorithms are investigated to counteract the adverse effect of cross-correlation in multivariate time-series on shift-detection performance. The proposed methods are suitable to be run in real-time. Their performance is evaluated through experiments using several synthetic and real-world datasets. Results show that all the covariate shifts are detected with much reduced false-alarms compared to other methods.'},\n",
       " '10.1007/978-3-642-41230-1_6': {'title': 'Detecting Opinion Drift from Chinese Web Comments Based on Sentiment Distribution Computing',\n",
       "  'abstract': 'Opinion drift is regarded as the change of sentiment distribution in this paper. In opinion and sentiment mining, how to detect opinion drifts and analyze their reasons, is an important problem for Web public opinion analysis. To tackle this problem, an approach of opinion drift detection for Chinese Web comment is proposed. For a comment set during a long time about a hot event, the proposed approach first determines possible drift timestamps according to the change of comment number, computes different sentiment orientations and their distributions at these timestamps, detects opinion drift according to the distribution changes, and analyzes the influences of related events occurring in the timestamps. Extensive experiments were conducted in a real comment set of Chinese forum. The results show that drift timestamps determined and opinion drifts detected correspond to the real event, so the approach proposed in this paper is feasible and effective in the application of Web public opinion analysis.'},\n",
       " '10.1016/j.patrec.2011.08.019': {'title': 'Exponentially weighted moving average charts for detecting concept drift',\n",
       "  'abstract': 'Classifying streaming data requires the development of methods which are computationally efficient and able to cope with changes in the underlying distribution of the stream, a phenomenon known in the literature as concept drift. We propose a new method for detecting concept drift which uses an exponentially weighted moving average (EWMA) chart to monitor the misclassification rate of an streaming classifier. Our approach is modular and can hence be run in parallel with any underlying classifier to provide an additional layer of concept drift detection. Moreover our method is computationally efficient with overhead O(1) and works in a fully online manner with no need to store data points in memory. Unlike many existing approaches to concept drift detection, our method allows the rate of false positive detections to be controlled and kept constant over time.'},\n",
       " '10.1007/978-3-540-28645-5_29': {'title': 'Learning with Drift Detection',\n",
       "  'abstract': 'Most of the work in machine learning assume that examples are generated at random according to some stationary probability distribution. In this work we study the problem of learning when the distribution that generate the examples changes over time. We present a method for detection of changes in the probability distribution of examples. The idea behind the drift detection method is to control the online error-rate of the algorithm. The training examples are presented in sequence. When a new training example is available, it is classified using the actual model. Statistical theory guarantees that while the distribution is stationary, the error will decrease. When the distribution changes, the error will increase. The method controls the trace of the online error of the algorithm. For the actual context we define a warning level, and a drift level. A new context is declared, if in a sequence of examples, the error increases reaching the warning level at example k w , and the drift level at example k d . This is an indication of a change in the distribution of the examples. The algorithm learns a new model using only the examples since k w . The method was tested with a set of eight artificial datasets and a real world dataset. We used three learning algorithms: a perceptron, a neural network and a decision tree. The experimental results show a good performance detecting drift and with learning the new concept. We also observe that the method is independent of the learning algorithm.'},\n",
       " '10.1016/j.ipm.2015.04.003': {'title': 'Polarity shift detection, elimination and ensemble: A three-stage model for document-level sentiment analysis',\n",
       "  'abstract': 'The polarity shift problem is a major factor that affects classification performance of machine-learning-based sentiment analysis systems. In this paper, we propose a three-stage cascade model to address the polarity shift problem in the context of document-level sentiment classification. We first split each document into a set of subsentences and build a hybrid model that employs rules and statistical methods to detect explicit and implicit polarity shifts, respectively. Secondly, we propose a polarity shift elimination method, to remove polarity shift in negations. Finally, we train base classifiers on training subsets divided by different types of polarity shifts, and use a weighted combination of the component classifiers for sentiment classification. The results on a range of experiments illustrate that our approach significantly outperforms several alternative methods for polarity shift detection and elimination.'},\n",
       " '10.1016/j.fmre.2024.01.017': {'title': 'An Overview of Fake News Detection: From A New Perspective',\n",
       "  'abstract': 'With the rapid development and popularization of Internet technology, the propagation and diffusion of information become much easier and faster. While making life more convenient, the Internet also promotes the wide spread of fake news, which will have great negative impact on countries, societies, and individuals. Therefore, a lot of research efforts have been made to combat fake news. Fake news detection is typically a classification problem aiming at verifying the veracity of news contents, which may include texts, images and videos. This article provides a comprehensive survey of fake news detection. We first summarize three intrinsic characteristics of fake news by analyzing its entire diffusion process, namely intentional creation, heteromorphic transmission, and controversial reception. The first refers to why users publish fake news, the second denotes how fake news propagates and distributes, and the last means what viewpoints different users may hold for fake news. We then discuss existing fake news detection approaches according to these characteristics. Thus, this review will enable readers to better understand this field from a new perspective. We finally discuss the trends of technological advances in this field and also outline some potential directions for future research.'},\n",
       " '10.1007/s40747-023-01244-8': {'title': 'Sentence-level heuristic tree search for long text generation',\n",
       "  'abstract': 'Abstract In this study, we primarily aim to address the exposure bias issue in long text generation intrinsic to statistical language models. We propose a sentence-level heuristic tree search algorithm, specially tailored for long text generation, to mitigate the problem by managing generated texts in a tree structure and curbing the compounding of biases. Our algorithm utilizes two pre-trained language models, an auto-regressive model for generating new sentences and an auto-encoder model for evaluating sentence quality. These models work in tandem to perform four critical operations: expanding the text tree with new sentences, evaluating the quality of the additions, sampling potential unfinished text fragments for further generation, and pruning leaf nodes deemed unpromising. This iterative process continues until a pre-defined number of [EOS] tokens are produced, at which point we select the highest-scoring completed text as our final output. Moreover, we pioneer two novel token-level decoding techniques—nucleus sampling with temperature and diverse beam search with sampling. These methods, integrated with our sentence-level search algorithm, aim to improve the consistency and diversity of text generation. Experimental results, both automated measures (including Jaccard similarity, Word2vec similarity, and unique word ratio) and human evaluations (assessing consistency, fluency, and rhetorical skills), conclusively demonstrate that our approach considerably enhances the quality of machine-generated long-form text. Through this research, we aim to inspire further innovations in sentence-level search-based text generation algorithms.'},\n",
       " '10.1007/978-981-16-7088-6_3': {'title': 'A Comprehensive Approach to Misinformation Analysis and Detection of Low-Credibility News',\n",
       "  'abstract': 'Misinformation is information that is inaccurate and is usually circulated online with the intent to deceive. The spread of misinformation has escalated with the development of technology, with millions of bots spreading false news on several social media platforms. This has slowly become an issue that needs to be battled, calling for a software system that relies on linguistic, context-based, user-profile-based, and social features to detect and analyze fake news. The objective of this paper is to put forth a review of various literature available on approaches to fake news detection and delineate the aspects of the implemented solution. This approach aims to detect the bots that spread false news as well as track and trace fake information in the form of text. The solution involves text analysis to identify the characteristics of fake news and employs Natural Language Processing and Machine Learning techniques for the same.'},\n",
       " '10.1007/978-3-030-44041-1_114': {'title': 'Generating Sentiment-Preserving Fake Online Reviews Using Neural Language Models and Their Human- and Machine-Based Detection',\n",
       "  'abstract': 'Advanced neural language models (NLMs) are widely used in sequence generation tasks because they are able to produce fluent and meaningful sentences. They can also be used to generate fake reviews, which can then be used to attack online review systems and influence the buying decisions of online shoppers. To perform such attacks, it is necessary for experts to train a tailored LM for a specific topic. In this work, we show that a low-skilled threat model can be built just by combining publicly available LMs and show that the produced fake reviews can fool both humans and machines. In particular, we use the GPT-2 NLM to generate a large number of high-quality reviews based on a review with the desired sentiment and then using a BERT based text classifier (with accuracy of 96%) to filter out reviews with undesired sentiments. Because none of the words in the review are modified, fluent samples like the training data can be generated from the learned distribution. A subjective evaluation with 80 participants demonstrated that this simple method can produce reviews that are as fluent as those written by people. It also showed that the participants tended to distinguish fake reviews randomly. Three countermeasures, Grover, GLTR, and OpenAI GPT-2 detector, were found to be difficult to accurately detect fake review.'},\n",
       " '10.1080/07317131.2019.1584985': {'title': 'Fake news and alternative facts: information literacy in a post-truth era',\n",
       "  'abstract': '\"Fake news and alternative facts: information literacy in a post-truth era.\" Technical Services Quarterly, 36(2), pp. 231–232'},\n",
       " '10.1016/S0346-251X(01)00039-2': {'title': 'Differences in the metacognitive awareness of reading strategies among native and non-native readers',\n",
       "  'abstract': 'In this study, we examine differences in the reported use of reading strategies of native and non-native English speakers when reading academic materials. Participants were 302 college students (150 native-English-speaking US and 152 ESL students), who completed a survey of reading strategies aimed at discerning the strategies readers report using when coping with academic reading tasks. Results of the study revealed, first, that both US and ESL students display awareness of almost all of the strategies included in the survey. Secondly, both groups attribute the same order of importance to categories of reading strategies in the survey, regardless of their reading ability or gender: cognitive strategies (the deliberate actions readers take when comprehension problems develop), followed by metacognitive strategies (advanced planning and comprehension monitoring techniques), and support strategies (the tools readers seek out to aid comprehension). Thirdly, both ESL and US high-reading-ability students show comparable degrees of higher reported usage for cognitive and metacognitive reading strategies than lower-reading-ability students in the respective groups, and while the US high-reading-ability students seem to consider support reading strategies to be relatively more valuable than low-reading-ability US students, ESL students attribute high value to support reading strategies, regardless of their reading ability level. Lastly, in the US group, the females report significantly higher frequency of strategy usage; this gender effect is not reflected in the ESL sample.'},\n",
       " '10.1016/j.cviu.2024.103976': {'title': 'Simple contrastive learning in a self-supervised manner for robust visual question answering',\n",
       "  'abstract': 'Recent observations have revealed that Visual Question Answering models are susceptible to learning the spurious correlations formed by dataset biases, i.e., the language priors, instead of the intended solution. For instance, given a question and a relative image, some VQA systems are prone to provide the frequently occurring answer in the dataset while disregarding the image content. Such a preferred tendency has caused them to be brittle in real-world settings, harming the robustness of VQA models. We experimentally found that conventional VQA methods often confuse negative samples that with identical questions but different images, which results in the generation of linguistic bias. In this paper, we propose a simple contrastive learning scheme, namely SCLSM, to mitigate the above issues in a self-supervised manner. We construct several special negative samples and introduce a debiasing-aware contrastive learning approach to help the model learn more discriminative multimodal features, thus improving the ability of debiasing. The SCLSM is compatible with numerous VQA baselines. Experimental results on the widely-used public datasets VQA-CP v2 and VQA v2 validate the effectiveness of our proposed model.'},\n",
       " '10.1016/j.patrec.2024.01.009': {'title': 'Debiased Visual Question Answering via the perspective of question types',\n",
       "  'abstract': 'Visual Question Answering (VQA) aims to answer questions according to the given image. However, current VQA models tend to rely solely on textual information from the questions and ignore the visual information in the images to get answers, which is caused by bias that is generated during the training phase. Previous studies have shown that bias in VQA is mainly caused by the text modality, and our analysis suggests that question type is a crucial factor in bias formation. To address this bias, we proposed a self-supervised method including the Against Biased Samples(ABS) module that performs targeted debiasing by selecting samples that are prone to bias, and the Shuffle Question types(SQT) module that constructs negative samples by randomly replacing the question types of the samples selected by the ABS, to interrupting the shortcuts from question type to answer. Our approach mitigates the question-to-answer bias without using external annotations, overcoming the prior language problem. Additionally, we designed a new objective function for negative samples. Experimental results indicate that our method outperforms both self-supervised-based and supervised-based state-of-the-art approaches, achieving 70.36% accuracy on the VQA-CP v2 dataset.'},\n",
       " '10.1016/j.eswa.2023.123125': {'title': 'ASCL: Adaptive self-supervised counterfactual learning for robust visual question answering',\n",
       "  'abstract': 'Visual question answering (VQA) is a critical multimodal task in which an agent must answer questions according to the visual cue. Unfortunately, language bias is a common problem in VQA, which refers to the situation where the model generates answers solely based on the surface-level correlations between the question-answer pairs in the training set, without fully understanding the visual content. To reduce the language bias, Several recent approaches increase the image-dependency by introducing auxiliary tasks. However, these auxiliary tasks balance the data by adding extra manual image annotations or simply constructing counterfactual samples, without fully exploring the intrinsic information of the samples themselves. In this paper, we tackle the language bias problem by proposing an adaptive self-supervised counterfactual learning (ASCL) method to enhance the model’s understanding of images. We propose a new adaptive feature selection module to mine the intrinsic information of the samples. This module can adaptively divides the image into question-relevant visual positive objects and question-irrelevant visual negative objects based on the given question. The question-relevant visual positive objects are used directly to generate the predicted answer, in order to reduce the influence of visual distracting information on the model’s understanding of the image and ensure the actual cause of the answer. The question-irrelevant visual negative objects are treated as counterfactual samples to guide model training and prevent the model from being driven by language bias. To avoid incorrect classification of images on the classification edge during training, we propose an adaptive contrastive loss learning method that automatically adjusts the measurement distance to increase the distance between images on the classification edge. Our method has been extensively evaluated on the VQA-CP dataset, demonstrating its effectiveness and yielding improved results. Specifically, by leveraging the LMH model as a foundation, we achieve state-of-the-art performance on both the VQA CPv1 and VQA CPv2 datasets. Notably, our method significantly enhances the accuracy of the baseline, with improvements of 10.36% on the VQA CPv2 dataset and 9.38% on the VQA CPv1 dataset. The source code is publicly available at: https://github.com/shuxy0120/ASCL.'},\n",
       " '10.1016/j.neucom.2023.127144': {'title': 'Multi-modal anchor adaptation learning for multi-modal summarization',\n",
       "  'abstract': 'In this paper, we focus on analyzing the relationship between the input of source text and source image, and then through the integration and generalization of the multi-modal information (e.g., texts and images), outputs the multi-modal summarization including text and image. However, existing multi-modal summarization methods face several challenges: (1) Different modalities exist in different semantic spaces, and expressing the multi-modal information of source modalities in a similar semantic representation space is crucial. (2) For the result of text summarization, it is crucial to explore how to capture both the differences and similarities within the source modalities, which can reduce redundancy to improve the quality of text summarization. In order to overcome the challenge above, Multi-Modal Anchor Adaptation Learning for Multi-Modal Summarization (MA-Sum) has been proposed. Specifically, MA-Sum employs a novel and highly efficient image anchor selection method, which selects the object sample containing the richest image information as the image anchor. Simultaneously, it carefully selects the text sentence closely intertwined with the image semantics to serve as the language anchor. Therefore, the multi-modal anchor can be seen as a bridge for multi-modal alignment to alleviate the semantic gap between textual and visual. Moreover, based on the distance between the anchors and the semantic information in the respective modal, the positive and negative semantic information of each modal will be distinguished. Based on negative semantic information, the counterfactual learning mechanism is constructed to optimize the result of multi-modal summarization. Finally, the process of multi-modal features interaction is optimized by image summary which is chosen by using multi-modal anchors. According to the experimental results, compared with the state-of-art multi-modal summarization, our proposed MA-Sum can be optimized in terms of summarization consistency and completeness, so as to obtain the optimal multi-modal summarization metric.'},\n",
       " '10.1016/j.patrec.2023.11.024': {'title': 'Self-supervised knowledge distillation in counterfactual learning for VQA',\n",
       "  'abstract': 'As a popular cross-modal reasoning task, Visual Question Answering (VQA) has achieved great progress in recent years. However, the issue of language bias has always affected the reliability of VQA models. To address this problem, counterfactual learning methods are proposed to learn more robust features to mitigate the bias problem. However, current counterfactual learning approaches mainly focus on generating synthesized samples and assigning answers to them, neglecting the relationship between factual and original data, which hinders robust feature learning for effective reasoning. To overcome this limitation, we propose a Self-supervised Knowledge Distillation approach in Counterfactual Learning for VQA, dubbed as VQA-SkdCL, which utilizes a self-supervised constraint to make good use of the hidden knowledge in the factual samples, enhancing the robustness of VQA models. We demonstrate the effectiveness of the proposed approach on VQA v2, VQA-CP v1, and VQA-CP v2 datasets and our approach achieves excellent performance.'},\n",
       " '10.1016/j.cviu.2023.103842': {'title': 'Empirical study on using adapters for debiased Visual Question Answering',\n",
       "  'abstract': 'In this work, we empirically study debiased Visual Question Answering (VQA) works with Adapters. Most VQA debiasing works sacrifice in-distribution (ID) performance for the sake of out-of-distribution (OOD) performance. Hence, we explore and experiment with the use of adapters to preserve the ID performance by training only a simple adapter network to debias and recreate performance. We conduct an extensive empirical study on recent well-established VQA debiasing works and show that the entirety of the debiasing information from the proposed debiasing methods can be captured and modeled using a single fully connected layer while preserving original network performance by skipping the adapters. Through our exploration, we find that different placements of adapters are required for different debiasing techniques and show the different possibilities of using adapters for debiasing through our experiments. We believe our findings in this work open up more questions to be asked and explored for the VQA community.'},\n",
       " '10.1016/j.knosys.2023.110879': {'title': 'Question-conditioned debiasing with focal visual context fusion for visual question answering',\n",
       "  'abstract': 'Existing Visual Question Answering models suffer from the language prior, where the answers provided by the models overly rely on the correlations between questions and answers, ignoring the exact visual information, resulting in a significant drop in the out-of-distribution datasets. To eliminate such language bias, prevalent approaches mainly focus on weakening the language prior with one auxiliary question-only branch while focusing on the statistical question type–answer pairs’ distribution prior rather than that of question–answer pairs. Besides, most models provide the answer with improper visual groundings. This paper proposes a model-agnostic framework to address the above drawbacks by question-conditioned debiasing with focal visual context fusion. To begin with, instead of the question type-conditioned correlations, we overcome the language distribution shortcut from the aspect of question-conditioned correlations by removing the shortcut between questions and the most occurring answer. Additionally, we utilize the deviation of the predicted answer distribution and ground truth as the pseudo target to avoid the model falling into other frequent answers’ distribution bias. Further, we stress the imbalance of the number of images and questions that post higher requirements of a proper visual context. We improve the correct visual utilization ability based on contrastive sampling and design a focal visual context fusion module that incorporates the critical object word extracted from the question after the Part-Of-Speech tagging into the visual features to augment the salient visual information without human annotations. Extensive experiments on the three public benchmark datasets, i.e., VQA v2, VQA-CP v2, and VQA-CP v1, demonstrate the effectiveness of our model.'},\n",
       " '10.1016/j.compmedimag.2023.102290': {'title': 'Incremental learning for an evolving stream of medical ultrasound images via counterfactual thinking',\n",
       "  'abstract': 'Despite the fact that traditional deep learning (DL) approaches provide promising accuracy and efficiency in medical ultrasound image analysis, they cannot replace the physician in making a diagnosis since the DL model is only appropriate in static application scenarios. Currently, most DL-based models are incapable of learning new tasks in the dynamic clinical environments due to the catastrophic forgetting of old tasks. To address the above problem, we propose an incremental classifier that is sequentially trained on evolving tasks for medical ultrasound images by counterfactual thinking. Specifically, the proposed model consists of a feature extractor and a classifier that can add new classes at any time during training. Toward a more discriminative model in the continual learning setting, a contrastive strategy is designed to leverage fine-grained information by generating a series of counterfactual regions. For model optimization, we design a multi-task loss made up of a knowledge distillation loss, a cross-entropy loss, and a contrasting loss. This objective jointly enjoys the merits of less forgetting, better accuracy, and fine-grained information utilization. A newly collected dataset with 52 medical ultrasound classification tasks is used to demonstrate the effectiveness of our method. The proposed approach achieves 76.59%, 11.67%, and 7.93% in terms of the average incremental accuracy, forgetting rate, and feature retention, respectively.'},\n",
       " '10.1007/978-981-99-6207-5_4': {'title': 'Overcoming Language Priors with Counterfactual Inference for Visual Question Answering',\n",
       "  'abstract': 'Recent years have seen a lot of efforts in attacking the issue of language priors in the field of Visual Question Answering (VQA). Among the extensive efforts, causal inference is regarded as a promising direction to mitigate language bias by weakening the direct causal effect of questions on answers. In this paper, we follow the same direction and attack the issue of language priors by incorporating counterfactual data. Moreover, we propose a two-stage training strategy which is deemed to make better use of counterfactual data. Experiments on the widely used benchmark VQA-CP v2 demonstrate the effectiveness of the proposed approach, which improves the baseline by $$21.21\\\\%$$ and outperforms most of the previous systems.'},\n",
       " '10.11834/jig.211137': {'title': 'Answer mask-fused visual question answering model',\n",
       "  'abstract': \"目的 现有的视觉问答模型由于受到语言先验的影响，预测准确率不高。虽然模型能够根据数据集中问题和答案的统计规律学习到它们之间简单的对应关系，但无法学习到问题和答案类型之间深层次的对应关系，容易出现答非所问的现象。为此，提出了一种使用答案掩码对预测结果中的无关答案进行遮盖的方法，迫使模型关注问题和答案类型之间的对应关系，提高模型的预测准确率。方法 首先对数据集中的答案进行聚类并为每一类答案生成不同的答案掩码，然后使用预训练的答案类型识别模型预测问题对应的答案类型，并根据该模型的预测结果选择相应的答案掩码对基线模型的预测结果进行遮盖，最终得到正确答案。结果 提出的方法使用UpDn（bottom-upand top-down ）、RUBi （reducing unimodal biases ）、LMH（learned-mixin+h ）和CSS（counterfactual samples synthesizing ）4种模型作为基线模型，在3个大型公开数据集上进行实验。在VQA（visual question answer）-CP v2.0数据集上的实验结果表明，本文方法使UpDn模型的准确率提高了2.15%，LMH模型的准确率提高了2.29%，融合本方法的CSS模型的准确率达到了60.14%，较原模型提升了2.02%，达到了目前较高的水平。在VQA v2.0和VQA-CP v1.0数据集上的结果也显示本文方法提高了大多数模型的准确率，具有良好的泛化性。此外，在VQA-CP v2.0上的消融实验证明了本文方法的有效性。结论 提出的方法通过答案掩码对视觉问答模型的预测结果进行遮盖，减少无关答案对最终结果的影响，使模型学习到问题和答案类型之间的对应关系，有效改善了视觉问答模型答非所问的现象，提高了模型的预测准确率。;Objective Visual question answering（VQA）is essential for artificial intelligence（AI）in recent years. Current VQA is concerned of the linkage of natural language processing and computer vision more. Therefore，VQA-related model is required for text and image information processing simultaneously，and the information of these two modes can be fused to infer the answer. Such popular VQA models like VQA v2. 0 dataset have been developing in terms of a deep neural network and trained samples. However，these prior language models-based tasks can be simplified to learn the surface relationship for answer questions between questions and answers. The weakness of uneven distribution of answers is still to be challenged for its weak generalization and poor performance in the VQA-CP v2. 0 dataset. Specifically，language problemsprior has threatened for its prediction errors of the model and the predicted answer and question are in irrelevance. To optimize this non-linkage and generalization of the model，we develop an answer mask-related method to cover the irrelevant answers for predictable results，which can forge the model to learn the deeper relationship between question and answer. The prediction accuracy of the model can be improved as well. Method The prediction results of the baseline model is masked via the answer mask. It is necessary to cluster all candidate answers and fewer answers-involved for each type of answer can be used to preserve accurate classification through more answers-irrelevant coverage of mask-of the prediction results. The answers consist of non-contextual words and phrases. Conventional Word2Vec and Glove is still challenged for its effectiveness of these encoded answers. Such clip is illustrated as the encoder to extract the answer features. And，the kmeans algorithm is used to cluster answer-extracted feature vectors. After clustering，original dataset can be modified and the corresponded type is changed to the clustering-after type answer of the dataset，and different answer mask vectors are generated for each answer type. The answer mask vector is structured of 0 and 1. The elements of the vector can be assigned to 1 when the corresponding positions are contained for each answer type，and the others are configured to 0；the impact of irrelevant answers of prediction can be eliminated for final results of the baseline model. We design an answer type recognition model，which uses the questions and answers types for pre-training. Input question-based model can be used to predict the answer type corresponding to the question. The model’s accuracy can reflect the quality of clustering work，and its prediction results are the basis for the optioned answers mask types- task. The baseline model is focused on encoding the image and text and depth neural network is linked to fuse the image and text features. The preliminary prediction results can be obtained through the classifier as well. First，corresponding answer mask vector is leaked out in terms of answer type identification model-based prediction results. Then，the multiplied prediction results are generated via the baseline model and the distribution of irrelevant answers are covered in the prediction results of the baseline model. At the end，final results are predicted. The model is trained to learn the corresponding relationship between the types of questions and answers. Result We selected out UpDn，RUBi，LMH and CSS as baseline models and experiments are carried out on three large public datasets mentioned below. VQA-CP v2. 0 dataset-related experiments can show its potentials for model’s accuracy. Three sort of accuracy of the UpDn，LMH and CSS model are improved by 2. 15%，2. 29% and 2. 02% each. Among them，the higher accuracy of the CSS model is reached to 60. 14%. Additionally，our model's accuracy is preserved when VQA v2. 0-related accuracy is reduced. The VQA v2. 0-based experimental results show that the accuracy of most baseline models are improved further. Among them，the accuracy of the CSS model is optimized by 3. 18%. To demonstrate better generalization of our model，comparative experiments are carried out on VQA-CP v1. 0 dataset further. The experimental results show that our method is mutual-benefited for most of baseline models，which is sufficient to reflect its potential ability of generalization. Furthermore，ablation experiment on VQA-CP v2. 0 shows that the accuracy can be optimized further in terms of the answer mask. Conclusion We develop an answer mask-related method to cover irrelevant answers in the model prediction results and the final influence of irrelevant answers can be alleviated. The model is yielded to learn the corresponding relationship between the question and the answer type，and its challenge can be resolved for the question-irrelevant model's prediction answer to a certain extent ，and the model’s generalization and accuracy can be optimized as well.\"},\n",
       " '10.1007/978-3-031-26316-3_26': {'title': 'FunnyNet: Audiovisual Learning of Funny Moments in Videos',\n",
       "  'abstract': 'Automatically understanding funny moments (i.e., the moments that make people laugh) when watching comedy is challenging, as they relate to various features, such as facial expression, body language, dialogues and culture. In this paper, we propose FunnyNet, a model that relies on cross- and self-attention for both visual and audio data to predict funny moments in videos. Unlike most methods that focus on text with or without visual data to identify funny moments, in this work in addition to visual cues, we exploit audio. Audio comes naturally with videos, and moreover it contains higher-level cues associated with funny moments, such as intonation, pitch and pauses. To acquire labels for training, we propose an unsupervised approach that spots and labels funny audio moments. We provide experiments on five datasets: the sitcoms TBBT, MHD, MUStARD, Friends, and the TED talk UR-Funny. Extensive experiments and analysis show that FunnyNet successfully exploits visual and auditory cues to identify funny moments, while our findings corroborate our claim that audio is more suitable than text for funny moment prediction. FunnyNet sets the new state of the art for laughter detection with audiovisual or multimodal cues on all datasets.'},\n",
       " '10.1007/978-981-19-0964-1': {'title': 'Visual Question Answering',\n",
       "  'abstract': 'This book usually combines visual inputs like image and video with a natural language question concerning the input and generates a natural language answer'},\n",
       " '10.1007/978-3-030-58607-2_34': {'title': 'Learning What Makes a Difference from Counterfactual Examples and Gradient Supervision',\n",
       "  'abstract': 'One of the primary challenges limiting the applicability of deep learning is its susceptibility to learning spurious correlations rather than the underlying mechanisms of the task of interest. The resulting failure to generalise cannot be addressed by simply using more data from the same distribution. We propose an auxiliary training objective that improves the generalization capabilities of neural networks by leveraging an overlooked supervisory signal found in existing datasets. We use pairs of minimally-different examples with different labels, a.k.a counterfactual or contrasting examples, which provide a signal indicative of the underlying causal structure of the task. We show that such pairs can be identified in a number of existing datasets in computer vision (visual question answering, multi-label image classification) and natural language processing (sentiment analysis, natural language inference). The new training objective orients the gradient of a model’s decision function with pairs of counterfactual examples. Models trained with this technique demonstrate improved performance on out-of-distribution test sets.'},\n",
       " '10.1007/s11263-019-01228-7': {'title': 'Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization',\n",
       "  'abstract': 'We propose a technique for producing ‘visual explanations’ for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable. Our approach—Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say ‘dog’ in a classification network or a sequence of words in captioning network) flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g.VGG), (2) CNNs used for structured outputs (e.g.captioning), (3) CNNs used in tasks with multi-modal inputs (e.g.visual question answering) or reinforcement learning, all without architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are robust to adversarial perturbations, (d) are more faithful to the underlying model, and (e) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show that even non-attention based models learn to localize discriminative regions of input image. We devise a way to identify important neurons through Grad-CAM and combine it with neuron names (Bau et al. in Computer vision and pattern recognition, 2017) to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a ‘stronger’ deep network from a ‘weaker’ one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/, along with a demo on CloudCV (Agrawal et al., in: Mobile cloud visual media computing, pp 265–290. Springer, 2015) (http://gradcam.cloudcv.org) and a video at http://youtu.be/COjUB9Izk6E.'},\n",
       " '10.1007/s10489-024-05455-5': {'title': 'Revisiting clustering for efficient unsupervised dialogue structure induction',\n",
       "  'abstract': 'Abstract In the development of a task-oriented dialogue system, defining the dialogue structure is a time-consuming task. Hence, several works have looked into automatically inferring it from data, e.g., actual conversations between a customer and a support agent. To recover such dialogue structure, recent methods based on discrete variational models learn to jointly encode and cluster utterances in dialogue states, but (i) represent utterances by only considering preceding dialogue context, and (ii) are slow to train since they are optimized with a compute-expensive decoding objective. We revisit and improve upon an existing efficient pipeline approach, commonly adopted as a baseline, that first encodes utterances and then clusters them with k -means to induce the dialogue structure. However, the existing approach represents utterances as bag-of-words or skip-thought vectors, which have been shown to perform poorly in semantic similarity tasks, and without considering dialogue context. We therefore first investigate the use of more powerful transformer-based encoders for encoding utterances. Next, we propose ell o dar , a method for learning representations that capture both preceding and subsequent dialogue context, inspired by word-to-vec training strategies. ell o dar is efficient since representations are learned directly in the encoding space by finetuning just a single linear layer on top of a frozen sentence encoder with a vector-to-vector regression training objective. Extensive experiments on representative datasets for dialogue structure induction (SimDial, Schema Guided Dialogues, DSTC2, and CamRest676) demonstrate that in terms of effectiveness to induce the correct dialogue structure, (i) clustering utterances represented by transformed-based encoders improves recent joint models by 13%–32% on standard cluster metrics, and (ii) clustering ell o dar ’s representations yields additional improvements ranging from +20% to +26%, with speedups of $$\\\\times $$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mo>×</mml:mo> </mml:math> $$\\\\textbf{10}$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mn>10</mml:mn> </mml:math> – $$\\\\textbf{10}^{\\\\textbf{4}}$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:msup> <mml:mn>10</mml:mn> <mml:mn>4</mml:mn> </mml:msup> </mml:math> compared to the recent joint models.'},\n",
       " '10.1016/j.neucom.2023.127132': {'title': 'Evidence, my Dear Watson: Abstractive dialogue summarization on learnable relevant utterances',\n",
       "  'abstract': 'Abstractive dialogue summarization requires distilling and rephrasing key information from noisy multi-speaker documents. Combining pre-trained language models with input augmentation techniques has recently led to significant research progress. However, existing solutions still struggle to select relevant chat segments, primarily relying on open-domain and unsupervised annotators not tailored to the actual needs of the summarization task. In this paper, we propose DearWatson, a task-aware utterance-level annotation framework for improving the effectiveness and interpretability of pre-trained dialogue summarization models. Precisely, we learn relevant utterances in the source document and mark them with special tags, that then act as supporting evidence for the generated summary. Quantitative experiments are conducted on two datasets made up of real-life messenger conversations. The results show that DearWatson allows model attention to focus on salient tokens, achieving new state-of-the-art results in three evaluation metrics, including semantic and factuality measures. Human evaluation proves the superiority of our solution in semantic consistency and recall. Finally, extensive ablation studies confirm each module’s importance, also exploring different annotation strategies and parameter-efficient fine-tuning of large generative language models.'},\n",
       " '10.1007/978-3-031-44693-1_1': {'title': 'A Task-Oriented Dialog Model with Task-Progressive and Policy-Aware Pre-training',\n",
       "  'abstract': 'Pre-trained conversation models (PCMs) have achieved promising progress in recent years. However, existing PCMs for Task-oriented dialog (TOD) are insufficient for capturing the sequential nature of the TOD-related tasks, as well as for learning dialog policy information. To alleviate these problems, this paper proposes a task-progressive PCM with two policy-aware pre-training tasks. The model is pre-trained through three stages where TOD-related tasks are progressively employed according to the task logic of the TOD system. A global policy consistency task is designed to capture the multi-turn dialog policy sequential relation, and an act-based contrastive learning task is designed to capture similarities among samples with the same dialog policy. Our model achieves better results on both MultiWOZ and In-Car end-to-end dialog modeling benchmarks with only 18% parameters and 25% pre-training data compared to the previous state-of-the-art PCM, GALAXY. We make our code and data publicly available ( https://github.com/lucenzhong/TPLD ).'},\n",
       " '10.1016/j.nlp.2023.100037': {'title': 'On the instability of further pre-training: Does a single sentence matter to BERT?',\n",
       "  'abstract': 'We observe a remarkable instability in BERT-like models: minimal changes in the internal representations of BERT, as induced by one-step further pre-training with even a single sentence, can noticeably change the behaviour of subsequently fine-tuned models. While the pre-trained models seem to be essentially the same, also by means of established similarity assessment techniques, the measurable tiny changes appear to substantially impact the models’ tuning path, leading to significantly different fine-tuned systems and affecting downstream performance. After testing a very large number of combinations, which we briefly summarize, the experiments reported in this short paper focus on an intermediate phase consisting of a single-step and single-sentence masked language modeling stage and its impact on a sentiment analysis task. We discuss a series of unexpected findings which leave some open questions over the nature and stability of further pre-training.'},\n",
       " '10.1016/j.inffus.2023.101988': {'title': 'A survey on semantic processing techniques',\n",
       "  'abstract': 'Semantic processing is a fundamental research domain in computational linguistics. In the era of powerful pre-trained language models and large language models, the advancement of research in this domain appears to be decelerating. However, the study of semantics is multi-dimensional in linguistics. The research depth and breadth of computational semantic processing can be largely improved with new technologies. In this survey, we analyzed five semantic processing tasks, e.g., word sense disambiguation, anaphora resolution, named entity recognition, concept extraction, and subjectivity detection. We study relevant theoretical research in these fields, advanced methods, and downstream applications. We connect the surveyed tasks with downstream applications because this may inspire future scholars to fuse these low-level semantic processing tasks with high-level natural language processing tasks. The review of theoretical research may also inspire new tasks and technologies in the semantic processing domain. Finally, we compare the different semantic processing techniques and summarize their technical trends, application trends, and future directions.'},\n",
       " '10.1038/s41598-022-24787-1': {'title': 'Multiturn dialogue generation by modeling sentence-level and discourse-level contexts',\n",
       "  'abstract': 'Currently, multiturn dialogue models generate human-like responses based on pretrained language models given a dialogue history. However, most existing models simply concatenate dialogue histories, which makes it difficult to maintain a high degree of consistency throughout the generated text. We speculate that this is because the encoder ignores information about the hierarchical structure between sentences. In this paper, we propose a novel multiturn dialogue generation model that captures contextual information at the sentence level and at the discourse level during the encoding process. The context semantic information is dynamically modeled through a difference-aware module. A sentence order prediction training task is also designed to learn representation by reconstructing the order of disrupted sentences with a learning-to-rank algorithm. Experiments on the multiturn dialogue dataset, DailyDialog, demonstrate that our model substantially outperforms the baseline model in terms of both automatic and human evaluation metrics, generating more fluent and informative responses than the baseline model.'},\n",
       " '10.1007/978-3-031-15168-2_1': {'title': 'Call Larisa Ivanovna: Code-Switching Fools Multilingual NLU Models',\n",
       "  'abstract': 'Practical needs of developing task-oriented dialogue assistants require the ability to understand many languages. Novel benchmarks for multilingual natural language understanding (NLU) include monolingual sentences in several languages, annotated with intents and slots. In such setup models for cross-lingual transfer show remarkable performance in joint intent recognition and slot filling. However, existing benchmarks lack of code-switched utterances, which are difficult to gather and label due to complexity in the grammatical structure. The evaluation of NLU models seems biased and limited, since code-switching is being left out of scope. Our work adopts recognized methods to generate plausible and naturally-sounding code-switched utterances and uses them to create a synthetic code-switched test set. Based on experiments, we report that the state-of-the-art NLU models are unable to handle code-switching. At worst, the performance, evaluated by semantic accuracy, drops as low as 15% from 80% across languages. Further we show, that pre-training on synthetic code-mixed data helps to maintain performance on the proposed test set at a comparable level with monolingual data. Finally, we analyze different language pairs and show that the closer the languages are, the better the NLU model handles their alternation. This is in line with the common understanding of how multilingual models conduct transferring between languages.'},\n",
       " '10.1016/J.KNOSYS.2021.107186': {'title': 'Heterogeneous Relational Graph Neural Networks with Adaptive Objective for End-to-End Task-Oriented Dialogue',\n",
       "  'abstract': 'End-to-end task-oriented dialogue systems, which provide a natural and informative way for human–computer interaction, are gaining more and more attention. The main challenge of such dialogue systems is how to effectively incorporate external knowledge bases into the learning framework. However, existing approaches usually overlook the natural graph structure information in the knowledge base and the relevant information between the knowledge base and the dialogue history, which makes them deficient in handling the above challenge. Besides, existing methods ignore the entity imbalance problem and treat different entities in system responses indiscriminately, which limits the learning of hard target entities. To address the two challenges, we propose Heterogeneous Relational Graph Neural Networks with Adaptive Objective (HRGNN-AO) for end-to-end task-oriented dialogue systems. In the method, we explore effective heterogeneous relational graphs to jointly capture multi-perspective graph structure information from the knowledge base and the dialogue history, which ultimately facilitates the generation of informative responses. Moreover, we design two components, shared-private parameterization and hierarchical attention mechanism, to solve the overfitting and confusion problems in the heterogeneous relational graph, respectively. To handle the entity imbalance problem, we propose an adaptive objective, which dynamically adjusts the weights of different target entities during the training process. The experimental results show that HRGNN-AO is effective in generating informative responses and outperforms state-of-the-art dialogue systems on the SMD and extended Multi-WOZ 2.1 datasets.'},\n",
       " '10.1007/978-981-19-5538-9_1': {'title': 'Out-of-Scope Domain and Intent Classification through Hierarchical Joint Modeling',\n",
       "  'abstract': 'User queries for a real-world dialog system may sometimes fall outside the scope of the system’s capabilities, but appropriate system responses will enable smooth processing throughout the human-computer interaction. This paper is concerned with the user’s intent, and focuses on out-of-scope intent classification in dialog systems. Although user intents are highly correlated with the application domain, few studies have exploited such correlations for intent classification. Rather than developing a two-stage approach that first classifies the domain and then the intent, we propose a hierarchical multi-task learning approach based on a joint model to classify domain and intent simultaneously. Novelties in the proposed approach include (1) sharing supervised out-of-scope signals in joint modeling of domain and intent classification to replace a two-stage pipeline and (2) introducing a hierarchical model that learns the intent and domain representations in the higher and lower layers respectively. Experiments show that the model outperforms existing methods in terms of accuracy, out-of-scope recall, and $$F_1$$ . Additionally, threshold-based post-processing further improves performance by balancing precision and recall in intent classification.'},\n",
       " '10.1007/978-3-030-82099-2_4': {'title': 'Fuzzy Classification of Multi-intent Utterances',\n",
       "  'abstract': 'Current intent classification approaches assign binary intent class memberships to natural language utterances while disregarding the inherent vagueness in language and the corresponding vagueness in intent class boundaries. In this work, we propose a scheme to address the ambiguity in single-intent as well as multi-intent natural language utterances by creating degree memberships over fuzzified intent classes. To our knowledge, this is the first work to address and quantify the impact of the fuzzy nature of natural language utterances over intent category memberships. Additionally, our approach overcomes the sparsity of multi-intent utterance data to train classification models by using a small database of single intent utterances to generate class memberships over multi-intent utterances. We evaluate our approach over two task-oriented dialog datasets, across different fuzzy membership generation techniques and approximate string similarity measures. Our results reveal the impact of lexical overlap between utterances of different intents, and the underlying data distributions, on the fuzzification of intent memberships. Moreover, we evaluate the accuracy of our approach by comparing the defuzzified memberships to their binary counterparts, across different combinations of membership functions and string similarity measures.'},\n",
       " '10.1007/978-3-030-75768-7_23': {'title': 'Meta-context Transformers for Domain-Specific Response Generation',\n",
       "  'abstract': 'Transformer-based models, such as GPT-2, have revolutionized the landscape of dialogue generation by capturing the long-range structures through language modeling. Though these models have exhibited excellent language coherence, they often lack relevance and terms when used for domain-specific response generation. In this paper, we present DSRNet (Domain Specific Response Network), a transformer-based model for dialogue response generation by reinforcing domain-specific attributes. In particular, we extract meta attributes from context and joinly model with the dialogue context utterances for better attention over domain-specific keyterms and relevance. We study the use of DSRNet in a multi-turn multi-interlocutor environment for domain-specific response generation. In our experiments, we evaluate DSRNet on Ubuntu dialogue datasets, which are mainly composed of various technical domain related dialogues for IT domain issue resolutions and also on CamRest676 dataset, which contains restaurant domain conversations. We observe that the responses produced by our model carry higher relevance due to the presence of domain-specific key attributes that exhibit better overlap with the attributes of the context. Our analysis shows that the performance improvement is mostly due to the infusion of key terms along with dialogues which result in better attention over domain-relevant terms.'},\n",
       " '10.1016/j.neucom.2022.10.036': {'title': 'Dialogue-adaptive language model pre-training from quality estimation☆',\n",
       "  'abstract': 'Pre-trained language models (PrLMs) have achieved great success on a wide range of natural language processing tasks by virtue of the universal language representation ability obtained by self-supervised learning on a large corpus. These models are pre-trained on standard plain texts with general language model (LM) training objectives, which would be insufficient to model dialogue-exclusive attributes like specificity and informativeness reflected in these tasks that are not explicitly captured by the pre-trained universal language representations. In this work, we propose dialogue-adaptive pre-training objectives (DAPO) derived from quality estimation to simulate dialogue-specific features, namely coherence, specificity, and informativeness. As the foundation for model pre-training, we synthesize a new dialogue corpus and build our training set with two unsupervised methods: 1) coherence-oriented context corruption, including utterance ordering, insertion, and replacement, to help the model capture the coherence inside the dialogue contexts; and 2) specificity-oriented automatic rescoring, which encourages the model to measure the quality of the synthesized data for dialogue-adaptive pre-training by considering specificity and informativeness. Experimental results on widely used open-domain response selection and quality estimation benchmarks show that DAPO significantly improves the baseline models and achieves state-of-the-art performance on the MuTual leaderboard, verifying the effectiveness of estimating quality evaluation factors into pre-training.'},\n",
       " '10.1016/j.inffus.2020.06.005': {'title': 'Conversational transfer learning for emotion recognition',\n",
       "  'abstract': 'Recognizing emotions in conversations is a challenging task due to the presence of contextual dependencies governed by self- and inter-personal influences. Recent approaches have focused on modeling these dependencies primarily via supervised learning. However, purely supervised strategies demand large amounts of annotated data, which is lacking in most of the available corpora in this task. To tackle this challenge, we look at transfer learning approaches as a viable alternative. Given the large amount of available conversational data, we investigate whether generative conversational models can be leveraged to transfer affective knowledge for detecting emotions in context. We propose an approach, TL-ERC, where we pre-train a hierarchical dialogue model on multi-turn conversations (source) and then transfer its parameters to a conversational emotion classifier (target). In addition to the popular practice of using pre-trained sentence encoders, our approach also incorporates recurrent parameters that model inter-sentential context across the whole conversation. Based on this idea, we perform several experiments across multiple datasets and find improvement in performance and robustness against limited training data. TL-ERC also achieves better validation performances in significantly fewer epochs. Overall, we infer that knowledge acquired from dialogue generators can indeed help recognize emotions in conversations.'},\n",
       " '10.1007/978-3-030-66665-1_21': {'title': 'OWI: Open-World Intent Identification Framework for Dialog Based System',\n",
       "  'abstract': 'Automated task-oriented dialog based system, generally stated as Chatbot, is widely used nowadays by service-oriented platforms such as banking, mobile service providers and travel management firms. The most imperative part of the task-oriented dialog system is to distinguish the intent of the queries asked. If the system erroneously identifies the intent of the query, then the given answer is either incorrect or not related to the query asked. This raises the risk of deteriorating the reliability of the entire system and the organization. Such kind of systems struggle when a user asks queries that contain words for which training classes are not available. These classes may be termed as unseen classes. Our aim is to find the unseen classes in an automated task-oriented dialog system. This paper focuses on open-world learning. Specifically, we propose a deep learning-based Intent Identification framework, OWI, to identify unseen classes for an automated dialog-based system. The OWI framework is based on convolutional neural network with a 1-vs-rest output layer to identify the unseen classes. The proposed model is evaluated on various performance matrices. In addition, we compare OWI with an existing state-of-the-art model. The experimental results show that the OWI outperforms the existing model with respect to identifying unseen classes.'},\n",
       " '10.1016/J.ENGAPPAI.2019.07.010': {'title': 'A reproducible survey on word embeddings and ontology-based methods for word similarity: Linear combinations outperform the state of the art',\n",
       "  'abstract': 'Human similarity and relatedness judgements between concepts underlie most of cognitive capabilities, such as categorisation, memory, decision-making and reasoning. For this reason, the proposal of methods for the estimation of the degree of similarity and relatedness between words and concepts has been a very active line of research in the fields of artificial intelligence, information retrieval and natural language processing among others. Main approaches proposed in the literature can be categorised in two large families as follows: (1) Ontology-based semantic similarity Measures (OM) and (2) distributional measures whose most recent and successful methods are based on Word Embedding (WE) models. However, the lack of a deep analysis of both families of methods slows down the advance of this line of research and its applications. This work introduces the largest, reproducible and detailed experimental survey of OM measures and WE models reported in the literature which is based on the evaluation of both families of methods on a same software platform, with the aim of elucidating what is the state of the problem. We show that WE models which combine distributional and ontology-based information get the best results, and in addition, we show for the first time that a simple average of two best performing WE models with other ontology-based measures or WE models is able to improve the state of the art by a large margin. In addition, we provide a very detailed reproducibility protocol together with a collection of software tools and datasets as supplementary material to allow the exact replication of our results.'},\n",
       " '10.1016/j.knosys.2018.03.016': {'title': 'Enhancing user creativity: Semantic measures for idea generation',\n",
       "  'abstract': 'Human creativity generates novel ideas to solve real-world problems. This thereby grants us the power to transform the surrounding world and extend our human attributes beyond what is currently possible. Creative ideas are not just new and unexpected, but are also successful in providing solutions that are useful, efficient and valuable. Thus, creativity optimizes the use of available resources and increases wealth. The origin of human creativity, however, is poorly understood, and semantic measures that could predict the success of generated ideas are currently unknown. Here, we analyze a dataset of design problem-solving conversations in real-world settings by using 49 semantic measures based on WordNet 3.1 and demonstrate that a divergence of semantic similarity, an increased information content, and a decreased polysemy predict the success of generated ideas. The first feedback from clients also enhances information content and leads to a divergence of successful ideas in creative problem solving. These results advance cognitive science by identifying real-world processes in human problem solving that are relevant to the success of produced solutions and provide tools for real-time monitoring of problem solving, student training and skill acquisition. A selected subset of information content (IC Sánchez–Batet) and semantic similarity (Lin/Sánchez–Batet) measures, which are both statistically powerful and computationally fast, could support the development of technologies for computer-assisted enhancements of human creativity or for the implementation of creativity in machines endowed with general artificial intelligence.'},\n",
       " '10.1016/j.jbi.2017.03.007': {'title': 'Using ontology-based semantic similarity to facilitate the article screening process for systematic reviews',\n",
       "  'abstract': 'Systematic Reviews (SRs) are utilized to summarize evidence from high quality studies and are considered the preferred source of evidence-based practice (EBP). However, conducting SRs can be time and labor intensive due to the high cost of article screening. In previous studies, we demonstrated utilizing established (lexical) article relationships to facilitate the identification of relevant articles in an efficient and effective manner. Here we propose to enhance article relationships with background semantic knowledge derived from Unified Medical Language System (UMLS) concepts and ontologies.We developed a pipelined semantic concepts representation process to represent articles from an SR into an optimized and enriched semantic space of UMLS concepts. Throughout the process, we leveraged concepts and concept relations encoded in biomedical ontologies (SNOMED-CT and MeSH) within the UMLS framework to prompt concept features of each article. Article relationships (similarities) were established and represented as a semantic article network, which was readily applied to assist with the article screening process. We incorporated the concept of active learning to simulate an interactive article recommendation process, and evaluated the performance on 15 completed SRs. We used work saved over sampling at 95% recall (WSS95) as the performance measure.We compared the WSS95 performance of our ontology-based semantic approach to existing lexical feature approaches and corpus-based semantic approaches, and found that we had better WSS95 in most SRs. We also had the highest average WSS95 of 43.81% and the highest total WSS95 of 657.18%.We demonstrated using ontology-based semantics to facilitate the identification of relevant articles for SRs. Effective concepts and concept relations derived from UMLS ontologies can be utilized to establish article semantic relationships. Our approach provided a promising performance and can easily apply to any SR topics in the biomedical domain with generalizability.'},\n",
       " '10.1016/j.knosys.2016.12.013': {'title': 'Interpretable semantic textual similarity: Finding and explaining differences between sentences',\n",
       "  'abstract': 'User acceptance of artificial intelligence agents might depend on their ability to explain their reasoning, which requires adding an interpretability layer that fa- cilitates users to understand their behavior. This paper focuses on adding an in- terpretable layer on top of Semantic Textual Similarity (STS), which measures the degree of semantic equivalence between two sentences. The interpretability layer is formalized as the alignment between pairs of segments across the two sentences, where the relation between the segments is labeled with a relation type and a similarity score. We present a publicly available dataset of sentence pairs annotated following the formalization. We then develop a system trained on this dataset which, given a sentence pair, explains what is similar and different, in the form of graded and typed segment alignments. When evaluated on the dataset, the system performs better than an informed baseline, showing that the dataset and task are well-defined and feasible. Most importantly, two user studies show how the system output can be used to automatically produce explanations in natural language. Users performed better when having access to the explanations, pro- viding preliminary evidence that our dataset and method to automatically produce explanations is useful in real applications.'},\n",
       " '10.1007/978-3-319-45243-2_12': {'title': 'WSD-TIC: Word Sense Disambiguation Using Taxonomic Information Content',\n",
       "  'abstract': 'Word sense disambiguation (WSD) is the ability to identify the meaning of words in context in a computational manner. WSD is considered as an AI-complete problem, that is, a task whose solution is at least as hard as the most difficult problems in artificial intelligence. This is basically used in application like information retrieval, machine translation, information extraction because of its semantics understanding. This paper describes the proposed approach (WSD-TIC) which is based on the words surrounding the polysemous word in a context. Each meaning of these words is represented by a vector composed of weighted nouns using taxonomic information content. The main emphasis of this paper is feature selection for disambiguation purpose. The assessment of WSD systems is discussed in the context of the Senseval campaign, aiming at the objective evaluation of our proposal to the systems participating in several different disambiguation tasks.'},\n",
       " '10.1016/j.engappai.2016.01.033': {'title': 'Derivation of “is a” taxonomy from Wikipedia Category Graph',\n",
       "  'abstract': 'Knowledge acquisition still represents one of the main challenging obstacles to designing intelligent systems exhibiting human-level performance in complex intelligent tasks. The recent developments in crowdsourcing technologies have opened new promising opportunities to overcome this problem by exploiting large amounts of machine readable knowledge to perform tasks requiring human intelligence. Wikipedia is a case of this research trend, being the largest collaborative and multilingual resource and linguistic knowledge that contains unstructured and semi-structured information. In this paper, we propose an approach for deriving “is a” taxonomy from the Wikipedia Categories Graph (WCG), which is an open collaborative resource. After building and filtering the WCG from a Wikipedia dump, the process would mainly consist in the exploitation of the “BY” tag and the sharing of plural headers. These methods provide a graph formed by a set of non-connected sub-graphs. Therefore, we propose a process for linking them to finally obtain an “is a” taxonomy with only one root and modeled as a direct acyclic graph (DAG). In this work, specific DAG handling algorithms are used, including an algorithm for a DAG into sub-DAGs and another for merging two DAGs. The obtained taxonomy is assessed using semantic similarity measures, which consist in quantifying the likeness between two concepts or words. Therefore, we exploit a set of well-known benchmarks to compare the results obtained via the generated taxonomy to those achieved with WordNet, a resource created and maintained by domain experts. The experimental results revealed good correlations between computed values and human judgments. Compared to WordNet, the derived taxonomy was also noted to lead to an enhanced coverage capacity.'},\n",
       " '10.1007/978-3-319-18111-0_25': {'title': 'Lemon and Tea Are Not Similar: Measuring Word-to-Word Similarity by Combining Different Methods',\n",
       "  'abstract': 'Substantial amount of work has been done on measuring word-to-word relatedness which is also commonly referred as similarity. Though relatedness and similarity are closely related, they are not the same as illustrated by the words lemon and tea which are related but not similar. The relatedness takes into account a broader ranLemge of relations while similarity only considers subsumption relations to assess how two objects are similar. We present in this paper a method for measuring the semantic similarity of words as a combination of various techniques including knowledge-based and corpus-based methods that capture different aspects of similarity. Our corpus based method exploits state-of-the-art word representations. We performed experiments with a recently published significantly large dataset called Simlex-999 and achieved a significantly better correlation (ρ = 0.642, P < 0.001) with human judgment compared to the individual performance.'},\n",
       " '10.1016/j.ins.2014.03.021': {'title': 'A semantic similarity measure based on information distance for ontology alignment',\n",
       "  'abstract': 'Ontology alignment is the key point to reach interoperability over ontologies. In semantic web environment, ontologies are usually distributed and heterogeneous and thus it is necessary to find the alignment between them before processing across them. Many efforts have been conducted to automate the alignment by discovering the correspondence between entities of ontologies. However, some problems are still obvious, and the most crucial one is that it is almost impossible to extract semantic meaning of a lexical label that denotes the entity by traditional methods. In this paper, ontology alignment is formalized as a problem of information distance metric. In this way, discovery of optimal alignment is cast as finding out the correspondences with minimal information distance. We demonstrate a novel measure named link weight that uses semantic characteristics of two entities and Google page count to calculate an information distance similarity between them. The experimental results show that our method is able to create alignments between different lexical entities that denotes the same ones. These results outperform the typical ontology alignment methods like PROMPT (Noy and Musen, 2000) [38], QOM (Ehrig and Staab, 2004) [12], and APFEL (Ehrig et al., 2005) [13] in terms of semantic precision and recall.'},\n",
       " '10.1016/j.websem.2013.05.005': {'title': 'Repeatable and reliable semantic search evaluation',\n",
       "  'abstract': 'An increasing amount of structured data on the Web has attracted industry attention and renewed research interest in what is collectively referred to as semantic search. These solutions exploit the explicit semantics captured in structured data such as RDF for enhancing document representation and retrieval, or for finding answers by directly searching over the data. These data have been used for different tasks and a wide range of corresponding semantic search solutions have been proposed in the past. However, it has been widely recognized that a standardized setting to evaluate and analyze the current state-of-the-art in semantic search is needed to monitor and stimulate further progress in the field. In this paper, we present an evaluation framework for semantic search, analyze the framework with regard to repeatability and reliability, and report on our experiences on applying it in the Semantic Search Challenge 2010 and 2011.'},\n",
       " '10.1016/j.eswa.2012.09.006': {'title': 'Semantic similarity measures for enhancing information retrieval in folksonomies',\n",
       "  'abstract': \"Collaborative tagging systems, also known as folksonomies, enable a user to annotate various web resources with a free set of tags for sharing and searching purposes. Tags in a folksonomy reflect users' collaborative cognition about information. Tags play an important role in a folksonomy as a means of indexing information to facilitate search and navigation of resources. However, the semantics of the tags, and therefore the semantics of the resources, are neither known nor explicitly stated. It is therefore difficult for users to find related resources due to the absence of a consistent semantic meaning among tags. The shortage of relevant tags increases data sparseness and decreases the rate of information extraction with respect to user queries. Defining semantic relationships between tags, resources, and users is an important research issue for the retrieval of related information from folksonomies. In this research, a method for finding semantic relationships among tags is proposed. The present study considers not only the pairwise relationships between tags, resources, and users, but also the relationships among all three. Experimental results using real datasets from Flickr and Del.icio.us show that the method proposed here is more effective than previous methods such as LCH, JCN, and LIN in finding semantic relationships among tags in a folksonomy.\"},\n",
       " '10.1016/j.datak.2007.10.001': {'title': 'Learning non-taxonomic relationships from web documents for domain ontology construction',\n",
       "  'abstract': 'In recent years, much effort has been put in ontology learning. However, the knowledge acquisition process is typically focused in the taxonomic aspect. The discovery of non-taxonomic relationships is often neglected, even though it is a fundamental point in structuring domain knowledge. This paper presents an automatic and unsupervised methodology that addresses the non-taxonomic learning process for constructing domain ontologies. It is able to discover domain-related verbs, extract non-taxonomically related concepts and label relationships, using the Web as corpus. The paper also discusses how the obtained relationships can be automatically evaluated against WordNet and presents encouraging results for several domains.'},\n",
       " '10.1007/978-3-540-25956-5_5': {'title': 'S-Match: an Algorithm and an Implementation of Semantic Matching',\n",
       "  'abstract': 'We think of Match as an operator which takes two graph-like structures (e.g., conceptual hierarchies or ontologies) and produces a mapping between those nodes of the two graphs that correspond semantically to each other. Semantic matching is a novel approach where semantic correspondences are discovered by computing, and returning as a result, the semantic information implicitly or explicitly codified in the labels of nodes and arcs. In this paper we present an algorithm implementing semantic matching, and we discuss its implementation within the S-Match system. We also test S-Match against three state of the art matching systems. The results, though preliminary, look promising, in particular for what concerns precision and recall.'},\n",
       " '10.1007/3-540-36456-0_24': {'title': 'Using Measures of Semantic Relatedness for Word Sense Disambiguation',\n",
       "  'abstract': 'This paper generalizes the Adapted Lesk Algorithm of Banerjee and Pedersen (2002) to a method of word sense disambiguation based on semantic relatedness. This is possible since Lesk’s original algorithm (1986) is based on gloss overlaps which can be viewed as a measure of semantic relatedness. We evaluate a variety of measures of semantic relatedness when applied to word sense disambiguation by carrying out experiments using the English lexical sample data of Senseval-2. We find that the gloss overlaps of Adapted Lesk and the semantic distance measure of Jiang and Conrath (1997) result in the highest accuracy.'},\n",
       " '10.1016/S0167-7152(98)00006-6': {'title': \"A weighted Kendall's tau statistic\",\n",
       "  'abstract': \"A weighted Kendall's tau statistic (τw) is proposed to measure weighted correlation. It can place more emphasis on items having low rankings than those have high rankings, or vice versa. The null limiting distribution is derived by the theory of U-statistics. An application, power comparison, and some critical values of τw are presented.\"},\n",
       " '10.1016/j.eswa.2016.09.028': {'title': 'A semantic similarity measure integrating multiple conceptual relationships for web service discovery',\n",
       "  'abstract': 'The process of Web service discovery identifies the most relevant services to requesters’ service queries. We propose a new measure of semantic similarity integrating multiple conceptual relationships (SIMCR) for Web service discovery. The new measure enables more accurate service-request comparison by treating different conceptual relationships in ontologies such as is-a, has-a and antonomy differently. Each service or request is represented by vectors of terms (or words) that characterize both the interface signature and textual description. The overall semantic similarity is computed as a weighted aggregation of interface similarity and description similarity. The experimental results confirm the effectiveness of the proposed semantic similarity measure. As demonstrated in this study, the semantic Web service discovery method based on the proposed similarity measure outperforms existing state-of-the-art discovery methods in terms of precision, recall and F-measure. The proposed semantic similarity measure has wider applications such as to improve document classification or clustering, and to more accurately represent and apply knowledge in expert and intelligent systems.'},\n",
       " '10.1016/J.COMPIND.2013.07.011': {'title': 'Ontology-based similarity for product information retrieval',\n",
       "  'abstract': 'Product development of today is becoming increasingly knowledge intensive. Specifically, design teams face considerable challenges in making effective use of increasing amounts of information. In order to support product information retrieval and reuse, one approach is to use case-based reasoning (CBR) in which problems are solved \"by using or adapting solutions to old problems.\" In CBR, a case includes both a representation of the problem and a solution to that problem. Case-based reasoning uses similarity measures to identify cases which are more relevant to the problem to be solved. However, most non-numeric similarity measures are based on syntactic grounds, which often fail to produce good matches when confronted with the meaning associated to the words they compare. To overcome this limitation, ontologies can be used to produce similarity measures that are based on semantics. This paper presents an ontology-based approach that can determine the similarity between two classes using feature-based similarity measures that replace features with attributes. The proposed approach is evaluated against other existing similarities. Finally, the effectiveness of the proposed approach is illustrated with a case study on product–service–system design problems.'},\n",
       " '10.1007/978-3-319-00032-9_13': {'title': 'On Two Classes of Weighted Rank Correlation Measures Deriving from the Spearman’s ρ',\n",
       "  'abstract': 'Weighted Rank Correlation indices are useful for measuring the agreement of two rankings when the top ranks are considered more important than the lower ones. This paper investigates, from a descriptive perspective, the behaviour of (i) five existing indices that introduce suitable weights in the simplified formula of the Spearman’s ρ and (ii) an additional five indices we derive using the same weights in the Pearson’s product-moment correlation index between ranks. For their evaluation, we consider that a good Weighted Rank Correlation index should (1) differ from ρ, if computed on the same pair of rankings and (2) assume a broad variety of values in the range $$[-1,+1]$$ , in order to better discriminate amongst different reorderings of the ranks. Results suggest that linear weights should be avoided and show that indices (ii) do not have equalities with ρ and are more sensitive.'},\n",
       " '10.1007/978-3-642-14350-2_2': {'title': 'An Effective Measure of Semantic Similarity',\n",
       "  'abstract': 'Measuring semantic similarity between two concepts is an important problem in web mining, targeted advertisement and domains that need semantic content matching. Nevertheless, developing a computational method capable of generating satisfactory results close to what humans would perceive is still a difficult task somewhat owed to the subjective nature of similarity. This paper presents an effective measure of semantic similarity between two concepts. It relies on hierarchical structure of WordNet 3.0, and considers not only semantic distance but also depth sum and depth difference between two concepts. The correlation value of the proposed semantic similarity measure compared with the human ratings reported by Miller and Charles for the dataset of 28 pairs of noun is higher than some other reported semantic similarity measures for the same dataset.'},\n",
       " '10.1007/978-3-322-95233-2_9': {'title': 'Decision Making in the Presence of Noise',\n",
       "  'abstract': 'We consider problems of decision making based on imperfect information. We derive Bayesian optimal decision procedures for some simple one-person games on trees in which the player is given redundant but noisy information about the true configuration of the game. Our procedures are computationally efficient, and the decision rules which they implement are describable by simple formulas. Not surprisingly, the presence of noise greatly affects the decision procedure, and decisions procedures that are optimal for the corresponding noiseless games may be far from optimal in the presence of noise. In many cases, the optimal decision depends not only on the given noisy data but also on knowledge of the expected amount of noise present in the data. For arbitrary m ∊ N, we present examples in which the optimal decision changes m times as the probability of error in an individual datum increases from 0 to 1/2. Thus, no decision procedure that is insensitive to (or does not know) the amount of uncertainty in the data can perform as well as one that is aware of the unreliability of its data.'},\n",
       " '10.1007/s10489-022-03678-y': {'title': 'Reminding the incremental language model via data-free self-distillation',\n",
       "  'abstract': 'Incremental language learning, which involves retrieving pseudo-data from previous tasks, can alleviate catastrophic forgetting. However, previous methods require a large amount of pseudo-data to approach the performance of multitask learning, and the performance decreases dramatically when there is significantly less pseudo-data than new task data. This decrease occurs because the pseudo-data are learned inefficiently and deviate from the real data. To address these issues, we propose reminding the incremental language model via data-free self-distillation (DFSD), which includes 1) self-distillation based on the Earth mover’s distance (SD-EMD) and 2) hidden data augmentation (HDA). SD-EMD can increase the efficiency of the model by adaptively estimating the knowledge distribution in all GPT-2 layers and effectively transferring data from the teacher model to the student model via adaptive self-multilayer-to-multilayer mapping. HDA can reduce deviations by decomposing the generation process via data augmentation and bootstrapping. Our experiments on decaNLP and text classification tasks with low pseudo-data sampling ratios reveal that the DFSD model outperforms previous state-of-the-art incremental methods. The advantages of DFSD become more apparent when there is less pseudo-data and larger deviations.'},\n",
       " '10.1007/978-3-030-84186-7_14': {'title': 'Multi-strategy Knowledge Distillation Based Teacher-Student Framework for Machine Reading Comprehension',\n",
       "  'abstract': 'The irrelevant information in documents poses a great challenge for machine reading comprehension (MRC). To deal with such a challenge, current MRC models generally fall into two separate parts: evidence extraction and answer prediction, where the former extracts the key evidence corresponding to the question, and the latter predicts the answer based on those sentences. However, such pipeline paradigms tend to accumulate errors, i.e. extracting the incorrect evidence results in predicting the wrong answer. In order to address this problem, we propose a Multi-Strategy Knowledge Distillation based Teacher-Student framework (MSKDTS) for machine reading comprehension. In our approach, we first take evidence and document respectively as the input reference information to build a teacher model and a student model. Then the multi-strategy knowledge distillation method transfers the knowledge from the teacher model to the student model at both feature and prediction level through knowledge distillation approach. Therefore, in the testing phase, the enhanced student model can predict answer similar to the teacher model without being aware of which sentence is the corresponding evidence in the document. Experimental results on the ReCO dataset demonstrate the effectiveness of our approach, and further ablation studies prove the effectiveness of both knowledge distillation strategies.'},\n",
       " '10.1007/978-3-030-01219-9_27': {'title': 'Lifelong Learning via Progressive Distillation and Retrospection',\n",
       "  'abstract': 'Lifelong learning aims at adapting a learned model to new tasks while retaining the knowledge gained earlier. A key challenge for lifelong learning is how to strike a balance between the preservation on old tasks and the adaptation to a new one within a given model. Approaches that combine both objectives in training have been explored in previous works. Yet the performance still suffers from considerable degradation in a long sequence of tasks. In this work, we propose a novel approach to lifelong learning, which tries to seek a better balance between preservation and adaptation via two techniques: Distillation and Retrospection. Specifically, the target model adapts to the new task by knowledge distillation from an intermediate expert, while the previous knowledge is more effectively preserved by caching a small subset of data for old tasks. The combination of Distillation and Retrospection leads to a more gentle learning curve for the target model, and extensive experiments demonstrate that our approach can bring consistent improvements on both old and new tasks (Project page: http://mmlab.ie.cuhk.edu.hk/projects/lifelong/ ).'},\n",
       " '10.1007/978-3-030-01219-9_9': {'title': 'Memory Aware Synapses: Learning What (not) to Forget',\n",
       "  'abstract': 'Humans can learn in a continuous manner. Old rarely utilized knowledge can be overwritten by new incoming information while important, frequently used knowledge is prevented from being erased. In artificial learning systems, lifelong learning so far has focused mainly on accumulating knowledge over tasks and overcoming catastrophic forgetting. In this paper, we argue that, given the limited model capacity and the unlimited new information to be learned, knowledge has to be preserved or erased selectively. Inspired by neuroplasticity, we propose a novel approach for lifelong learning, coined Memory Aware Synapses (MAS). It computes the importance of the parameters of a neural network in an unsupervised and online manner. Given a new sample which is fed to the network, MAS accumulates an importance measure for each parameter of the network, based on how sensitive the predicted output function is to a change in this parameter. When learning a new task, changes to important parameters can then be penalized, effectively preventing important knowledge related to previous tasks from being overwritten. Further, we show an interesting connection between a local version of our method and Hebb’s rule, which is a model for the learning process in the brain. We test our method on a sequence of object recognition tasks and on the challenging problem of learning an embedding for predicting <subject, predicate, object> triplets. We show state-of-the-art performance and, for the first time, the ability to adapt the importance of the parameters based on unlabeled data towards what the network needs (not) to forget, which may vary depending on test conditions.'},\n",
       " '10.1007/978-3-319-46493-0_37': {'title': 'Learning Without Forgetting',\n",
       "  'abstract': 'When building a unified vision system or gradually adding new capabilities to a system, the usual assumption is that training data for all tasks is always available. However, as the number of tasks grows, storing and retraining on such data becomes infeasible. A new problem arises where we add new capabilities to a Convolutional Neural Network (CNN), but the training data for its existing capabilities are unavailable. We propose our Learning without Forgetting method, which uses only new task data to train the network while preserving the original capabilities. Our method performs favorably compared to commonly used feature extraction and fine-tuning adaption techniques and performs similarly to multitask learning that uses original task data we assume unavailable. A more surprising observation is that Learning without Forgetting may be able to replace fine-tuning as standard practice for improved new task performance.'},\n",
       " '10.1007/s10506-023-09374-7': {'title': 'Bringing order into the realm of Transformer-based language models for artificial intelligence and law',\n",
       "  'abstract': 'Abstract Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the state-of-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitations and opportunities for further research development.'},\n",
       " '10.1016/j.asoc.2022.109438': {'title': 'Metapath and syntax-aware heterogeneous subgraph neural networks for spam review detection',\n",
       "  'abstract': 'Spam Review Detection is a subclass of text classification that aims to distinguish genuine reviews from spam reviews (e.g., irrelevant reviews, deceptive reviews, machine-generated reviews, and non-review messages). Previous studies have focused on review text analysis, abnormal behavior detection, and intrinsic relationship identification. However, these methods ignore different fraudulent camouflages and writing styles. In this paper, we instead design a Spam detection model Metapath-based Subgraph Aggregated Neural Network (Spam-MSANN) integrating three metapath-based subgraphs (i.e. User-Item Subgraph, Review Subgraph, and User-Review-Item Subgraph) and syntactic information to enhance the relevant representation of the review information with subgraph aggregation operations. Experimental results on benchmarking datasets (i.e. YelpCHI and Amazon) demonstrate that our Spam-MSANN model significantly improves the state-of-the-art models. Specifically, Spam-MSANN outperforms 11 of the 12 advanced benchmark models on these two datasets, which further manifests that the fusion of different metapath-based subgraphs and syntactic information is adequate for the spam review detection task.'},\n",
       " '10.1007/s12626-022-00101-3': {'title': 'Applying BERT Embeddings to Predict Legal Textual Entailment',\n",
       "  'abstract': 'Abstract Textual entailment classification is one of the hardest tasks for the Natural Language Processing community. In particular, working on entailment with legal statutes comes with an increased difficulty, for example in terms of different abstraction levels, terminology and required domain knowledge to solve this task. In course of the COLIEE competition, we develop three approaches to classify entailment. The first approach combines Sentence-BERT embeddings with a graph neural network, while the second approach uses the domain-specific model LEGAL-BERT, further trained on the competition’s retrieval task and fine-tuned for entailment classification. The third approach involves embedding syntactic parse trees with the KERMIT encoder and using them with a BERT model. In this work, we discuss the potential of the latter technique and why of all our submissions, the LEGAL-BERT runs may have outperformed the graph-based approach.'},\n",
       " '10.1016/0004-3702(90)90005-K': {'title': 'Recursive distributed representations',\n",
       "  'abstract': 'A longstanding difficulty for connectionist modeling has been how to represent variable-sized recursive data structures, such as trees and lists, in fixed-width patterns. This paper presents a connectionist architecture which automatically develops compact distributed representations for such compositional structures, as well as efficient accessing mechanisms for them. Patterns which stand for the internal nodes of fixed-valence trees are devised through the recursive use of backpropagation on three-layer auto-associative encoder networks. The resulting representations are novel, in that they combine apparently immiscible aspects of features, pointers, and symbol structures. They form a bridge between the data structures necessary for high-level cognitive tasks and the associative, pattern recognition machinery provided by neural networks.'},\n",
       " '10.1016/0010-0277(88)90031-5': {'title': 'Connectionism and cognitive architecture: A critical analysis',\n",
       "  'abstract': \"This paper explores differences between Connectionist proposals for cognitive architecture and the sorts of models that have traditionally been assumed in cognitive science. We claim that the major distinction is that, while both Connectionist and Classical architectures postulate representational mental states, the latter but not the former are committed to a symbol-level of representation, or to a ‘language of thought’: i.e., to representational states that have combinatorial syntactic and semantic structure. Several arguments for combinatorial structure in mental representations are then reviewed. These include arguments based on the ‘systematicity’ of mental representation: i.e., on the fact that cognitive capacities always exhibit certain symmetries, so that the ability to entertain a given thought implies the ability to entertain thoughts with semantically related contents. We claim that such arguments make a powerful case that mind/brain architecture is not Connectionist at the cognitive level. We then consider the possibility that Connectionism may provide an account of the neural (or ‘abstract neurological’) structures in which Classical cognitive architecture is implemented. We survey a number of the standard arguments that have been offered in favor of Connectionism, and conclude that they are coherent only on this interpretation. Cet articleétudie les différences entre modèles connectionistes et modèles classiques de la structure cognitive. Nous pensons que, bien que les deux types de modèles stipulent l'existence d'états mentaux représentationnels, la différence essentielle est que seuls les modèles classiques requièrent l'existence d'un niveau de représentation symbolique—un “langage de la pensée”—, c'est-à-dire d'états représentationnels possédant une structure syntaxique et sémantique. Nous examinons ensuite différents arguments qui militent en faveur de l'existence de représentations mentales ayant ces propriétés. Certains de ces arguments reposent sur la “systématicité” des représentations mentales, c'est-à-dire sur le fait que les capacités cognitives exhibent toujours certaines symétries, de sorte que la capacitéd'entretenir certaines pensées implique la capacitéd'entretenir d'autres pensées apparentées par leur contenu sémantique. Nous pensons que ces arguments montrent de manière convainquante que l'architecture de l'esprit/du cerveau n'est pas connectioniste au niveau cognitif. Nous nous demandons ensuite s'il est possible d'interpréter le connectionisme comme une analyse des structures neuronales (ou des structures neurologiques “abstraites”) dans lesquelles est réalisée l'architecture cognitive classique. Nous examinons plusieurs des arguments avancés habituellement en défense du connectionisme, et en concluons que ceux-ci n'ont de sens que dans cette interprétation.\"},\n",
       " '10.1007/978-94-011-2624-3_3': {'title': 'Syntactic Transformations on Distributed Representations',\n",
       "  'abstract': 'There has been much interest in the possibility of connectionist models whose representations can be endowed with compositional structure, and a variety of such models have been proposed. These models typically use distributed representations that arise from the functional composition of constituent parts. Functional composition and decomposition alone, however, yield only an implementation of classical symbolic theories. This paper explores the possibility of moving beyond implementation by exploiting holistic structure-sensitive operations on distributed representations. An experiment is performed using Pollack’s Recursive Auto-Associative Memory (RAAM). RAAM is used to construct distributed representations of syntactically structured sentences. A feed-forward network is then trained to operate directly on these representations, modeling syntactic transformations of the represented sentences. Successful training and generalization is obtained, demonstrating that the implicit structure present in these representations can be used for a kind of structure-sensitive processing unique to the connectionist domain.'},\n",
       " '10.1007/s10462-023-10633-x': {'title': 'Exploring aspect-based sentiment quadruple extraction with implicit aspects, opinions, and ChatGPT: a comprehensive survey',\n",
       "  'abstract': 'Abstract In contrast to earlier ABSA studies primarily concentrating on individual sentiment components, recent research has ventured into more complex ABSA tasks encompassing multiple elements, including pair, triplet, and quadruple sentiment analysis. Quadruple sentiment analysis, also called aspect-category-opinion-sentiment quadruple Extraction (ACOSQE), aims to dissect aspect terms, aspect categories, opinion terms, and sentiment polarities while considering implicit sentiment within sentences. Nonetheless, a comprehensive overview of ACOSQE and its corresponding solutions is currently lacking. This is the precise gap that our survey seeks to address. To be more precise, we systematically reclassify all subtasks of ABSA, reorganizing existing research from the perspective of the involved sentiment elements, with a primary focus on the latest advancements in the ACOSQE task. Regarding solutions, our survey offers a comprehensive summary of the state-of-the-art utilization of language models within the ACOSQE task. Additionally, we explore the application of ChatGPT in sentiment analysis. Finally, we review emerging trends and discuss the challenges, providing insights into potential future directions for ACOSQE within the broader context of ABSA.'},\n",
       " '10.1016/j.neucom.2022.04.064': {'title': 'Pair-wise aspect and opinion terms extraction as graph parsing via a novel mutually-aware interaction mechanism',\n",
       "  'abstract': 'The pair-wise aspect and opinion term extraction (PAOTE) task aims to extract aspect terms and opinion terms from reviews in the form of opinion pairs, which provides a global profile for reviews of goods or users. Up-to-date studies ignore the interaction between term detection and term pairing, which may be crucial for the PAOTE task. Other studies use syntactic dependency structures to enhance their models, which cannot better provide task-specific structural information. In this work, we design an aspect-to-opinion graph and transform PAOTE into a graph parsing task. To exploit the interaction between term detection and pairing, we propose a novel mutually-aware interaction network (MAIN), which interactively updates the representations for term detection and pairing via graph sampling and convolution. Further, the word-word graph learned during training can be iteratively refined and gradually approaches the aspect-to-opinion graph. Experimental results on four benchmark datasets show that our proposed method significantly outperforms strong baselines with state-of-the-art performance and achieves a maximum increase of 2.01 points on the F1 metric. Further analysis demonstrates the advance of the aspect-to-opinion graph and the effectiveness of the mutually-aware interaction mechanism.'},\n",
       " '10.1007/978-3-319-24033-6_20': {'title': 'LecTrack: Incremental Dialog State Tracking with Long Short-Term Memory Networks',\n",
       "  'abstract': 'A dialog state tracker is an important component in modern spoken dialog systems. We present the first trainable incremental dialog state tracker that directly uses automatic speech recognition hypotheses to track the state. It is based on a long short-term memory recurrent neural network, and it is fully trainable from annotated data. The tracker achieves promising performance on the Method and Requested tracking sub-tasks in DSTC2.'},\n",
       " '10.1021/cen-v039n019.p011': {'title': 'YOU NEED!',\n",
       "  'abstract': 'RETURN TO ISSUEPREVAdvertisementNEXTYOU NEED!Cite this: Chem. Eng. News 1961, 39, 19, 11Publication Date (Print):May 8, 1961Publication History Published online6 November 2010Published inissue 8 May 1961https://doi.org/10.1021/cen-v039n019.p011Copyright © 1961 American Chemical SocietyArticle Views62Altmetric-Citations-LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InReddit PDF (445 KB) Get e-Alerts'},\n",
       " '10.1038/s42256-023-00626-4': {'title': 'Parameter-efficient fine-tuning of large-scale pre-trained language models',\n",
       "  'abstract': 'Abstract With the prevalence of pre-trained language models (PLMs) and the pre-training–fine-tuning paradigm, it has been continuously shown that larger models tend to yield better performance. However, as PLMs scale up, fine-tuning and storing all the parameters is prohibitively costly and eventually becomes practically infeasible. This necessitates a new branch of research focusing on the parameter-efficient adaptation of PLMs, which optimizes a small portion of the model parameters while keeping the rest fixed, drastically cutting down computation and storage costs. In general, it demonstrates that large-scale models could be effectively stimulated by the optimization of a few parameters. Despite the various designs, here we discuss and analyse the approaches under a more consistent and accessible term ‘delta-tuning’, where ‘delta’ a mathematical notation often used to denote changes, is borrowed to refer to the portion of parameters that are ‘changed’ during training. We formally describe the problem and propose a unified categorization criterion for existing delta-tuning methods to explore their correlations and differences. We also discuss the theoretical principles underlying the effectiveness of delta-tuning and interpret them from the perspectives of optimization and optimal control. Furthermore, we provide a holistic empirical study on over 100 natural language processing tasks and investigate various aspects of delta-tuning. With comprehensive study and analysis, our research demonstrates the theoretical and practical properties of delta-tuning in the adaptation of PLMs.'},\n",
       " '10.2200/s01118ed1v01y202107hlt051': {'title': 'Explainable Natural Language Processing',\n",
       "  'abstract': 'This book presents a taxonomy framework and survey of methods relevant to explaining the decisions and analyzing the inner workings of Natural Language Processing (NLP) models.The book is intended to provide a snapshot of Explainable NLP, though the field continues to rapidly grow.The book is intended to be both readable by first-year M.Sc.students and interesting to an expert audience.The book opens by motivating a focus on providing a consistent taxonomy, pointing out inconsistencies and redundancies in previous taxonomies.It goes on to present (i) a taxonomy or framework for thinking about how approaches to explainable NLP relate to one another; (ii) brief surveys of each of the classes in the taxonomy, with a focus on methods that are relevant for NLP; and (iii) a discussion of the inherent limitations of some classes of methods, as well as how to best evaluate them.Finally, the book closes by providing a list of resources for further research on explainability.'},\n",
       " '10.1007/978-3-031-20044-1_14': {'title': 'DnA: Improving Few-Shot Transfer Learning with Low-Rank Decomposition and Alignment',\n",
       "  'abstract': 'Self-supervised (SS) learning has achieved remarkable success in learning strong representation for in-domain few-shot and semi-supervised tasks. However, when transferring such representations to downstream tasks with domain shifts, the performance degrades compared to its supervised counterpart, especially at the few-shot regime. In this paper, we proposed to boost the transferability of the self-supervised pre-trained models on cross-domain tasks via a novel self-supervised alignment step on the target domain using only unlabeled data before conducting the downstream supervised fine-tuning. A new reparameterization of the pre-trained weights is also presented to mitigate the potential catastrophic forgetting during the alignment step. It involves low-rank and sparse decomposition, that can elegantly balance between preserving the source domain knowledge without forgetting (via fixing the low-rank subspace), and the extra flexibility to absorb the new out-of-the-domain knowledge (via freeing the sparse residual). Our resultant framework, termed Decomposition-and-Alignment (DnA), significantly improves the few-shot transfer performance of the SS pre-trained model to downstream tasks with domain gaps. (The code is released at https://github.com/VITA-Group/DnA ).'},\n",
       " '10.1007/978-3-030-32381-3_16': {'title': 'How to Fine-Tune BERT for Text Classification?',\n",
       "  'abstract': 'Language model pre-training has proven to be useful in learning universal language representations. As a state-of-the-art language model pre-training model, BERT (Bidirectional Encoder Representations from Transformers) has achieved amazing results in many language understanding tasks. In this paper, we conduct exhaustive experiments to investigate different fine-tuning methods of BERT on text classification task and provide a general solution for BERT fine-tuning. Finally, the proposed solution obtains new state-of-the-art results on eight widely-studied text classification datasets.'},\n",
       " '10.1007/978-3-030-01225-0_5': {'title': 'Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights',\n",
       "  'abstract': 'This work presents a method for adapting a single, fixed deep neural network to multiple tasks without affecting performance on already learned tasks. By building upon ideas from network quantization and pruning, we learn binary masks that “piggyback” on an existing network, or are applied to unmodified weights of that network to provide good performance on a new task. These masks are learned in an end-to-end differentiable fashion, and incur a low overhead of 1 bit per network parameter, per task. Even though the underlying network is fixed, the ability to mask individual weights allows for the learning of a large number of filters. We show performance comparable to dedicated fine-tuned networks for a variety of classification tasks, including those with large domain shifts from the initial task (ImageNet), and a variety of network architectures. Our performance is agnostic to task ordering and we do not suffer from catastrophic forgetting or competition between tasks.'},\n",
       " '10.1007/978-3-319-46493-0_32': {'title': 'XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks',\n",
       "  'abstract': 'We propose two efficient approximations to standard convolutional neural networks: Binary-Weight-Networks and XNOR-Networks. In Binary-Weight-Networks, the filters are approximated with binary values resulting in 32 $$\\\\times $$ memory saving. In XNOR-Networks, both the filters and the input to convolutional layers are binary. XNOR-Networks approximate convolutions using primarily binary operations. This results in 58 $$\\\\times $$ faster convolutional operations (in terms of number of the high precision operations) and 32 $$\\\\times $$ memory savings. XNOR-Nets offer the possibility of running state-of-the-art networks on CPUs (rather than GPUs) in real-time. Our binary networks are simple, accurate, efficient, and work on challenging visual tasks. We evaluate our approach on the ImageNet classification task. The classification accuracy with a Binary-Weight-Network version of AlexNet is the same as the full-precision AlexNet. We compare our method with recent network binarization methods, BinaryConnect and BinaryNets, and outperform these methods by large margins on ImageNet, more than $$16\\\\,\\\\%$$ in top-1 accuracy. Our code is available at: http://allenai.org/plato/xnornet .'},\n",
       " '10.1016/S1364-6613(99)01294-2': {'title': 'Catastrophic forgetting in connectionist networks',\n",
       "  'abstract': \"All natural cognitive systems, and, in particular, our own, gradually forget previously learned information. Plausible models of human cognition should therefore exhibit similar patterns of gradual forgetting of old information as new information is acquired. Only rarely does new learning in natural cognitive systems completely disrupt or erase previously learned information; that is, natural cognitive systems do not, in general, forget 'catastrophically'. Unfortunately, though, catastrophic forgetting does occur under certain circumstances in distributed connectionist networks. The very features that give these networks their remarkable abilities to generalize, to function in the presence of degraded input, and so on, are found to be the root cause of catastrophic forgetting. The challenge in this field is to discover how to keep the advantages of distributed connectionist networks while avoiding the problem of catastrophic forgetting. In this article the causes, consequences and numerous solutions to the problem of catastrophic forgetting in neural networks are examined. The review will consider how the brain might have overcome this problem and will also explore the consequences of this solution for distributed connectionist networks.\"},\n",
       " '10.1017/9781139051699.031': {'title': 'Neural Networks for Machine Learning',\n",
       "  'abstract': 'In order for a digital neocortex to learn a new skill, it will still require many iterations of education, just as a biological neocortex does, but once a single neocortex somewhere and at some time learns something, it can share that knowledge with every other digital neocortex without delay. We can each have our own private neocortex extenders in the cloud, just as we have our own private stores of personal data today.—How to Create a Mind, Ray Kurzweil (2012)'},\n",
       " '10.1007/978-3-642-19400-9_14': {'title': 'Part-of-Speech Tagging from 97% to 100%: Is It Time for Some Linguistics?',\n",
       "  'abstract': 'I examine what would be necessary to move part-of-speech tagging performance from its current level of about 97.3% token accuracy (56% sentence accuracy) to close to 100% accuracy. I suggest that it must still be possible to greatly increase tagging performance and examine some useful improvements that have recently been made to the Stanford Part-of-Speech Tagger. However, an error analysis of some of the remaining errors suggests that there is limited further mileage to be had either from better machine learning or better features in a discriminative sequence classifier. The prospects for further gains from semi-supervised learning also seem quite limited. Rather, I suggest and begin to demonstrate that the largest opportunity for further progress comes from improving the taxonomic basis of the linguistic resources from which taggers are trained. That is, from improved descriptive linguistics. However, I conclude by suggesting that there are also limits to this process. The status of some words may not be able to be adequately captured by assigning them to one of a small number of categories. While conventions can be used in such cases to improve tagging consistency, they lack a strong linguistic basis.'},\n",
       " '10.1016/j.aei.2022.101557': {'title': 'Natural language generation and deep learning for intelligent building codes',\n",
       "  'abstract': 'Many existing automated compliance checking (ACC) systems require the processes of extracting regulatory information from natural-language building-code requirements and transforming the extracted information into computer-processable semantic representations. These processes could, however, be jeopardized by the ambiguous nature of the natural language and the hierarchically complex structures of building-code requirements. To address this problem, this paper proposes the concept of intelligent building code for bypassing the error-prone information extraction and transformation processes. In the proposed intelligent code, the natural-language requirements in the code are connected with highly structured computer-understandable semantic information, which is represented in the form of semantic requirement hierarchies and can be readily used by computers for ACC. The paper also proposes a deep learning-based method to automatically generate such intelligent code. The method leverages the requirement hierarchy representation, a proposed deep learning unit-to-text model for generating requirement sentence segments, and a proposed semantic correspondence score for configuring the segments into requirement sentences. The method was implemented and tested on a dataset from multiple regulatory documents. The generated intelligent requirements were evaluated in terms of both natural-language requirement comprehensibility and correspondence between the natural language and the semantic representation, with the results indicating high performance for the proposed representation and method. The proposed intelligent code will help reduce ACC errors, improve requirement comprehensibility, and facilitate intelligent code analytics.'},\n",
       " '10.1007/978-3-319-46448-0_51': {'title': 'Visual Relationship Detection with Language Priors',\n",
       "  'abstract': 'Visual relationships capture a wide variety of interactions between pairs of objects in images (e.g. “man riding bicycle” and “man pushing bicycle”). Consequently, the set of possible relationships is extremely large and it is difficult to obtain sufficient training examples for all possible relationships. Because of this limitation, previous work on visual relationship detection has concentrated on predicting only a handful of relationships. Though most relationships are infrequent, their objects (e.g. “man” and “bicycle”) and predicates (e.g. “riding” and “pushing”) independently occur more frequently. We propose a model that uses this insight to train visual models for objects and predicates individually and later combines them together to predict multiple relationships per image. We improve on prior work by leveraging language priors from semantic word embeddings to finetune the likelihood of a predicted relationship. Our model can scale to predict thousands of types of relationships from a few examples. Additionally, we localize the objects in the predicted relationships as bounding boxes in the image. We further demonstrate that understanding relationships can improve content based image retrieval.'},\n",
       " '10.1016/s1574-6526(07)x0300-6': {'title': 'Handbook of Knowledge Representation',\n",
       "  'abstract': 'Knowledge Representation, which lies at the core of Artificial Intelligence, is concerned with encoding knowledge on computers to enable systems to reason automatically. The Handbook of Knowledge Representation is an up-to-date review of twenty-five key topics in knowledge representation, written by the leaders of each field.This book is an essential resource for students, researchers and practitioners in all areas of Artificial Intelligence. * Make your computer smarter* Handle qualitative and uncertain information* Improve computational tractability to solve your problems easily'},\n",
       " '10.1007/b98634': {'title': 'Natural Language Generation',\n",
       "  'abstract': 'The Third International Conference on Natural Language Generation (INLG 2004) was held from 14th to 16th July 2004 at Careys Manor, Brockenhurst, UK. Supported by the Association for Computational Lin'},\n",
       " '10.1007/978-3-319-45510-5_27': {'title': 'CzEng 1.6: Enlarged Czech-English Parallel Corpus with Processing Tools Dockered',\n",
       "  'abstract': 'We present a new release of the Czech-English parallel corpus CzEng. CzEng 1.6 consists of about 0.5 billion words (\"gigaword\") in each language. The corpus is equipped with automatic annotation at a deep syntactic level of representation and alternatively in Universal Dependencies. Additionally, we release the complete annotation pipeline as a virtual machine in the Docker virtualization toolkit.'},\n",
       " '10.1145/3639233.3639354': {'title': 'Exploring Naive Approaches to Tell Apart LLMs Productions from Human-written Text',\n",
       "  'abstract': 'Powerful Large Language Models (large LMs or LLMs) such as BERT and GPT are making the task of detecting machine-generated text more and more prominent and crucial to minimize threats posed by text generation models misuse. Nonetheless, only a limited number of efforts exist so far, which can be classified into simple classifiers, zero-shot approaches, and fine-tuned LMs. These approaches usually rely on LMs whose discrimination accuracy decreases as the size difference in favor of the generator model increases (hence, a detector should always employ a LM with at least the same number of parameters of the source LM). Also, most of these approaches do not explicitly investigate whether the sentence syntactic structure can provide additional information that helps to build better detectors. All these considerations make the generalizing ability of detection methods into question. While generation techniques become more and more capable of producing human-like text, are the detection techniques capable of keeping up if not properly trained?'},\n",
       " '10.1007/978-981-99-4752-2_60': {'title': 'STADEE: STAtistics-Based DEEp Detection of Machine Generated Text',\n",
       "  'abstract': 'We present STADEE, a \\\\textbf{STA}tistics-based \\\\textbf{DEE}p detection method to identify machine-generated text, addressing the limitations of current methods that rely heavily on fine-tuning pre-trained language models (PLMs). STADEE integrates key statistical text features with a deep classifier, focusing on aspects like token probability and cumulative probability, crucial for handling nucleus sampling. Tested across diverse datasets and scenarios (in-domain, out-of-domain, and in-the-wild), STADEE demonstrates superior performance, achieving an 87.05% F1 score in-domain and outperforming both traditional statistical methods and fine-tuned PLMs, especially in out-of-domain and in-the-wild settings, highlighting its effectiveness and generalizability.'},\n",
       " '10.1016/j.xcrp.2023.101426': {'title': 'Distinguishing academic science writing from humans or ChatGPT with over 99% accuracy using off-the-shelf machine learning tools',\n",
       "  'abstract': 'ChatGPT has enabled access to artificial intelligence (AI)-generated writing for the masses, initiating a culture shift in the way people work, learn, and write. The need to discriminate human writing from AI is now both critical and urgent. Addressing this need, we report a method for discriminating text generated by ChatGPT from (human) academic scientists, relying on prevalent and accessible supervised classification methods. The approach uses new features for discriminating (these) humans from AI; as examples, scientists write long paragraphs and have a penchant for equivocal language, frequently using words like “but,” “however,” and “although.” With a set of 20 features, we built a model that assigns the author, as human or AI, at over 99% accuracy. This strategy could be further adapted and developed by others with basic skills in supervised classification, enabling access to many highly accurate and targeted models for detecting AI usage in academic writing and beyond.'},\n",
       " '10.1007/s41060-021-00299-5': {'title': 'Detecting computer-generated disinformation',\n",
       "  'abstract': 'Abstract Modern neural language models can be used by malicious actors to automatically produce textual content looking as it has been written by genuine human users. Due to progress in the controllability of computer-generated text, there is a risk that state-sponsored actors may start using such methods for conducting large-scale information operations. Various detection algorithms have been suggested in the research literature to identify texts produced by language model-based generators, but these are often mainly evaluated on test data from the same distribution as they have been trained on. We evaluate promising Transformer-based detection algorithms in a large variety of experiments involving both in-distribution and out-of-distribution test data, as well as evaluation on more realistic in-the-wild data. It is shown that the generalizability of the detectors can be questioned, especially when applied to short social media posts. Moreover, the best performing (RoBERTa-based) detector is shown to be non-robust also to basic adversarial attacks, illustrating how easy it is for malicious actors to avoid detection by the current state-of-the-art detection algorithms.'},\n",
       " '10.1016/j.patrec.2020.04.020': {'title': 'Masking domain-specific information for cross-domain deception detection',\n",
       "  'abstract': 'The facilities provided by social media and computer-mediated communication make easy the dissemination of deceptive behavior, after which different entities or people could be affected. The deception detection by supervised learning has been widely studied; however, the scenario in which there is one domain of interest and the labeled data is in another domain has received poor attention. This paper presents, to our knowledge, the first domain adaptation approach for cross-domain deception detection in texts. Our proposal consists in modifying original texts from the source and target domains in a form in which common content and style information is maintained, but domain-specific information is masked. In order to adequately select domain-specific terms to be masked, the proposed method uses unlabeled instances from both domains. Our experiments demonstrate that the masking technique is a good idea for detecting deception in cross-domain scenarios; and the performance could be further improved if unlabeled information from the target domain is considered.'},\n",
       " '10.1016/j.eswa.2019.112909': {'title': 'Early author profiling on Twitter using profile features with multi-resolution',\n",
       "  'abstract': 'The Author Profiling (AP) task aims to predict demographic characteristics about the authors from documents (e.g., age, gender, native language). The research so far has focused only on forensic scenarios by performing post-analysis using all the available text evidence. This paper introduces the task of Early Author Profiling (EAP) in Twitter. The goal is to effectively recognize profiles using as few tweets as possible from the user history. The task is highly relevant to support social media analysis and different problems related to security and marketing, where prevention and anticipation is crucial. This work proposes a novel strategy that combines a state of the art representation for early text classification and specialized word-vectors for author profiling tasks. In this strategy we build prototypical features called Profile based Meta-Words, which allow us to model AP information at different levels of granularity. Our evaluation shows that the proposed methodology is well suited for profiling little text evidence (e.g., a handful of tweets) in early stages, but as more tweets become available other granularities better encode larger amounts of text in late stages. We evaluated the proposed ideas on gender and language variety identification for English and Spanish, and showed that the proposal outperforms state of the art methodologies.'},\n",
       " '10.14744/AnatolJCardiol.2018.2': {'title': 'New Term',\n",
       "  'abstract': 'I learned with great sorrow that the esteemed'},\n",
       " '10.1007/978-3-319-66402-6_6': {'title': 'Source Code Authorship Attribution Using Long Short-Term Memory Based Networks',\n",
       "  'abstract': 'Machine learning approaches to source code authorship attribution attempt to find statistical regularities in human-generated source code that can identify the author or authors of that code. This has applications in plagiarism detection, intellectual property infringement, and post-incident forensics in computer security. The introduction of features derived from the Abstract Syntax Tree (AST) of source code has recently set new benchmarks in this area, significantly improving over previous work that relied on easily obfuscatable lexical and format features of program source code. However, these AST-based approaches rely on hand-constructed features derived from such trees, and often include ancillary information such as function and variable names that may be obfuscated or manipulated. In this work, we provide novel contributions to AST-based source code authorship attribution using deep neural networks. We implement Long Short-Term Memory (LSTM) and Bidirectional Long Short-Term Memory (BiLSTM) models to automatically extract relevant features from the AST representation of programmers’ source code. We show that our models can automatically learn efficient representations of AST-based features without needing hand-constructed ancillary information used by previous methods. Our empirical study on multiple datasets with different programming languages shows that our proposed approach achieves the state-of-the-art performance for source code authorship attribution on AST-based features, despite not leveraging information that was previously thought to be required for high-confidence classification.'},\n",
       " '10.1016/j.ins.2017.01.015': {'title': 'Neural networks for deceptive opinion spam detection: An empirical study',\n",
       "  'abstract': 'The products reviews are increasingly used by individuals and organizations for purchase and business decisions. Driven by the desire of profit, spammers produce synthesized reviews to promote some products or demote competitors products. So deceptive opinion spam detection has attracted significant attention from both business and research communities in recent years. Existing approaches mainly focus on traditional discrete features, which are based on linguistic and psychological cues. However, these methods fail to encode the semantic meaning of a document from the discourse perspective, which limits the performance. In this work, we empirically explore a neural network model to learn document-level representation for detecting deceptive opinion spam. First, the model learns sentence representation with convolutional neural network. Then, sentence representations are combined using a gated recurrent neural network, which can model discourse information and yield a document vector. Finally, the document representations are directly used as features to identify deceptive opinion spam. Based on three domains datasets, the results on in-domain and cross-domain experiments show that our proposed method outperforms state-of-the-art methods.'},\n",
       " '10.1016/j.procs.2014.08.201': {'title': 'Influence of Data Discretization on Efficiency of Bayesian Classifier for Authorship Attribution',\n",
       "  'abstract': 'Authorship attribution is one of the research areas in data mining domain and various methods can be employed for performing that task. The paper presents results of research on influence of data discretization on efficiency of Naive Bayes classifier. The analysis has been carried on datasets founded on texts of two male and two female authors using the WEKA data mining software framework. The binary classification was performed separately for both datasets for wide range of parameters of discretization process in order to investigate dependency between ways of discretization and quality of classification using Naive Bayes method. The numerical results of tests have been compared and discussed and some observations and conclusions formulated.'},\n",
       " '10.1016/j.eswa.2024.123749': {'title': 'Learning legal text representations via disentangling elements',\n",
       "  'abstract': \"Recently, a rising number of works has been focusing on tasks in the legal field for providing references to professionals in order to improve their work efficiency. Learning legal text representations, being the most common initial step, can strongly influence the performance of downstream tasks. Existing works have shown that utilizing domain knowledge, such as legal elements, in text representation learning can improve the prediction performance of downstream models. However, existing methods are typically focused on specific downstream tasks, hindering their effective generalization to other legal tasks. Moreover, these models tend to entangle various legal elements into a unified representation, overlooking the nuances among distinct legal elements. To solve the aforementioned limitation, we (1) introduce a generic model, called eVec (legal text to element-related Vector), based on a triplet loss to learn discriminative representations of legal texts concerning a specific element, and (2) present a framework eVecs for learning disentangled representations w.r.t. multiple elements. The learned representations are independent of each other in terms of elements, and can be directly applied to or fine-tuned for various downstream tasks. We conducted comprehensive experiments on two real-world legal applications, the results of which indicate that the proposed model outperforms a range of baselines by a margin of up to 34.2% on a similar case matching task and 14% on a legal element identification task. When a small quantity of labeled data is accessible, the proposed model's superior performance becomes even more evident.\"},\n",
       " '10.1007/s43681-023-00289-2': {'title': 'Auditing large language models: a three-layered approach',\n",
       "  'abstract': 'Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducted in a structured and coordinated manner on all three levels, can be a feasible and effective mechanism for identifying and managing some of the ethical and social risks posed by LLMs. However, it is important to remain realistic about what auditing can reasonably be expected to achieve. Therefore, we discuss the limitations not only of our three-layered approach but also of the prospect of auditing LLMs at all. Ultimately, this article seeks to expand the methodological toolkit available to technology providers and policymakers who wish to analyse and evaluate LLMs from technical, ethical, and legal perspectives.'},\n",
       " '10.1016/j.nlp.2024.100062': {'title': 'Understanding latent affective bias in large pre-trained neural language models',\n",
       "  'abstract': 'Groundbreaking inventions and highly significant performance improvements in deep learning based Natural Language Processing are witnessed through the development of transformer based large Pre-trained Language Models (PLMs). The wide availability of unlabeled data within human generated data deluge along with self-supervised learning strategy helps to accelerate the success of large PLMs in language generation, language understanding, etc. But at the same time, latent historical bias/unfairness in human minds towards a particular gender, race, etc., encoded unintentionally/intentionally into the corpora harms and questions the utility and efficacy of large PLMs in many real-world applications, particularly for the protected groups. In this paper, we present an extensive investigation towards understanding the existence of \"Affective Bias\" in large PLMs to unveil any biased association of emotions such as anger, fear, joy, etc., towards a particular gender, race or religion with respect to the downstream task of textual emotion detection. We conduct our exploration of affective bias from the very initial stage of corpus level affective bias analysis by searching for imbalanced distribution of affective words within a domain, in large scale corpora that are used to pre-train and fine-tune PLMs. Later, to quantify affective bias in model predictions, we perform an extensive set of class-based and intensity-based evaluations using various bias evaluation corpora. Our results show the existence of statistically significant affective bias in the PLM based emotion detection systems, indicating biased association of certain emotions towards a particular gender, race, and religion.'},\n",
       " '10.1016/j.websem.2022.100759': {'title': 'LaSER: Language-specific event recommendation',\n",
       "  'abstract': 'While societal events often impact people worldwide, a significant fraction of events has a local focus that primarily affects specific language communities. Examples include national elections, the development of the Coronavirus pandemic in different countries, and local film festivals such as the César Awards in France and the Moscow International Film Festival in Russia. However, existing entity recommendation approaches do not sufficiently address the language context of recommendation. This article introduces the novel task of language-specific event recommendation, which aims to recommend events relevant to the user query in the language-specific context. This task can support essential information retrieval activities, including web navigation and exploratory search, considering the language context of user information needs. We propose LaSER, a novel approach toward language-specific event recommendation. LaSER blends the language-specific latent representations (embeddings) of entities and events and spatio-temporal event features in a learning to rank model. This model is trained on publicly available Wikipedia Clickstream data. The results of our user study demonstrate that LaSER outperforms state-of-the-art recommendation baselines by up to 33 percentage points in MAP@5 concerning the language-specific relevance of recommended events.'},\n",
       " '10.1016/j.ipm.2022.103050': {'title': 'Speciesist language and nonhuman animal bias in English Masked Language Models',\n",
       "  'abstract': 'Various existing studies have analyzed what social biases are inherited by NLP models. These biases may directly or indirectly harm people, therefore previous studies have focused only on human attributes. However, until recently no research on social biases in NLP regarding nonhumans existed. In this paper, we analyze biases to nonhuman animals, i.e. speciesist bias, inherent in English Masked Language Models such as BERT. We analyzed speciesist bias against 46 animal names using template-based and corpus-extracted sentences containing speciesist (or non-speciesist) language. We found that pre-trained masked language models tend to associate harmful words with nonhuman animals and have a bias toward using speciesist language for some nonhuman animal names. Our code for reproducing the experiments will be made available on GitHub.'},\n",
       " '10.1007/s10618-022-00910-8': {'title': 'Social norm bias: residual harms of fairness-aware algorithms',\n",
       "  'abstract': 'Many modern machine learning algorithms mitigate bias by enforcing fairness constraints across coarsely-defined groups related to a sensitive attribute like gender or race. However, these algorithms seldom account for within-group heterogeneity and biases that may disproportionately affect some members of a group. In this work, we characterize Social Norm Bias (SNoB), a subtle but consequential type of algorithmic discrimination that may be exhibited by machine learning models, even when these systems achieve group fairness objectives. We study this issue through the lens of gender bias in occupation classification. We quantify SNoB by measuring how an algorithm’s predictions are associated with conformity to inferred gender norms. When predicting if an individual belongs to a male-dominated occupation, this framework reveals that “fair” classifiers still favor biographies written in ways that align with inferred masculine norms. We compare SNoB across algorithmic fairness techniques and show that it is frequently a residual bias, and post-processing approaches do not mitigate this type of bias at all.'},\n",
       " '10.2139/ssrn.4561423': {'title': 'Mitigation of User-Prompt Bias in Large Language Models: A Natural Langauge Processing and Deep Learning Based Framework',\n",
       "  'abstract': 'The advent of large language models has opened new frontiers in the field of automated text generation, enabling more refined engagement with complex language-based tasks. Concurrently, this advancement has revealed a potential vulnerability: the inadvertent amplification of biases from user prompts, which may lead to the reinforcement of detrimental stereotypes and misinformation by these large language models. Addressing this multifaceted challenge, this paper delineates a framework that integrates natural language processing and deep learning, designed to detect, and neutralize bias in user prompts in real time. The core of this system is a carefully formulated algorithm, the result of rigorous training, validation, and testing on the CrowS-Pairs dataset, specifically aimed at measuring the degree to which U.S. stereotypical biases are present in language models. The framework achieved an accuracy of 93% and an F1- Score of 0.92 in pinpointing and alleviating biases.'},\n",
       " '10.1016/j.jacr.2018.05.014': {'title': 'Gender Bias',\n",
       "  'abstract': 'On its surface, the epigram I have chosen for this month’s editorial is outrageous. Many readers might well ask, What could he possibly be smoking? With good reason. Although I can vouch only for my own experience, it is hard for me to imagine that any self-aware person working in radiology over the past several decades has not witnessed or even been party to some act of gender discrimination in workplace decisions. In this regard, I have seen male colleagues go to the wall against the will of their superiors in support of women they hardly knew. I have seen my gender embarrassed by craven acts of sycophancy in support of the boss’s bias toward keeping the (pick one) team, partnership, leadership, and so on, homogeneously male. More often than either of these responses to a prejudicial proposal has been silent acquiescence. Plausible deniability: I didn’t understand. If only. And if the ramifications of overlooking a more qualified woman cleared the way for personal advancement—well, what could I have done? I cannot claim that my record is without blemish.'},\n",
       " '10.1080/13691058.2013.872316': {'title': 'Black sexual politics: African Americans, gender, and the new racism',\n",
       "  'abstract': 'In Black sexual politics: African Americans, gender and the new racism, Patricia Hill Collins uses her background in sociology, critical theory and feminism to challenge the idea of monolithic iden...'},\n",
       " '10.1007/978-1-4842-2845-6_6': {'title': 'Convolutional Neural Network',\n",
       "  'abstract': 'The importance of the deep neural network lies in the fact that it opened the door to the complicated non-linear model and systematic approach for the hierarchical processing of knowledge.'},\n",
       " '10.1007/978-3-642-37456-2_14': {'title': 'Density-Based Clustering Based on Hierarchical Density Estimates',\n",
       "  'abstract': 'We propose a theoretically and practically improved density-based, hierarchical clustering method, providing a clustering hierarchy from which a simplified tree of significant clusters can be constructed. For obtaining a “flat” partition consisting of only the most significant clusters (possibly corresponding to different density thresholds), we propose a novel cluster stability measure, formalize the problem of maximizing the overall stability of selected clusters, and formulate an algorithm that computes an optimal solution to this problem. We demonstrate that our approach outperforms the current, state-of-the-art, density-based clustering methods on a wide variety of real world data.'},\n",
       " '10.1086/730711': {'title': \"Measuring and understanding parties' anti-elite strategies\",\n",
       "  'abstract': \"Next article No AccessMeasuring and understanding parties' anti-elite strategiesHauke Licht, Tarik Abou-Chadi, Pablo Barbera, and Whitney HuaHauke Licht, Tarik Abou-Chadi, Pablo Barbera, and Whitney HuaPDFPDF PLUS Add to favoritesDownload CitationTrack CitationsPermissionsReprints Share onFacebookTwitterLinkedInRedditEmailPrint SectionsMoreDetailsFiguresReferencesCited by The Journal of Politics Just Accepted Sponsored by the Southern Political Science Association Article DOIhttps://doi.org/10.1086/730711 PermissionsRequest permissions HistoryAccepted March 06, 2024 © 2024 Southern Political Science Association. All Rights reserved.PDF download Crossref reports no articles citing this article.\"},\n",
       " '10.1016/j.schres.2024.03.014': {'title': 'Automated linguistic analysis in speech samples of Turkish-speaking patients with schizophrenia-spectrum disorders',\n",
       "  'abstract': \"Modern natural language processing (NLP) methods provide ways to objectively quantify language disturbances for potential use in diagnostic classification. We performed computerized language analysis in speech samples of 82 Turkish-speaking subjects, including 44 patients with schizophrenia spectrum disorders (SSD) and 38 healthy controls (HC). Exploratory analysis of speech samples involved 16 sentence-level semantic similarity features using SBERT (Sentence Bidirectional Encoder Representation from Text) as well as 8 generic and 8 part-of-speech (POS) features. The random forest classifier using SBERT-derived semantic similarity features achieved a mean accuracy of 85.6 % for the classification of SSD and HC. When semantic similarity features were combined with generic and POS features, the classifier's mean accuracy reached to 86.8 %. Our analysis reflected increased sentence-level semantic similarity scores in SSD. Generic and POS analyses revealed an increase in the use of verbs, proper nouns and pronouns in SSD while our results showed a decrease in the utilization of conjunctions, determiners, and both average and maximum sentence length in SSD compared to HC. Quantitative language features were correlated with the expressive deficit domain of BNSS (Brief Negative Symptom Scale) as well as with the duration of illness. These findings from Turkish-speaking interviews contribute to the growing evidence-based NLP-derived assessments in non-English-speaking patients.\"},\n",
       " '10.1016/j.engappai.2023.107450': {'title': 'Transformer models for mining intents and predicting activities from emails in knowledge-intensive processes',\n",
       "  'abstract': 'Process mining is an interdisciplinary field that combines Artificial Intelligence and Business Process Management to extract insights from historical event data. Knowledge-intensive processes, which predominantly involve knowledge work, are often inadequately monitored by process-aware information systems. Consequently, the event data necessary for applying process mining techniques are frequently unavailable. Emails are widely used in knowledge-intensive processes for scheduling meetings, sharing documents, and reporting on the completion of outstanding tasks, which makes them suitable candidates for replacing event logs as the primary data source. In this work, we focus on the task of extracting the set of next recommended activities from incoming emails. Yet, we face two major challenges. Firstly, emails do not express process information explicitly but rather contain subtext that implies what the next best actions would be. Secondly, email data lacks domain-specific labels that would enable the use of machine learning. We overcome these limitations by utilizing an email taxonomy to represent user intents, thus bridging the gap between textual information and process semantics, as well as leveraging pre-trained transformer models applied in zero-shot and few-shot settings that require little to no labeled email data. An evaluation of our method on real-world unlabeled email communications demonstrates its effectiveness in recognizing intents and extracting activities.'},\n",
       " '10.1007/978-3-031-53308-2_15': {'title': 'Find the Cliffhanger: Multi-modal Trailerness in Soap Operas',\n",
       "  'abstract': 'Creating a trailer requires carefully picking out and piecing together brief enticing moments out of a longer video, making it a challenging and time-consuming task. This requires selecting moments based on both visual and dialogue information. We introduce a multi-modal method for predicting the trailerness to assist editors in selecting trailer-worthy moments from long-form videos. We present results on a newly introduced soap opera dataset, demonstrating that predicting trailerness is a challenging task that benefits from multi-modal information. Code is available at https://github.com/carlobretti/cliffhanger'},\n",
       " '10.1007/s10506-023-09380-9': {'title': 'A neural network to identify requests, decisions, and arguments in court rulings on custody',\n",
       "  'abstract': 'Abstract Court rulings are among the most important documents in all legal systems. This article describes a study in which natural language processing is used for the automatic characterization of Spanish judgments that deal with the physical custody (joint or individual) of minors. The model was trained to identify a set of elements: the type of custody requested by the plaintiff, the type of custody decided on by the court, and eight of the most commonly used arguments in this type of judgment. Two jurists independently annotated more than 3000 judgments, which were used to train a model based on transformers. The main difficulties encountered in this task were the complexity of the judicial language and the need to work with appellate court rulings that have a more complicated structure than decisions at first instance. For the complete court rulings, the F1 score of the inter-annotator agreement ranged from 0.60 to 0.86 and the Kappa index from 0.33 to 0.73. The F1 score of the agreement between the model and the annotators ranged from 0.66 to 0.93 and the Kappa index from 0.57 to 0.80. These results in which the model performance exceeds even the inter-annotator agreement show the high ability of transformers to identify abstract entities in legal texts.'},\n",
       " '10.1016/j.datak.2024.102281': {'title': 'A new sentence embedding framework for the education and professional training domain with application to hierarchical multi-label text classification',\n",
       "  'abstract': 'In recent years, Natural Language Processing (NLP) has made significant advances through advanced general language embeddings, allowing breakthroughs in NLP tasks such as semantic similarity and text classification. However, complexity increases with hierarchical multi-label classification (HMC), where a single entity can belong to several hierarchically organized classes. In such complex situations, applied on specific-domain texts, such as the Education and professional training domain, general language embedding models often inadequately represent the unique terminologies and contextual nuances of a specialized domain. To tackle this problem, we present HMCCCProbT, a novel hierarchical multi-label text classification approach. This innovative framework chains multiple classifiers, where each individual classifier is built using a novel sentence-embedding method BERTEPro based on existing Transformer models, whose pre-training has been extended on education and professional training texts, before being fine-tuned on several NLP tasks. Each individual classifier is responsible for the predictions of a given hierarchical level and propagates local probability predictions augmented with the input feature vectors to the classifier in charge of the subsequent level. HMCCCProbT tackles issues of model scalability and semantic interpretation, offering a powerful solution to the challenges of domain-specific hierarchical multi-label classification. Experiments over three domain-specific textual HMC datasets indicate the effectiveness of HMCCCProbT to compare favorably to state-of-the-art HMC algorithms in terms of classification accuracy and also the ability of BERTEPro to obtain better probability predictions, well suited to HMCCCProbT, than three other vector representation techniques.'},\n",
       " '10.1145/3639233.3639332': {'title': 'Cantonese to Written Chinese Translation via HuggingFace Translation Pipeline',\n",
       "  'abstract': 'Cantonese, a low-resource language [5] that has been used in Southeastern China for hundreds of years, with over 85 million native speakers worldwide, is poorly supported in the mainstream language model for existing translation platforms such as Baidu, Google and Bing. This paper presents a large parallel corpus of 130 thousand Cantonese and Written Chinese pairs. The data are used to train a translation model using the translation pipeline of the Hugging Face Transformers architecture, a dominant architecture for natural language processing nowadays [18]. The BLEU score and manual assessment evaluate the performance. The translation results achieve a BLEU score of 41.35and chrF++ score of 44.88on the entire validation set. The model also works reasonably well with long sentences of over 20 Chinese characters. It achieves a BLEU score of 48.61and chrF++ score of 39.87on long sentences. Those results are comparable with the existing Baidu Fanyi and Bing Translate. We also establish a Cantonese sentence evaluation metric to classify the quality of the source Cantonese sentence by professional translators. We then compare the BLEU and chrF++ scores with the corresponding evaluation score and found that the better the quality of the source sentence, the higher the BLEU and chrF++ scores. Last, we proved that our corpus enabled the Cantonese translation capability of the Chinese BART pre-trained model.'},\n",
       " '10.1007/s40593-023-00383-w': {'title': 'Short-Answer Grading for German: Addressing the Challenges',\n",
       "  'abstract': 'Abstract Short-Answer Grading (SAG) is a time-consuming task for teachers that automated SAG models have long promised to make easier. However, there are three challenges for their broad-scale adoption: A technical challenge regarding the need for high-quality models, which is exacerbated for languages with fewer resources than English; a usability challenge in adapting high-quality research prototypes to the needs of non-expert users, and a trust challenge in communicating the abilities and limitations of the tools. We propose to meet the technical challenge for German with a robust Transformer-based SAG model. We address the usability challenge with an easy-to-use graphical user interface for the SAG model, and the trust challenge with a workflow that allows teachers to evaluate the model on their own data, to choose on the basis of this evaluation which model predictions to trust, and in consequence to stay in control of grading their students while saving grading effort.'},\n",
       " '10.1016/j.knosys.2023.111304': {'title': 'Unsupervised multilingual machine translation with pretrained cross-lingual encoders',\n",
       "  'abstract': 'Multilingual Neural Machine Translation (MNMT) has recently made great progress in training models that can translate between multiple languages. However, MNMT faces a significant challenge due to the lack of sufficient parallel corpora for all language pairs. Unsupervised machine translation methods, which utilize monolingual data, have emerged as a solution to this challenge. In this paper, we propose a method that leverages cross-lingual encoders, such as XLM-R, in an unsupervised manner (i.e., using monolingual data and bilingual dictionaries) to train a MNMT model. Our method initializes the MNMT model with a pre-trained cross-lingual encoder and employs two levels of alignment to further align the representation space in MNMT model. Experimental results demonstrate that our method outperforms strong baseline systems and exhibits robust domain and language transfer capabilities while preserving the performance of the original pre-trained encoder on other downstream tasks.'},\n",
       " '10.1007/s10994-023-06449-z': {'title': 'Predicting potential real-time donations in YouTube live streaming services via continuous-time dynamic graphs',\n",
       "  'abstract': 'Abstract Online live streaming platforms, such as YouTube Live and Twitch, have seen a surge in popularity in recent years. These platforms allow viewers to send real-time gifts to streamers, which can bring significant profits and fame. However, there has been little research on the donation system used on live streaming platforms. This paper aims to fill this gap by building a continuous-time dynamic graph to model the interactions among viewers based on real-time chat messages and predict the real-time donations on live streaming platforms. To achieve this, we propose a novel model called the Temporal Difference Graph Neural Network (TDGNN) that incorporates imbalanced learning strategies to identify potential donors during live streaming. Our model can predict the exact time when donations will appear. We conduct extensive experiments on three live streaming video datasets and demonstrate that our proposed model is more effective and robust than other baseline methods from other fields.'},\n",
       " '10.1038/s41598-024-53124-x': {'title': 'Cross-platform social dynamics: an analysis of ChatGPT and COVID-19 vaccine conversations',\n",
       "  'abstract': 'Abstract The role of social media in information dissemination and agenda-setting has significantly expanded in recent years. By offering real-time interactions, online platforms have become invaluable tools for studying societal responses to significant events as they unfold. However, online reactions to external developments are influenced by various factors, including the nature of the event and the online environment. This study examines the dynamics of public discourse on digital platforms to shed light on this issue. We analyzed over 12 million posts and news articles related to two significant events: the release of ChatGPT in 2022 and the global discussions about COVID-19 vaccines in 2021. Data was collected from multiple platforms, including Twitter, Facebook, Instagram, Reddit, YouTube, and GDELT. We employed topic modeling techniques to uncover the distinct thematic emphases on each platform, which reflect their specific features and target audiences. Additionally, sentiment analysis revealed various public perceptions regarding the topics studied. Lastly, we compared the evolution of engagement across platforms, unveiling unique patterns for the same topic. Notably, discussions about COVID-19 vaccines spread more rapidly due to the immediacy of the subject, while discussions about ChatGPT, despite its technological importance, propagated more gradually.'},\n",
       " '10.1007/978-3-031-43421-1_1': {'title': 'Unsupervised Deep Cross-Language Entity Alignment',\n",
       "  'abstract': 'Cross-lingual entity alignment is the task of finding the same semantic entities from different language knowledge graphs. In this paper, we propose a simple and novel unsupervised method for cross-language entity alignment. We utilize the deep learning multi-language encoder combined with a machine translator to encode knowledge graph text, which reduces the reliance on label data. Unlike traditional methods that only emphasize global or local alignment, our method simultaneously considers both alignment strategies. We first view the alignment task as a bipartite matching problem and then adopt the re-exchanging idea to accomplish alignment. Compared with the traditional bipartite matching algorithm that only gives one optimal solution, our algorithm generates ranked matching results which enabled many potentials downstream tasks. Additionally, our method can adapt two different types of optimization (minimal and maximal) in the bipartite matching process, which provides more flexibility. Our evaluation shows, we each scored 0.966, 0.990, and 0.996 Hits@1 rates on the $$\\\\textrm{DBP15K}$$ dataset in Chinese, Japanese, and French to English alignment tasks. We outperformed the state-of-the-art method in unsupervised and semi-supervised categories. Compared with the state-of-the-art supervised method, our method outperforms 2.6% and 0.4% in Ja-En and Fr-En alignment tasks while marginally lower by 0.2% in the Zh-En alignment task.'},\n",
       " '10.1007/978-3-031-43153-1_15': {'title': 'A Deep Natural Language Inference Predictor Without Language-Specific Training Data',\n",
       "  'abstract': 'In this paper we present a technique of NLP to tackle the problem of inference relation (NLI) between pairs of sentences in a target language of choice without a language-specific training dataset. We exploit a generic translation dataset, manually translated, along with two instances of the same pre-trained model—the first to generate sentence embeddings for the source language, and the second fine-tuned over the target language to mimic the first. This technique is known as Knowledge Distillation. The model has been evaluated over machine translated Stanford NLI test dataset, machine translated Multi-Genre NLI test dataset, and manually translated RTE3-ITA test dataset We also test the proposed architecture over different tasks to empirically demonstrate the generality of the NLI task. The model has been evaluated over the native Italian ABSITA dataset, on the tasks of Sentiment Analysis, Aspect-Based Sentiment Analysis, and Topic Recognition. We emphasise the generality and exploitability of the Knowledge Distillation technique that outperforms other methodologies based on machine translation, even though the former was not directly trained on the data it was tested over.'},\n",
       " '10.3758/s13428-023-02129-x': {'title': 'Perceived similarity as a window into representations of integrated sentence meaning',\n",
       "  'abstract': 'Abstract When perceiving the world around us, we are constantly integrating pieces of information. The integrated experience consists of more than just the sum of its parts. For example, visual scenes are defined by a collection of objects as well as the spatial relations amongst them and sentence meaning is computed based on individual word semantic but also syntactic configuration. Having quantitative models of such integrated representations can help evaluate cognitive models of both language and scene perception. Here, we focus on language, and use a behavioral measure of perceived similarity as an approximation of integrated meaning representations. We collected similarity judgments of 200 subjects rating nouns or transitive sentences through an online multiple arrangement task. We find that perceived similarity between sentences is most strongly modulated by the semantic action category of the main verb. In addition, we show how non-negative matrix factorization of similarity judgment data can reveal multiple underlying dimensions reflecting both semantic as well as relational role information. Finally, we provide an example of how similarity judgments on sentence stimuli can serve as a point of comparison for artificial neural networks models (ANNs) by comparing our behavioral data against sentence similarity extracted from three state-of-the-art ANNs. Overall, our method combining the multiple arrangement task on sentence stimuli with matrix factorization can capture relational information emerging from integration of multiple words in a sentence even in the presence of strong focus on the verb.'},\n",
       " '10.1016/j.engappai.2023.106088': {'title': 'One-class learning for fake news detection through multimodal variational autoencoders',\n",
       "  'abstract': 'Machine learning methods to detect fake news typically use textual features and Binary or Multi-class classification. However, accurately labeling a large news set is still a very costly process. On the other hand, one of the prominent approaches is One-Class Learning (OCL). OCL requires only the labeling of fake news, minimizing data labeling efforts. Although we eliminate the need to label non-interest news, the efficiency of OCL algorithms depends directly on the data representation model adopted. Most existing methods in the OCL literature explore representations based on one modality to detect fake news. However, different text features can be the reason for the news to be fake, such as topic or linguistic features. We model this behavior as different modalities for news to represent different textual feature sets. Thus, we present the MVAE-FakeNews, a multimodal method to represent the texts in the fake news detection through OCL that learns a new representation from the combination of promising modalities for news data: text embeddings, topic, and linguistic information. We used real-world fake news datasets in Portuguese and English in the experimental evaluation. Results show that MVAE-FakeNews obtained a better F1-Score and AUC-ROC, outperforming another fourteen methods in three datasets and getting competitive results on the other three. Moreover, our MVAE-FakeNews, with only 3% of labeled fake news, obtained comparable or higher results than other methods. To improve the experimental evaluation, we also propose the Multimodal LIME for OCL to identify how each modality is associated with the fake news class.'},\n",
       " '10.1038/s41598-023-35151-2': {'title': 'Exploratory preferences explain the human fascination for imaginary worlds in fictional stories',\n",
       "  'abstract': 'Imaginary worlds are present and often central in many of the most culturally successful modern narrative fictions, be it in novels (e.g., Harry Potter), movies (e.g., Star Wars), video games (e.g., The Legend of Zelda), graphic novels (e.g., One Piece) and TV series (e.g., Game of Thrones). We propose that imaginary worlds are popular because they activate exploratory preferences that evolved to help us navigate the real world and find new fitness-relevant information. Therefore, we hypothesize that the attraction to imaginary worlds is intrinsically linked to the desire to explore novel environments and that both are influenced by the same underlying factors. Notably, the inter-individual and cross-cultural variability of the preference for imaginary worlds should follow the inter-individual and cross-cultural variability of exploratory preferences (with the personality trait Openness-to-experience, age, sex, and ecological conditions). We test these predictions with both experimental and computational methods. For experimental tests, we run a pre-registered online experiment about movie preferences (N = 230). For computational tests, we leverage two large cultural datasets, namely the Internet Movie Database (N = 9424 movies) and the Movie Personality Dataset (N = 3.5 million participants), and use machine-learning algorithms (i.e., random forest and topic modeling). In all, consistent with how the human preference for spatial exploration adaptively varies, we provide empirical evidence that imaginary worlds appeal more to more explorative people, people higher in Openness-to-experience, younger individuals, males, and individuals living in more affluent environments. We discuss the implications of these findings for our understanding of the cultural evolution of narrative fiction and, more broadly, the evolution of human exploratory preferences.'},\n",
       " '10.1007/s41019-023-00211-0': {'title': 'Improving Gender-Related Fairness in Sentence Encoders: A Semantics-Based Approach',\n",
       "  'abstract': 'Abstract The ever-increasing number of systems based on semantic text analysis is making natural language understanding a fundamental task: embedding-based language models are used for a variety of applications, such as resume parsing or improving web search results. At the same time, despite their popularity and widespread use, concern is rapidly growing due to their display of social bias and lack of transparency. In particular, they exhibit a large amount of gender bias, favouring the consolidation of social stereotypes. Recently, sentence embeddings have been introduced as a novel and powerful technique to represent entire sentences as vectors. We propose a new metric to estimate gender bias in sentence embeddings, named bias score . Our solution leverages semantic importance of words and previous research on bias in word embeddings, and it is able to discern between neutral and biased gender information at sentence level. Experiments on a real-world dataset demonstrate that our novel metric can identify gender stereotyped sentences. Furthermore, we employ bias score to detect and then remove or compensate for the more stereotyped entries in text corpora used to train sentence encoders, improving their degree of fairness. Finally, we prove that models retrained on fairer corpora are less prone to make stereotypical associations compared to their original counterpart, while preserving accuracy in natural language understanding tasks. Additionally, we compare our experiments with traditional methods for reducing bias in embedding-based language models.'},\n",
       " '10.5594/jmi.2023.3245685': {'title': 'Machine Learning Applied to Media Libraries for Insights, Search, and Segmentation',\n",
       "  'abstract': 'Recent advances in machine learning (ML) have produced a new form of semantic indexing that lets users enhance searches and gain new insights into their media libraries. Unlike typical search systems that use extracted metadata, semantic indexing allows users to find relevant material without the need to tag the media with selections from a predefined taxonomy. With semantic search, users can simply enter unstructured text, and the system will find the best matching media clips. This article extends the use of this technology to gather analytics on the data, which can then be further correlated to generate various insights. This new form of media indexing can be performed with the contrastive language-image pretraining (CLIP) model from OpenAI for images and similar models for video and audio. These models encode media into embeddings that can be searched to find the closest semantic similarity, enhanced with learned cultural knowledge. These systems have the benefit of finding media based on keywords, synonyms, and summaries. The systems can also be used for analytics and insights, such as segmentation, shot detection, and creating a 2D map to display correlations. This article ends with a discussion of the next steps, including using knowledge graphs for semantic search.'},\n",
       " '10.1007/s11135-023-01625-8': {'title': 'Moral rhetoric in discrete choice models: a Natural Language Processing approach',\n",
       "  'abstract': 'Abstract This paper proposes a new method to combine choice- and text data to infer moral motivations from people’s actions. To do this, we rely on moral rhetoric, in other words, extracting moral values from verbal expressions with Natural Language Processing techniques. We use moral rhetoric based on a well-established moral, psychological theory called Moral Foundations Theory. We use moral rhetoric as input in Discrete Choice Models to gain insights into moral behaviour based on people’s words and actions. We test our method in a case study of voting and party defection in the European Parliament. Our results indicate that moral rhetoric have significant explanatory power in modelling voting behaviour. We interpret the results in the light of political science literature and propose ways for future investigations.'},\n",
       " '10.1007/s40593-022-00322-1': {'title': 'Reducing Workload in Short Answer Grading Using Machine Learning',\n",
       "  'abstract': 'Abstract Machine learning methods can be used to reduce the manual workload in exam grading, making it possible for teachers to spend more time on other tasks. However, when it comes to grading exams, fully eliminating manual work is not yet possible even with very accurate automated grading, as any grading mistakes could have significant consequences for the students. Here, the evaluation of an automated grading approach is therefore extended from measuring workload in relation to the accuracy of automated grading, to also measuring the overall workload required to correctly grade a full exam, with and without the support of machine learning. The evaluation was performed during an introductory computer science course with over 400 students. The exam consisted of 64 questions with relatively short answers and a two-step approach for automated grading was applied. First, a subset of answers to the exam questions was manually graded and next used as training data for machine learning models classifying the remaining answers. A number of different strategies for how to select which answers to include in the training data were evaluated. The time spent on different grading actions was measured along with the reduction of effort using clustering of answers and automated scoring. Compared to fully manual grading, the overall reduction of workload was substantial—between 64% and 74%—even with a complete manual review of all classifier output to ensure a fair grading.'},\n",
       " '10.1016/j.jbi.2023.104297': {'title': 'Supporting SNOMED CT postcoordination with knowledge graph embeddings',\n",
       "  'abstract': 'SNOMED CT postcoordination is an underused mechanism that can help to implement advanced systems for the automatic extraction and encoding of clinical information from text. It allows defining non-existing SNOMED CT concepts by their relationships with existing ones. Manually building postcoordinated expressions is a difficult task. It requires a deep knowledge of the terminology and the support of specialized tools that barely exist. In order to support the building of postcoordinated expressions, we have implemented KGE4SCT: a method that suggests the corresponding SNOMED CT postcoordinated expression for a given clinical term. We leverage on the SNOMED CT ontology and its graph-like structure and use knowledge graph embeddings (KGEs). The objective of such embeddings is to represent in a vector space knowledge graph components (e.g. entities and relations) in a way that captures the structure of the graph. Then, we use vector similarity and analogies for obtaining the postcoordinated expression of a given clinical term. We obtained a semantic type accuracy of 98%, relationship accuracy of 90%, and analogy accuracy of 60%, with an overall completeness of postcoordination of 52% for the Spanish SNOMED CT version. We have also applied it to the English SNOMED CT version and outperformed state of the art methods in both, corpus generation for language model training for this task (improvement of 6% for analogy accuracy), and automatic postcoordination of SNOMED CT expressions, with an increase of 17% for partial conversion rate.'},\n",
       " '10.1007/978-3-031-11647-6_92': {'title': 'Predicting Knowledge Gain for MOOC Video Consumption',\n",
       "  'abstract': 'Informal learning on the Web using search engines as well as more structured learning on MOOC platforms have become very popular in recent years. As a result of the vast amount of available learning resources, intelligent retrieval and recommendation methods are indispensable -- this is true also for MOOC videos. However, the automatic assessment of this content with regard to predicting (potential) knowledge gain has not been addressed by previous work yet. In this paper, we investigate whether we can predict learning success after MOOC video consumption using 1) multimodal features covering slide and speech content, and 2) a wide range of text-based features describing the content of the video. In a comprehensive experimental setting, we test four different classifiers and various feature subset combinations. We conduct a detailed feature importance analysis to gain insights in which modality benefits knowledge gain prediction the most.'},\n",
       " '10.1016/j.ipm.2022.103105': {'title': 'Automated monitoring of online news accuracy with change classification models',\n",
       "  'abstract': 'In the past decade, news consumption has shifted from printed news media to online alternatives. Although these come with advantages, online news poses challenges as well. Notable here is the increased competition between online newspapers and other online news providers to attract readers. Hereby, speed is often favored over quality. As a consequence, the need for new tools to monitor online news accuracy has grown. In this work, a fundamentally new and automated procedure for the monitoring of online news accuracy is proposed. The approach relies on the fact that online news articles are often updated after initial publication, thereby also correcting errors. Automated observation of the changes being made to online articles and detection of the errors that are corrected may offer useful insights concerning news accuracy. The potential of the presented automated error correction detection model is illustrated by building supervised classification models for the detection of objective, subjective and linguistic errors in online news updates respectively. The models are built using a large news update data set being collected during two consecutive years for six different Flemish online newspapers. A subset of 21,129 changes is then annotated using a combination of automated and human annotation via an online annotation platform. Finally, manually crafted features and text embeddings obtained by four different language models (TF-IDF, word2vec, BERTje and SBERT) are fed to three supervised machine learning algorithms (logistic regression, support vector machines and decision trees) and performance of the obtained models is subsequently evaluated. Results indicate that small differences in performance exist between the different learning algorithms and language models. Using the best-performing models, F2-scores of 0.45, 0.25 and 0.80 are obtained for the classification of objective, subjective and linguistic errors respectively.'},\n",
       " '10.1007/s10796-022-10329-7': {'title': 'Does Fake News in Different Languages Tell the Same Story? An Analysis of Multi-level Thematic and Emotional Characteristics of News about COVID-19',\n",
       "  'abstract': 'Fake news is being generated in different languages, yet existing studies are dominated by English news. The analysis of fake news content has focused on lexical and stylometric features, giving little attention to semantic features. A few studies involving semantic features have either used them as the inputs to classifiers with no interpretations, or treated them in isolation. This research aims to investigate both thematic and emotional characteristics of fake news at different levels and compare them between different languages for the first time. It extends a state-of-the-art topic modeling technique to extract news topics and introduces a divergence measure to assess the importance of thematic characteristics for identifying fake news. We further examine associations of the thematic and emotional characteristics of fake news. The empirical findings have implications for developing both general and language-specific countermeasures for fake news.'},\n",
       " '10.1007/s10579-022-09613-4': {'title': 'Develop corpora and methods for cross-lingual text reuse detection for English Urdu language pair at lexical, syntactical, and phrasal levels',\n",
       "  'abstract': 'In recent years, Cross-Lingual Text Reuse Detection (CLTRD) has attracted the attention of the research community because large digital repositories and efficient Machine Translation systems are readily and freely available, which makes it easier to reuse text across the languages and very difficult to detect it. In the previous studies, the problem of CLTRD for the English-Urdu language pair has been explored at the sentence/passage and document level, and benchmark corpora and methods have been developed. However, there is a lack of benchmark corpora and methods for the CLTRD for the English-Urdu language pair at the lexical, syntactical, and phrasal levels. To fulfill this research gap, this study presents three large benchmark corpora for detecting the Cross-Lingual Text Reuse (CLTR) at three levels of rewrite (Wholly Derived (WD), Partially Derived (PD), and Non Derived (ND)). The CLEU-Lex, CLEU-Syn and CLEU-Phr corpora contain 66,485 (WD = 22,236, PD = 20,315 and ND = 23,934), 60,267 (WD = 20,007, PD = 16,979 and ND = 23,281) and 60,106 (WD = 23,862, PD = 15,878 and ND = 20,366) CLTR pairs respectively. As a secondary major contribution, we have applied the Cross-Lingual Word Embedding (CLWE), Cross-Lingual Semantic Tagger (CLST), and Cross-Lingual Sentence Transformer (CLSTR) based methods on our three proposed corpora for the CLTRD. Our extensive experimentation showed that for the binary classification task, the best results on the CLEU-Lex corpus were obtained using the cross-lingual sentence transformer ( $$F_{1}$$ = 0.80). For the CLEU-Syn and CLEU-Phr corpora, the best results were obtained using the cross-lingual sentence transformer and a combination of the CLWE, CLST and CLSTR methods ( $$F_{1}$$ = 0.92 on CLEU-Syn and $$F_{1}$$ = 0.94 on CLEU-Phr). For the ternary classification task, the best results on the CLEU-Lex corpus were obtained using the cross-lingual sentence transformer method ( $$F_{1}$$ = 0.69). For the CLEU-Syn corpus, the best results were obtained using a combination of the CLWE, CLST, and CLSTR methods ( $$F_{1}$$ = 0.82). For the CLEU-Phr corpus the best results were obtained using cross-lingual sentence transformer and combination of CLWE, CLST, and CLSTR methods ( $$F_{1}$$ = 0.78). To foster and promote research in Urdu (a low-resourced language) all the three proposed corpora are free and publicly available for research purposes.'},\n",
       " '10.1016/j.iswa.2022.200113': {'title': 'A privacy-preserving dialogue system based on argumentation',\n",
       "  'abstract': 'Dialogue systems are a class of increasingly popular AI-based solutions to support timely and interactive communication with users in many domains. Due to the apparent possibility of users disclosing their sensitive data when interacting with such systems, ensuring that the systems follow the relevant laws, regulations, and ethical principles should be of primary concern. In this context, we discuss the main open points regarding these aspects and propose an approach grounded on a computational argumentation framework. Our approach ensures that user data are managed according to data minimization, purpose limitation, and integrity. Moreover, it is endowed with the capability of providing motivations for the system responses to offer transparency and explainability. We illustrate the architecture using as a case study a COVID-19 vaccine information system, discuss its theoretical properties, and evaluate it empirically.'},\n",
       " '10.1007/s42979-022-01295-7': {'title': 'Enhancing Cross-lingual Biomedical Concept Normalization Using Deep Neural Network Pretrained Language Models',\n",
       "  'abstract': 'Abstract In this study, we propose a new approach for cross-lingual biomedical concept normalization, the process of mapping text in non-English documents to English concepts of a knowledge base. The resulting mappings, named as semantic annotations, enhance data integration and interoperability of documents in different languages. The US FDA (Food and Drug Administration), therefore, requires all submitted medical forms to be semantically annotated. These standardized medical forms are used in health care practice and biomedical research and are translated/adapted into various languages. Mapping them to the same concepts (normally in English) facilitates the comparison of multiple medical studies even cross-lingually. However, the translation and adaptation of these forms can cause them to deviate from its original text syntactically and in wording. This leads the conventional string matching methods to produce low-quality annotation results. Therefore, our new approach incorporates semantics into the cross-lingual concept normalization process. This is done using sentence embeddings generated by BERT-based pretrained language models. We evaluate the new approach by annotating entire questions of German medical forms with concepts in English, as required by the FDA. The new approach achieves an improvement of 136% in recall, 52% in precision and 66% in F-measure compared to the conventional string matching methods.'},\n",
       " '10.1016/j.lingua.2022.103377': {'title': 'Corpus similarity measures remain robust across diverse languages',\n",
       "  'abstract': 'This paper experiments with frequency-based corpus similarity measures across 39 languages using a register prediction task. The goal is to quantify (i) the distance between different corpora from the same language and (ii) the homogeneity of individual corpora. Both of these goals are essential for measuring how well corpus-based linguistic analysis generalizes from one dataset to another. The problem is that previous work has focused on Indo-European languages, raising the question of whether these measures are able to provide robust generalizations across diverse languages. This paper uses a register prediction task to evaluate competing measures across 39 languages: how well are they able to distinguish between corpora representing different contexts of production? Each experiment compares three corpora from a single language, with the same three digital registers shared across all languages: social media, web pages, and Wikipedia. Results show that measures of corpus similarity retain their validity across different language families, writing systems, and types of morphology. Further, the measures remain robust when evaluated on out-of-domain corpora, when applied to low-resource languages, and when applied to different sets of registers. These findings are significant given our need to make generalizations across the rapidly increasing number of corpora available for analysis.'},\n",
       " '10.1007/s12559-022-10066-8': {'title': 'Exploring Dimensionality Reduction Techniques in Multilingual Transformers',\n",
       "  'abstract': 'Abstract In scientific literature and industry, semantic and context-aware Natural Language Processing-based solutions have been gaining importance in recent years. The possibilities and performance shown by these models when dealing with complex Human Language Understanding tasks are unquestionable, from conversational agents to the fight against disinformation in social networks. In addition, considerable attention is also being paid to developing multilingual models to tackle the language bottleneck. An increase in size has accompanied the growing need to provide more complex models implementing all these features without being conservative in the number of dimensions required. This paper aims to provide a comprehensive account of the impact of a wide variety of dimensional reduction techniques on the performance of different state-of-the-art multilingual siamese transformers, including unsupervised dimensional reduction techniques such as linear and nonlinear feature extraction, feature selection, and manifold techniques. In order to evaluate the effects of these techniques, we considered the multilingual extended version of Semantic Textual Similarity Benchmark (mSTSb) and two different baseline approaches, one using the embeddings from the pre-trained version of five models and another using their fine-tuned STS version. The results evidence that it is possible to achieve an average reduction of $$91.58\\\\% \\\\pm 2.59\\\\%$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mrow> <mml:mn>91.58</mml:mn> <mml:mo>%</mml:mo> <mml:mo>±</mml:mo> <mml:mn>2.59</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> in the number of dimensions of embeddings from pre-trained models requiring a fitting time $$96.68\\\\% \\\\pm 0.68\\\\%$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mrow> <mml:mn>96.68</mml:mn> <mml:mo>%</mml:mo> <mml:mo>±</mml:mo> <mml:mn>0.68</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> faster than the fine-tuning process. Besides, we achieve $$54.65\\\\% \\\\pm 32.20\\\\%$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mrow> <mml:mn>54.65</mml:mn> <mml:mo>%</mml:mo> <mml:mo>±</mml:mo> <mml:mn>32.20</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> dimensionality reduction in embeddings from fine-tuned models. The results of this study will significantly contribute to the understanding of how different tuning approaches affect performance on semantic-aware tasks and how dimensional reduction techniques deal with the high-dimensional embeddings computed for the STS task and their potential for other highly demanding NLP tasks.'},\n",
       " '10.1007/s40593-022-00289-z': {'title': 'Towards Trustworthy AutoGrading of Short, Multi-lingual, Multi-type Answers',\n",
       "  'abstract': 'Abstract Autograding short textual answers has become much more feasible due to the rise of NLP and the increased availability of question-answer pairs brought about by a shift to online education. Autograding performance is still inferior to human grading. The statistical and black-box nature of state-of-the-art machine learning models makes them untrustworthy, raising ethical concerns and limiting their practical utility. Furthermore, the evaluation of autograding is typically confined to small, monolingual datasets for a specific question type. This study uses a large dataset consisting of about 10 million question-answer pairs from multiple languages covering diverse fields such as math and language, and strong variation in question and answer syntax. We demonstrate the effectiveness of fine-tuning transformer models for autograding for such complex datasets. Our best hyperparameter-tuned model yields an accuracy of about 86.5%, comparable to the state-of-the-art models that are less general and more tuned to a specific type of question, subject, and language. More importantly, we address trust and ethical concerns. By involving humans in the autograding process, we show how to improve the accuracy of automatically graded answers, achieving accuracy equivalent to that of teaching assistants. We also show how teachers can effectively control the type of errors made by the system and how they can validate efficiently that the autograder’s performance on individual exams is close to the expected performance.'},\n",
       " '10.1016/j.asoc.2021.107693': {'title': 'A multimodal approach for regional GDP prediction using social media activity and historical information',\n",
       "  'abstract': 'This work proposes a multimodal approach with which to predict the regional Gross Domestic Product (GDP) by combining historical GDP values with the embodied information in Twitter messages concerning the current economic condition. This proposal is of great interest, since it delivers forecasts at higher frequencies than both the official statistics (published only annually at the regional level in Spain) and the existing unofficial quarterly predictions (which rely on economic indicators that are available only after months of delay). The proposed method is based on a two-stage architecture. In the first stage, a multi-task autoencoder is initially used to obtain a GDP-related representation of tweets, which are then filtered to remove outliers and to obtain the GDP prediction from the consensus of opinions. In a second stage, this result is combined with the historical GDP values of the region using a multimodal network. The method is evaluated in four different regions of Spain using the tweets written by the most relevant economists, politicians, newspapers and institutions in each one. The results show that our approach successfully learns the evolution of the GDP using only historical information and tweets, thus making it possible to provide earlier forecasts about the regional GDP. This method also makes it possible to establish which the most or least influential opinions regarding this prediction are. As an additional exercise, we have assessed how well our method predicted the effect of the COVID-19 pandemic.'},\n",
       " '10.1016/J.JJIMEI.2021.100025': {'title': 'Optimization of paraphrase generation and identification using language models in natural language processing',\n",
       "  'abstract': \"Paraphrase Generation is one of the most important and challenging tasks in the field of Natural Language Generation. The paraphrasing techniques help to identify or to extract/generate phrases/sentences conveying the similar meaning. The paraphrasing task can be bifurcated into two sub-tasks namely, Paraphrase Identification (PI) and Paraphrase Generation (PG). Most of the existing proposed state-of-the-art systems have the potential to solve only one problem at a time. This paper proposes a light-weight unified model that can simultaneously classify whether given pair of sentences are paraphrases of each other and the model can also generate multiple paraphrases given an input sentence. Paraphrase Generation module aims to generate fluent and semantically similar paraphrases and the Paraphrase Identification system aims to classify whether sentences pair are paraphrases of each other or not. The proposed approach uses an amalgamation of data sampling or data variety with a granular fine-tuned Text-To-Text Transfer Transformer (T5) model. This paper proposes a unified approach which aims to solve the problems of Paraphrase Identification and generation by using carefully selected data-points and a fine-tuned T5 model. The highlight of this study is that the same light-weight model trained by keeping the objective of Paraphrase Generation can also be used for solving the Paraphrase Identification task. Hence, the proposed system is light-weight in terms of the model's size along with the data used to train the model which facilitates the quick learning of the model without having to compromise with the results. The proposed system is then evaluated against the popular evaluation metrics like BLEU (BiLingual Evaluation Understudy):, ROUGE (Recall-Oriented Understudy for Gisting Evaluation), METEOR, WER (Word Error Rate), and GLEU (Google-BLEU) for Paraphrase Generation and classification metrics like accuracy, precision, recall and F1-score for Paraphrase Identification system. The proposed model achieves state-of-the-art results on both the tasks of Paraphrase Identification and paraphrase Generation.\"},\n",
       " '10.1007/978-3-030-89906-6_19': {'title': 'Predicting Next Dialogue Action in Emotionally Loaded Conversation',\n",
       "  'abstract': 'This paper reports on creating a neural network model for prediction of the next action in a dialogue considering conversation history, i.e. entities, context variables and emotion indicators marking emotionally loaded user utterances. Several experiments were performed to see how the information about emotions affects the accuracy of the model. For the purposes of these experiments, a dataset containing 206 dialogs in Latvian in the transport inquiry domain was created containing both neutral and emotionally loaded utterances. To see if the proposed next dialogue action prediction model architecture is suitable for other languages, the original Latvian utterances were translated into English and a separate model was trained with English data. Some experiments were performed training the model with the data in one language and testing with the data in another language as well as training a single model using data in both languages. Experiments were performed with several fastText and Transformer pre-trained embedding models. Models for both languages Latvian and English achieved 0.91 accuracy on 10-fold cross-validation.'},\n",
       " '10.1007/978-3-030-93736-2_20': {'title': 'Web Image Context Extraction with Graph Neural Networks and Sentence Embeddings on the DOM Tree',\n",
       "  'abstract': 'Web Image Context Extraction (WICE) consists in obtaining the textual information describing an image using the content of the surrounding webpage. A common preprocessing step before performing WICE is to render the content of the webpage. When done at a large scale (e.g., for search engine indexation), it may become very computationally costly (up to several seconds per page). To avoid this cost, we introduce a novel WICE approach that combines Graph Neural Networks (GNNs) and Natural Language Processing models. Our method relies on a graph model containing both node types and text as features. The model is fed through several blocks of GNNs to extract the textual context. Since no labeled WICE dataset with ground truth exists, we train and evaluate the GNNs on a proxy task that consists in finding the semantically closest text to the image caption. We then interpret importance weights to find the most relevant text nodes and define them as the image context. Thanks to GNNs, our model is able to encode both structural and semantic information from the webpage. We show that our approach gives promising results to help address the large-scale WICE problem using only HTML data.'},\n",
       " '10.1007/978-3-030-89391-0_27': {'title': 'An Argumentative Dialogue System for COVID-19 Vaccine Information',\n",
       "  'abstract': 'Dialogue systems are widely used in AI to support timely and interactive communication with users. We propose a general-purpose dialogue system architecture that leverages computational argumentation to perform reasoning and provide consistent and explainable answers. We illustrate the system using a COVID-19 vaccine information case study.'},\n",
       " '10.1016/J.IPM.2021.102544': {'title': 'A joint learning approach with knowledge injection for zero-shot cross-lingual hate speech detection',\n",
       "  'abstract': 'Hate speech is an increasingly important societal issue in the era of digital communication. Hateful expressions often make use of figurative language and, although they represent, in some sense, the dark side of language, they are also often prime examples of creative use of language. While hate speech is a global phenomenon, current studies on automatic hate speech detection are typically framed in a monolingual setting. In this work, we explore hate speech detection in low-resource languages by transferring knowledge from a resource-rich language, English, in a zero-shot learning fashion. We experiment with traditional and recent neural architectures, and propose two joint-learning models, using different multilingual language representations to transfer knowledge between pairs of languages. We also evaluate the impact of additional knowledge in our experiment, by incorporating information from a multilingual lexicon of abusive words. The results show that our joint-learning models achieve the best performance on most languages. However, a simple approach that uses machine translation and a pre-trained English language model achieves a robust performance. In contrast, Multilingual BERT fails to obtain a good performance in cross-lingual hate speech detection. We also experimentally found that the external knowledge from a multilingual abusive lexicon is able to improve the models’ performance, specifically in detecting the positive class. The results of our experimental evaluation highlight a number of challenges and issues in this particular task. One of the main challenges is related to the issue of current benchmarks for hate speech detection, in particular how bias related to the topical focus in the datasets influences the classification performance. The insufficient ability of current multilingual language models to transfer knowledge between languages in the specific hate speech detection task also remain an open problem. However, our experimental evaluation and our qualitative analysis show how the explicit integration of linguistic knowledge from a structured abusive language lexicon helps to alleviate this issue.'},\n",
       " '10.1016/j.asoc.2021.107172': {'title': 'Transductive transfer learning based Genetic Programming for balanced and unbalanced document classification using different types of features',\n",
       "  'abstract': 'Document classification is one of the predominant tasks in Natural Language Processing. However, some document classification tasks do not have ground truth while other similar datasets may have ground truth. Transfer learning can utilize similar datasets with ground truth to train effective classifiers on the dataset without ground truth. This paper introduces a transductive transfer learning method for document classification using two different text feature representations—the term frequency (TF) and the semantic feature doc2vec. It has three main contributions. First, it enables the sharing knowledge in a dataset using TF and a dataset using doc2vec in transductive transfer learning for performance improvement. Second, it demonstrates that the partially learned programs from TFs and from doc2vecs can be alternatively used to \"label then learn\" and they improve each other. Lastly, it addresses the unbalanced dataset problem by considering the unbalanced distributions on categories for evolving proper Genetic Programming (GP) programs on the target domains. Our experimental results on two popular document datasets show that the proposed technique effectively transfers knowledge from the GP programs evolved from the source domains to the new GP programs on the target domains using TF or doc2vec. There are obviously more than 10 percentages improvement achieved by the GP programs evolved by the proposed method over the GP programs directly evolved from the source domains. Also, the proposed technique effectively utilizes GP programs evolved from unbalanced datasets (on the source and target domains) to evolve new GP programs on the target domains, which balances predictions on different categories.'},\n",
       " '10.1007/s10588-021-09329-w': {'title': '“The coronavirus is a bioweapon”: classifying coronavirus stories on fact-checking sites',\n",
       "  'abstract': 'The 2020 coronavirus pandemic has heightened the need to flag coronavirus-related misinformation, and fact-checking groups have taken to verifying misinformation on the Internet. We explore stories reported by fact-checking groups PolitiFact, Poynter and Snopes from January to June 2020. We characterise these stories into six clusters, then analyse temporal trends of story validity and the level of agreement across sites. The sites present the same stories 78% of the time, with the highest agreement between Poynter and PolitiFact. We further break down the story clusters into more granular story types by proposing a unique automated method, which can be used to classify diverse story sources in both fact-checked stories and tweets. Our results show story type classification performs best when trained on the same medium, with contextualised BERT vector representations outperforming a Bag-Of-Words classifier.'},\n",
       " '10.1007/S00521-021-05751-Y': {'title': 'Deep-Sync: A novel deep learning-based tool for semantic-aware subtitling synchronisation',\n",
       "  'abstract': \"Subtitles are a key element to make any media content accessible for people who suffer from hearing impairment and for elderly people, but also useful when watching TV in a noisy environment or learning new languages. Most of the time, subtitles are generated manually in advance, building a verbatim and synchronised transcription of the audio. However, in TV live broadcasts, captions are created in real time by a re-speaker with the help of a voice recognition software, which inevitability leads to delays and lack of synchronisation. In this paper, we present Deep-Sync, a tool for the alignment of subtitles with the audio-visual content. The architecture integrates a deep language representation model and a real-time voice recognition software to build a semantic-aware alignment tool that successfully aligns most of the subtitles even when there is no direct correspondence between the re-speaker and the audio content. In order to avoid any kind of censorship, Deep-Sync can be deployed directly on users' TVs causing a small delay to perform the alignment, but avoiding to delay the signal at the broadcaster station. Deep-Sync was compared with other subtitles alignment tool, showing that our proposal is able to improve the synchronisation in all tested cases.\"},\n",
       " '10.1007/978-3-030-72113-8_23': {'title': 'Evaluating Multilingual Text Encoders for Unsupervised Cross-Lingual Retrieval',\n",
       "  'abstract': \"Pretrained multilingual text encoders based on neural Transformer architectures, such as multilingual BERT (mBERT) and XLM, have achieved strong performance on a myriad of language understanding tasks. Consequently, they have been adopted as a go-to paradigm for multilingual and cross-lingual representation learning and transfer, rendering cross-lingual word embeddings (CLWEs) effectively obsolete. However, questions remain to which extent this finding generalizes 1) to unsupervised settings and 2) for ad-hoc cross-lingual IR (CLIR) tasks. Therefore, in this work we present a systematic empirical study focused on the suitability of the state-of-the-art multilingual encoders for cross-lingual document and sentence retrieval tasks across a large number of language pairs. In contrast to supervised language understanding, our results indicate that for unsupervised document-level CLIR – a setup with no relevance judgments for IR-specific fine-tuning – pretrained encoders fail to significantly outperform models based on CLWEs. For sentence-level CLIR, we demonstrate that state-of-the-art performance can be achieved. However, the peak performance is not met using the general-purpose multilingual text encoders 'off-the-shelf', but rather relying on their variants that have been further specialized for sentence understanding tasks.\"},\n",
       " '10.1007/978-3-030-78270-2_16': {'title': 'Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses',\n",
       "  'abstract': 'Introductory hands-on courses such as our smartphone-based coding course, SuaCode require a lot of support for students to accomplish learning goals. Online environments make it even more difficult to get assistance especially more recently because of COVID-19. Given the multilingual context of SuaCode students—learners across 42 African countries that are mostly Anglophone or Francophone—in this work, we developed a bilingual Artificial Intelligence (AI) Teaching Assistant (TA)—Kwame—that provides answers to students’ coding questions from SuaCode courses in English and French. Kwame is a Sentence-BERT (SBERT)-based question-answering (QA) system that we trained and evaluated offline using question-answer pairs created from the course’s quizzes, lesson notes and students’ questions in past cohorts. Kwame finds the paragraph most semantically similar to the question via cosine similarity. We compared the system with TF-IDF and Universal Sentence Encoder. Our results showed that fine-tuning on the course data and returning the top 3 and 5 answers improved the accuracy results. Kwame will make it easy for students to get quick and accurate answers to questions in SuaCode courses.'},\n",
       " '10.1016/j.procs.2023.10.111': {'title': 'AI4HR Recruiter: a job recommender system for internal recruitment in consulting companies',\n",
       "  'abstract': 'Recruiting job candidates is a crucial activity for consulting companies to fulfill their consulting activities for customers or internal projects. Due to the complexity of the recruitment process, companies adopt standardized resume formats to be able to identify or compare candidates. However, this process requires significant involvement from human resource specialists and project leaders. In this paper, we present AI4HR Recruiter, a recommender system designed to improve the internal recruitment process of consultants. The system uses artificial intelligence-based techniques, specifically pre-trained sentence transformers. It aims at supporting recruiters in identifying and selecting candidates, rather than automating the process. We measure improvement in efficiency in terms of gains in recruiters time induced by the recommendation explanation presence. We also measure the impact on users’ satisfaction of two different types of algorithm to generate recommendations. To do so, we have been conducting a two fold study in a real-life setting for six months, where on the one hand, telemetry data was gathered while recommendation process user interaction was being performed and on the other hand, surveys about users’ satisfaction were conducted afterward. Our results evaluation demonstrates the effectiveness of the system in assisting recruiters in candidates selection process.'},\n",
       " '10.1007/978-3-031-34560-9_24': {'title': 'Detecting Deviations Between External and Internal Regulatory Requirements for Improved Process Compliance Assessment',\n",
       "  'abstract': 'In order to assure process compliance, a wide range of regulatory requirements from various documents must be considered. These external requirements are typically transformed into internal requirements such as policies or handbooks for process compliance in an organization. The transformation is mostly done manually, without the ability of a digitalized quality check. To support users, this work provides a semi-automatic approach based on state-of-the-art NLP algorithms. We first provide a list of Regulatory Compliance Assessment Solution Requirements (RCASR) based on which deviations between external and internal textual requirements can be detected and the root cause of the deviations can be identified. This detailed analysis helps to find mitigation actions in order to improve process compliance. The proposed approach is evaluated based on two Case studies with greatly varying regulatory documents and their realizations by companies. The evaluation demonstrates the feasibility of the approach and provides further insights into the applicability of NLP-based automation techniques in the field of process compliance assurance and management.'},\n",
       " '10.1016/j.procs.2022.09.011': {'title': 'Classifying news articles in multiple languages: leveraging context aware models',\n",
       "  'abstract': 'Despite the recent advances in text classification and the performance improvement yielded by Transformers models, the absence or inaccessibility of an adequate dataset to train a text classifier motivates the choice for alternative routes. In this study, the need to detect specific topics in the news and to discard irrelevant content encouraged the development of an article tagging pipeline which assesses the similarity between a user-defined dictionary of topic-specific keywords and news article keywords. The innovation of the paper stands in the exploitation of two BERT-based algorithms to retrieve article keywords and to embed them, which previous studies have shown to outperform state of the art solutions for keywords extraction and semantic textual similarity. In a nutshell, the pipeline computes the semantic similarity between the sentence embeddings generated from topic-specific keywords and those produced from news article keywords extracted with the KeyBERT algorithm, finally classifying each article according to a previously defined topic. The results are supported by sound coherence and diversity metrics computed, by aggregating each article by their first tag, which attests to the semantic validity of the pipeline outputs.'},\n",
       " '10.1007/978-3-031-08754-7_7': {'title': 'Devulgarization of Polish Texts Using Pre-trained Language Models',\n",
       "  'abstract': 'We propose a text style transfer method for replacing vulgar expressions in Polish utterances with their non-vulgar equivalents while preserving the meaning of the text. We fine-tune three pre-trained language models on a newly created parallel corpus of vulgar/non-vulgar sentence pairs, then we evaluate style transfer accuracy, content preservation and language quality. To the best of our knowledge, the proposed solution is the first of its kind for Polish.'},\n",
       " '10.1007/978-3-031-08751-6_50': {'title': 'Deep Neural Sequence to Sequence Lexical Substitution for the Polish Language',\n",
       "  'abstract': 'The aim of this paper is to investigate the applicability of language models to the problem of lexical substitution in a strongly inflected language. For this purpose, we focus on pre-trained models based on transformer architectures, in particular BERT and BART. We present a solution in the form of the BART-based sequence-to-sequence model. Then we propose and explore a number of approaches to generate an artificial dataset for lexical substitution, using the adapted PLEWiC dataset as a reference. During this study we focus on Polish as an example of a strongly inflected language.'},\n",
       " '10.1016/j.knosys.2020.106586': {'title': 'Leveraging unstructured call log data for customer churn prediction',\n",
       "  'abstract': 'Customer retention is important in the financial services industry. Machine learning has been incorporated into customer data analytics to predict client churn risks. Despite its success, existing approaches primarily use only structured data, e.g., demographics and account history. Data mining with unstructured data, e.g., customer interaction, can reveal more insights, which has not been adequately leveraged. In this research, we propose a customer churn prediction model utilizing the unstructured data, which is the spoken contents in phone communication. We collected a large-scale call center dataset with two million calls from more than two hundred thousand customers and conducted extensive experiments. The results show that our model can accurately predict the client churn risks and generate meaningful insights using interpretable machine learning with personality traits and customer segments. We discuss how these insights can help managers develop retention strategies customized for different customer segments.'},\n",
       " '10.1007/978-3-030-88189-4_7': {'title': 'Iterative Strict Density-Based Clustering for News Stream',\n",
       "  'abstract': 'News Streams are booming with the prosperity of the Internet, leading to increased demand for an efficient and effective news clustering method. Since news reports vary greatly in different countries, languages and news-topics, clustering diverse news has proven to be a big challenge for all researchers. The results of current clustering methods expose their inability to detect fine-grained topics. They tend to detect topics on a coarse-grained scale, resulting in clustering different fine-grained topics together.In this paper, we propose Iterative Strict Density-based Clustering (ISDC), a new approach for detecting fine-grained topics in an evolving news stream. The main idea of ISDC is to keep every cluster as a high-density cluster throughout the news stream by iteratively splitting growing clusters. We further apply multilingual-sentence-bert instead of word embedding as the news encoder to improve the news representation quality. We conduct comprehensive experiments on two datasets and demonstrate the superiority of our proposed method.'},\n",
       " '10.1007/978-3-030-85251-1_4': {'title': 'SubjectivITA: An Italian Corpus for Subjectivity Detection in Newspapers',\n",
       "  'abstract': 'We present SubjectivITA: the first Italian corpus for subjectivity detection on news articles, with annotations at sentence and document level. Our corpus consists of 103 articles extracted from online newspapers, amounting to 1,841 sentences. We also define baselines for sentence- and document-level subjectivity detection using transformer-based and statistical classifiers. Our results suggest that sentence-level subjectivity annotations may often be sufficient to classify the whole document.'},\n",
       " '10.1007/978-3-030-91608-4_31': {'title': 'Countering Misinformation Through Semantic-Aware Multilingual Models',\n",
       "  'abstract': 'The presence of misinformation and harmful content on social networks is an emerging problem that endangers public health. One of the most successful approaches for detecting, assessing, and providing prompt responses to this misinformation problem is Natural Language Processing (NLP) techniques based on semantic similarity. However, language constitutes one of the most significant barriers to address, denoting the need to develop multilingual tools for an effective fight against misinformation. This paper presents an approach for countering misinformation through a semantic-aware multilingual architecture. Due to the specificity of the task addressed, which involves assessing the level of similarity between a pair of texts in a multilingual scenario, we built an extension of the well-known Semantic Textual Similarity Benchmark (STSb) to 15 languages. This new dataset allows to fine-tune and evaluate multilingual models based on Transformers with a siamese network topology on monolingual and cross-lingual Semantic Textual Similarity (STS) tasks, achieving a maximum average Spearman correlation coefficient of 83.60%. We validate our proposal using the Covid-19 MLIA @ Eval Multilingual Semantic Search Task. The results reported demonstrate that semantic-aware multilingual architectures are successful at measuring the degree of similarity between pairs of texts, while broadening our understanding of the multilingual capabilities of this type of models. The results and the new multilingual STS Benchmark data presented and made publicly in this study constitute an initial step towards extending methods proposed in the literature that employ semantic similarity to combat misinformation at a multilingual level.'},\n",
       " '10.1007/978-3-030-91608-4_10': {'title': 'Combining Encoplot and NLP Based Deep Learning for Plagiarism Detection',\n",
       "  'abstract': 'This paper tackles the classical problem of plagiarism detection by employing current state-of-the-art NLP methods based on Deep Learning. We investigate whether transformer models may be used along with existing solutions for plagiarism detection, such as Encoplot and clustering, to improve their results. Experimental results show that transformers represent a good solution for capturing the semantics of texts when dealing with plagiarism. Further efficiency improvements are needed as the proposed method is highly effective but also requires high computational resources. This prototype approach paves the way to further fine-tuning such that we may obtain a solution that scales well for a large number of source documents and large-sized documents.'},\n",
       " '10.1007/978-3-030-91699-2_8': {'title': 'Evaluating Topic Models in Portuguese Political Comments About Bills from Brazil’s Chamber of Deputies',\n",
       "  'abstract': 'The popular participation in Law-making is an important resource in the evolution of Democracy and Direct Legislation. The amount of legislative documents produced within the past decade has risen dramatically, making it difficult for law practitioners to attend to legislation and still listen to the opinion of the citizens. This work focuses on the use of topic models for summarizing and visualizing Brazilian comments about legislation (bills). In this paper, we provide a qualitative evaluation from a legal expert and compare it with the topics predicted by our model. For such, we designed a specific sentence embedding technique able to induce models for Portuguese texts, and we used these models as topic model, obtaining very good results. We experimentally compared our proposal with other techniques for multilingual sentence embeddings, evaluating them in three topical corpora prepared by us, two of them annotated by a specialist and the other automatically annotated by hashtags.'},\n",
       " '10.1007/978-3-030-91699-2_27': {'title': 'Comparing Contextual Embeddings for Semantic Textual Similarity in Portuguese',\n",
       "  'abstract': 'Semantic textual similarity (STS) measures how semantically similar two sentences are. In the context of the Portuguese language, STS literature is still incipient but includes important initiatives like the ASSIN and ASSIN 2 shared tasks. The state-of-the-art for those datasets is a contextual embedding produced by a Portuguese pre-trained and fine-tuned BERT model. In this work, we investigate the application of Sentence-BERT (SBERT) contextual embeddings to these datasets. Compared to BERT, SBERT is a more computationally efficient approach, enabling its application to scalable unsupervised learning problems. Given the absence of SBERT models pre-trained in Portuguese and the computational cost for such training, we adopt multilingual models and also fine-tune them for Portuguese. Results showed that SBERT embeddings were competitive especially after fine-tuning, numerically surpassing the results of BERT on ASSIN 2 and the results observed during the shared tasks for all datasets considered.'},\n",
       " '10.1007/978-3-030-97532-6_11': {'title': 'Do Fake News Between Different Languages Talk Alike? A Case Study of COVID-19 Related Fake News',\n",
       "  'abstract': 'Social media fuels fake news’ spread across the world. English news has dominated existing fake news research, and how fake news in different languages compares remains severely under studied. To address this scarcity of literature, this research examines the content and linguistic behaviors of fake news in relation to COVID-19. The comparisons reveal both differences and similarities between English and Spanish fake news. The findings have implications for global collaboration in combating fake news.'},\n",
       " '10.1007/978-3-030-32381-3_30': {'title': 'Point the Point: Uyghur Morphological Segmentation Using PointerNetwork with GRU',\n",
       "  'abstract': 'Uyghur is an agglutinative language that has many morphemes. It is necessary for processing Uyghur to segment words into morphemes. This work is called morphological segmentation. Previous works treat morphological segmentation as a tagging task and classify each character as one of four classes, which are $$\\\\{b,m,e,s\\\\}$$ . However, these labels are not independent from each other, which makes the models easily overfitted. We propose a new method for the segmentation task. Instead of using these labels, we use only segmentation points for modeling. The model used in our method is more robust and easier to train than previous methods. Applying our model to Uyghur morphological segmentation, it achieves high accuracy and higher recall and f1 score than previous models.'},\n",
       " '10.1007/978-3-642-23138-4_5': {'title': 'HFST—Framework for Compiling and Applying Morphologies',\n",
       "  'abstract': 'HFST–Helsinki Finite-State Technology ( ) is a framework for compiling and applying linguistic descriptions with finite-state methods. HFST currently connects some of the most important finite-state tools for creating morphologies and spellers into one open-source platform and supports extending and improving the descriptions with weights to accommodate the modeling of statistical information. HFST offers a path from language descriptions to efficient language applications in key environments and operating systems. HFST also provides an opportunity to exchange transducers between different software providers in order to get the best out of each finite-state library.'},\n",
       " '10.1016/j.artint.2022.103665': {'title': 'Unsupervised and few-shot parsing from pretrained language models',\n",
       "  'abstract': 'Pretrained language models are generally acknowledged to be able to encode syntax [46], [16], [13]. In this article, we propose UPOA, an Unsupervised constituent Parsing model that calculates an Out Association score solely based on the self-attention weight matrix learned in a pretrained language model as the syntactic distance for span segmentation. We further propose an enhanced version, UPIO, which exploits both inside association and outside association scores for estimating the likelihood of a span. Experiments with UPOA and UPIO disclose that the linear projection matrices for the query and key in the self-attention mechanism play an important role in parsing. We therefore extend the unsupervised models to few-shot parsing models (FPOA, FPIO) that use a few annotated trees to learn better linear projection matrices for parsing. Experiments on the Penn Treebank demonstrate that our unsupervised parsing model UPIO achieves results comparable to the state of the art on short sentences (length <= 10). Our few-shot parsing model FPIO trained with only 20 annotated trees outperforms a previous few-shot parsing method trained with 50 annotated trees. Experiments on cross-lingual parsing show that both unsupervised and few-shot parsing methods are better than previous methods on most languages of SPMRL [39].'},\n",
       " '10.1007/978-3-319-46218-9_2': {'title': 'Argumentation Mining in Parliamentary Discourse',\n",
       "  'abstract': 'We examine whether using frame choices in forum statements can help us identify framing strategies in parliamentary discourse. In this analysis, we show how features based on embedding representations can improve the discovery of various frames in argumentative political speech. Given the complex nature of the parliamentary discourse, the initial results that are presented here are promising. We further present a manually annotated corpus for frame recognition in parliamentary discourse.'},\n",
       " '10.1016/j.ins.2023.120034': {'title': 'A provably stable neural network Turing Machine with finite precision and time',\n",
       "  'abstract': 'We introduce a neural stack architecture with a differentiable parameterized stack operator approximating stack push and pop operations. We prove the stability of this stack architecture for arbitrarily many stack operations, showing that the state of the neural stack still closely resembles the state of a discrete stack. Using the neural stack with a recurrent neural network, we devise a neural network Pushdown Automaton (nnPDA). A new theoretical bound shows that an nnPDA can recognize any PDA using only finite precision state neurons in finite time. By using two neural stacks to construct a neural tape together with a recurrent neural network, we define a neural network Turing Machine (nnTM). Just like the neural stack, we show these architectures are also stable. Furthermore, we show the nnTM is Turing complete. It requires finite precision state neurons with an arbitrary number of stack neurons to recognize any TM in finite time, thus providing a new and much stronger computational upper bound for neural networks that are Turing complete.'},\n",
       " '10.1007/978-1-4612-0289-9': {'title': 'Finite Automata, Formal Logic, and Circuit Complexity',\n",
       "  'abstract': 'The study of the connections between mathematical automata and for mal logic is as old as theoretical computer science itself. In the founding paper of the subject, published in 1936, Turing showed ho'},\n",
       " '10.1016/S0022-0000(71)80003-X': {'title': 'Dot-depth of star-free events',\n",
       "  'abstract': 'A regular event is star-free if it can be denoted by a regular expression involvingonly Boolean operations and concatenation (dot). The family of star-free events can be constructed by alternately applying Boolean operations and concatenation. This approach leads to a hierarchy of star-free events, and to the definition of \"dot-depth\" of a star-free event which appears to be useful as a measure of the complexity of the event. Properties of dot-depth are examined; for example, it is shown that the dot-depthof a star-free event cannot be increased by the quotient operation with respect to any language, nor can it be increased by multiplying the event by a finite language. The use of two-sided quotients adds insight to the theory of star-free events and permits the derivation of some new properties of these events; in particular, every star-free event has at least one quotient which is either empty or full. The family of star-free events has been shown to be equivalent to the family ofregular noncounting events, and also corresponds to the family of finite automata whose semigroups have no nontrivial subgroups (group-fee automata). In the final section an algorithm is developed for constructing a star-free expression for the event accepted by a group-free finite automaton. An upper bound for the dot-depth of the event is found. We conjecture that for each n≥0, there exist star-free events of dot depth n. We have been able to show this only for n≤2; the general problem remains open.'},\n",
       " '10.1162/106454603321489545': {'title': \"The Atoms of Language: The Mind's Hidden Rules of Grammar; Foundations of Language: Brain, Meaning, Grammar, Evolution\",\n",
       "  'abstract': \"January 01 2003 The Atoms of Language: The Mind's Hidden Rules of Grammar; Foundations of Language: Brain, Meaning, Grammar, Evolution The Atoms of Language: The Mind's Hidden Rules of Grammar. Mark C.Baker. ( 2001, Basic Books.) 250 pages.Foundations of Language: Brain, Meaning, Grammar, Evolution. RayJackendoff. ( 2002, Oxford University Press.) 496 pages. Bart de Boer Bart de Boer Artificial Intelligence Laboratory, Vrije Universiteit Brussel, Pleinlaan 2, B-1050 Brussels, Belgium, bartb@arti.vub.ac.be Search for other works by this author on: This Site Google Scholar Author and Article Information Bart de Boer Artificial Intelligence Laboratory, Vrije Universiteit Brussel, Pleinlaan 2, B-1050 Brussels, Belgium, bartb@arti.vub.ac.be Online Issn: 1530-9185 Print Issn: 1064-5462 © 2003 Massachusetts Institute of Technology2003 Artificial Life (2003) 9 (1): 89–91. https://doi.org/10.1162/106454603321489545 Cite Icon Cite Permissions Share Icon Share Facebook Twitter LinkedIn Email Views Icon Views Article contents Figures & tables Video Audio Supplementary Data Search Site Citation Bart de Boer; The Atoms of Language: The Mind's Hidden Rules of Grammar; Foundations of Language: Brain, Meaning, Grammar, Evolution. Artif Life 2003; 9 (1): 89–91. doi: https://doi.org/10.1162/106454603321489545 Download citation file: Ris (Zotero) Reference Manager EasyBib Bookends Mendeley Papers EndNote RefWorks BibTex toolbar search Search nav search search input Search input auto suggest search filter All ContentAll JournalsArtificial Life Search Advanced Search This content is only available as a PDF. © 2003 Massachusetts Institute of Technology2003 Article PDF first page preview Close Modal You do not currently have access to this content.\"},\n",
       " '10.1016/S0885-2308(02)00024-4': {'title': 'Learning visually grounded words and syntax for a scene description task',\n",
       "  'abstract': 'A spoken language generation system has been developed that learns to describe objects in computer-generated visual scenes. The system is trained by a ‘show-and-tell’ procedure in which visual scenes are paired with natural language descriptions. Learning algorithms acquire probabilistic structures which encode the visual semantics of phrase structure, word classes, and individual words. Using these structures, a planning algorithm integrates syntactic, semantic, and contextual constraints to generate natural and unambiguous descriptions of objects in novel scenes. The system generates syntactically well-formed compound adjective noun phrases, as well as relative spatial clauses. The acquired linguistic structures generalize from training data, enabling the production of novel word sequences which were never observed during training. The output of the generation system is synthesized using word-based concatenative synthesis drawing from the original training speech corpus. In evaluations of semantic comprehension by human judges, the performance of automatically generated spoken descriptions was comparable to human-generated descriptions. This work is motivated by our long-term goal of developing spoken language processing systems which grounds semantics in machine perception and action.'},\n",
       " '10.3758/BF03194928': {'title': 'Perceptual components of situation models',\n",
       "  'abstract': \"These experiments examined the hypothesis that situation model construction involves perceptual processing--specifically, processing that involves visuospatial information. In this research, a dual-task paradigm was used to demonstrate that tasks that engage visuospatial processes interfere more with the generation of a situation model than tasks that are less likely to involve these processes or tasks that are verbal in nature. Using Albrecht and O'Brien's (1993) contradiction effect as evidence of situation model construction, Experiment 1 demonstrated that participants reading short texts while simultaneously holding high-imagery sentences in memory failed to show a significant contradiction effect in comparison with readers holding low-imagery sentences in memory. In Experiment 2, participants reading texts while retaining a difficult visuospatial memory load showed disrupted comprehension in comparison with readers retaining a verbal memory load.\"},\n",
       " '10.1016/S0004-3702(98)00066-6': {'title': 'The origins of syntax in visually grounded robotic agents',\n",
       "  'abstract': 'The paper proposes a set of principles and a general architecture that may explain how language and meaning may originate and complexify in a group of physically grounded distributed agents. An experimental setup is introduced for concretising and validating specific mechanisms based on these principles. The setup consists of two robotic heads that watch static or dynamic scenes and engage in language games, in which one robot describes to the other what they see. The first results from experiments showing the emergence of distinctions, of a lexicon, and of primitive syntactic structures are reported.'},\n",
       " '10.1007/978-1-4612-5110-1_1': {'title': 'Asymptotically Subminimax Solutions of Compound Statistical Decision Problems',\n",
       "  'abstract': 'When statistical decision problems of the same type are considered in large groups the minimax solution may not be the “best,” since there may exist solutions which are “asymptotically subminimax.” This is shown in detail for a classical problem in the theory of testing hypotheses.'},\n",
       " '10.1016/j.dss.2024.114183': {'title': 'FedDQA: A novel regularization-based deep learning method for data quality assessment in federated learning',\n",
       "  'abstract': 'Researchers strive to designing artificial intelligence (AI) models that can fully utilize the potentials of data while protecting privacy. Federated learning is a promising solution because it utilizes data but shields it from those who do not own them. However, assessing data quality becomes a challenge in federated learning. We propose a data quality assessment method, Federated Data Quality Assessment (FedDQA), and compare it with traditional federated learning methods. FedDQA identifies low-quality data from participants and reduces their influence on the global model. We integrate data quality regularization strategies at the instance, feature, and participant levels into federate learning model. In various data poisoning settings, FedDQA outperforms existing federated learning methods in prediction performance and the accuracy in detecting low-quality data.'},\n",
       " '10.1016/j.cmpb.2023.107771': {'title': 'Identifying predictive biomarkers for repetitive transcranial magnetic stimulation response in depression patients with explainability',\n",
       "  'abstract': 'Repetitive Transcranial Magnetic Stimulation (rTMS) is an evidence-based treatment for depression. However, the patterns of response to this treatment modality are inconsistent. Whilst many people see a significant reduction in the severity of their depression following rTMS treatment, some patients do not. To support and improve patient outcomes, recent work is exploring the possibility of using Machine Learning to predict rTMS treatment outcomes. Our proposed model is the first to combine functional magnetic resonance imaging (fMRI) connectivity with deep learning techniques to predict treatment outcomes before treatment starts. Furthermore, with the use of Explainable AI (XAI) techniques, we identify potential biomarkers that may discriminate between rTMS responders and non-responders. Our experiments utilize 200 runs of repeated bootstrap sampling on two rTMS datasets. We compare performances between our proposed feedforward deep neural network against existing methods, and compare the average accuracy, balanced accuracy and F1-score on a held-out test set. The results of these experiments show that our model outperforms existing methods with an average accuracy of 0.9423, balanced accuracy of 0.9423, and F1-score of 0.9461 in a sample of 61 patients. We found that functional connectivity measures between the Subgenual Anterior Cingulate Cortex and Centeral Opercular Cortex are a key determinant of rTMS treatment response. This knowledge provides psychiatrists with further information to explore the potential mechanisms of responses to rTMS treatment. Our developed prototype is ready to be deployed across large datasets in multiple centres and different countries.'},\n",
       " '10.1007/978-3-030-93842-0_1': {'title': 'Active Learning for Reducing Labeling Effort in Text Classification Tasks',\n",
       "  'abstract': 'Labeling data can be an expensive task as it is usually performed manually by domain experts. This is cumbersome for deep learning, as it is dependent on large labeled datasets. Active learning (AL) is a paradigm that aims to reduce labeling effort by only using the data which the used model deems most informative. Little research has been done on AL in a text classification setting and next to none has involved the more recent, state-of-the-art Natural Language Processing (NLP) models. Here, we present an empirical study that compares different uncertainty-based algorithms with BERT $$_{base}$$ as the used classifier. We evaluate the algorithms on two NLP classification datasets: Stanford Sentiment Treebank and KvK-Frontpages. Additionally, we explore heuristics that aim to solve presupposed problems of uncertainty-based AL; namely, that it is unscalable and that it is prone to selecting outliers. Furthermore, we explore the influence of the query-pool size on the performance of AL. Whereas it was found that the proposed heuristics for AL did not improve performance of AL; our results show that using uncertainty-based AL with BERT $$_{base}$$ outperforms random sampling of data. This difference in performance can decrease as the query-pool size gets larger.'},\n",
       " '10.1007/s10115-022-01756-8': {'title': 'Interpretable deep learning: interpretation, interpretability, trustworthiness, and beyond',\n",
       "  'abstract': 'Deep neural networks have been well-known for their superb handling of various machine learning and artificial intelligence tasks. However, due to their over-parameterized black-box nature, it is often difficult to understand the prediction results of deep models. In recent years, many interpretation tools have been proposed to explain or reveal how deep models make decisions. In this paper, we review this line of research and try to make a comprehensive survey. Specifically, we first introduce and clarify two basic concepts—interpretations and interpretability—that people usually get confused about. To address the research efforts in interpretations, we elaborate the designs of a number of interpretation algorithms, from different perspectives, by proposing a new taxonomy. Then, to understand the interpretation results, we also survey the performance metrics for evaluating interpretation algorithms. Further, we summarize the current works in evaluating models’ interpretability using “trustworthy” interpretation algorithms. Finally, we review and discuss the connections between deep models’ interpretations and other factors, such as adversarial robustness and learning from interpretations, and we introduce several open-source libraries for interpretation algorithms and evaluation approaches.'},\n",
       " '10.1016/j.patter.2021.100336': {'title': 'Data and its (dis)contents: A survey of dataset development and use in machine learning research',\n",
       "  'abstract': 'In this work, we survey a breadth of literature that has revealed the limitations of predominant practices for dataset collection and use in the field of machine learning. We cover studies that critically review the design and development of datasets with a focus on negative societal impacts and poor outcomes for system performance. We also cover approaches to filtering and augmenting data and modeling techniques aimed at mitigating the impact of bias in datasets. Finally, we discuss works that have studied data practices, cultures, and disciplinary norms and discuss implications for the legal, ethical, and functional challenges the field continues to face. Based on these findings, we advocate for the use of both qualitative and quantitative approaches to more carefully document and analyze datasets during the creation and usage phases.'},\n",
       " '10.1007/978-3-031-35260-7_5': {'title': 'The Impact of Importance-Aware Dataset Partitioning on Data-Parallel Training of Deep Neural Networks',\n",
       "  'abstract': 'Deep neural networks used for computer vision tasks are typically trained on datasets consisting of thousands of images, called examples. Recent studies have shown that examples in a dataset are not of equal importance for model training and can be categorized based on quantifiable measures reflecting a notion of “hardness” or “importance”. In this work, we conduct an empirical study of the impact of importance-aware partitioning of the dataset examples across workers on the performance of data-parallel training of deep neural networks. Our experiments with CIFAR-10 and CIFAR-100 image datasets show that data-parallel training with importance-aware partitioning can perform better than vanilla data-parallel training, which is oblivious to the importance of examples. More specifically, the proper choice of the importance measure, partitioning heuristic, and the number of intervals for dataset repartitioning can improve the best accuracy of the model trained for a fixed number of epochs. We conclude that the parameters related to importance-aware data-parallel training, including the importance measure, number of warmup training epochs, and others defined in the paper, may be considered as hyperparameters of data-parallel model training.'},\n",
       " '10.1007/978-3-030-99739-7_36': {'title': 'ALWars: Combat-Based Evaluation of Active Learning Strategies',\n",
       "  'abstract': 'The demand for annotated datasets for supervised machine learning (ML) projects is growing rapidly. Annotating a dataset often requires domain experts and is a timely and costly process. A premier method to reduce this overhead drastically is Active Learning (AL). Despite a tremendous potential for annotation cost savings, AL is still not used universally in ML projects. The large number of available AL strategies has significantly risen during the past years leading to an increased demand for thorough evaluations of AL strategies. Existing evaluations show in many cases contradicting results, without clear superior strategies. To help researchers in taming the AL zoo we present ALWars: an interactive system with a rich set of features to compare AL strategies in a novel replay view mode of all AL episodes with many available visualization and metrics. Under the hood we support a rich variety of AL strategies by supporting the API of the powerful AL framework ALiPy [21], amounting to over 25 AL strategies out-of-the-box.'},\n",
       " '10.1007/978-3-031-08754-7_69': {'title': 'Neuro-Symbolic Models for Sentiment Analysis',\n",
       "  'abstract': 'We propose and test multiple neuro-symbolic methods for sentiment analysis. They combine deep neural networks – transformers and recurrent neural networks – with external knowledge bases. We show that for simple models, adding information from knowledge bases significantly improves the quality of sentiment prediction in most cases. For medium-sized sets, we obtain significant improvements over state-of-the-art transformer-based models using our proposed methods: Tailored KEPLER and Token Extension. We show that the cases with the improvement belong to the hard-to-learn set.'},\n",
       " '10.1080/13658816.2010.528422': {'title': 'Facility location: concepts, models, algorithms and case studies. Series: Contributions to Management Science',\n",
       "  'abstract': 'Network analysis and location analysis constitute an essential part of spatial analysis, and one can hardly find a textbook on this topic in which these subjects are not addressed. Although the imp...'},\n",
       " '10.1038/s41398-023-02592-2': {'title': 'Natural language processing for mental health interventions: a systematic review and research framework',\n",
       "  'abstract': 'Abstract Neuropsychiatric disorders pose a high societal cost, but their treatment is hindered by lack of objective outcomes and fidelity metrics. AI technologies and specifically Natural Language Processing (NLP) have emerged as tools to study mental health interventions (MHI) at the level of their constituent conversations. However, NLP’s potential to address clinical and research challenges remains unclear. We therefore conducted a pre-registered systematic review of NLP-MHI studies using PRISMA guidelines (osf.io/s52jh) to evaluate their models, clinical applications, and to identify biases and gaps. Candidate studies (n = 19,756), including peer-reviewed AI conference manuscripts, were collected up to January 2023 through PubMed, PsycINFO, Scopus, Google Scholar, and ArXiv. A total of 102 articles were included to investigate their computational characteristics (NLP algorithms, audio features, machine learning pipelines, outcome metrics), clinical characteristics (clinical ground truths, study samples, clinical focus), and limitations. Results indicate a rapid growth of NLP MHI studies since 2019, characterized by increased sample sizes and use of large language models. Digital health platforms were the largest providers of MHI data. Ground truth for supervised learning models was based on clinician ratings ( n = 31), patient self-report ( n = 29) and annotations by raters ( n = 26). Text-based features contributed more to model accuracy than audio markers. Patients’ clinical presentation ( n = 34), response to intervention ( n = 11), intervention monitoring ( n = 20), providers’ characteristics ( n = 12), relational dynamics ( n = 14), and data preparation ( n = 4) were commonly investigated clinical categories. Limitations of reviewed studies included lack of linguistic diversity, limited reproducibility, and population bias. A research framework is developed and validated (NLPxMHI) to assist computational and clinical researchers in addressing the remaining gaps in applying NLP to MHI, with the goal of improving clinical utility, data access, and fairness.'},\n",
       " '10.1038/s41597-023-02203-1': {'title': 'CHQ- SocioEmo: Identifying Social and Emotional Support Needs in Consumer-Health Questions',\n",
       "  'abstract': \"General public, often called consumers, are increasingly seeking health information online. To be satisfactory, answers to health-related questions often have to go beyond informational needs. Automated approaches to consumer health question answering should be able to recognize the need for social and emotional support. Recently, large scale datasets have addressed the issue of medical question answering and highlighted the challenges associated with question classification from the standpoint of informational needs. However, there is a lack of annotated datasets for the non-informational needs. We introduce a new dataset for non-informational support needs, called CHQ-SocioEmo. The Dataset of Consumer Health Questions was collected from a community question answering forum and annotated with basic emotions and social support needs. This is the first publicly available resource for understanding non-informational support needs in consumer health-related questions online. We benchmark the corpus against multiple state-of-the-art classification models to demonstrate the dataset's effectiveness.\"},\n",
       " '10.1038/s41598-023-33703-0': {'title': 'Automatic evaluation-feedback system for automated social skills training',\n",
       "  'abstract': \"Social skills training (SST), which is a rehabilitation program for improving daily interpersonal communication, has been used for more than 40 years. Although such training's demand is increasing, its accessibility is limited due to the lack of experienced trainers. To tackle this issue, automated SST systems have been studied for years. An evaluation-feedback pipeline of social skills is a crucial component of an SST system. Unfortunately, research that considers both the evaluation and feedback parts of automation remains insufficient. In this paper, we collected and analyzed the characteristics of a human-human SST dataset that consisted of 19 healthy controls, 15 schizophreniacs, 16 autism spectrum disorder (ASD) participants, and 276 sessions with score labels of six clinical measures. From our analysis of this dataset, we developed an automated SST evaluation-feedback system under the supervision of professional, experienced SST trainers. We identified their preferred or most acceptable feedback methods by running a user-study on the following conditions: with/without recorded video of the role-plays of users and different amounts of positive and corrective feedback. We confirmed a reasonable performance of our social-skill-score estimation models as our system's evaluation part with a maximum Spearman's correlation coefficient of 0.68. For the feedback part, our user-study concluded that people understood more about what aspects they need to improve by watching recorded videos of their own performance. In terms of the amount of feedback, participants most preferred a 2-positive/1-corrective format. Since the average amount of feedback preferred by the participants nearly equaled that from experienced trainers in human-human SSTs, our result suggests the practical future possibilities of an automated evaluation-feedback system that complements SSTs done by professional trainers.\"},\n",
       " '10.1016/j.ipm.2022.103192': {'title': 'An analysis of cognitive change in online mental health communities: A textual data analysis based on post replies of support seekers',\n",
       "  'abstract': 'The replies of people seeking support in online mental health communities can be analyzed to discover if they feel better after receiving support; feeling better indicates a cognitive change. Most research uses key phrase matching and word frequency statistics to identify psychological cognitive change, methods that result in omissions and inaccuracy. This study constructs an intelligent method for identifying psychological cognitive change based on natural language processing technology. It incorporates information related to emotions that appears in reply text to help identify whether psychological cognitive change has occurred. The model first encodes the emotion information based on rule matching and manual annotation, then adds the encoded emotion lexicon and a cognitive change lexicon to a word2vec high-dimensional semantic word vector training, converts the annotated cognitive change recognition text into a vector matrix using the trained model, and train in the annotated text using TextCNN. To compare the results with those of the traditional methods (key phrase matching and sentiment word frequency statistics), this study uses a semi-automated approach to construct a lexicon of psychological cognitive change, as well as a keyword lexicon without cognitive change, based on word vectors and similarity. We compare the performance of the classifier before and after the fusion of the graphical emotion information, compare the LSTM and Transformer as baselines, and compare traditional word frequency statistics methods. The experimental results show that our proposed classification model performs better than the others; it achieves 84.38% precision, an 84.09% recall rate, and an 84.17% F1 value. Our work bears methodological implications for online mental health platforms.'},\n",
       " '10.1038/s44184-022-00020-9': {'title': 'A computational approach to measure the linguistic characteristics of psychotherapy timing, responsiveness, and consistency',\n",
       "  'abstract': 'Abstract Although individual psychotherapy is generally effective for a range of mental health conditions, little is known about the moment-to-moment language use of effective therapists. Increased access to computational power, coupled with a rise in computer-mediated communication (telehealth), makes feasible the large-scale analyses of language use during psychotherapy. Transparent methodological approaches are lacking, however. Here we present novel methods to increase the efficiency of efforts to examine language use in psychotherapy. We evaluate three important aspects of therapist language use - timing, responsiveness, and consistency - across five clinically relevant language domains: pronouns, time orientation, emotional polarity, therapist tactics, and paralinguistic style. We find therapist language is dynamic within sessions, responds to patient language, and relates to patient symptom diagnosis but not symptom severity. Our results demonstrate that analyzing therapist language at scale is feasible and may help answer longstanding questions about specific behaviors of effective therapists.'},\n",
       " '10.1016/j.ipm.2022.103074': {'title': 'Chatbot as an emergency exist: Mediated empathy for resilience via human-AI interaction during the COVID-19 pandemic',\n",
       "  'abstract': \"As a global health crisis, the COVID-19 pandemic has also made heavy mental and emotional tolls become shared experiences of global communities, especially among females who were affected more by the pandemic than males for anxiety and depression. By connecting multiple facets of empathy as key mechanisms of information processing with the communication theory of resilience, the present study examines human-AI interactions during the COVID-19 pandemic in order to understand digitally mediated empathy and how the intertwining of empathic and communicative processes of resilience works as coping strategies for COVID-19 disruption. Mixed methods were adopted to explore the using experiences and effects of Replika, a chatbot companion powered by AI, with ethnographic research, in-depth interviews, and grounded theory-based analysis. Findings of this research extend empathy theories from interpersonal communication to human-AI interactions and show five types of digitally mediated empathy among Chinese female Replika users with varying degrees of cognitive empathy, affective empathy, and empathic response involved in the information processing processes, i.e., companion buddy, responsive diary, emotion-handling program, electronic pet, and tool for venting. When processing information obtained from AI and collaborative interactions with the AI chatbot, multiple facets of mediated empathy become unexpected pathways to resilience and enhance users' well-being. This study fills the research gap by exploring empathy and resilience processes in human-AI interactions. Practical implications, especially for increasing individuals' psychological resilience as an important component of global recovery from the pandemic, suggestions for future chatbot design, and future research directions are also discussed.\"},\n",
       " '10.1038/s42256-022-00593-2': {'title': 'Human–AI collaboration enables more empathic conversations in text-based peer-to-peer mental health support',\n",
       "  'abstract': 'Advances in artificial intelligence (AI) are enabling systems that augment and collaborate with humans to perform simple, mechanistic tasks such as scheduling meetings and grammar-checking text. However, such human–AI collaboration poses challenges for more complex tasks, such as carrying out empathic conversations, due to the difficulties that AI systems face in navigating complex human emotions and the open-ended nature of these tasks. Here we focus on peer-to-peer mental health support, a setting in which empathy is critical for success, and examine how AI can collaborate with humans to facilitate peer empathy during textual, online supportive conversations. We develop HAILEY, an AI-in-the-loop agent that provides just-in-time feedback to help participants who provide support (peer supporters) respond more empathically to those seeking help (support seekers). We evaluate HAILEY in a non-clinical randomized controlled trial with real-world peer supporters on TalkLife (N = 300), a large online peer-to-peer support platform. We show that our human–AI collaboration approach leads to a 19.6% increase in conversational empathy between peers overall. Furthermore, we find a larger, 38.9% increase in empathy within the subsample of peer supporters who self-identify as experiencing difficulty providing support. We systematically analyse the human–AI collaboration patterns and find that peer supporters are able to use the AI feedback both directly and indirectly without becoming overly reliant on AI while reporting improved self-efficacy post-feedback. Our findings demonstrate the potential of feedback-driven, AI-in-the-loop writing systems to empower humans in open-ended, social and high-stakes tasks such as empathic conversations. AI language modelling and generation approaches have developed fast in the last decade, opening promising new directions in human–AI collaboration. An AI-in-the loop conversational system called HAILEY is developed to empower peer supporters in providing empathic responses to mental health support seekers.'},\n",
       " '10.1007/978-3-030-92307-5_30': {'title': 'DYME: A Dynamic Metric for Dialog Modeling Learned from Human Conversations',\n",
       "  'abstract': 'With increasing capabilities of dialog generation methods, modeling human conversation characteristics to steer the dialog generation towards natural, human-like interactions has garnered research interest. So far, dialogs have mostly been modeled with developer-defined, static metrics. This work shows that metrics change within individual conversations and differ between conversations, illustrating the need for flexible metrics to model human dialogs. We propose DYME, a DYnamic MEtric for dialog modeling learned from human conversational data with a neural-network-based approach. DYME outperforms a moving average baseline in predicting the metrics for the next utterance of a given conversation by about 20%, demonstrating the ability of this new approach to model dynamic human communication characteristics.'},\n",
       " '10.1016/S2215-0366(17)30513-8': {'title': \"The Lancet Psychiatry Commission on psychological treatments research in tomorrow's science\",\n",
       "  'abstract': 'Psychological treatments occupy an important place in evidence-based mental health treatments. Now is an exciting time to fuel treatment research: a pressing demand for improvements is poised alongside new opportunities from closer links with sister scientific and clinical disciplines. The need to improve mental health treatment is great; even the best treatments do not work for everyone, treatments have not been developed for many mental disorders, and the implementation of treatments needs to address worldwide scalability.'},\n",
       " '10.1016/j.beth.2014.11.002': {'title': 'More Than Reflections: Empathy in Motivational Interviewing Includes Language Style Synchrony Between Therapist and Client',\n",
       "  'abstract': 'Empathy is a basic psychological process that involves the development of synchrony in dyads. It is also a foundational ingredient in specific, evidence-based behavioral treatments like motivational interviewing (MI). Ratings of therapist empathy typically rely on a gestalt, \"felt sense\" of therapist understanding and the presence of specific verbal behaviors like reflective listening. These ratings do not provide a direct test of psychological processes like behavioral synchrony that are theorized to be an important component of empathy in psychotherapy. To explore a new objective indicator of empathy, we hypothesized that synchrony in language style (i.e., matching how statements are phrased) between client and therapists would predict gestalt ratings of empathy over and above the contribution of reflections. We analyzed 122 MI transcripts with high and low empathy ratings based on the Motivational Interviewing Treatment Integrity global rating scale. Linguistic inquiry and word count was used to estimate language style synchrony (LSS) of adjacent client and therapist talk turns. High-empathy sessions showed greater LSS across 11 language style categories compared with low-empathy sessions (p<.01), and overall, average LSS was notably higher in high-empathy versus low-empathy sessions (d=0.62). Regression analyses showed that LSS was predictive of empathy ratings over and above reflection counts; a 1 SD increase in LSS is associated with a 2.4 times increase in the odds of a high-empathy rating, controlling for therapist reflections (odds ratio=2.4; 95% CI: 1.36; 4.24, p<.01). These findings suggest empathy ratings are related to synchrony in language style, over and above synchrony of content as measured by therapist reflections. Novel indicators of therapist empathy may have implications for the study of MI process as well as the training of therapists.'},\n",
       " '10.1016/S0140-6736(05)67407-7': {'title': 'Empathy',\n",
       "  'abstract': \"Empathy is widely seen as the essential corrective to the modern dehumanisation of the patient. In his Harveian Oration on “Science, Society and the Perplexed Physician” at London's Royal College of Physicians, UK, in 2000, Lord Turnberg suggested that development of empathy was increasingly important because of the desensitising effects of clinical training. Yet this nostalgia for a lost empathic relationship between doctor and patient is curious, since the word was only invented at the beginning of the 20th century. Empathy was coined in 1904 by the occult novelist and aesthete Vernon Lee (1856–1935) (aka Violet Paget), who was fascinated by ideas of spiritual possession and identification. In Otillie (1883), a supernatural fiction, she described a brother and sister's mysterious unspoken bond. In later works, she explored haunting and the ways that the identities of the dead could supposedly shape the minds of the living. Empathy was held up as an aesthetic parallel to these psychic processes. Lee saw it as the projection of our “energies, activities and feelings” into a material work of art and emphasised its equivalence to the process of Einfühlung identified by the German experimental psychologist, Theodor Lipps (1851–1914). Lee and Lipps both saw empathy as a form of transference, like John Ruskin's “pathetic fallacy”, in which human attributes were ascribed to inanimate objects. This notion is very different to the practitioner's understanding of empathy today. The reversal in the meaning of empathy is largely the result of efforts by therapists and psychoanalysts, notably Carl Rogers (1902–87), to develop a more open form of psychotherapy. In Client-Centred Therapy (1951), Rogers suggested that therapeutic success could only be achieved through the cultivation of a genuine interest in the patient. As this idea of empathy entered the psychotherapeutic mainstream, it was transformed into a natural category—a human attribute—whose absence (according to Diagnostic and Statistical Manual of Mental Disorders IV) could be seen as indicative of an underlying personality disorder. Yet despite this process of naturalisation, it is still difficult to distinguish between personal sympathy and egotistic projection. At one level, the ambivalent etymological origins of empathy help to remind us of the unstable agenda behind our own pursuit of empathy.\"},\n",
       " '10.1038/139919a0': {'title': 'Modern Applications of Psychology',\n",
       "  'abstract': 'DR. C. S. MYERS, in a paper before the Royal Society of Arts on March 10 on “Industrial Psychology and the Modern World”, began by showing the indebtedness of this most recent application of psychology to the educational and medical applications that had preceded it. The field covered by it is very wide, since it is concerned with all grades of occupational life, with industrial relations, personnel management and with all the environmental conditions that can hinder or further the happiness, health and efficiency of those engaged in industry. Already the pioneer work done in England is being developed and adapted by many other countries. By a scientific study of individual differences and of the requirements for success in particular occupations, the industrial psychologist has been able to develop a technique which enables him to direct an entrant into the occupation for which he seems most fitted, and also to help the employer to select from a number of applicants those with the fundamental requirements. The young person is thereby saved from much futile groping and the attendant sense of failure. When, however, the right selection has been made, it becomes necessary to train the beginner in the right methods, instead of letting him pick up for himself methods that might be good or might be bad. In this field, the industrial psychologist has made a special study of the best movements and methods of work that should be taught, and of the suitable methods of teaching the required movements. He has also much to offer to management, and could prevent the unnecessary friction resulting from those in authority having more knowledge of the machinery and of the materials involved than of the human beings for whom they are responsible.'},\n",
       " '10.1016/j.eswa.2024.123956': {'title': 'A meta-contrastive learning with data augmentation framework for zero-shot stance detection',\n",
       "  'abstract': 'Zero-shot stance detection (ZSSD) identifies the stances of targets that have not been encountered during the testing phase. Most of the existing efforts are dedicated to enhancing the generalizability of models while ignoring data issues such as data scarcity and targets that are not explicitly mentioned. Therefore, we consider approaching this task from both the data and model perspectives and propose a meta-contrastive learning with data augmentation framework. We first use a generation model to generate target keyphrases for enhancing the original text. Then, we utilize a meta-learning technique that incorporates contrastive learning for improving the generalizability of the model, enabling it to better adapt to unknown targets. The experimental results obtained on three benchmark datasets prove that our framework achieves outstanding performance improvements in the ZSSD task. Our code is available at https://github.com/qifen37/MCLDA.'},\n",
       " '10.1007/s44196-023-00359-7': {'title': 'Adversarial Distillation Adaptation Model with Sentiment Contrastive Learning for Zero-Shot Stance Detection',\n",
       "  'abstract': 'Abstract Zero-shot stance detection is both crucial and challenging because it demands detecting the stances of previously unseen targets in the inference stage. Learning transferable target invariant features effectively from training data is crucial for zero-shot stance detection. This paper proposes an adversarial adaptation approach for zero-shot stance detection, which applies an adversarial discriminative domain adaptation network to transfer knowledge efficiently. Specifically, the proposed model applies knowledge distillation to prevent overfitting the destination data and forgetting the learned source knowledge. Moreover, stance contrastive learning is applied to enhance the quality of feature representation for superior generalization, and sentiment information is extracted to assist with stance detection. The experimental results indicate that our model performs competitively on two benchmark datasets.'},\n",
       " '10.1016/j.neucom.2023.126943': {'title': 'Commonsense-based adversarial learning framework for zero-shot stance detection',\n",
       "  'abstract': 'Zero-shot stance detection (ZSSD) aims to identify the stance for a diverse range of topics with limited or no training data. It is more suitable for evolving real-world topics that are constantly evolving. However, ZSSD faces major challenges which are the lack of unseen target information and the inability to generalize training information to unseen targets effectively. To overcome these challenges, we propose a commonsense-based adversarial learning framework that comprises a commonsense graph encoder and a feature separation adversarial network. Specifically, our approach utilizes an external commonsense graph encoder to learn unseen target information. Moreover, we design a novel feature separation adversarial network to learn target-invariant and target-specific features, which enhances the model’s ability to reason beyond the seen targets. Experiments on two benchmark datasets show that our proposed framework achieves state-of-the-art performance.'},\n",
       " '10.1016/j.ipm.2023.103361': {'title': 'Zero-shot stance detection via multi-perspective contrastive learning with unlabeled data',\n",
       "  'abstract': \"Stance detection is to distinguish whether the text's author supports, opposes, or maintains a neutral stance towards a given target. In most real-world scenarios, stance detection needs to work in a zero-shot manner, i.e., predicting stances for unseen targets without labeled data. One critical challenge of zero-shot stance detection is the absence of contextual information on the targets. Current works mostly concentrate on introducing external knowledge to supplement information about targets, but the noisy schema-linking process hinders their performance in practice. To combat this issue, we argue that previous studies have ignored the extensive target-related information inhabited in the unlabeled data during the training phase, and propose a simple yet efficient Multi-Perspective Contrastive Learning Framework for zero-shot stance detection. Our framework is capable of leveraging information not only from labeled data but also from extensive unlabeled data. To this end, we design target-oriented contrastive learning and label-oriented contrastive learning to capture more comprehensive target representation and more distinguishable stance features. We conduct extensive experiments on three widely adopted datasets (from 4870 to 33,090 instances), namely SemEval-2016, WT-WT, and VAST. Our framework achieves 53.6%, 77.1%, and 72.4% macro-average F1 scores on these three datasets, showing 2.71% and 0.25% improvements over state-of-the-art baselines on the SemEval-2016 and WT-WT datasets and comparable results on the more challenging VAST dataset.\"},\n",
       " '10.1016/j.patrec.2023.05.006': {'title': 'Meta-learning with topic-agnostic representations for zero-shot stance detection',\n",
       "  'abstract': 'Zero-shot stance detection (ZSSD) aims to classify stances on unseen topic data with the ability of a model to generalize in the range of topics in the real world. The key point of ZSSD is to prevent the model from overfitting on seen topic data and show robust stance recognition performance on unseen topic samples. In this paper, we propose a new ZSSD framework to generalize stance detection performance by alleviating seen data information from the encoder and focusing on improving stance classification ability in zero-shot conditions. The proposed framework involves two learning stages contributing to ZSSD: topic-agnostic text encoder learning and zero-shot meta-learning. Our framework achieves notable improvements on the three benchmark zero-shot stance detection datasets and zero-shot aspect target sentiment classification dataset showing the effectiveness of our method in the zero-shot settings.'},\n",
       " '10.1016/j.engappai.2022.105801': {'title': 'Review of stance detection for rumor verification in social media',\n",
       "  'abstract': 'Social media is a perfect breeding ground for false rumors due to the simplicity of sharing information, which may have negative implications in a variety of domains, including economics, healthcare, and politics. Previous research indicates that public reactions to false rumors are a critical indicator for determining the truthfulness of news. In social media, substantial effort has been invested in detecting and debunking rumors based on crowd stance, given that stance is a vital part of automatic news verification. This paper presents a review of recent approaches in the area of rumor verification using stance detection, which attempts to determine a given document’s stance with respect to a given piece of news. The review offers a detailed list of datasets, as well as a summary of relevant experiments and methods employed, as well as analysis of helpful features for addressing this issue. Finally, we highlight the main challenges and future directions in this field by utilizing stance detection.'},\n",
       " '10.1007/s00521-023-08285-7': {'title': 'A systematic review of machine learning techniques for stance detection and its applications',\n",
       "  'abstract': \"Stance detection is an evolving opinion mining research area motivated by the vast increase in the variety and volume of user-generated content. In this regard, considerable research has been recently carried out in the area of stance detection. In this study, we review the different techniques proposed in the literature for stance detection as well as other applications such as rumor veracity detection. Particularly, we conducted a systematic literature review of empirical research on the machine learning (ML) models for stance detection that were published from January 2015 to October 2022. We analyzed 96 primary studies, which spanned eight categories of ML techniques. In this paper, we categorize the analyzed studies according to a taxonomy of six dimensions: approaches, target dependency, applications, modeling, language, and resources. We further classify and analyze the corresponding techniques from each dimension's perspective and highlight their strengths and weaknesses. The analysis reveals that deep learning models that adopt a mechanism of self-attention have been used more frequently than the other approaches. It is worth noting that emerging ML techniques such as few-shot learning and multitask learning have been used extensively for stance detection. A major conclusion of our analysis is that despite that ML models have shown to be promising in this field, the application of these models in the real world is still limited. Our analysis lists challenges and gaps to be addressed in future research. Furthermore, the taxonomy presented can assist researchers in developing and positioning new techniques for stance detection-related applications.\"},\n",
       " '10.1007/978-3-030-88483-3_39': {'title': 'Distant Finetuning with Discourse Relations for Stance Classification',\n",
       "  'abstract': 'Approaches for the stance classification task, an important task for understanding argumentation in debates and detecting fake news, have been relying on models which deal with individual debate topics. In this paper, in order to train a system independent from topics, we propose a new method to extract data with silver labels from raw text to finetune a model for stance classification. The extraction relies on specific discourse relation information, which is shown as a reliable and accurate source for providing stance information. We also propose a 3-stage training framework where the noisy level in the data used for finetuning decreases over different stages going from the most noisy to the least noisy. Detailed experiments show that the automatically annotated dataset as well as the 3-stage training help improve model performance in stance classification. Our approach ranks 1\\\\(^{\\\\text {st}}\\\\) among 26 competing teams in the stance classification track of the NLPCC 2021 shared task Argumentative Text Understanding for AI Debater, which confirms the effectiveness of our approach.'},\n",
       " '10.1016/J.IPM.2021.102597': {'title': 'Stance detection on social media: State of the art and trends',\n",
       "  'abstract': 'Stance detection on social media is an emerging opinion mining paradigm for various social and political applications in which sentiment analysis may be sub-optimal. There has been a growing research interest for developing effective methods for stance detection methods varying among multiple communities including natural language processing, web science, and social computing, where each modeled stance detection in different ways. In this paper, we survey the work on stance detection across those communities and present an exhaustive review of stance detection techniques on social media, including the task definition, different types of targets in stance detection, features set used, and various machine learning approaches applied. Our survey reports state-of-the-art results on the existing benchmark datasets on stance detection, and discusses the most effective approaches. In addition, we explore the emerging trends and different applications of stance detection on social media, including opinion mining and prediction and recently using it for fake news detection. The study concludes by discussing the gaps in the current existing research and highlights the possible future directions for stance detection on social media.'},\n",
       " '10.1016/j.inffus.2024.102386': {'title': 'Zero-shot stance detection based on multi-perspective transferable feature fusion',\n",
       "  'abstract': 'Zero-shot stance detection involves predicting stances that have not previously been encountered by adapting models to learn transferable features by aligning the source and destination target spaces. The acquisition of transferable target-invariant features is crucial for zero-shot stance detection. This work proposes a stance detection technique that can effectively adapt to new unseen targets, and the essence lies in acquiring fine-grained and easy-to-migrate target-invariant features from multiple perspectives as transferable knowledge. Specifically, we first perform data augmentation by masking topic keywords to mitigate the target dependency introduced by topic keywords in the text. Then, to account for the diversity and granularity of the sample features, we leverage instance-wise contrastive learning to extract transferable meta-features from multiple perspectives. The meta-features bridge features migration from known targets to unseen targets by incorporating different viewpoints. Finally, we incorporate an attention mechanism to fuse the multi-perspective transferable features for predicting the stance of previously unseen targets. The experimental results demonstrate the superiority of our model over competitive baselines across four benchmark datasets.'},\n",
       " '10.1007/978-981-99-6207-5_26': {'title': 'Adversarial Network with External Knowledge for Zero-Shot Stance Detection',\n",
       "  'abstract': 'Zero-shot stance detection intends to detect previously unseen targets’ stances in the testing phase. However, achieving this goal can be difficult, as it requires minimizing the domain transfer between different targets, and improving the model’s inference and generalization abilities. To address this challenge, we propose an adversarial network with external knowledge (ANEK) model. Specifically, we adopt adversarial learning based on pre-trained models to learn transferable knowledge from the source targets, thereby enabling the model to generalize well to unseen targets. Additionally, we incorporate sentiment information and common sense knowledge into the contextual representation to further enhance the model’s understanding. Experimental results on several datasets reveal that our method achieves excellent performance, demonstrating its validity and feasibility.'},\n",
       " '10.1007/978-3-031-08757-8_48': {'title': 'SEGP: Stance-Emotion Joint Data Augmentation with Gradual Prompt-Tuning for Stance Detection',\n",
       "  'abstract': 'Stance detection is an important task in opinion mining, which aims to determine whether the author of a text is in favor of, against, or neutral towards a specific target. By now, the scarcity of annotations is one of the remaining problems in stance detection. In this paper, we propose a Stance-Emotion joint Data Augmentation with Gradual Prompt-tuning (SEGP) model to address this problem. In order to generate more training samples, we propose an auxiliary sentence based Stance-Emotion joint Data Augmentation (SEDA) method, formulate data augmentation as a conditional masked language modeling task. We leverage different relations between stance and emotion to construct auxiliary sentences. SEDA generates augmented samples by predicting the masked words conditioned on both their context and auxiliary sentences. Furthermore, we propose a Gradual Prompt-tuning method to make better use of the augmented samples, which is a combination of prompt-tuning and curriculum learning. Specifically, the model starts by training on only original samples, then adds augmented samples as training progresses. Experimental results show that SEGP significantly outperforms the state-of-the-art approaches.'},\n",
       " '10.1016/j.is.2015.08.004': {'title': 'Tree edit distance: Robust and memory-efficient',\n",
       "  'abstract': 'Hierarchical data are often modelled as trees. An interesting query identifies pairs of similar trees. The standard approach to tree similarity is the tree edit distance, which has successfully been applied in a wide range of applications. In terms of runtime, the state-of-the-art algorithm for the tree edit distance is RTED, which is guaranteed to be fast independent of the tree shape. Unfortunately, this algorithm requires up to twice the memory of its competitors. The memory is quadratic in the tree size and is a bottleneck for the tree edit distance computation. In this paper we present a new, memory efficient algorithm for the tree edit distance, AP-TED (All Path Tree Edit Distance). Our algorithm runs at least as fast as RTED without trading in memory efficiency. This is achieved by releasing memory early during the first step of the algorithm, which computes a decomposition strategy for the actual distance computation. We show the correctness of our approach and prove an upper bound for the memory usage. The strategy computed by AP-TED is optimal in the class of all-path strategies, which subsumes the class of LRH strategies used in RTED. We further present the AP-TED+ algorithm, which requires less computational effort for very small subtrees and improves the runtime of the distance computation. Our experimental evaluation confirms the low memory requirements and the runtime efficiency of our approach.'},\n",
       " '10.1016/0377-0427(87)90125-7': {'title': 'Silhouettes: A graphical aid to the interpretation and validation of cluster analysis',\n",
       "  'abstract': 'A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects lie well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an ‘appropriate’ number of clusters.'},\n",
       " '10.1007/978-3-540-78246-9_76': {'title': 'Projecting Dialect Distances to Geography: Bootstrap Clustering vs. Noisy Clustering',\n",
       "  'abstract': 'Dialectometry produces aggregate DISTANCE MATRICES in which a distance is specified for each pair of sites. By projecting groups obtained by clustering onto geography one compares results with traditional dialectology, which produced maps partitioned into implicitly non-overlapping DIALECT AREAS. The importance of dialect areas has been challenged by proponents of CONTINUA, but they too need to compare their findings to older literature, expressed in terms of areas. Simple clustering is unstable, meaning that small differences in the input matrix can lead to large differences in results (Jain et al. 1999). This is illustrated with a 500-site data set from Bulgaria, where input matrices which correlate very highly (r = 0.97) still yield very different clusterings. Kleiweg et al. (2004) introduce COMPOSITE CLUSTERING, in which random noise is added to matrices during repeated clustering. The resulting borders are then projected onto the map. The present contribution compares Kleiweg et al.’s procedure to resampled bootstrapping, and also shows how the same procedure used to project borders from composite clustering may be used to project borders from bootstrapping.'},\n",
       " '10.1016/j.eswa.2024.123191': {'title': 'Input-oriented demonstration learning for hybrid evidence fact verification',\n",
       "  'abstract': 'Hybrid evidence fact verification aims to verify claims against retrieved text and table evidence. Existing methods primarily focus on evidence format conversion and unification strategies to reformat the input to align with the corpus of the pre-trained textual or tabular models. However, these models fail to extract task-specific knowledge from the language model (LM) to learn the correlation between input claim-evidence pairs and output verdicts. Therefore, we propose an input-oriented demonstration learning approach (IODL) for hybrid evidence fact verification. IODL activates the LM’s comprehension capability by incorporating a few examples (task demonstrations) into the input context. Our approach comprises a novel retrieval strategy for selecting examples with similar reasoning patterns to the inputs and a demonstration fusion network that mitigates the LM’s input length limitation, allowing it to leverage more examples. Consequently, the quality and quantity of task demonstrations can be simultaneously enhanced, enabling the demonstration learning paradigm to be well-adapted to our supervised fact verification task. Extensive experiments on the large-scale benchmark FEVEROUS dataset demonstrate the superiority of our proposed method over state-of-the-art baselines. IODL consistently outperforms conventional demonstration-based methods in low-resource and complex reasoning challenge scenarios.'},\n",
       " '10.1007/978-3-030-18305-9_38': {'title': 'Enhancing Unsupervised Pretraining with External Knowledge for Natural Language Inference',\n",
       "  'abstract': 'Unsupervised pretraining such as BERT (Bidirectional Encoder Representations from Transformers) [2] represents the most recent advance on learning representation for natural language, which has helped achieve leading performance on many natural language processing problems. Although BERT can leverage large corpora, we assume it cannot learn all needed semantics and knowledge for natural language inference (NLI). In this paper, we leverage human-authorized external knowledge to further improve BERT, and our results show that BERT, the current state-of-the-art pretraining framework, can benefit from external knowledge.'},\n",
       " '10.1016/j.neunet.2023.03.001': {'title': 'Nested relation extraction via self-contrastive learning guided by structure and semantic similarity',\n",
       "  'abstract': 'The conventional Relation Extraction (RE) task involves identifying whether relations exist between two entities in a given sentence and determining their relation types. However, the complexity of practical application scenarios and the flexibility of natural language demand the ability to extract nested relations, i.e., the recognized relation triples may be components of the higher-level relations. Previous studies have highlighted several challenges that affect the nested RE task, including the lack of abundant labeled data, inappropriate neural networks, and underutilization of the nested relation structures. To address these issues, we formalize the nested RE task and propose a hierarchical neural network to iteratively identify the nested relations between entities and relation triples in a layer by layer manner. Moreover, a novel self-contrastive learning optimization strategy is presented to adapt our method to low-data settings by fully exploiting the constraints due to the nested structure and semantic similarity between paired input sentences. Our method outperformed the state-of-the-art baseline methods in extensive experiments, and ablation experiments verified the effectiveness of the proposed self-contrastive learning optimization strategy.'},\n",
       " '10.1016/J.IS.2021.101718': {'title': 'Multi-label legal document classification: A deep learning-based approach with label-attention and domain-specific pre-training',\n",
       "  'abstract': 'Multi-label document classification has a broad range of applicability to various practical problems, such as news article topic tagging, sentiment analysis, medical code classification, etc. A variety of approaches (e.g., tree-based methods, neural networks and deep learning systems that are specifically based on pre-trained language models) have been developed for multi-label document classification problems and have achieved satisfying performance on different datasets. In the legal domain, however, one is often faced with several key challenges when working with multi-label classification tasks. One critical challenge is the lack of high-quality human labeled datasets, which prevents researchers and practitioners from achieving decent performance on respective tasks. Also, existing methods on multi-label classification typically focus on the majority classes, which results in an unsatisfying performance for other important classes that do not have sufficient training samples. In order to tackle the above challenges, in this paper, we first present POSTURE50K, a novel legal extreme multi-label classification dataset, which we will release to the research community. The dataset contains 50,000 legal opinions and their manually labeled legal procedural postures. Labels in this dataset follow a Zipfian distribution, leaving many of the classes with only a few samples. Furthermore, we propose a deep learning architecture that adopts domain-specific pre-training and a label-attention mechanism for multi-label document classification. We evaluate our proposed architecture on POSTURE50K and another legal multi-label dataset EUROLEX57K, and show that our approach achieves better performances than two baseline systems and another four recent state-of-the-art methods on both datasets.'},\n",
       " '10.1007/s00521-020-04748-3': {'title': 'A survey on face data augmentation for the training of deep neural networks',\n",
       "  'abstract': 'The quality and size of training set have a great impact on the results of deep learning-based face-related tasks. However, collecting and labeling adequate samples with high-quality and balanced distributions still remains a laborious and expensive work, and various data augmentation techniques have thus been widely used to enrich the training dataset. In this paper, we review the existing works of face data augmentation from the perspectives of the transformation types and methods, with the state-of-the-art approaches involved. Among all these approaches, we put the emphasis on the deep learning-based works, especially the generative adversarial networks which have been recognized as more powerful and effective tools in recent years. We present their principles, discuss the results and show their applications as well as limitations. Different evaluation metrics for evaluating these approaches are also introduced. We point out the challenges and opportunities in the field of face data augmentation and provide brief yet insightful discussions.'},\n",
       " '10.1007/978-3-319-68345-4_34': {'title': 'Bridging Between Computer and Robot Vision Through Data Augmentation: A Case Study on Object Recognition',\n",
       "  'abstract': 'Despite the impressive progress brought by deep network in visual object recognition, robot vision is still far from being a solved problem. The most successful convolutional architectures are developed starting from ImageNet, a large scale collection of images of object categories downloaded from the Web. This kind of images is very different from the situated and embodied visual experience of robots deployed in unconstrained settings. To reduce the gap between these two visual experiences, this paper proposes a simple yet effective data augmentation layer that zooms on the object of interest and simulates the object detection outcome of a robot vision system. The layer, that can be used with any convolutional deep architecture, brings to an increase in object recognition performance of up to 7%, in experiments performed over three different benchmark databases. An implementation of our robot data augmentation layer has been made publicly available.'},\n",
       " '10.53070/bbd.990959': {'title': 'Creating a Parallel Corpora for Turkish-English Academic Translations',\n",
       "  'abstract': 'Özetçe-Paralel corpora aynı anlama gelen cümlelerin farklı dillerde temsil edilmesiyle oluşturulan veri setleridir.Makine çeviri sistemlerinde kaliteyi belirleyen en önemli öğelerden birisi büyük miktarda ve yüksek kalitede oluşturulmuş paralel corporadır.Türkçe -İngilizce dil çifti için oluşturulan bu tür veriler genellikle yetersizdir.Bu çalışmada Türkçe -İngilizce dilleri arasında akademik çeviriler için kullanılabilecek büyük miktarda paralel corpora oluşturulmuştur.Bu veri seti oluşturulurken lisansüstü tezlerinin özet kısımları kullanılmıştır.Vecalign ve Hunalign gibi cümle hizalama algoritmaları kullanılarak en iyi eşleştirmeler elde edilmiştir.Yapılan çalışmalar sonucunda 1M paralel cümle çifti elde edilmiştir.Ayrıca elde edilen verinin kalitesini ölçebilmek için Bi'},\n",
       " '10.1007/s10462-023-10661-7': {'title': 'A survey on neural topic models: methods, applications, and challenges',\n",
       "  'abstract': 'Topic models have been prevalent for decades to discover latent topics and infer topic proportions of documents in an unsupervised fashion. They have been widely used in various applications like text analysis and context recommendation. Recently, the rise of neural networks has facilitated the emergence of a new research field -- Neural Topic Models (NTMs). Different from conventional topic models, NTMs directly optimize parameters without requiring model-specific derivations. This endows NTMs with better scalability and flexibility, resulting in significant research attention and plentiful new methods and applications. In this paper, we present a comprehensive survey on neural topic models concerning methods, applications, and challenges. Specifically, we systematically organize current NTM methods according to their network structures and introduce the NTMs for various scenarios like short texts and cross-lingual documents. We also discuss a wide range of popular applications built on NTMs. Finally, we highlight the challenges confronted by NTMs to inspire future research.'},\n",
       " '10.1007/s11036-021-01847-w': {'title': 'TA-BiLSTM: An Interpretable Topic-Aware Model for Misleading Information Detection in Mobile Social Networks',\n",
       "  'abstract': 'As essential information acquisition tools in our lives, mobile social networks have brought us great convenience for communication. However, misleading information such as spam emails, clickbait links, and false health information appears everywhere in mobile social networks. Prior studies have adopted various approaches to detecting this information but ignored global semantic features of the corpus and lacked interpretability. In this paper, we propose a novel end-to-end model called Topic-Aware BiLSTM (TA-BiLSTM) to handle the problems above. We firstly design a neural topic model for mining global semantic patterns, which encodes word relatedness into topic embeddings. Simultaneously, a detection model extracts local hidden states from text content with LSTM layers. Then, the model fuses those global and local representations with the Topic-Aware attention mechanism and performs misleading information detection. Experiments on three real datasets prove that the TA-BiLSTM could generate more coherent topics and improve the detecting performance jointly. Furthermore, case study and visualization demonstrate that the proposed TA-BiLSTM could discover latent topics and help in enhancing interpretability.'},\n",
       " '10.1016/J.IPM.2019.102098': {'title': 'ATM: Adversarial-neural Topic Model',\n",
       "  'abstract': 'Topic models are widely used for thematic structure discovery in text. But traditional topic models often require dedicated inference procedures for specific tasks at hand. Also, they are not designed to generate word-level semantic representations. To address the limitations, we propose a neural topic modeling approach based on the Generative Adversarial Nets (GANs), called Adversarial-neural Topic Model (ATM) in this paper. To our best knowledge, this work is the first attempt to use adversarial training for topic modeling. The proposed ATM models topics with dirichlet prior and employs a generator network to capture the semantic patterns among latent topics. Meanwhile, the generator could also produce word-level semantic representations. Besides, to illustrate the feasibility of porting ATM to tasks other than topic modeling, we apply ATM for open domain event extraction. To validate the effectiveness of the proposed ATM, two topic modeling benchmark corpora and an event dataset are employed in the experiments. Our experimental results on benchmark corpora show that ATM generates more coherence topics (considering five topic coherence measures), outperforming a number of competitive baselines. Moreover, the experiments on event dataset also validate that the proposed approach is able to extract meaningful events from news articles.'},\n",
       " '10.1016/b978-0-12-824521-7.00014-4': {'title': 'Machine reading between the lines (RBL) of medical complaints',\n",
       "  'abstract': 'In this chapter, we formulate the problem of Reading Between the Lines (RBL) as forming natural language (NL) expressions that are not included by an author in text but that are believed to be assumed by the author. RBL is necessary to identify hidden meaning of text, something the author intends to conceal, not to confess or explicitly state. In medical complaints, RBL is essential to reveal the information the patient does not want to share with the physician. We rely on discourse analysis to identify a position in text where RBL is expected to yield results, syntactic generalization to formulate a query for web mining, and information extraction from documents to obtain RBL results. The RBL procedure is evaluated on various texts in the health domain with respect to relevance of RBL expressions to what we believe the author intended to say. The input to the RBL evaluation procedure is a text with a sentence or phrase removed. The output of the RBL is subject to similarity assessment with the removed sentence and if such similarity is high, we conclude that RBL succeeds. We also evaluate how RBL improves a search recall by extending a search index with RBL expressions. The conclusion is that the proposed RBL procedure is an efficient way to obtain and represent invisible knowledge in text.'},\n",
       " '10.1007/978-3-030-00825-3_13': {'title': 'Stories for Images-in-Sequence by Using Visual and Narrative Components',\n",
       "  'abstract': 'Recent research in AI is focusing towards generating narrative stories about visual scenes. It has the potential to achieve more human-like understanding than just basic description generation of images-in-sequence. In this work, we propose a solution for generating stories for images-in-sequence that is based on the Sequence to Sequence model. As a novelty, our encoder model is composed of two separate encoders, one that models the behaviour of the image sequence and other that models the sentence-story generated for the previous image in the sequence of images. By using the image sequence encoder we capture the temporal dependencies between the image sequence and the sentence-story and by using the previous sentence-story encoder we achieve a better story flow. Our solution generates long human-like stories that not only describe the visual context of the image sequence but also contains narrative and evaluative language. The obtained results were confirmed by manual human evaluation.'},\n",
       " '10.1016/j.neucom.2024.127549': {'title': 'SSRI-Net: Subthreads Stance-Rumor Interaction Network for rumor verification',\n",
       "  'abstract': \"As online rumors have the potential to greatly affect areas such as social order, stock prices, and presidential elections, there is an emerging necessity for the automation of rumor verification. Although the current methods have achieved satisfactory performance, they still suffer from the following problems. First, the current methods simply concatenate the representations of different subthreads in their models, which may result in omitting some important information. Second, although stance information has been considered for the rumor verification task, it has not been fully utilized. To solve the problems, we propose the Subthreads Stance-Rumor Interaction Network (SSRI-Net) model for rumor verification. The proposed SSRI-Net model first introduces the Subthreads Interaction Attention mechanism between different subthreads to capture the interaction information between subthreads for a better understanding on user posts. Moreover, we also design the Stance-Rumor Interaction Network to fully integrate users' stance information with rumor verification. We have conducted experiments on two public datasets, namely SemEval-2017 and PHEME datasets, for performance evaluation. Our SSRI-Net model outperforms the previous best models by 5.8% and 7.1% in Macro-F1 and Accuracy respectively on the SemEval-2017 dataset. In addition, our SSRI-Net model also outperforms the previous best models by 4.7% and 5.4% in Macro-F1 and Accuracy respectively on the PHEME dataset. The experimental results have shown that our proposed SSRI-Net model has outperformed the baseline models and achieved the state-of-the-art performance for rumor verification.\"},\n",
       " '10.1016/j.hcc.2023.100190': {'title': 'Graph reasoning over explicit semantic relation',\n",
       "  'abstract': 'Multi-hop reasoning over language or graphs represents a significant challenge in contemporary research, particularly with the reliance on deep neural networks. These networks are integral to text reasoning processes, yet they present challenges in extracting and representing domain or commonsense knowledge, and they often lack robust logical reasoning capabilities. To address these issues, we introduce an innovative text reasoning framework. This framework is grounded in the use of a semantic relation graph and a graph neural network, designed to enhance the model’s ability to encapsulate knowledge and facilitate complex multi-hop reasoning. Our framework operates by extracting knowledge from a broad range of texts. It constructs a semantic relationship graph based on the logical relationships inherent in the reasoning process. Beginning with the core question, the framework methodically deduces key knowledge, using it as a guide to iteratively establish a complete evidence chain, thereby determining the final answer. Leveraging the advanced reasoning capabilities of the graph neural network, this approach is adept at multi-hop logical reasoning. It demonstrates strong performance in tasks like machine reading comprehension and question answering, while also clearly delineating the path of logical reasoning.'},\n",
       " '10.1016/j.eswa.2023.119873': {'title': 'Topic-aware multi-hop machine reading comprehension using weighted graphs',\n",
       "  'abstract': 'The problem of Machine Reading Comprehension (MRC) aims to answer a question based on a natural language context. Multi-hop MRC is a challenging task as it requires a deep comprehension and reasoning of disjoint pieces of information to find the answer. Recently, graph-based methods have become very popular in multi-hop MRC as they well model the problem and ease the reasoning task. However, most existing studies ignore some valuable information of the context. As a result, they focus on partial information instead of covering the full information of the context. To fill this gap, a new approach is presented in this study for the graph-based multi-hop MRC that takes more important information of the context into consideration, including the topic of sentences, the topic of relationships, and the importance and strength of relationships to generate and reason an enrich weighted graph. Several experiments have been conducted to demonstrate the usefulness of the proposed approach. Experiments on the HotpotQA benchmark show that our proposed approach has achieved the new state-of-the-art results.'},\n",
       " '10.1587/transinf.2021edp7154': {'title': 'MKGN: A Multi-Dimensional Knowledge Enhanced Graph Network for Multi-Hop Question and Answering',\n",
       "  'abstract': 'Machine reading comprehension with multi-hop reasoning always suffers from reasoning path breaking due to the lack of world knowledge, which always results in wrong answer detection. In this paper, we analyze what knowledge the previous work lacks, e.g., dependency relations and commonsense. Based on our analysis, we propose a Multi-dimensional Knowledge enhanced Graph Network, named MKGN, which exploits specific knowledge to repair the knowledge gap in reasoning process. Specifically, our approach incorporates not only entities and dependency relations through various graph neural networks, but also commonsense knowledge by a bidirectional attention mechanism, which aims to enhance representations of both question and contexts. Besides, to make the most of multi-dimensional knowledge, we investigate two kinds of fusion architectures, i.e., in the sequential and parallel manner. Experimental results on HotpotQA dataset demonstrate the effectiveness of our approach and verify that using multi-dimensional knowledge, especially dependency relations and commonsense, can indeed improve the reasoning process and contribute to correct answer detection.'},\n",
       " '10.1016/j.knosys.2022.108248': {'title': 'Flexible entity marks and a fine-grained style control for knowledge based natural answer generation',\n",
       "  'abstract': 'Knowledge-based natural answer generation systems are generally difficult to train because numerous entities rarely appear. One way is to replace the entities with their respective types. However, the entity type requires additional recognition with limited accuracy and ignores semantic meanings. Consequently, we propose a question answering system with flexible marks, copying, and retrieving mechanisms (MarkCRQA) to generate natural and accurate answers. By requiring random marks to be shared among all entity types, MarkCRQA attaches the marks to the entities in questions, answers, and knowledge base, which avoids the additional recognition process for entity types and reduces the training difficulty. In addition, we propose to finely control the naturalness and knowledge level of each answer for different real-world scenarios and user needs. Experiments show that MarkCRQA achieves state-of-the-art performance on two open-domain question answering datasets.'},\n",
       " '10.1007/s10844-021-00645-w': {'title': 'Coarse-grained decomposition and fine-grained interaction for multi-hop question answering',\n",
       "  'abstract': 'In recent years, question answering (QA) and reading comprehension (RC) has attracted much attention, and most research on QA has focused on multi-hop QA task which requires connecting multiple pieces of evidence scattered in a long context to answer the question. The key to the multi-hop QA task is semantic feature interaction between documents and questions, which is widely processed by Bi-directional Attention Flow (Bi-DAF), but Bi-DAF generally captures only the surface semantics of words in complex questions, and fails to capture implied semantic feature of intermediate answers, as well as ignoring parts of contexts related to the question and failing to extract the most important parts of multiple documents. In this paper, we propose a new model architecture for multi-hop question answering by applying two completion strategies:(1) Coarse-Grained complex question Decomposition (CGDe) strategy is introduced to decompose complex questions into simple ones without any additional annotations; (2) Fine-Grained Interaction (FGIn) strategy is introduced to explicitly represent each word in documents and extract more comprehensive and accurate sentences related to the inference path. The above two strategies are combined and tested on the SQuAD and HotpotQA datasets, and the experimental results show that our method outperforms state-of-the-art baselines.'},\n",
       " '10.1007/978-3-031-18315-7_5': {'title': 'EventBERT: Incorporating Event-Based Semantics for Natural Language Understanding',\n",
       "  'abstract': 'Natural language understanding tasks require a comprehensive understanding of natural language and further reasoning about it, on the basis of holistic information at different levels to gain comprehensive knowledge. In recent years, pre-trained language models (PrLMs) have shown impressive performance in natural language understanding. However, they rely mainly on extracting context-sensitive statistical patterns without explicitly modeling linguistic information, such as semantic relationships entailed in natural language. In this work, we propose EventBERT, an event-based semantic representation model that takes BERT as the backbone and refines with event-based structural semantics in terms of graph convolution networks. EventBERT benefits simultaneously from rich event-based structures embodied in the graph and contextual semantics learned in pre-trained model BERT. Experimental results on the GLUE benchmark show that the proposed model consistently outperforms the baseline model.'},\n",
       " '10.1007/s11063-024-11609-w': {'title': 'Efficient Visual Metaphor Image Generation Based on Metaphor Understanding',\n",
       "  'abstract': 'Abstract Metaphor has significant implications for revealing cognitive and thinking mechanisms. Visual metaphor image generation not only presents metaphorical connotations intuitively but also reflects AI’s understanding of metaphor through the generated images. This paper investigates the task of generating images based on text with visual metaphors. We explore metaphor image generation and create a dataset containing sentences with visual metaphors. Then, we propose a visual metaphor generation image framework based on metaphor understanding, which is more tailored to the essence of metaphor, better utilizes visual features, and has stronger interpretability. Specifically, the framework extracts the source domain, target domain, and metaphor interpretation from metaphorical sentences, separating the elements of the metaphor to deepen the understanding of its themes and intentions. Additionally, the framework introduces image data from the source domain to capture visual similarities and generate visual enhancement prompts specific to the domain. Finally, these prompts are combined with metaphorical interpretation sentences to form the final prompt text. Experimental results demonstrate that this approach effectively captures the essence of metaphor and generates metaphorical images consistent with the textual meaning.'},\n",
       " '10.1145/3616855.3635754': {'title': 'Motif-based Prompt Learning for Universal Cross-domain Recommendation',\n",
       "  'abstract': 'Cross-Domain Recommendation (CDR) stands as a pivotal technology addressing issues of data sparsity and cold start by transferring general knowledge from the source to the target domain. However, existing CDR models suffer limitations in adaptability across various scenarios due to their inherent complexity. To tackle this challenge, recent advancements introduce universal CDR models that leverage shared embeddings to capture general knowledge across domains and transfer it through \"Multi-task Learning\\'\\' or \"Pre-train, Fine-tune\\'\\' paradigms. However, these models often overlook the broader structural topology that spans domains and fail to align training objectives, potentially leading to negative transfer. To address these issues, we propose a motif-based prompt learning framework, MOP, which introducesmotif-based shared embeddings to encapsulate generalized domain knowledge, catering to both intra-domain and inter-domain CDR tasks. Specifically, we devise three typical motifs: butterfly, triangle, and random walk, and encode them through a Motif-based Encoder to obtain motif-based shared embeddings. Moreover, we train MOP under the \"Pre-training & Prompt Tuning\\'\\' paradigm. By unifying pre-training and recommendation tasks as a common motif-based similarity learning task and integrating adaptable prompt parameters to guide the model in downstream recommendation tasks, MOP excels in transferring domain knowledge effectively. Experimental results on four distinct CDR tasks demonstrate the effectiveness of MOP than the state-of-the-art models.'},\n",
       " '10.1016/j.isprsjprs.2024.02.005': {'title': 'Few-shot remote sensing image scene classification: Recent advances, new baselines, and future trends',\n",
       "  'abstract': 'Remote sensing image scene classification (RSI-SC) is crucial for various high-level applications, including RSI retrieval, image captioning, and object detection. Deep learning-based methods can accurately predict scene categories. However, these approaches often require numerous labeled samples for training, limiting their practicality in real-world RS applications with scarce label resources. In contrast, few-shot remote sensing image scene classification (FS-RSI-SC) has garnered substantial research interest owing to its potential to mitigate the need for extensive training samples. In recent years, there has been a surge in studies on FS-RSI-SC. This paper presents a comprehensive overview of FS-RSI-SC research, categorizing existing methods into two groups. The first group comprises approaches based on data augmentation, transfer learning, metric learning, and meta-learning. Our analysis reveals that most existing FS-RSI-SC methods fall into the meta-learning category, employing attention mechanisms, self-supervised learning (SSL), and feature fusion techniques for enhanced performance. Additionally, transfer learning-based methods consistently outperform other approaches in this category. The second group is centered around large-scale pre-training, which has demonstrated remarkable competitiveness across various tasks, including FS-RSI-SC. This special group of methods has shown considerable potential and is expected to attract more attention with the increasing popularity of large-scale pre-training and the unimodal and multimodal foundation models. Moreover, we proposed a pipeline that harnesses the capabilities of powerful large vision-language models (VLMs) as image encoders, establishing new baselines for FS-RSI-SC on commonly used datasets under standard experimental settings. Our empirical results validated the effectiveness of utilizing large VLMs and highlighted their potential for FS-RSI-SC. Through a joint analysis of state-of-the-art methods and our experiments with VLMs, we identified the prevailing challenges in FS-RSI-SC and outlined promising directions for future research.'},\n",
       " '10.1007/s40747-023-01341-8': {'title': 'Exploring better image captioning with grid features',\n",
       "  'abstract': 'Abstract Nowadays, Artificial Intelligence Generated Content (AIGC) has shown promising prospects in both computer vision and natural language processing communities. Meanwhile, as an essential aspect of AIGC, image to captions has received much more attention. Recent vision-language research is developing from the bulky region visual representations based on object detectors toward more convenient and flexible grid ones. However, this kind of research typically concentrates on image understanding tasks like image classification, with less attention paid to content generation tasks. In this paper, we explore how to capitalize on the expressive features embedded in the grid visual representations for better image captioning. To this end, we present a Transformer-based image captioning model, dubbed FeiM, with two straightforward yet effective designs. We first design the feature queries that consist of a limited set of learnable vectors, which act as the local signals to capture specific visual information from global grid features. Then, taking augmented global grid features and the local feature queries as inputs, we develop a feature interaction module to query relevant visual concepts from grid features, and to enable interaction between the local signal and overall context. Finally, the refined grid visual representations and the linguistic features pass through a Transformer architecture for multi-modal fusion. With the two novel and simple designs, FeiM can fully leverage meaningful visual knowledge to improve image captioning performance. Extensive experiments are performed on the competitive MSCOCO benchmark to confirm the effectiveness of the proposed approach, and the results show that FeiM yields more eminent results than existing advanced captioning models.'},\n",
       " '10.1145/3597503.3623343': {'title': 'Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries',\n",
       "  'abstract': 'Bugs in Deep Learning (DL) libraries may affect almost all downstream DL applications, and it is crucial to ensure the quality of such systems. It is challenging to generate valid input programs for fuzzing DL libraries, since the input programs need to satisfy both the syntax/semantics of the supported languages (e.g., Python) and the tensor/operator constraints for constructing valid computational graphs. Recently, the TitanFuzz work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the language and DL computation constraints to generate valid programs for fuzzing DL libraries (and beyond). However, LLMs tend to generate ordinary programs following similar patterns/tokens with typical programs seen in their massive pre-training corpora (e.g., GitHub), while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced.'},\n",
       " '10.1016/j.eswa.2024.123478': {'title': 'GAP: A novel Generative context-Aware Prompt-tuning method for relation extraction',\n",
       "  'abstract': 'Prompt-tuning was proposed to bridge the gap between pretraining and downstream tasks, and it has achieved promising results in Relation Extraction (RE) tasks in recent years. Although the existing prompt-based RE methods have outperformed the methods based on the fine-tuning paradigm, these methods require domain experts to design prompt templates, making them hard to generalize. In this paper, we proposed a Generative context-Aware Prompt-tuning method (GAP) to address these limitations. Our method consists of three crucial modules: (1) a pretrained prompt generator module that extracts or generates the relation triggers from the context and embeds them into the prompt tokens, (2) an in-domain adaptive pretraining module that further trains the Pretrained Language Models (PLMs) to promote the adaptability of the model, and (3) a joint contrastive loss that prevents PLMs from generating results unrelated to the relation labels while optimizing our model more effectively. We observed that the context-enhanced prompt tokens generated by GAP can better guide PLMs to make accurate relationship predictions. And the in-domain pretraining can effectively inject domain knowledge to enhance the robustness of the model. We conduct experiments on four public RE datasets under the supervised and few-shot settings. The experimental results have demonstrated the superiority of GAP over existing benchmark methods and GAP shows remarkable improvements in few-shot settings, with average F1 score enhancements of 3.5%, 2.7%, and 3.4% on the TACRED, TACREV, and Re-TACRED datasets, respectively. Furthermore, GAP still achieved state-of-the-art (SOTA) performance in supervised settings.'},\n",
       " '10.1016/j.patcog.2024.110250': {'title': 'Exploring low-resource medical image classification with weakly supervised prompt learning',\n",
       "  'abstract': 'Most advances in medical image recognition supporting clinical auxiliary diagnosis meet challenges due to the low-resource situation in the medical field, where annotations are highly expensive and professional. This low-resource problem can be alleviated by leveraging the transferable representations of large-scale pre-trained vision-language models like CLIP. After being pre-trained using large-scale unlabeled medical images and texts (such as medical reports), the vision-language models can learn transferable representations and support flexible downstream clinical tasks such as medical image classification via relevant medical text prompts. However, existing pre-trained vision-language models require domain experts (clinicians) to carefully design the medical text prompts based on different datasets when applied to specific medical image tasks, which is extremely time-consuming and greatly increases the burden on clinicians. To address this problem, we propose a weakly supervised prompt learning method MedPrompt for automatically generating medical prompts, which includes an unsupervised pre-trained vision-language model and a weakly supervised prompt learning model. The unsupervised pre-trained vision-language model adopts large-scale medical images and texts for pre-training, utilizing the natural correlation between medical images and corresponding medical texts without manual annotations. The weakly supervised prompt learning model only utilizes the classes of images in the dataset to guide the learning of the specific class vector in the prompt, while the learning of other context vectors in the prompt does not require any manual annotations for guidance. To the best of our knowledge, this is the first model to automatically generate medical prompts. With the assistance of these prompts, the pre-trained vision-language model can be freed from the strong expert dependency of manual annotation and manual prompt design, thus achieving end-to-end, low-cost medical image classification. Experimental results show that the model using our automatically generated prompts outperforms all its hand-crafted prompts counterparts in full-shot learning on all four datasets, and achieves superior accuracy on zero-shot image classification and few-shot learning in three of the four medical benchmark datasets and comparable accuracy in the remaining one. In addition, the proposed prompt generator is lightweight and therefore has the potential to be embedded into any network architecture.'},\n",
       " '10.1016/j.knosys.2023.111347': {'title': 'STID-Prompt: Prompt learning for sentiment-topic-importance detection in financial news',\n",
       "  'abstract': 'With the development of the Internet and the financial industry, the analysis and judgement of financial news has become increasingly important. Common tasks in this area include sentiment analysis, topic classification, and importance judgement. Existing approaches use fine-tuning paradigms to address these tasks. However, the lack of labeled data in the field of financial news poses a small sample learning problem. The new paradigm represented by prompt learning provides a new way and means to improve the performance of small-sample classification. In addition, existing methods do not focus on research on sentiment, topic, and importance simultaneously, which is also an important factor in evaluating financial news. In practical applications, joint judgment of sentiment, topic, and importance is more effective. Finally, these methods require different tuning for each specific task. They do not consider relationships between individual tasks and cannot utilize information across tasks. This limits their application in complex situations. In this work, we propose a prompt-based financial news classification model (STID-Prompt) to address these issues. For the first two problems, we solve the sentiment analysis task, the topic classification task, the importance judgment task, and the 〈sentiment, topic, importance〉 classification task by designing complex prompt templates. For the third problem, we propose a unique prompt-based joint multi-task learning approach. It learns knowledge from multiple tasks and integrates it into the target task, and the multi-task learning approach further improves the performance of the model. Experimental results show the effectiveness of our approach even with less training data.'},\n",
       " '10.1016/j.patcog.2023.110096': {'title': 'F-SCP: An automatic prompt generation method for specific classes based on visual language pre-training models',\n",
       "  'abstract': 'The zero-shot classification performance of large-scale vision-language pre-training models (e.g., CLIP, BLIP and ALIGN) can be enhanced by incorporating a prompt (e.g., “a photo of a [CLASS]”) before the class words. Modifying the prompt slightly can have significant effect on the classification outcomes of these models. Thus, it is crucial to include an appropriate prompt tailored to the classes. However, manual prompt design is labor-intensive and necessitates domain-specific expertise. The CoOp (Context Optimization) converts hand-crafted prompt templates into learnable word vectors to automatically generate prompts, resulting in substantial improvements for CLIP. However, CoOp exhibited significant variation in classification performance across different classes. Although CoOp-CSC (Class-Specific Context) has a separate prompt for each class, only shows some advantages on fine-grained datasets. In this paper, we propose a novel automatic prompt generation method called F-SCP (Filter-based Specific Class Prompt), which distinguishes itself from the CoOp-UC (Unified Context) model and the CoOp-CSC model. Our approach focuses on prompt generation for low-accuracy classes and similar classes. We add the Filter and SCP modules to the prompt generation architecture. The Filter module selects the poorly classified classes, and then reproduce the prompts through the SCP (Specific Class Prompt) module to replace the prompts of specific classes. Experimental results on six multi-domain datasets shows the superiority of our approach over the state-of-the-art methods. Particularly, the improvement in accuracy for the specific classes mentioned above is significant. For instance, compared with CoOp-UC on the OxfordPets dataset, the low-accuracy classes, such as, Class21 and Class26, are improved by 18% and 12%, respectively.'},\n",
       " '10.1007/s11467-023-1325-z': {'title': 'Advances of machine learning in materials science: Ideas and techniques',\n",
       "  'abstract': 'In this big data era, the use of large dataset in conjunction with machine learning (ML) has been increasingly popular in both industry and academia. In recent times, the field of materials science is also undergoing a big data revolution, with large database and repositories appearing everywhere. Traditionally, materials science is a trial-and-error field, in both the computational and experimental departments. With the advent of machine learning-based techniques, there has been a paradigm shift: materials can now be screened quickly using ML models and even generated based on materials with similar properties; ML has also quietly infiltrated many sub-disciplinary under materials science. However, ML remains relatively new to the field and is expanding its wing quickly. There are a plethora of readily-available big data architectures and abundance of ML models and software; The call to integrate all these elements in a comprehensive research procedure is becoming an important direction of material science research. In this review, we attempt to provide an introduction and reference of ML to materials scientists, covering as much as possible the commonly used methods and applications, and discussing the future possibilities.'},\n",
       " '10.1016/j.eswa.2023.121029': {'title': 'Efficient framework for low-resource abstractive summarization by meta-transfer learning and pointer-generator networks',\n",
       "  'abstract': 'Recently, large language models have shown great success on various abstractive summarization datasets. These datasets consist of numerous data that are enough to train a large number of parameters. However, for a new domain, there is a lack of labeled data to train those parameters and the model is easily overfitted to a small amount of data. In addition, because annotating document-summary pairs is too expensive and transfer learning using high-resource datasets causes a domain shifting problem, a low-resource abstractive summarization task is becoming necessary. Herein, we propose an efficient framework for low-resource abstractive summarization using a pointer-generator network and a meta-learning technique to address the above problems. Meta-learning using existing high-resource datasets enables our model to rapidly adapt to a new domain using limited data to solve the domain shifting problem. In addition, we explore the copy mechanism using a pointer-generator network that can copy words from a source document when generating a summary. The experimental results on 11 different datasets show that the proposed model outperforms the previous state-of-the-art models in low-resource abstractive summarization on most of the datasets.'},\n",
       " '10.1016/j.jbvi.2023.e00388': {'title': 'The artificially intelligent entrepreneur: ChatGPT, prompt engineering, and entrepreneurial rhetoric creation',\n",
       "  'abstract': \"To better understand the role of artificial intelligence in the development of entrepreneurial rhetoric, we examine how generative language models such as ChatGPT serve as viable tools for content creation. Using an established framework for examining CEO celebrity (Creator, Transformer, Rebel, and Savior), we illustrate how such models can effectively produce and refine elevator pitches, social media pitches, and crowdfunding pitches commonly used in the study of entrepreneurial rhetoric. We demonstrate ChatGPT's ability to mimic each celebrity CEO archetype by prompting language in the style of exemplars, including Elon Musk, Indra Nooyi, Tony Hsieh, and Lisa Su. Implications of prompt engineering—the fine-tuning of inputs fed into language models to produce precise output—for entrepreneurship research and practice are discussed. We conclude by advancing the idea that the emergent and enduring value of generative models is, at its core, dependent on effective prompt engineering.\"},\n",
       " '10.1049/cim2.12078': {'title': 'Industrial‐generative pre‐trained transformer for intelligent manufacturing systems',\n",
       "  'abstract': 'Abstract Manufacturing enterprises are facing how to utilise industrial knowledge and continuously accumulating massive unlabelled data to achieve human‐cyber‐physical collaborative and autonomous intelligence. Recently, artificial intelligence‐generative content has achieved great performance in several domains and scenarios. A new concept of industrial generative pre‐trained Transformer (Industrial‐GPT) for intelligent manufacturing systems is introduced to solve various scenario tasks. It refers to pre‐training with industrial datasets, fine‐tuning with industrial scenarios, and reinforcement learning with domain knowledge. To enable Industrial‐GPT to better empower the manufacturing industry, Model as a Service is introduced to cloud computing as a new service mode, which provides a more efficient and flexible service approach by directly invoking the general model of the upper layer and customising it for specific businesses. Then, the operation mechanism of the Industrial‐GPT driven intelligent manufacturing system is described. Finally, the challenges and prospects of applying the Industrial‐GPT in the manufacturing industry are discussed.'},\n",
       " '10.1016/j.knosys.2023.110605': {'title': 'DictPrompt: Comprehensive dictionary-integrated prompt tuning for pre-trained language model',\n",
       "  'abstract': \"The textual semantics contained in the PLM (Pre-trained Language Model) is constrained by the text distribution in the original training corpus. Due to the lack of sufficient contextual training corpus, the low-frequency word representations in the PLM often have difficulty capturing their actual semantics. Previous research has shown that using semantic information from dictionaries can alleviate this problem. Unfortunately, these works neglected the infinite potential of example sentences from different target words with various meanings. To re-explore methods for enhancing PLM using the dictionary, we propose a novel Comprehensive Dictionary-based tuning approach integrating the latest Prompt learning (DictPrompt). We first collect a dataset based on the Oxford Advanced Learner's English Dictionary. Then, we designed a set of comprehensive prompt templates with the corpus combining the word, the definition, and its example sentence. Finally, we insert a word game training task between pre-training and fine-tuning using these templates, allowing the model to inject more semantic information into PLM. We test our Dictprompt tuning method on three commonly used PLMs. The testing results on five fine-grained semantic tasks show that our dictionary-based secondary tuning can bring additional gains to the model's performance. The best accuracy improves 3.09% on average with our tuning on the WiC task and 7.93% on the WSC task. We also plot the sentence embedding scatters of polysemy words. Our method can smooth the decision boundary and help the model output more distinguishable embedding. The code is available at https://github.com/xbdxwyh/Dictprompt.\"},\n",
       " '10.1016/j.jbi.2024.104606': {'title': 'SPeC: A Soft Prompt-Based Calibration on Performance Variability of Large Language Model in Clinical Notes Summarization',\n",
       "  'abstract': 'Electronic health records (EHRs) store an extensive array of patient information, encompassing medical histories, diagnoses, treatments, and test outcomes. These records are crucial for enabling healthcare providers to make well-informed decisions regarding patient care. Summarizing clinical notes further assists healthcare professionals in pinpointing potential health risks and making better-informed decisions. This process contributes to reducing errors and enhancing patient outcomes by ensuring providers have access to the most pertinent and current patient data. Recent research has shown that incorporating instruction prompts with large language models (LLMs) substantially boosts the efficacy of summarization tasks. However, we show that this approach also leads to increased performance variance, resulting in significantly distinct summaries even when instruction prompts share similar meanings. To tackle this challenge, we introduce a model-agnostic Soft Prompt-BasedCalibration (SPeC) pipeline that employs soft prompts to lower variance while preserving the advantages of prompt-based summarization. Experimental findings on multiple clinical note tasks and LLMs indicate that our method not only bolsters performance but also effectively regulates variance across different LLMs, providing a more consistent and reliable approach to summarizing critical medical information.'},\n",
       " '10.1007/s11633-022-1409-1': {'title': 'Compositional Prompting Video-language Models to Understand Procedure in Instructional Videos',\n",
       "  'abstract': 'Instructional videos are very useful for completing complex daily tasks, which naturally contain abundant clip-narration pairs. Existing works for procedure understanding are keen on pretraining various video-language models with these pairs and then fine-tuning downstream classifiers and localizers in predetermined category space. These video-language models are proficient at representing short-term actions, basic objects, and their combinations, but they are still far from understanding long-term procedures. In addition, the predetermined procedure category faces the problem of combination disaster and is inherently inapt to unseen procedures. Therefore, we propose a novel compositional prompt learning (CPL) framework to understand long-term procedures by prompting short-term video-language models and reformulating several classical procedure understanding tasks into general video-text matching problems. Specifically, the proposed CPL consists of one visual prompt and three compositional textual prompts (including the action prompt, object prompt, and procedure prompt), which could compositionally distill knowledge from short-term video-language models to facilitate long-term procedure understanding. Besides, the task reformulation enables our CPL to perform well in all zero-shot, few-shot, and fully-supervised settings. Extensive experiments on two widely-used datasets for procedure understanding demonstrate the effectiveness of the proposed approach.'},\n",
       " '10.1016/j.knosys.2022.110064': {'title': 'KEPT: Knowledge Enhanced Prompt Tuning for event causality identification',\n",
       "  'abstract': 'Event causality identification (ECI) aims to identify causal relations of event mention pairs in text. Despite achieving certain accomplishments, existing methods are still not effective due to the following two issues: (1) the lack of causal reasoning ability, imposing restrictions on recognizing implicit causal relations; (2) the significant gap between fine-tuning and pre-training, which hinders the utilization of pre-trained language models (PLMs). In this paper, we propose a novel Knowledge Enhanced Prompt Tuning (KEPT) framework for ECI to address the issues mentioned above. Specifically, this method leverages prompt tuning to incorporate two kinds of knowledge obtained from external knowledge bases (KBs), including background information and relational information, for causal reasoning. To introduce external knowledge into our model, we first convert it to textual descriptions, then design an interactive attention mechanism and a selective attention mechanism to fuse background information and relational information, respectively. In addition, to further capture implicit relations between events, we adopt the objective from knowledge representation learning to jointly optimize the representations of causal relations and events. Experiment results on two widely-used benchmarks demonstrate that the proposed method outperforms the state-of-the-art models.'},\n",
       " '10.1007/s10489-022-03896-4': {'title': 'Label prompt for multi-label text classification',\n",
       "  'abstract': 'Multi-label text classification has been widely concerned by scholars due to its contribution to practical applications. One of the key challenges in multi-label text classification is how to extract and leverage the correlation among labels. However, it is quite challenging to directly model the correlations among labels in a complex and unknown label space. In this paper, we propose a Label Prompt Multi-label Text Classification model (LP-MTC), which is inspired by the idea of prompt learning of pre-trained language model. Specifically, we design a set of templates for multi-label text classification, integrate labels into the input of the pre-trained language model, and jointly optimize by Masked Language Models (MLM). In this way, the correlations among labels as well as semantic information between labels and text with the help of self-attention can be captured, and thus the model performance is effectively improved. Extensive empirical experiments on multiple datasets demonstrate the effectiveness of our method. Compared with BERT, LP-MTC improved 3.4% micro-F1 on average over the four public datasets.'},\n",
       " '10.1007/s11023-022-09602-0': {'title': 'Playing Games with Ais: The Limits of GPT-3 and Similar Large Language Models',\n",
       "  'abstract': 'Abstract This article contributes to the debate around the abilities of large language models such as GPT-3, dealing with: firstly, evaluating how well GPT does in the Turing Test, secondly the limits of such models, especially their tendency to generate falsehoods, and thirdly the social consequences of the problems these models have with truth-telling. We start by formalising the recently proposed notion of reversible questions, which Floridi &amp; Chiriatti (2020) propose allow one to ‘identify the nature of the source of their answers’, as a probabilistic measure based on Item Response Theory from psychometrics. Following a critical assessment of the methodology which led previous scholars to dismiss GPT’s abilities, we argue against claims that GPT-3 completely lacks semantic ability. Using ideas of compression, priming, distributional semantics and semantic webs we offer our own theory of the limits of large language models like GPT-3, and argue that GPT can competently engage in various semantic tasks. The real reason GPT’s answers seem senseless being that truth-telling is not amongst them. We claim that these kinds of models cannot be forced into producing only true continuation, but rather to maximise their objective function they strategize to be plausible instead of truthful. This, we moreover claim, can hijack our intuitive capacity to evaluate the accuracy of its outputs. Finally, we show how this analysis predicts that a widespread adoption of language generators as tools for writing could result in permanent pollution of our informational ecosystem with massive amounts of very plausible but often untrue texts.'},\n",
       " '10.1007/s11263-022-01653-1': {'title': 'Learning to Prompt for Vision-Language Models',\n",
       "  'abstract': \"Large pre-trained vision-language models like CLIP have shown great potential in learning representations that are transferable across a wide range of downstream tasks. Different from the traditional representation learning that is based mostly on discretized labels, vision-language pre-training aligns images and texts in a common feature space, which allows zero-shot transfer to a downstream task via prompting, i.e., classification weights are synthesized from natural language describing classes of interest. In this work, we show that a major challenge for deploying such models in practice is prompt engineering, which requires domain expertise and is extremely time-consuming -- one needs to spend a significant amount of time on words tuning since a slight change in wording could have a huge impact on performance. Inspired by recent advances in prompt learning research in natural language processing (NLP), we propose Context Optimization (CoOp), a simple approach specifically for adapting CLIP-like vision-language models for downstream image recognition. Concretely, CoOp models a prompt's context words with learnable vectors while the entire pre-trained parameters are kept fixed. To handle different image recognition tasks, we provide two implementations of CoOp: unified context and class-specific context. Through extensive experiments on 11 datasets, we demonstrate that CoOp requires as few as one or two shots to beat hand-crafted prompts with a decent margin and is able to gain significant improvements over prompt engineering with more shots, e.g., with 16 shots the average gain is around 15% (with the highest reaching over 45%). Despite being a learning-based approach, CoOp achieves superb domain generalization performance compared with the zero-shot model using hand-crafted prompts.\"},\n",
       " '10.1007/s11263-023-01882-y': {'title': 'MineGAN++: Mining Generative Models for Efficient Knowledge Transfer to Limited Data Domains',\n",
       "  'abstract': 'Given the often enormous effort required to train GANs, both computationally as well as in dataset collection, the re-use of pretrained GANs largely increases the potential impact of generative models. Therefore, we propose a novel knowledge transfer method for generative models based on mining the knowledge that is most beneficial to a specific target domain, either from a single or multiple pretrained GANs. This is done using a miner network that identifies which part of the generative distribution of each pretrained GAN outputs samples closest to the target domain. Mining effectively steers GAN sampling towards suitable regions of the latent space, which facilitates the posterior finetuning and avoids pathologies of other methods, such as mode collapse and lack of flexibility. Furthermore, to prevent overfitting on small target domains, we introduce sparse subnetwork selection, that restricts the set of trainable neurons to those that are relevant for the target dataset. We perform comprehensive experiments on several challenging datasets using various GAN architectures (BigGAN, Progressive GAN, and StyleGAN) and show that the proposed method, called MineGAN, effectively transfers knowledge to domains with few target images, outperforming existing methods. In addition, MineGAN can successfully transfer knowledge from multiple pretrained GANs. MineGAN .'},\n",
       " '10.26599/tst.2022.9010044': {'title': 'Prompting and Tuning: A Two-Stage Unsupervised Domain Adaptive Person Re-identification Method on Vision Transformer Backbone',\n",
       "  'abstract': 'This paper explores the Vision Transformer (ViT) backbone for Unsupervised Domain Adaptive (UDA) person Re-Identification (Re-ID). While some recent studies have validated ViT for supervised Re-ID, no study has yet to use ViT for UDA Re-ID. We observe that the ViT structure provides a unique advantage for UDA Re-ID, i.e., it has a prompt (the learnable class token) at its bottom layer, that can be used to efficiently condition the deep model for the underlying domain. To utilize this advantage, we propose a novel two-stage UDA pipeline named Prompting And Tuning (PAT) which consists of a prompt learning stage and a subsequent fine-tuning stage. In the first stage, PAT roughly adapts the model from source to target domain by learning the prompts for two domains, while in the second stage, PAT fine-tunes the entire backbone for further adaption to increase the accuracy. Although these two stages both adopt the pseudo labels for training, we show that they have different data preferences. With these two preferences, prompt learning and fine-tuning integrated well with each other and jointly facilitated a competitive PAT method for UDA Re-ID.'},\n",
       " '10.1007/s44230-023-00058-8': {'title': 'A Local Explainability Technique for Graph Neural Topic Models',\n",
       "  'abstract': 'Abstract Topic modelling is a Natural Language Processing (NLP) technique that has gained popularity in the recent past. It identifies word co-occurrence patterns inside a document corpus to reveal hidden topics. Graph Neural Topic Model (GNTM) is a topic modelling technique that uses Graph Neural Networks (GNNs) to learn document representations effectively. It provides high-precision documents-topics and topics-words probability distributions. Such models find immense application in many sectors, including healthcare, financial services, and safety-critical systems like autonomous cars. This model is not explainable. As a matter of fact, the user cannot comprehend the underlying decision-making process. The paper introduces a technique to explain the documents-topics probability distributions output of GNTM. The explanation is achieved by building a local explainable model such as a probabilistic Naïve Bayes classifier. The experimental results using various benchmark NLP datasets show a fidelity of 88.39% between the predictions of GNTM and the local explainable model. This similarity implies that the proposed technique can effectively explain the documents-topics probability distribution output of GNTM.'},\n",
       " '10.1016/j.ipm.2023.103298': {'title': 'Unified benchmark for zero-shot Turkish text classification',\n",
       "  'abstract': 'Effective learning schemes such as fine-tuning, zero-shot, and few-shot learning, have been widely used to obtain considerable performance with only a handful of annotated training data. In this paper, we presented a unified benchmark to facilitate the problem of zero-shot text classification in Turkish. For this purpose, we evaluated three methods, namely, Natural Language Inference, Next Sentence Prediction and our proposed model that is based on Masked Language Modeling and pre-trained word embeddings on nine Turkish datasets for three main categories: topic, sentiment, and emotion. We used pre-trained Turkish monolingual and multilingual transformer models which can be listed as BERT, ConvBERT, DistilBERT and mBERT. The results showed that ConvBERT with the NLI method yields the best results with 79% and outperforms previously used multilingual XLM-RoBERTa model by 19.6%. The study contributes to the literature using different and unattempted transformer models for Turkish and showing improvement of zero-shot text classification performance for monolingual models over multilingual models.'},\n",
       " '10.1007/s10579-022-09605-4': {'title': 'Resources for Turkish natural language processing: A critical survey',\n",
       "  'abstract': 'This paper presents a comprehensive survey of corpora and lexical resources available for Turkish. We review a broad range of resources, focusing on the ones that are publicly available. In addition to providing information about the available linguistic resources, we present a set of recommendations, and identify gaps in the data available for conducting research and building applications in Turkish Linguistics and Natural Language Processing.'},\n",
       " '10.1007/978-3-030-41505-1_39': {'title': 'The ASSIN 2 Shared Task: A Quick Overview',\n",
       "  'abstract': 'This paper offers a brief overview on the ASSIN 2, an evaluation shared task collocated with STIL 2019. ASSIN 2 covered two different but related tasks: Recognizing Textual Entailment (RTE), also known as Natural Language Inference (NLI), and Semantic Textual Similarity (STS). The ASSIN 2 collection was made of pairs of sentences annotated with human judgments for NLI and STS. Participating teams could take part in any of the tasks or both: nine teams participated in the STS task and eight in the NLI task.'},\n",
       " '10.1016/J.JESTCH.2018.09.002': {'title': 'Diacritic restoration of Turkish tweets with word2vec',\n",
       "  'abstract': 'Social media platforms such as Twitter have grown at a tremendous pace in recent years and have become an important source of data providing information countless field. This situation was of interest to researchers and many studies on machine learning and natural language processing was conducted on social media data. However, the language is used in social media contains a very high amount of noisy data than the formal writing language. In this article, we present a study on diacritic restoration which is one of the important difficulties of social media text normalization in order to reduce the noise problem. Diacritic is a set of marks used to change the sound values of letters and is used on many languages besides Turkish. We suggest a 3-step model for this study to overcome the top of the diacritic restoration problem. In the first step, a candidate word generator produces possible word forms, in the second step the language validator chooses the correct word forms and at the final Word2vec is used to create vector representations of the words and make the most appropriate word choice by using cosine similarities. The proposed method was tested on both the 2 ad-hoc created datasets and the real dataset. Studies on small ad-hoc created dataset and real dataset provided a relative error reduction of 37.8% with an average performance of 94.5%. In addition, tests on more than 6 M words on large ad-hoc created dataset yielded a serious performance with an error rate of 3.9%. Furthermore, the proposed method was tested on the binary classification problem consisting of highway traffic data in order to evaluate the effects on classification performance, and a 3.1% increase in classification performance was achieved.'},\n",
       " '10.1007/978-3-319-99722-3_31': {'title': 'SICK-BR: A Portuguese Corpus for Inference',\n",
       "  'abstract': 'We describe SICK-BR, a Brazilian Portuguese corpus annotated with inference relations and semantic relatedness between pairs of sentences. SICK-BR is a translation and adaptation of the original SICK, a corpus of English sentences used in several semantic evaluations. SICK-BR consists of around 10k sentence pairs annotated for neutral/contradiction/entailment relations and for semantic relatedness, using a 5 point scale. Here we describe the strategies used for the adaptation of SICK, which preserve its original inference and relatedness relation labels in the SICK-BR Portuguese version. We also discuss some issues with the original corpus and how we might deal with them.'},\n",
       " '10.1007/s10579-015-9307-6': {'title': 'SentiTurkNet: a Turkish polarity lexicon for sentiment analysis',\n",
       "  'abstract': 'Sentiment analysis aims to extract the sentiment polarity of given segment of text. Polarity resources that indicate the sentiment polarity of words are commonly used in different approaches. While English is the richest language in regard to having such resources, the majority of other languages, including Turkish, lack polarity resources. In this work we present the first comprehensive Turkish polarity resource, SentiTurkNet, where three polarity scores are assigned to each synset in the Turkish WordNet, indicating its positivity, negativity, and objectivity (neutrality) levels. Our method is general and applicable to other languages. Evaluation results for Turkish show that the polarity scores obtained through this method are more accurate compared to those obtained through direct translation (mapping) from SentiWordNet.'},\n",
       " '10.1007/s10579-010-9128-6': {'title': 'Resources for Turkish morphological processing',\n",
       "  'abstract': 'We present a set of language resources and tools—a morphological parser, a morphological disambiguator, and a text corpus—for exploiting Turkish morphology in natural language processing applications. The morphological parser is a state-of-the-art finite-state transducer-based implementation of Turkish morphology. The disambiguator is based on the averaged perceptron algorithm and has the best accuracy reported for Turkish in the literature. The text corpus has been compiled from the web and contains about 500 million tokens. This is the largest Turkish web corpus published.'},\n",
       " '10.1007/978-3-642-21735-7_6': {'title': 'Transforming Auto-Encoders',\n",
       "  'abstract': 'The artificial neural networks that are used to recognize shapes typically use one or more layers of learned feature detectors that produce scalar outputs. By contrast, the computer vision community uses complicated, hand-engineered features, like SIFT [6], that produce a whole vector of outputs including an explicit representation of the pose of the feature. We show how neural networks can be used to learn features that output a whole vector of instantiation parameters and we argue that this is a much more promising way of dealing with variations in position, orientation, scale and lighting than the methods currently employed in the neural networks community. It is also more promising than the hand-engineered features currently used in computer vision because it provides an efficient way of adapting the features to the domain.'},\n",
       " '10.1007/978-3-031-43980-3_16': {'title': 'Engineering a Textbook Approach to Index Massive String Dictionaries',\n",
       "  'abstract': 'We study the problem of engineering space-time efficient indexes that support membership and lexicographic (rank) queries on very large static dictionaries of strings. Our solution is based on a very simple approach that consists of decoupling string storage and string indexing by means of a blockwise compression of the sorted dictionary strings (to be stored in external memory) and a succinct implementation of a Patricia trie (to be stored in internal memory) built on the first string of each block. Our experimental evaluation on two new datasets, which are at least one order of magnitude larger than the ones used in the literature, shows that (i) the state-of-the-art compressed string dictionaries (such as FST, PDT, CoCo-trie) do not provide significant benefits if used in an indexing setting compared to Patricia tries, and (ii) our two-level approach enables the indexing of 3.5 billion strings taking 273 GB in less than 200 MB of internal memory, which is available on any commodity machine, while still guaranteeing comparable or faster query performance than those offered by array-based solutions used in modern storage systems, such as RocksDB, thus possibly influencing their future designs.'},\n",
       " '10.1016/j.eswa.2023.121641': {'title': 'A systematic review on media bias detection: What is media bias, how it is expressed, and how to detect it',\n",
       "  'abstract': 'Media bias and the intolerance of media outlets and citizens to deal with opposing points of view pose a threat to the proper functioning of democratic processes. In this respect, we present a systematic review of the literature related to media bias detection, in order to characterize and classify the different types of media bias, and to explore the state-of-the-art of automatic media bias detection systems. The main objectives of this paper were twofold. First, we framed information, misinformation and disinformation within a theoretical framework that allows us to differentiate the different existing misinformation problems such as us media bias, fake news, or propaganda. Second, we studied the state of the art of automatic media bias detection systems: analyzing the most recently used techniques and their results, listing the available resources and the most relevant datasets, and establishing a discussion about how to increase the maturity of this area. After doing a comprehensive literature review, we have identified and selected a total of 17 forms of media bias that can be classified depending on the context (e.g., coverage bias, gatekeeping bias, or statement bias), and on the author’s intention (e.g., spin bias, or ideology bias). We also reviewed, following the PRISMA methodology, the main automatic media bias detection systems that have been developed so far, selecting 63 relevant articles, from which we extracted the most used techniques; including non-deep learning methods (e.g., linguistic-based methods, and reported speech-based methods), and deep learning methods (e.g., RNNs-based methods, and transformers-based methods). Additionally, we listed and summarized 18 available datasets for the task of automatic media bias detection. In conclusion, the current methods for automatic media bias detection are still in their infancy and there is still a lot of potential for improvement in terms of accuracy and robustness. We have proposed some future research lines that could potentially contribute to the development of more advanced techniques.'},\n",
       " '10.1016/j.ipm.2022.103146': {'title': 'Multi-view co-attention network for fake news detection by modeling topic-specific user and news source credibility',\n",
       "  'abstract': \"• We are the first to define topic-specific user credibility based on his socio-cognitive bias and use it for fake news detection. • We present a novel variant of the co-Att mechanism to implicitly model the credibility of users and news sources. • We produce great echo-chamber representation by using BiCM and user news sharing behaviors. • A novel heterogeneous graph is proposed to jointly model news media partisan bias and level of bias with weak supervision. • Our model employs knowledge entities in the news in addition to the partisan bias of its source for more effective representation of news political ideology. The wide spread of fake news and its negative impacts on society has attracted a lot of attention to fake news detection. In existing fake news detection methods, particular attention has been paid to the credibility of the users sharing the news on social media, and the news sources based on their level of participation in fake news dissemination. However, these methods have ignored the important role of news topical perspectives (like political viewpoint) in users'/sources' decisions to share/publish the news. These decisions are associated with the viewpoints shared by the echo-chamber that the users belong to, i.e., users' Socio-Cognitive (SC) biases, and the news sources' partisan bias. Therefore, the credibility of users and news sources are varied in different topics according to the mentioned biases; which are completely ignored in current fake news detection studies. In this paper, we propose a Multi-View Co-Attention Network (MVCAN) that jointly models the latent topic-specific credibility of users and news sources for fake news detection. The key idea is to represent news articles, users, and news sources in a way that the topical viewpoints of news articles, SC biases of users which determines the users' viewpoints in sharing news, and the partisan bias of news sources are encoded as vectors. Then a novel variant of the Multi-Head Co-Attention (MHCA) mechanism is proposed to encode the joint interaction from different views, including news-source and news-user to implicitly model the credibility of users and the news sources based on their interaction in real and fake news spreading on the news topic. We conduct extensive experiments on two public datasets. The results show that MVCAN significantly outperforms other state-of-the-art methods and outperforms the best baselines by 3% on average in terms of F1 and Accuracy.\"},\n",
       " '10.1007/s42001-022-00196-2': {'title': 'A scoping review on the use of natural language processing in research on political polarization: trends and research prospects',\n",
       "  'abstract': 'As part of the \"text-as-data\" movement, Natural Language Processing (NLP) provides a computational way to examine political polarization. We conducted a methodological scoping review of studies published since 2010 (n = 154) to clarify how NLP research has conceptualized and measured political polarization, and to characterize the degree of integration of the two different research paradigms that meet in this research area. We identified biases toward US context (59%), Twitter data (43%) and machine learning approach (33%). Research covers different layers of the political public sphere (politicians, experts, media, or the lay public), however, very few studies involved more than one layer. Results indicate that only a few studies made use of domain knowledge and a high proportion of the studies were not interdisciplinary. Those studies that made efforts to interpret the results demonstrated that the characteristics of political texts depend not only on the political position of their authors, but also on other often-overlooked factors. Ignoring these factors may lead to overly optimistic performance measures. Also, spurious results may be obtained when causal relations are inferred from textual data. Our paper provides arguments for the integration of explanatory and predictive modeling paradigms, and for a more interdisciplinary approach to polarization research.The online version contains supplementary material available at 10.1007/s42001-022-00196-2.'},\n",
       " '10.1016/j.future.2021.12.011': {'title': 'Psychographic traits identification based on political ideology: An author analysis study on Spanish politicians’ tweets posted in 2020',\n",
       "  'abstract': 'In general, people are usually more reluctant to follow advice and directions from politicians who do not have their ideology. In extreme cases, people can be heavily biased in favour of a political party at the same time that they are in sharp disagreement with others, which may lead to irrational decision making and can put people’s lives at risk by ignoring certain recommendations from the authorities. Therefore, considering political ideology as a psychographic trait can improve political micro-targeting by helping public authorities and local governments to adopt better communication policies during crises. In this work, we explore the reliability of determining psychographic traits concerning political ideology. Our contribution is twofold. On the one hand, we release the PoliCorpus-2020, a dataset composed by Spanish politicians’ tweets posted in 2020. On the other hand, we conduct two authorship analysis tasks with the aforementioned dataset: an author profiling task to extract demographic and psychographic traits, and an authorship attribution task to determine the author of an anonymous text in the political domain. Both experiments are evaluated with several neural network architectures grounded on explainable linguistic features, statistical features, and state-of-the-art transformers. In addition, we test whether the neural network models can be transferred to detect the political ideology of citizens. Our results indicate that the linguistic features are good indicators for identifying fine-grained political affiliation, they boost the performance of neural network models when combined with embedding-based features, and they preserve relevant information when the models are tested with ordinary citizens. Besides, we found that lexical and morphosyntactic features are more effective on author profiling, whereas stylometric features are more effective in authorship attribution.'},\n",
       " '10.1016/j.amc.2023.128219': {'title': 'Computational approaches to developing the implicit media bias dataset: Assessing political orientations of nonpolitical news articles',\n",
       "  'abstract': 'Research on media bias has been primarily conducted a number of times of news outlets referred on political news articles, but nonpolitical articles can still convey media bias that indicates the political orientation of the news outlet. Using manual human evaluation and computational approaches, we developed and publicly released the Implicit Media Bias Dataset, which contains the political orientations of 24,576 news articles featuring nonpolitical events. News articles published in the information technology and science section of the two most biased Korean news outlets (the most conservative and the most progressive) were collected, and each article was manually evaluated by human annotators in terms of its objectiveness, fairness, unbiasedness, and political orientation. The results revealed significant differences between the articles from the conservative and progressive news outlets in these domains. Next, deep learning models trained with a large corpus of nonpolitical articles were used to identify the political orientations of the first set of articles. They achieved over 98% accuracy in classifying the articles as conservative or progressive. The findings of this study demonstrate the effectiveness of computational methods in identifying and analyzing diverse forms of polarization in society.'},\n",
       " '10.1016/J.IPM.2019.03.005': {'title': 'Proppy: Organizing the news based on their propagandistic content',\n",
       "  'abstract': 'Propaganda is a mechanism to influence public opinion, which is inherently present in extremely biased and fake news. Here, we propose a model to automatically assess the level of propagandistic content in an article based on different representations, from writing style and readability level to the presence of certain keywords. We experiment thoroughly with different variations of such a model on a new publicly available corpus, and we show that character n-grams and other style features outperform existing alternatives to identify propaganda based on word n-grams. Unlike previous work, we make sure that the test data comes from news sources that were unseen on training, thus penalizing learning algorithms that model the news sources used at training time as opposed to solving the actual task. We integrate our supervised model in a public website, which organizes recent articles covering the same event on the basis of their propagandistic contents. This allows users to quickly explore different perspectives of the same story, and it also enables investigative journalists to dig further into how different media use stories and propaganda to pursue their agenda.'},\n",
       " '10.1007/978-3-540-76298-0_52': {'title': 'DBpedia: A Nucleus for a Web of Open Data',\n",
       "  'abstract': 'DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human- and machine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data.'},\n",
       " '10.1007/s44196-022-00144-y': {'title': 'Concept-Based Label Distribution Learning for Text Classification',\n",
       "  'abstract': 'Abstract Text classification is a crucial task in data mining and artificial intelligence. In recent years, deep learning-based text classification methods have made great development. The deep learning methods supervise model training by representing a label as a one-hot vector. However, the one-hot label representation cannot adequately reflect the relation between an instance and the labels, as labels are often not completely independent, and the instance may be associated with multiple labels in practice. Simply representing the labels as one-hot vectors leads to overconfidence in the model, making it difficult to distinguish some label confusions. In this paper, we propose a simulated label distribution method based on concepts (SLDC) to tackle this problem. This method captures the overlap between the labels by computing the similarity between an instance and the labels and generates a new simulated label distribution for assisting model training. In particular, we incorporate conceptual information from the knowledge base into the representation of instances and labels to address the surface mismatching problem when instances and labels are compared for similarity. Moreover, to fully use the simulated label distribution and the original label vector, we set up a multi-loss function to supervise the training process. Expensive experiments demonstrate the effectiveness of SLDC on five complex text classification datasets. Further experiments also verify that SLDC is especially helpful for confused datasets.'},\n",
       " '10.1016/j.ipm.2022.103185': {'title': 'Skill requirements in job advertisements: A comparison of skill-categorization methods based on wage regressions',\n",
       "  'abstract': 'In this paper, we compare different methods to extract skill demand from the text of job descriptions. We propose the fraction of wage variation explained by the extracted skills as a novel performance metric for the comparison of methods. Using this, we compare the performance of the word-counting method with three different dictionaries and that of three unsupervised topic-modeling techniques, the LDA, the PLSA and the BERTopic. We apply these methods to a U.K. job board dataset of 1,158,926 job advertisements from 35 industries collected in 2018. We find that each of the dictionary-based methods explain about 20% of the wage variation across jobs. The topic modeling techniques perform better as the PLSA is able to explain 36.5% of the wage variation, while BERTopic 32.6%. The best performing method is the LDA with 48.3% of the wage variation explained. Its disadvantage, however, is in the difficulty of interpretation of the skills extracted.'},\n",
       " '10.1007/978-3-031-27584-5': {'title': 'A Free Press, If You Can Keep It',\n",
       "  'abstract': '\\u200bThis Brief introduces interdisciplinary mixed-methods research approaches to investigate freedom of the press in Hong Kong.'},\n",
       " '10.1007/978-3-030-23887-2_27': {'title': 'Detecting Topics in Documents by Clustering Word Vectors',\n",
       "  'abstract': 'The automatic detection of topics in a set of documents is one of the most challenging and useful tasks in Natural Language Processing. Word2Vec has proven to be an effective tool for the distributed representation of words (word embeddings) usually applied to find their linguistic context. This paper proposes the use of a Self-Organizing Map (SOM) to cluster the word vectors generated by Word2Vec so as to find topics in the texts. After running SOM, a k-means algorithm is applied to separate the SOM output grid neurons into k clusters, such that the words mapped into each centroid represent the topics of that cluster. Our approach was tested on a benchmark text dataset with 19,997 texts and 20 groups. The results showed that the method is capable of finding the expected groups, sometimes merging some of them that deal with similar topics.'},\n",
       " '10.1007/s10489-023-04994-7': {'title': 'Dual selective knowledge transfer for few-shot classification',\n",
       "  'abstract': 'Abstract Few-shot learning aims at recognizing novel visual categories from very few labelled examples. Different from the existing few-shot classification methods that are mainly based on metric learning or meta-learning, in this work we focus on improving the representation capacity of feature extractors. For this purpose, we propose a new two-stage dual selective knowledge transfer (DSKT) framework, to guide models towards better optimization. Specifically, we first exploit an improved multi-task learning approach to train a feature extractor with robust representation capability as a teacher model. Then, we design an effective dual selective knowledge distillation method, which enables the student model to selectively learn knowledge from the teacher model and current samples, thereby improving the student model’s ability to generalize on unseen classes. Extensive experimental results show that our DSKT achieves competitive performances on four well-known few-shot classification benchmarks.'},\n",
       " '10.1038/s43246-024-00449-9': {'title': 'Accelerating materials language processing with large language models',\n",
       "  'abstract': 'Abstract Materials language processing (MLP) can facilitate materials science research by automating the extraction of structured data from research papers. Despite the existence of deep learning models for MLP tasks, there are ongoing practical issues associated with complex model architectures, extensive fine-tuning, and substantial human-labelled datasets. Here, we introduce the use of large language models, such as generative pretrained transformer (GPT), to replace the complex architectures of prior MLP models with strategic designs of prompt engineering. We find that in-context learning of GPT models with few or zero-shots can provide high performance text classification, named entity recognition and extractive question answering with limited datasets, demonstrated for various classes of materials. These generative models can also help identify incorrect annotated data. Our GPT-based approach can assist material scientists in solving knowledge-intensive MLP tasks, even if they lack relevant expertise, by offering MLP guidelines applicable to any materials science domain. In addition, the outcomes of GPT models are expected to reduce the workload of researchers, such as manual labelling, by producing an initial labelling set and verifying human-annotations.'},\n",
       " '10.1016/j.aiopen.2024.01.005': {'title': 'Few-shot Named Entity Recognition via encoder and class intervention',\n",
       "  'abstract': 'In the real world, the large and complex nature of text increases the difficulty of tagging and results in a limited amount of tagged text. Few-shot Named Entity Recognition(NER) only uses a small amount of annotation data to identify and classify entities. It avoids the above problems. Few-shot learning methods usually use prior knowledge to achieve good results. However, prior knowledge may become a confounding factor affecting the relation between sample features and real labels. This problem leads to bias and difficulty accurately capturing class. To solve this problem, a new model, Few-shot Named Entity Recognition via Encoder and Class Intervention, is proposed based on causality. We show that we can steer the model to manufacture interventions on encoder and class, and reduce the interference of confounding factors. Specifically, while cross-sample attention perturbation is used in the encoder layer, a practical causal relation between feature and classification label is developed in the class layer. This way is an attempt of causal methodology in the Few-shot Named Entity Recognition task, which improves the discrimination ability of the NER classifier. Experimental results demonstrate that our model outperforms baseline models in both 5-way and 10-way on two NER datasets.'},\n",
       " '10.1007/s11280-023-01143-5': {'title': 'Few-shot named entity recognition with hybrid multi-prototype learning',\n",
       "  'abstract': 'Information extraction provides the basic technical support for knowledge graph construction and Web applications. Named entity recognition (NER) is one of the fundamental tasks of information extraction. Recognizing unseen entities from numerous contents with the support of only a few labeled samples, also termed as few-shot learning, is a crucial issue to be studied. Few-shot NER aims at identifying emerging named entities from the context with the support of a few labeled samples. Existing methods mainly use the same strategy to construct a single prototype for each entity or non-entity class, which has limited expressiveness power and even biased representation. In this work, we propose a novel hybrid multi-prototype class representation approach. Specifically, for entity classes, we first insert labels after entities in support sentences to enrich the learned token and label embeddings with more contextual information. Then, for each entity span, the contextual token embeddings are averaged to form its entity-level prototype, while the contextual label embedding is considered as its label-level prototype. The set of prototypes for all entities in a class constitutes the multi-prototype of this entity class. For non-entity class, we directly use the set of token embeddings to represent it, where multi-prototype refers to the multiple token embeddings. By treating the entity and non-entity classes differently, our hybrid strategy can extract more precise class representations from the support examples. Furthermore, we establish a harder and more reasonable experimental setting of few-shot NER by offering a rigorous sampling strategy. Extensive empirical results show that our proposal improves performance over prior models on popular benchmark Few-NERD under both loose and our proposed rigorous sampling constraints, achieving comparable performance to current state-of-the-arts.'},\n",
       " '10.1016/j.csl.2022.101412': {'title': 'Multi-level context features extraction for named entity recognition',\n",
       "  'abstract': 'Bidirectional long short-term memory (Bi-LSTM), as one of the effective networks for sequence labeling tasks, is widely used in named entity recognition (NER). However, the sequential nature of Bi-LSTM and the inability to recognize multiple sentences at the same time make it impossible to obtain overall information. In this paper, to make up for the shortcomings of Bi-LSTM in extracting global information, we propose a hierarchical context model embedded with sentence-level and document-level feature extraction. In sentence-level feature extraction, we use the self-attention mechanism to extract sentence-level representations considering the different contribution of each word to the sentence. For document-level feature extraction, 3D convolutional neural network (CNN), which not only can extract features within sentences, but also pays attention to the sequential relationship between sentences, is used to extract document-level representations. Furthermore, we investigate a layer-by-layer residual (LBL Residual) structure to optimize each Bi-LSTM block of our model, which can solve the degradation problem that appears as the number of model layers increases. Experiments show that our model achieves results competitive with the state-of-the-art records on the CONLL-2003 and Ontonotes5.0 English datasets respectively.'},\n",
       " '10.1007/978-3-030-87839-9_3': {'title': 'Few-Sample Named Entity Recognition for Security Vulnerability Reports by Fine-Tuning Pre-trained Language Models',\n",
       "  'abstract': 'Public security vulnerability reports (e.g., CVE reports) play an important role in the maintenance of computer and network systems. Security companies and administrators rely on information from these reports to prioritize tasks on developing and deploying patches to their customers. Since these reports are unstructured texts, automatic information extraction (IE) can help scale up the processing by converting the unstructured reports to structured forms, e.g., software names and versions [] and vulnerability types []. Existing works on automated IE for security vulnerability reports often rely on a large number of labeled training samples [, , ]. However, creating massive labeled training set is both expensive and time consuming. In this work, for the first time, we propose to investigate this problem where only a small number of labeled training samples are available. In particular, we investigate the performance of fine-tuning several state-of-the-art pre-trained language models on our small training dataset. The results show that with pre-trained language models and carefully tuned hyperparameters, we have reached or slightly outperformed the state-of-the-art system [] on this task. Consistent with previous two-step process of first fine-tuning on main category and then transfer learning to others as in [], if otherwise following our proposed approach, the number of required labeled samples substantially decrease in both stages: 90% reduction in fine-tuning from 5758 to 576, and 88.8% reduction in transfer learning with 64 labeled samples per category. Our experiments thus demonstrate the effectiveness of few-sample learning on NER for security vulnerability report. This result opens up multiple research opportunities for few-sample learning for security vulnerability reports, which is discussed in the paper. Our implementation for few-sample vulnerability entity tagger in security reports could be found at https://github.com/guanqun-yang/FewVulnerability.'},\n",
       " '10.26599/tst.2022.9010043': {'title': 'Decoupled Two-Phase Framework for Class-Incremental Few-Shot Named Entity Recognition',\n",
       "  'abstract': 'Class-Incremental Few-Shot Named Entity Recognition (CIFNER) aims to identify entity categories that have appeared with only a few newly added (novel) class examples. However, existing class-incremental methods typically introduce new parameters to adapt to new classes and treat all information equally, resulting in poor generalization. Meanwhile, few-shot methods necessitate samples for all observed classes, making them difficult to transfer into a class-incremental setting. Thus, a decoupled two-phase framework method for the CIFNER task is proposed to address the above issues. The whole task is converted to two separate tasks named Entity Span Detection (ESD) and Entity Class Discrimination (ECD) that leverage parameter-cloning and label-fusion to learn different levels of knowledge separately, such as class-generic knowledge and class-specific knowledge. Moreover, different variants, such as the Conditional Random Field-based (CRF-based), word-pair-based methods in ESD module, and add-based, Natural Language Inference-based (NLI-based) and prompt-based methods in ECD module, are investigated to demonstrate the generalizability of the decoupled framework. Extensive experiments on the three Named Entity Recognition (NER) datasets reveal that our method achieves the state-of-the-art performance in the CIFNER setting.'},\n",
       " '10.1016/j.jbi.2015.07.020': {'title': 'Annotating longitudinal clinical narratives for de-identification: The 2014 i2b2/UTHealth corpus',\n",
       "  'abstract': 'The 2014 i2b2/UTHealth natural language processing shared task featured a track focused on the de-identification of longitudinal medical records. For this track, we de-identified a set of 1304 longitudinal medical records describing 296 patients. This corpus was de-identified under a broad interpretation of the HIPAA guidelines using double-annotation followed by arbitration, rounds of sanity checking, and proof reading. The average token-based F1 measure for the annotators compared to the gold standard was 0.927. The resulting annotations were used both to de-identify the data and to set the gold standard for the de-identification track of the 2014 i2b2/UTHealth shared task. All annotated private health information were replaced with realistic surrogates automatically and then read over and corrected manually. The resulting corpus is the first of its kind made available for de-identification research. This corpus was first used for the 2014 i2b2/UTHealth shared task, during which the systems achieved a mean F-measure of 0.872 and a maximum F-measure of 0.964 using entity-based micro-averaged evaluations.'},\n",
       " '10.1016/j.neucom.2023.127177': {'title': 'DKPE: Deep KeyPhrase Expansion',\n",
       "  'abstract': 'Keyphrase provides accurate information of document content that is highly compact, concise, full of meanings, and widely used for discourse comprehension, organization, and text retrieval. Though previous studies have made substantial efforts for automated keyphrase extraction and generation, surprisingly, few studies have been made for KeyPhrase Expansion. This task aims to add more keyphrases for documents (e.g. scientific publications) via taking advantage of document content along with a very limited number of known keyphrases, which can widely be used to improve the keyphrases-involved NLP tasks. In this paper, we introduce a novel problem concerning KeyPhrase Expansion and propose a novel keyphrase expansion method with an encoder–decoder framework. We name it Deep KeyPhrase Expansion (DKPE) since it attempts to capture the deep semantic meaning of the document content together with known keyphrases via a deep learning framework. Specifically, the encoder and the decoder in DKPE play different roles to make full use of the known keyphrases. The former considers the keyphrase-guiding factors, which aggregates information of known keyphrases into context. On the contrary, the latter considers the keyphrase-inhibited factor to inhibit semantically repeated keyphrase generation. Extensive experiments on benchmark datasets demonstrate the efficacy of our proposed model.'},\n",
       " '10.1016/j.knosys.2023.110760': {'title': 'Path-based multi-hop reasoning over knowledge graph for answering questions via adversarial reinforcement learning',\n",
       "  'abstract': 'Multi-hop knowledge graph question answering targets at pinpointing the answer entities by inferring across multiple triples in knowledge graphs. To enhance model interpretability, path-based methods are proposed. Specifically, with the advances of deep reinforcement learning (DRL), this paper explores to extend the line of RL-based approaches. However, existing solutions suffer from the issue of spurious paths. A major reason lies in that the agent takes an opportunistic way to explicitly pursue the predictive accuracy of answer entities instead of considering correct reasoning paths. To overcome this challenge, our idea is inspired by adversarial learning and we expect that a discriminator could effectively distinguish whether the reasoning chain is correct or not. To this end, we propose an interpretable reasoning method based on adversarial reinforcement learning for multi-hop KGQA, namely Adversarial Reinforcement Reasoning Network (AR2N). AR2N consists of two crucial components: an answer generator (i.e., policy network of RL) and a path discriminator. By alternately updating two components in an adversarial manner, the generator is able to infer answer entities by following the correct reasoning chain, the discriminator is capable of evaluating the plausibility of reasoning paths. Extensive experiments conducted over three benchmark datasets well demonstrate the effectiveness of our method.1'},\n",
       " '10.1016/j.ipm.2023.103382': {'title': 'From statistical methods to deep learning, automatic keyphrase prediction: A survey',\n",
       "  'abstract': 'Keyphrase prediction aims to generate phrases (keyphrases) that highly summarizes a given document. Recently, researchers have conducted in-depth studies on this task from various perspectives. In this paper, we comprehensively summarize representative studies from the perspectives of dominant models, datasets and evaluation metrics. Our work analyzes up to 167 previous works, achieving greater coverage of this task than previous surveys. Particularly, we focus highly on deep learning-based keyphrase prediction, which attracts increasing attention of this task in recent years. Afterwards, we conduct several groups of experiments to carefully compare representative models. To the best of our knowledge, our work is the first attempt to compare these models using the identical commonly-used datasets and evaluation metric, facilitating in-depth analyses of their disadvantages and advantages. Finally, we discuss the possible research directions of this task in the future.'},\n",
       " '10.1016/j.knosys.2023.110664': {'title': 'Towards unsupervised keyphrase extraction via an autoregressive approach',\n",
       "  'abstract': 'Keyphrase extraction is a technique used to capture the core information of documents and is an upstream task for advanced information retrieval systems, particularly in the academic realm. Current unsupervised methods are primarily built on a score-and-rank framework with a consistent inability to acquire mutual information between extracted keyphrases, especially with graph-based models. Utilizing the autoregressive structure that is typically used in sequence-to-sequence text generation models, we propose a plug-and-play optimizer named C-Decay that can be integrated into any graph-based unsupervised keyphrase extraction model for a stable performance boost, and that mitigates the bias of certain semantically or lexically dominant tokens by optimizing the origin score distribution output by graph-based models directly. The architecture of C-Decay includes the keyphrase pool, the gain vector and the decay factor, where the keyphrase pool is designed to realize an autoregressive structure and the gain vector and the decay factor are the optimization operator. Herein, we examine three graph-based models integrated with C-Decay, and the experiment is conducted on four datasets KDD, Semeval, Nguyen, and Krapivin. Moreover, we prove that C-Decay can improve accuracy and F-Measure by an average of approximately 50% and 20%, respectively.'},\n",
       " '10.1134/S1995080223010134': {'title': 'Applying Transformer-Based Text Summarization for Keyphrase Generation',\n",
       "  'abstract': \"Keyphrases are crucial for searching and systematizing scholarly documents. Most current methods for keyphrase extraction are aimed at the extraction of the most significant words in the text. But in practice, the list of keyphrases often includes words that do not appear in the text explicitly. In this case, the list of keyphrases represents an abstractive summary of the source text. In this paper, we experiment with popular transformer-based models for abstractive text summarization using four benchmark datasets for keyphrase extraction. We compare the results obtained with the results of common unsupervised and supervised methods for keyphrase extraction. Our evaluation shows that summarization models are quite effective in generating keyphrases in the terms of the full-match F1-score and BERTScore. However, they produce a lot of words that are absent in the author's list of keyphrases, which makes summarization models ineffective in terms of ROUGE-1. We also investigate several ordering strategies to concatenate target keyphrases. The results showed that the choice of strategy affects the performance of keyphrase generation.\"},\n",
       " '10.1016/j.knosys.2022.109581': {'title': 'Attend and select: A segment selective transformer for microblog hashtag generation',\n",
       "  'abstract': \"Hashtag generation aims to generate short and informal topical tags from a microblog post, in which tokens or phrases form the hashtags. These tokens or phrases may originate from primary fragmental textual pieces (e.g., segments) in the original text and are separated into different segments. However, conventional sequence-to-sequence generation methods are hard to filter out secondary information from different textual granularity and are not good at selecting crucial tokens. Thus, they are suboptimal in generating more condensed hashtags. In this work, we propose a modified Transformer-based generation model with adding a segments-selection procedure for the original encoding and decoding phases. The segments-selection phase is based on a novel Segments Selection Mechanism (SSM) to model different textual granularity on global text, local segments, and tokens, contributing to generating condensed hashtags. Specifically, it first attends to primary semantic segments and then transforms discontinuous segments from the source text into a sequence of hashtags by selecting crucial tokens. Extensive evaluations on the two datasets reveal our approach's superiority with significant improvements to the extraction and generation baselines. The code and datasets are available at https://github.com/OpenSUM/HashtagGen.\"},\n",
       " '10.1007/978-3-030-45442-5_41': {'title': 'Keyphrase Extraction as Sequence Labeling Using Contextualized Embeddings',\n",
       "  'abstract': 'In this paper, we formulate keyphrase extraction from scholarly articles as a sequence labeling task solved using a BiLSTM-CRF, where the words in the input text are represented using deep contextualized embeddings. We evaluate the proposed architecture using both contextualized and fixed word embedding models on three different benchmark datasets, and compare with existing popular unsupervised and supervised techniques. Our results quantify the benefits of: (a) using contextualized embeddings over fixed word embeddings; (b) using a BiLSTM-CRF architecture with contextualized word embeddings over fine-tuning the contextualized embedding model directly; and (c) using domain-specific contextualized embeddings (SciBERT). Through error analysis, we also provide some insights into why particular models work better than the others. Lastly, we present a case study where we analyze different self-attention layers of the two best models (BERT and SciBERT) to better understand their predictions.'},\n",
       " '10.1007/978-3-319-50127-7_58': {'title': 'Unsupervised Keyphrase Extraction: Introducing New Kinds of Words to Keyphrases',\n",
       "  'abstract': 'Current studies often extract keyphrases by collecting adjacent important adjectives and nouns. However, the statistics on four public corpora shows that about 15% of keyphrases contain other kinds of words. Even so, incorporating such kinds of words to the noun phrase patterns is not a solution to improve the extraction performance. In this work, we propose a solution to improve the extraction performance by involving new kinds of words to keyphrases. We have experimented on four public corpora to demonstrate that our proposal improve the performance of keyphrase extraction and new kinds of words are introduced to keyphrases. In addition, our proposal is also superior to the current unsupervised keyphrase extraction approaches.'},\n",
       " '10.1016/j.jbi.2022.104274': {'title': 'Benchmark datasets driving artificial intelligence development fail to capture the needs of medical professionals',\n",
       "  'abstract': 'Publicly accessible benchmarks that allow for assessing and comparing model performances are important drivers of progress in artificial intelligence (AI). While recent advances in AI capabilities hold the potential to transform medical practice by assisting and augmenting the cognitive processes of healthcare professionals, the coverage of clinically relevant tasks by AI benchmarks is largely unclear. Furthermore, there is a lack of systematized meta-information that allows clinical AI researchers to quickly determine accessibility, scope, content and other characteristics of datasets and benchmark datasets relevant to the clinical domain. To address these issues, we curated and released a comprehensive catalogue of datasets and benchmarks pertaining to the broad domain of clinical and biomedical natural language processing (NLP), based on a systematic review of literature and. A total of 450 NLP datasets were manually systematized and annotated with rich metadata, such as targeted tasks, clinical applicability, data types, performance metrics, accessibility and licensing information, and availability of data splits. We then compared tasks covered by AI benchmark datasets with relevant tasks that medical practitioners reported as highly desirable targets for automation in a previous empirical study. Our analysis indicates that AI benchmarks of direct clinical relevance are scarce and fail to cover most work activities that clinicians want to see addressed. In particular, tasks associated with routine documentation and patient data administration workflows are not represented despite significant associated workloads. Thus, currently available AI benchmarks are improperly aligned with desired targets for AI automation in clinical settings, and novel benchmarks should be created to fill these gaps.'},\n",
       " '10.1007/978-3-030-72240-1_1': {'title': 'Cross-Domain Retrieval in the Legal and Patent Domains: A Reproducibility Study',\n",
       "  'abstract': 'Domain specific search has always been a challenging information retrieval task due to several challenges such as the domain specific language, the unique task setting, as well as the lack of accessible queries and corresponding relevance judgements. In the last years, pretrained language models – such as BERT – revolutionized web and news search. Naturally, the community aims to adapt these advancements to cross-domain transfer of retrieval models for domain specific search. In the context of legal document retrieval, Shao et al. propose the BERT-PLI framework by modeling the Paragraph-Level Interactions with the language model BERT. In this paper we reproduce the original experiments, we clarify pre-processing steps and add missing scripts for framework steps, however we are not able to reproduce the evaluation results. Contrary to the original paper, we demonstrate that the domain specific paragraph-level modelling does not appear to help the performance of the BERT-PLI model compared to paragraph-level modelling with the original BERT. In addition to our legal search reproducibility study, we investigate BERT-PLI for document retrieval in the patent domain. We find that the BERT-PLI model does not yet achieve performance improvements for patent document retrieval compared to the BM25 baseline. Furthermore, we evaluate the BERT-PLI model for cross-domain retrieval between the legal and patent domain on individual components, both on a paragraph and document-level. We find that the transfer of the BERT-PLI model on the paragraph-level leads to comparable results between both domains as well as first promising results for the cross-domain transfer on the document-level. For reproducibility and transparency as well as to benefit the community we make our source code and the trained models publicly available.'},\n",
       " '10.1007/978-3-319-97289-3_20': {'title': 'Research Paper Recommender Systems on Big Scholarly Data',\n",
       "  'abstract': 'Rapidly growing scholarly data has been coined Big Scholarly Data (BSD), which includes hundreds of millions of authors, papers, citations, and other scholarly information. The effective utilization of BSD may expedite various research-related activities, which include research management, collaborator discovery, expert finding and recommender systems. Research paper recommender systems using smaller datasets have been studied with inconclusive results in the past. To facilitate research to tackle the BSD challenge, we built an analytic platform and developed a research paper recommender system. The recommender system may help researchers find research papers closely matching their interests. The system is not only capable of recommending proper papers to individuals based on his/her profile, but also able to recommend papers for a research field using the aggregated profiles of researchers in the research field. The BSD analytic platform is hosted on a computer cluster running data center operating system and initiated its data using Microsoft Academic Graph (MAG) dataset, which includes citation information from more than 126 million academic articles and over 528 million citation relationships between these articles. The research paper recommender system was implemented using Scala programming language and algorithms supplemented by Spark MLib. The performance of the recommender system is evaluated by the recall rate of the Top-N recommendations. The recall rates fall in the range of 0.3 to 0.6. Our recommender system currently bears the same limitation as other systems that are based on user-based collaborative filtering mechanisms. The cold-start problem can be mitigated by supplementing it with the item-based collaborative filtering mechanism.'},\n",
       " '10.1007/978-3-642-36973-5_92': {'title': 'ADRTrace: Detecting Expected and Unexpected Adverse Drug Reactions from User Reviews on Social Media Sites',\n",
       "  'abstract': 'We automatically extract adverse drug reactions (ADRs) from consumer reviews provided on various drug social media sites to identify adverse reactions not reported by the United States Food and Drug Administration (FDA) but touted by consumers. We utilize various lexicons, identify patterns, and generate a synonym set that includes variations of medical terms. We identify “expected” and “unexpected” ADRs. Background (drug) language is utilized to evaluate the strength of the detected unexpected ADRs. Evaluation results for our synonym set and ADR extraction are promising.'},\n",
       " '10.1186/1471-2105-10-46': {'title': 'Is searching full text more effective than searching abstracts?',\n",
       "  'abstract': 'With the growing availability of full-text articles online, scientists and other consumers of the life sciences literature now have the ability to go beyond searching bibliographic records (title, abstract, metadata) to directly access full-text content. Motivated by this emerging trend, I posed the following question: is searching full text more effective than searching abstracts? This question is answered by comparing text retrieval algorithms on MEDLINE abstracts, full-text articles, and spans (paragraphs) within full-text articles using data from the TREC 2007 genomics track evaluation. Two retrieval models are examined: bm25 and the ranking algorithm implemented in the open-source Lucene search engine.Experiments show that treating an entire article as an indexing unit does not consistently yield higher effectiveness compared to abstract-only search. However, retrieval based on spans, or paragraphs-sized segments of full-text articles, consistently outperforms abstract-only search. Results suggest that highest overall effectiveness may be achieved by combining evidence from spans and full articles.Users searching full text are more likely to find relevant articles than searching only abstracts. This finding affirms the value of full text collections for text retrieval and provides a starting point for future work in exploring algorithms that take advantage of rapidly-growing digital archives. Experimental results also highlight the need to develop distributed text retrieval algorithms, since full-text articles are significantly longer than abstracts and may require the computational resources of multiple machines in a cluster. The MapReduce programming model provides a convenient framework for organizing such computations.'},\n",
       " '10.1016/j.engappai.2023.107719': {'title': 'Topological persistence guided knowledge distillation for wearable sensor data',\n",
       "  'abstract': 'Deep learning methods have achieved a lot of success in various applications involving converting wearable sensor data to actionable health insights. A common application areas is activity recognition, where deep-learning methods still suffer from limitations such as sensitivity to signal quality, sensor characteristic variations, and variability between subjects. To mitigate these issues, robust features obtained by topological data analysis (TDA) have been suggested as a potential solution. However, there are two significant obstacles to using topological features in deep learning: (1) large computational load to extract topological features using TDA, and (2) different signal representations obtained from deep learning and TDA which makes fusion difficult. In this paper, to enable integration of the strengths of topological methods in deep-learning for time-series data, we propose to use two teacher networks - one trained on the raw time-series data, and another trained on persistence images generated by TDA methods. These two teachers are jointly used to distill a single student model, which utilizes only the raw time-series data at test-time. This approach addresses both issues. The use of KD with multiple teachers utilizes complementary information, and results in a compact model with strong supervisory features and an integrated richer representation. To assimilate desirable information from different modalities, we design new constraints, including orthogonality imposed on feature correlation maps for improving feature expressiveness and allowing the student to easily learn from the teacher. Also, we apply an annealing strategy in KD for fast saturation and better accommodation from different features, while the knowledge gap between the teachers and student is reduced. Finally, a robust student model is distilled, which can at test-time uses only the time-series data as an input, while implicitly preserving topological features. The experimental results demonstrate the effectiveness of the proposed method on wearable sensor data. The proposed method shows 71.74% in classification accuracy on GENEActiv with WRN16-1 (1D CNNs) student, which outperforms baselines and takes much less processing time (less than 17 sec) than teachers on 6k testing samples.'},\n",
       " '10.1007/s10462-023-10562-9': {'title': 'A survey of uncertainty in deep neural networks',\n",
       "  'abstract': 'Abstract Over the last decade, neural networks have reached almost every field of science and become a crucial part of various real world applications. Due to the increasing spread, confidence in neural network predictions has become more and more important. However, basic neural networks do not deliver certainty estimates or suffer from over- or under-confidence, i.e. are badly calibrated. To overcome this, many researchers have been working on understanding and quantifying uncertainty in a neural network’s prediction. As a result, different types and sources of uncertainty have been identified and various approaches to measure and quantify uncertainty in neural networks have been proposed. This work gives a comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities. It is intended to give anyone interested in uncertainty estimation in neural networks a broad overview and introduction, without presupposing prior knowledge in this field. For that, a comprehensive introduction to the most crucial sources of uncertainty is given and their separation into reducible model uncertainty and irreducible data uncertainty is presented. The modeling of these uncertainties based on deterministic neural networks, Bayesian neural networks (BNNs), ensemble of neural networks, and test-time data augmentation approaches is introduced and different branches of these fields as well as the latest developments are discussed. For a practical application, we discuss different measures of uncertainty, approaches for calibrating neural networks, and give an overview of existing baselines and available implementations. Different examples from the wide spectrum of challenges in the fields of medical image analysis, robotics, and earth observation give an idea of the needs and challenges regarding uncertainties in the practical applications of neural networks. Additionally, the practical limitations of uncertainty quantification methods in neural networks for mission- and safety-critical real world applications are discussed and an outlook on the next steps towards a broader usage of such methods is given.'},\n",
       " '10.1007/978-3-540-74958-5_14': {'title': 'Dual Strategy Active Learning',\n",
       "  'abstract': 'Active Learning methods rely on static strategies for sampling unlabeled point(s). These strategies range from uncertainty sampling and density estimation to multi-factor methods with learn-once-use-always model parameters. This paper proposes a dynamic approach, called DUAL, where the strategy selection parameters are adaptively updated based on estimated future residual error reduction after each actively sampled point. The objective of dual is to outperform static strategies over a large operating range: from very few to very many labeled points. Empirical results over six datasets demonstrate that DUAL outperforms several state-of-the-art methods on most datasets.'},\n",
       " '10.1007/978-981-99-8540-1_25': {'title': 'VCD: Visual Causality Discovery for Cross-Modal Question Reasoning',\n",
       "  'abstract': 'Existing visual question reasoning methods usually fail to explicitly discover the inherent causal mechanism and ignore jointly modeling cross-modal event temporality and causality. In this paper, we propose a visual question reasoning framework named Cross-Modal Question Reasoning (CMQR), to discover temporal causal structure and mitigate visual spurious correlation by causal intervention. To explicitly discover visual causal structure, the Visual Causality Discovery (VCD) architecture is proposed to find question-critical scene temporally and disentangle the visual spurious correlations by attention-based front-door causal intervention module named Local-Global Causal Attention Module (LGCAM). To align the fine-grained interactions between linguistic semantics and spatial-temporal representations, we build an Interactive Visual-Linguistic Transformer (IVLT) that builds the multi-modal co-occurrence interactions between visual and linguistic content. Extensive experiments on four datasets demonstrate the superiority of CMQR for discovering visual causal structures and achieving robust question reasoning. The supplementary file can be referred to https://github.com/YangLiu9208/VCD/blob/main/0793_supp.pdf .'},\n",
       " '10.1007/978-3-030-58589-1_27': {'title': 'TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval',\n",
       "  'abstract': 'We introduce TV show Retrieval (TVR), a new multimodal retrieval dataset. TVR requires systems to understand both videos and their associated subtitle (dialogue) texts, making it more realistic. The dataset contains 109K queries collected on 21.8K videos from 6 TV shows of diverse genres, where each query is associated with a tight temporal window. The queries are also labeled with query types that indicate whether each of them is more related to video or subtitle or both, allowing for in-depth analysis of the dataset and the methods that built on top of it. Strict qualification and post-annotation verification tests are applied to ensure the quality of the collected data. Additionally, we present several baselines and a novel Cross-modal Moment Localization (XML) network for multimodal moment retrieval tasks. The proposed XML model uses a late fusion design with a novel Convolutional Start-End detector (ConvSE), surpassing baselines by a large margin and with better efficiency, providing a strong starting point for future work. (TVR dataset and code are publicly available: https://tvr.cs.unc.edu/ . We also introduce TVC for multimodal captioning at https://tvr.cs.unc.edu/tvc.html ).'},\n",
       " '10.1007/978-3-030-01249-6_19': {'title': 'Action Anticipation with RBF Kernelized Feature Mapping RNN',\n",
       "  'abstract': 'We introduce a novel Recurrent Neural Network-based algorithm for future video feature generation and action anticipation called feature mapping RNN. Our novel RNN architecture builds upon three effective principles of machine learning, namely parameter sharing, Radial Basis Function kernels and adversarial training. Using only some of the earliest frames of a video, the feature mapping RNN is able to generate future features with a fraction of the parameters needed in traditional RNN. By feeding these future features into a simple multilayer perceptron facilitated with an RBF kernel layer, we are able to accurately predict the action in the video. In our experiments, we obtain 18% improvement on JHMDB-21 dataset, 6% on UCF101-24 and 13% improvement on UT-Interaction datasets over prior state-of-the-art for action anticipation.'},\n",
       " '10.1007/s11263-016-0987-1': {'title': 'Movie Description',\n",
       "  'abstract': 'Audio description (AD) provides linguistic descriptions of movies and allows visually impaired people to follow a movie along with their peers. Such descriptions are by design mainly visual and thus naturally form an interesting data source for computer vision and computational linguistics. In this work we propose a novel dataset which contains transcribed ADs, which are temporally aligned to full length movies. In addition we also collected and aligned movie scripts used in prior work and compare the two sources of descriptions. We introduce the Large Scale Movie Description Challenge (LSMDC) which contains a parallel corpus of 128,118 sentences aligned to video clips from 200 movies (around 150 h of video in total). The goal of the challenge is to automatically generate descriptions for the movie clips. First we characterize the dataset by benchmarking different approaches for generating video descriptions. Comparing ADs to scripts, we find that ADs are more visual and describe precisely what is shown rather than what should happen according to the scripts created prior to movie production. Furthermore, we present and compare the results of several teams who participated in the challenges organized in the context of two workshops at ICCV 2015 and ECCV 2016.'},\n",
       " '10.1016/j.engappai.2023.107037': {'title': 'Scaling-up medical vision-and-language representation learning with federated learning',\n",
       "  'abstract': 'Medical Vision-and-Language Pre-training (MedVLP), which learns generic vision-language representations from medical images and texts to benefit various downstream medical tasks, has drawn remarkable attention in both artificial intelligence and clinical medicine. However, existing works ignore the privacy issues and the heavy computation burden in MedVLP. In this study, we propose a FedMedVLP model, which adopts federated learning to unify the datasets from different clients, e.g., centers and hospitals, to form a large-scale pre-training dataset. As a result, the unified large-scale pre-training dataset can be used to pre-train the MedVLP to achieve strong performance. Overall, our FedMedVLP can improve the performance of MedVLP while preventing data leakage. Extensive experiments prove that the proposed model sets new state-of-the-art results on five benchmark datasets across three medical mainstream tasks, i.e., medical image–text retrieval, medical text-image retrieval, and medical visual question answering tasks. Besides, we further evaluate our method on our curated well-balanced medical dataset COVID-Fed.'},\n",
       " '10.1016/j.inffus.2023.101868': {'title': 'OpenViVQA: Task, dataset, and multimodal fusion models for visual question answering in Vietnamese',\n",
       "  'abstract': 'In recent years, visual question answering (VQA) has attracted attention from the research community because of its highly potential applications (such as virtual assistance on intelligent cars, assistant devices for blind people, or information retrieval from document images using natural language as queries) and challenge. The VQA task requires methods that have the ability to fuse the information from questions and images to produce appropriate answers. Neural visual question answering models have achieved tremendous growth on large-scale datasets which are mostly for resource-rich languages such as English. However, available datasets narrow the VQA task as the answers selection task or answer classification task. We argue that this form of VQA is far from human ability and eliminates the challenge of the answering aspect in the VQA task by just selecting answers rather than generating them. In this paper, we introduce the OpenViVQA (Open-domain Vietnamese Visual Question Answering) dataset, the first large-scale dataset for VQA with open-ended answers in Vietnamese, consists of 11,000+ images associated with 37,000+ question-answer pairs (QAs). Moreover, we proposed FST, QuMLAG, and MLPAG which fuse information from images and questions, then use these fused features to construct answers as humans iteratively. Our proposed methods achieve results that are competitive with SOTA models such as SAAA, MCAN, LORA, and M4C. The dataset1 is available to encourage the research community to develop more generalized algorithms including transformers for low-resource languages such as Vietnamese.'},\n",
       " '10.1016/J.PATCOG.2021.108217': {'title': 'Multi-task framework based on feature separation and reconstruction for cross-modal retrieval',\n",
       "  'abstract': 'Cross-modal retrieval has become a hot research topic in both computer vision and natural language processing areas. Learning intermediate common space for features of different modalities has become one of mainstream methods. In this paper, we propose a novel multi-task framework based on feature separation and reconstruction (mFSR) for cross-modal retrieval based on common space learning methods, which introduces feature separation module to deal with information asymmetry between different modalities, and introduces image and text reconstruction module to improve the quality of feature separation module. Extensive experiments on MS-COCO and Flickr30K datasets demonstrate that feature separation and specific information reconstruction can significantly improve the baseline performance of cross-modal image-caption retrieval.'},\n",
       " '10.1016/j.patcog.2021.107847': {'title': 'Inferring spatial relations from textual descriptions of images',\n",
       "  'abstract': 'Generating an image from its textual description requires both a certain level of language understanding and common sense knowledge about the spatial relations of the physical entities being described. In this work, we focus on inferring the spatial relation between entities, a key step in the process of composing scenes based on text. More specifically, given a caption containing a mention to a subject and the location and size of the bounding box of that subject, our goal is to predict the location and size of an object mentioned in the caption. Previous work did not use the caption text information, but a manually provided relation holding between the subject and the object. In fact, the used evaluation datasets contain manually annotated ontological triplets but no captions, making the exercise unrealistic: a manual step was required; and systems did not leverage the richer information in captions. Here we present a system that uses the full caption, and Relations in Captions (REC-COCO), a dataset derived from MS-COCO which allows to evaluate spatial relation inference from captions directly. Our experiments show that: (1) it is possible to infer the size and location of an object with respect to a given subject directly from the caption; (2) the use of full text allows to place the object better than using a manually annotated relation. Our work paves the way for systems that, given a caption, decide which entities need to be depicted and their respective location and sizes, in order to then generate the final image.'},\n",
       " '10.1007/978-3-319-46466-4_5': {'title': 'Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles',\n",
       "  'abstract': 'We propose a novel unsupervised learning approach to build features suitable for object detection and classification. The features are pre-trained on a large dataset without human annotation and later transferred via fine-tuning on a different, smaller and labeled dataset. The pre-training consists of solving jigsaw puzzles of natural images. To facilitate the transfer of features to other tasks, we introduce the context-free network (CFN), a siamese-ennead convolutional neural network. The features correspond to the columns of the CFN and they process image tiles independently (i.e., free of context). The later layers of the CFN then use the features to identify their geometric arrangement. Our experimental evaluations show that the learned features capture semantically relevant content. We pre-train the CFN on the training set of the ILSVRC2012 dataset and transfer the features on the combined training and validation set of Pascal VOC 2007 for object detection (via fast RCNN) and classification. These features outperform all current unsupervised features with $$51.8\\\\,\\\\%$$ for detection and $$68.6\\\\,\\\\%$$ for classification, and reduce the gap with supervised learning ( $$56.5\\\\,\\\\%$$ and $$78.2\\\\,\\\\%$$ respectively).'},\n",
       " '10.1007/978-3-319-46475-6_43': {'title': 'Perceptual Losses for Real-Time Style Transfer and Super-Resolution',\n",
       "  'abstract': 'We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by defining and optimizing perceptual loss functions based on high-level features extracted from pretrained networks. We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al. in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.'},\n",
       " '10.1093/llc/fqq006': {'title': \"Developing ODIN: A Multilingual Repository of Annotated Language Data for Hundreds of the World's Languages\",\n",
       "  'abstract': \"In this article, we review the process of building ODIN, the Online Database of Interlinear Text (http://odin.linguistlist.org) a multilingual repository of linguistically analyzed language data. ODIN is built from interlinear text that has been harvested from scholarly linguistic documents posted on the web. At the time of this writing, ODIN holds nearly 190,000 instances of interlinear text representing annotated language data for more than 1,000 languages (representing data from >10% of the world's languages). ODIN's charter has been to make these data available to linguists and other language researchers via search, providing the facility to find instances of language data and related resources (i.e. the documents from which data were extracted) by language name, language family, and even annotations used to markup the data (e.g. NOM, ACC, ERG, PST, 3SG). Further, we have sought to enrich the data we have collected and extract ‘knowledge’ from the enriched content. To enrich the data, we use a variety of statistical tagging and parsing methods applied in the English translations. An enhanced search facility allows users to find data across languages for a variety of syntactic constructions and constituent orders, facilitating unprecedented automated and online discovery of language data.\"},\n",
       " '10.1093/ACPROF:OSO/9780199547548.003.0003': {'title': '3 Parts and wholes: Implicative patterns in inflectional paradigms',\n",
       "  'abstract': 'Abstract Humans show an amazing ability to produce novel words based on previous experience. What analogical processes are at work in this process, and how do analogical generalizations emerge from complex morphological systems? This chapter addresses these questions with new quantitative measures. Words are construed as recombinant gestalts. The predictive value of particular words in relation to others is calculated in terms of measures of conditional entropy. When applied to Tundra Nenets nominal paradigms, the model captures central aspects of morphological organization and learning.'},\n",
       " '10.1016/j.datak.2013.08.005': {'title': 'COMPENDIUM: A text summarization system for generating abstracts of research papers',\n",
       "  'abstract': 'This article analyzes the appropriateness of a text summarization system, COMPENDIUM, for generating abstracts of biomedical papers. Two approaches are suggested: an extractive (COMPENDIUME), which only selects and extracts the most relevant sentences of the documents, and an abstractive-oriented one (COMPENDIUME–A), thus facing also the challenge of abstractive summarization. This novel strategy combines extractive information, with some pieces of information of the article that have been previously compressed or fused. Specifically, in this article, we want to study: i) whether COMPENDIUM produces good summaries in the biomedical domain; ii) which summarization approach is more suitable; and iii) the opinion of real users towards automatic summaries. Therefore, two types of evaluation were performed: quantitative and qualitative, for evaluating both the information contained in the summaries, as well as the user satisfaction. Results show that extractive and abstractive-oriented summaries perform similarly as far as the information they contain, so both approaches are able to keep the relevant information of the source documents, but the latter is more appropriate from a human perspective, when a user satisfaction assessment is carried out. This also confirms the suitability of our suggested approach for generating summaries following an abstractive-oriented paradigm.'},\n",
       " '10.1007/978-3-642-22327-3_2': {'title': 'COMPENDIUM: A Text Summarization System for Generating Abstracts of Research Papers',\n",
       "  'abstract': 'This paper presents compendium, a text summarization system, which has achieved good results in extractive summarization. Therefore, our main goal in this research is to extend it, suggesting a new approach for generating abstractive-oriented summaries of research papers. We conduct a preliminary analysis where we compare the extractive version of compendium ( $\\\\textsc{compendium}_{E}$ ) with the new abstractive-oriented approach ( $\\\\textsc{compendium}_{E-A}$ ). The final summaries are evaluated according to three criteria (content, topic, and user satisfaction) and, from the results obtained, we can conclude that the use of compendium is appropriate for producing summaries of research papers automatically, going beyond the simple selection of sentences.'},\n",
       " '10.1016/j.jiixd.2024.03.003': {'title': 'DI-VTR: Dual Inter-modal Interaction Model for Video-Text Retrieval',\n",
       "  'abstract': 'Video-text retrieval is a challenging task for multimodal information processing due to the semantic gap between different modalities. However, most existing methods do not fully mine the intra-modal interactions, as with the temporal correlation of video frames, which results in poor matching performance. Additionally, the imbalanced semantic information between videos and texts also leads to difficulty in the alignment of the two modalities. To this end, we propose a dual inter-modal interaction network for video-text retrieval, i.e., DI-VTR. To learn the intra-modal interaction of video frames, we design a contextual-related video encoder to obtain more fine-grained content-oriented video representations. We also propose a dual inter-modal interaction module to accomplish accurate multilingual alignment between the video and text modalities by introducing multilingual text to improve the representation ability of text semantic features. Extensive experimental results on commonly-used video-text retrieval datasets, including MSR-VTT, MSVD and VATEX, show that the proposed method achieves significantly improved performance compared with state-of-the-art methods.'},\n",
       " '10.1016/j.eswa.2023.121601': {'title': 'Contrastive topic-enhanced network for video captioning',\n",
       "  'abstract': 'In the field of video captioning, recent works usually focus on multi-modal video content understanding, in which transcripts are extracted from speech and are often adopted as an informational supplement. However, most existing works only consider transcripts as a supplementary modality, neglecting their potential in capturing high-level semantics, such as multi-modal topics. In fact, transcripts, as a textual attribute derived from the video, reflect the same high-level topics as the video content. Nonetheless, how to resolve the heterogeneity of multi-modal topics is still under-investigated and worth exploring. In this paper, we introduce a contrastive topic-enhanced network to consistently model heterogeneous topics, that is, inject an alignment module in advance, to learn a comprehensive latent topic space and guide caption generation. Specifically, our method includes a local semantic alignment module and a global topic fusion module. In the local semantic alignment module, a fine-grained semantic alignment at the clip-sentence granularity reduces the semantic gap between modalities. Extensive experiments have verified the effectiveness of our solution.'},\n",
       " '10.23919/icn.2023.0009': {'title': 'KnowER: Knowledge enhancement for efficient text-video retrieval',\n",
       "  'abstract': 'The widespread adoption of mobile Internet and the Internet of things (IoT) has led to a significant increase in the amount of video data. While video data are increasingly important, language and text remain the primary methods of interaction in everyday communication, text-based cross-modal retrieval has become a crucial demand in many applications. Most previous text-video retrieval works utilize implicit knowledge of pre-trained models such as contrastive language-image pre-training (CLIP) to boost retrieval performance. However, implicit knowledge only records the co-occurrence relationship existing in the data, and it cannot assist the model to understand specific words or scenes. Another type of out-of-domain knowledge—explicit knowledge—which is usually in the form of a knowledge graph, can play an auxiliary role in understanding the content of different modalities. Therefore, we study the application of external knowledge base in text-video retrieval model for the first time, and propose KnowER, a model based on knowledge enhancement for efficient text-video retrieval. The knowledge-enhanced model achieves state-of-the-art performance on three widely used text-video retrieval datasets, i.e., MSRVTT, DiDeMo, and MSVD.'},\n",
       " '10.1016/j.eswa.2023.119773': {'title': 'Evolution of visual data captioning Methods, Datasets, and evaluation Metrics: A comprehensive survey',\n",
       "  'abstract': 'Automatic Visual Captioning (AVC) generates syntactically and semantically correct sentences by describing important objects, attributes, and their relationships with each other. It is classified into two categories: image captioning and video captioning. It is widely used in various applications such as assistance for the visually impaired, human-robot interaction, video surveillance systems, scene understanding, etc. With the unprecedented success of deep-learning in Computer Vision and Natural Language Processing, the past few years have seen a surge of research in this domain. In this survey, the state-of-the-art is classified based on how they conceptualize the captioning problem, viz., traditional approaches that cast visual description either as retrieval or template-based description and deep learning approaches. A detailed review of existing methods, highlighting their pros and cons, societal impact as the number of citations, architectures used, datasets experimented on and GitHub link is presented. Moreover, the survey also provides an overview of the benchmark image and video datasets and the evaluation measures that have been developed to assess the quality of machine-generated captions. It is observed that dense or paragraph generation and Change Image Captioning (CIC) are stimulating the research community more due to the near-to-human abstraction ability. Finally, the paper explores future directions in the area of automatic visual caption generation.'},\n",
       " '10.1007/s13735-023-00267-8': {'title': 'Deep learning for video-text retrieval: a review',\n",
       "  'abstract': 'Video-Text Retrieval (VTR) aims to search for the most relevant video related to the semantics in a given sentence, and vice versa. In general, this retrieval task is composed of four successive steps: video and textual feature representation extraction, feature embedding and matching, and objective functions. In the last, a list of samples retrieved from the dataset is ranked based on their matching similarities to the query. In recent years, significant and flourishing progress has been achieved by deep learning techniques, however, VTR is still a challenging task due to the problems like how to learn an efficient spatial-temporal video feature and how to narrow the cross-modal gap. In this survey, we review and summarize over 100 research papers related to VTR, demonstrate state-of-the-art performance on several commonly benchmarked datasets, and discuss potential challenges and directions, with the expectation to provide some insights for researchers in the field of video-text retrieval.'},\n",
       " '10.1007/978-3-031-20059-5_11': {'title': 'Selective Query-Guided Debiasing for Video Corpus Moment Retrieval',\n",
       "  'abstract': 'Video moment retrieval (VMR) aims to localize target moments in untrimmed videos pertinent to a given textual query. Existing retrieval systems tend to rely on retrieval bias as a shortcut and thus, fail to sufficiently learn multi-modal interactions between query and video. This retrieval bias stems from learning frequent co-occurrence patterns between query and moments, which spuriously correlate objects (e.g., a pencil) referred in the query with moments (e.g., scene of writing with a pencil) where the objects frequently appear in the video, such that they converge into biased moment predictions. Although recent debiasing methods have focused on removing this retrieval bias, we argue that these biased predictions sometimes should be preserved because there are many queries where biased predictions are rather helpful. To conjugate this retrieval bias, we propose a Selective Query-guided Debiasing network (SQuiDNet), which incorporates the following two main properties: (1) Biased Moment Retrieval that intentionally uncovers the biased moments inherent in objects of the query and (2) Selective Query-guided Debiasing that performs selective debiasing guided by the meaning of the query. Our experimental results on three moment retrieval benchmarks (i.e., TVR, ActivityNet, DiDeMo) show the effectiveness of SQuiDNet and qualitative analysis shows improved interpretability.'},\n",
       " '10.1007/s00530-022-00926-6': {'title': 'Data-driven personalisation of television content: a survey',\n",
       "  'abstract': 'This survey considers the vision of TV broadcasting where content is personalised and personalisation is data-driven, looks at the AI and data technologies making this possible and surveys the current uptake and usage of those technologies. We examine the current state-of-the-art in standards and best practices for data-driven technologies and identify remaining limitations and gaps for research and innovation. Our hope is that this survey provides an overview of the current state of AI and data-driven technologies for use within broadcasters and media organisations. It also provides a pathway to the needed research and innovation activities to fulfil the vision of data-driven personalisation of TV content.'},\n",
       " '10.1007/s11633-022-1369-5': {'title': 'VLP: A Survey on Vision-language Pre-training',\n",
       "  'abstract': 'Abstract In the past few years, the emergence of pre-training models has brought uni-modal fields such as computer vision (CV) and natural language processing (NLP) to a new era. Substantial works have shown that they are beneficial for downstream uni-modal tasks and avoid training a new model from scratch. So can such pre-trained models be applied to multi-modal tasks? Researchers have explored this problem and made significant progress. This paper surveys recent advances and new frontiers in vision-language pre-training (VLP), including image-text and video-text pre-training. To give readers a better overall grasp of VLP, we first review its recent advances in five aspects: feature extraction, model architecture, pre-training objectives, pre-training datasets, and downstream tasks. Then, we summarize the specific VLP models in detail. Finally, we discuss the new frontiers in VLP. To the best of our knowledge, this is the first survey focused on VLP. We hope that this survey can shed light on future research in the VLP field.'},\n",
       " '10.1007/978-3-031-18907-4_29': {'title': 'CLIP Meets Video Captioning: Concept-Aware Representation Learning Does Matter',\n",
       "  'abstract': 'For video captioning, “pre-training and fine-tuning” has become a de facto paradigm, where ImageNet Pre-training (INP) is usually used to encode the video content, then a task-oriented network is fine-tuned from scratch to cope with caption generation. This paper first investigates the impact of the recently proposed CLIP (Contrastive Language-Image Pre-training) on video captioning. Through the empirical study on INP vs. CLIP, we identify the potential deficiencies of INP and explore the key factors for accurate description generation. The results show that the INP-based model is tricky to capture concepts’ semantics and sensitive to irrelevant background information. By contrast, the CLIP-based model significantly improves the caption quality and highlights the importance of concept-aware representation learning. With these findings, we propose Dual Concept Detection (DCD) further to inject concept knowledge into the model during training. DCD is an auxiliary task that requires a caption model to learn the correspondence between video content and concepts and the co-occurrence relations between concepts. Experiments on MSR-VTT and VATEX demonstrate the effectiveness of DCD, and the visualization results further reveal the necessity of learning concept-aware representations.'},\n",
       " '10.1007/978-3-031-19806-9_5': {'title': 'VL-LTR: Learning Class-wise Visual-Linguistic Representation for Long-Tailed Visual Recognition',\n",
       "  'abstract': 'Recently, computer vision foundation models such as CLIP and ALI-GN, have shown impressive generalization capabilities on various downstream tasks. But their abilities to deal with the long-tailed data still remain to be proved. In this work, we present a novel framework based on pre-trained visual-linguistic models for long-tailed recognition (LTR), termed VL-LTR, and conduct empirical studies on the benefits of introducing text modality for long-tailed recognition tasks. Compared to existing approaches, the proposed VL-LTR has the following merits. (1) Our method can not only learn visual representation from images but also learn corresponding linguistic representation from noisy class-level text descriptions collected from the Internet; (2) Our method can effectively use the learned visual-linguistic representation to improve the visual recognition performance, especially for classes with fewer image samples. We also conduct extensive experiments and set the new state-of-the-art performance on widely-used LTR benchmarks. Notably, our method achieves 77.2% overall accuracy on ImageNet-LT, which significantly outperforms the previous best method by over 17 points, and is close to the prevailing performance training on the full ImageNet. Code is available at https://github.com/ChangyaoTian/VL-LTR .'},\n",
       " '10.1007/978-3-030-98355-0_28': {'title': 'Multi-modal Semantic Inconsistency Detection in Social Media News Posts',\n",
       "  'abstract': 'As computer-generated content and deepfakes make steady improvements, semantic approaches to multimedia forensics will become more important. In this paper, we introduce a novel classification architecture for identifying semantic inconsistencies between video appearance and text caption in social media news posts. While similar systems exist for text and images, we aim to detect inconsistencies in a more ambiguous setting, as videos can be long and contain several distinct scenes, in addition to adding audio as an extra modality. We develop a multi-modal fusion framework to identify mismatches between videos and captions in social media posts by leveraging an ensemble method based on textual analysis of the caption, automatic audio transcription, semantic video analysis, object detection, named entity consistency, and facial verification. To train and test our approach, we curate a new video-based dataset of 4,000 real-world Facebook news posts for analysis. Our multi-modal approach achieves 60.5% classification accuracy on random mismatches between caption and appearance, compared to accuracy below 50% for uni-modal models. Further ablation studies confirm the necessity of fusion across modalities for correctly identifying semantic inconsistencies.'},\n",
       " '10.1016/j.neucom.2022.07.028': {'title': 'CLIP4Clip: An empirical study of CLIP for end to end video clip retrieval and captioning',\n",
       "  'abstract': 'Video clip retrieval and captioning tasks play an essential role in multimodal research and are the fundamental research problem for multimodal understanding and generation. The CLIP (Contrastive Language-Image Pre-training) model has demonstrated the power of visual concepts learning from web collected image-text datasets. In this paper, we propose a CLIP4Clip model to transfer the knowledge of the image-text pretrained CLIP model to video-text tasks in an end-to-end manner. Furthermore, we conduct several empirical studies including 1) Whether image feature is enough for video-text retrieval and captioning? 2) How a post-pretraining on a large-scale video-text dataset based on the CLIP affect the performance? 3) What is the practical mechanism to model temporal dependency between video frames? And 4) The Hyper-parameters sensitivity of the model. Extensive experimental results present that the CLIP4Clip model transferred from the CLIP can achieve SOTA results on various video-text datasets, including MSR-VTT, MSVD, LSMDC, and DiDeMo for multimodal understanding and generation tasks.'},\n",
       " '10.1016/J.NEUCOM.2021.02.092': {'title': 'A comparative study of language transformers for video question answering',\n",
       "  'abstract': 'With the goal of correctly answering questions about images or videos, visual question answering (VQA) has quickly developed in recent years. However, current VQA systems mainly focus on answering questions about a single image and face many challenges in answering video-based questions. VQA in video not only has to understand the evolution between video frames but also requires a certain understanding of corresponding subtitles. In this paper, we propose a language Transformer-based video question answering model to encode the complex semantics from video clips. Different from previous models which represent visual features by recurrent neural networks, our model encodes visual concept sequences with a pre-trained language Transformer. We investigate the performance of our model using four language Transformers over two different datasets. The results demonstrate outstanding improvements compared to previous work.'},\n",
       " '10.1007/s11263-021-01547-8': {'title': 'Perspectives and Prospects on Transformer Architecture for Cross-Modal Tasks with Language and Vision',\n",
       "  'abstract': 'Transformer architectures have brought about fundamental changes to computational linguistic field, which had been dominated by recurrent neural networks for many years. Its success also implies drastic changes in cross-modal tasks with language and vision, and many researchers have already tackled the issue. In this paper, we review some of the most critical milestones in the field, as well as overall trends on how transformer architecture has been incorporated into visuolinguistic cross-modal tasks. Furthermore, we discuss its current limitations and speculate upon some of the prospects that we find imminent.'},\n",
       " '10.1007/978-3-030-66840-2_109': {'title': 'A Multimodal Memes Classification: A Survey and Open Research Issues',\n",
       "  'abstract': 'Memes are graphics and text overlapped so that together they present concepts that become dubious if one of them is absent. It is spread mostly on social media platforms, in the form of jokes, sarcasm, motivating, etc. After the success of BERT in Natural Language Processing (NLP), researchers inclined to Visual-Linguistic (VL) multimodal problems like memes classification, image captioning, Visual Question Answering (VQA), and many more. Unfortunately, many memes get uploaded each day on social media platforms that need automatic censoring to curb misinformation and hate. Recently, this issue has attracted the attention of researchers and practitioners. State-of-the-art methods that performed significantly on other VL dataset, tends to fail on memes classification. In this context, this work aims to conduct a comprehensive study on memes classification, generally on the VL multimodal problems and cutting edge solutions. We propose a generalized framework for VL problems. We cover the early and next-generation works on VL problems. Finally, we identify and articulate several open research issues and challenges. This is the first study that presents the generalized view of the advanced classification techniques concerning memes classification to the best of our knowledge. We believe this study presents a clear road-map for the Machine Learning (ML) research community to implement and enhance memes classification techniques.'},\n",
       " '10.1007/978-3-030-58539-6_34': {'title': 'Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models',\n",
       "  'abstract': 'Recent Transformer-based large-scale pre-trained models have revolutionized vision-and-language (V+L) research. Models such as ViLBERT, LXMERT and UNITER have significantly lifted state of the art across a wide range of V+L benchmarks. However, little is known about the inner mechanisms that destine their impressive success. To reveal the secrets behind the scene, we present Value (Vision-And-Language Understanding Evaluation), a set of meticulously designed probing tasks (e.g., Visual Coreference Resolution, Visual Relation Detection) generalizable to standard pre-trained V+L models, to decipher the inner workings of multimodal pre-training (e.g., implicit knowledge garnered in individual attention heads, inherent cross-modal alignment learned through contextualized multimodal embeddings). Through extensive analysis of each archetypal model architecture via these probing tasks, our key observations are: (i) Pre-trained models exhibit a propensity for attending over text rather than images during inference. (ii) There exists a subset of attention heads that are tailored for capturing cross-modal interactions. (iii) Learned attention matrix in pre-trained models demonstrates patterns coherent with the latent alignment between image regions and textual words. (iv) Plotted attention patterns reveal visually-interpretable relations among image regions. (v) Pure linguistic knowledge is also effectively encoded in the attention heads. These are valuable insights serving to guide future work towards designing better model architecture and objectives for multimodal pre-training. (Code is available at https://github.com/JizeCao/VALUE ).'},\n",
       " '10.1007/978-3-030-88480-2_63': {'title': 'XGPT: Cross-modal Generative Pre-Training for Image Captioning',\n",
       "  'abstract': 'In this paper, we propose XGPT, a new method of Cross-modal Generative Pre-Training for Image Captioning that is designed to pre-train text-to-image caption generators through four novel generation tasks, including Adversarial Image Captioning (AIC), Image-conditioned Masked Language Modeling (IMLM), Image-conditioned Denoising Autoencoding (IDA), and Text-conditioned Image Feature Generation (TIFG). As a result, the pre-trained XGPT can obtain new state-of-the-art results on the benchmark datasets, including COCO Captions and Flickr30k Captions. We also use XGPT to generate image captions as data augmentation for the image retrieval task and achieve significant improvement on all recall metrics.'},\n",
       " '10.1007/978-3-030-58523-5_20': {'title': 'Large-Scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline',\n",
       "  'abstract': 'Prior work in visual dialog has focused on training deep neural models on VisDial in isolation. Instead, we present an approach to leverage pretraining on related vision-language datasets before transferring to visual dialog. We adapt the recently proposed ViLBERT model for multi-turn visually-grounded conversations. Our model is pretrained on the Conceptual Captions and Visual Question Answering datasets, and finetuned on VisDial. Our best single model outperforms prior published work by $$1\\\\%$$ absolute on NDCG and MRR. Next, we find that additional finetuning using \"dense\" annotations in VisDial leads to even higher NDCG – more than $$10\\\\%$$ over our base model – but hurts MRR – more than $$17\\\\%$$ below our base model! This highlights a trade-off between the two primary metrics – NDCG and MRR – which we find is due to dense annotations not correlating well with the original ground-truth answers to questions.'},\n",
       " '10.1007/978-3-030-58577-8_7': {'title': 'UNITER: UNiversal Image-TExt Representation Learning',\n",
       "  'abstract': 'Joint image-text embedding is the bedrock for most Vision-and-Language (V+L) tasks, where multimodality inputs are simultaneously processed for joint visual and textual understanding. In this paper, we introduce UNITER, a UNiversal Image-TExt Representation, learned through large-scale pre-training over four image-text datasets (COCO, Visual Genome, Conceptual Captions, and SBU Captions), which can power heterogeneous downstream V+L tasks with joint multimodal embeddings. We design four pre-training tasks: Masked Language Modeling (MLM), Masked Region Modeling (MRM, with three variants), Image-Text Matching (ITM), and Word-Region Alignment (WRA). Different from previous work that applies joint random masking to both modalities, we use conditional masking on pre-training tasks (i.e., masked language/region modeling is conditioned on full observation of image/text). In addition to ITM for global image-text alignment, we also propose WRA via the use of Optimal Transport (OT) to explicitly encourage fine-grained alignment between words and image regions during pre-training. Comprehensive analysis shows that both conditional masking and OT-based WRA contribute to better pre-training. We also conduct a thorough ablation study to find an optimal combination of pre-training tasks. Extensive experiments show that UNITER achieves new state of the art across six V+L tasks (over nine datasets), including Visual Question Answering, Image-Text Retrieval, Referring Expression Comprehension, Visual Commonsense Reasoning, Visual Entailment, and NLVR\\\\(^2\\\\) (Code is available at https://github.com/ChenRocks/UNITER.).'},\n",
       " '10.1007/978-3-030-01234-2_29': {'title': 'A Joint Sequence Fusion Model for Video Question Answering and Retrieval',\n",
       "  'abstract': 'We present an approach named JSFusion (Joint Sequence Fusion) that can measure semantic similarity between any pairs of multimodal sequence data (e.g. a video clip and a language sentence). Our multimodal matching network consists of two key components. First, the Joint Semantic Tensor composes a dense pairwise representation of two sequence data into a 3D tensor. Then, the Convolutional Hierarchical Decoder computes their similarity score by discovering hidden hierarchical matches between the two sequence modalities. Both modules leverage hierarchical attention mechanisms that learn to promote well-matched representation patterns while prune out misaligned ones in a bottom-up manner. Although the JSFusion is a universal model to be applicable to any multimodal sequence data, this work focuses on video-language tasks including multimodal retrieval and video QA. We evaluate the JSFusion model in three retrieval and VQA tasks in LSMDC, for which our model achieves the best performance reported so far. We also perform multiple-choice and movie retrieval tasks for the MSR-VTT dataset, on which our approach outperforms many state-of-the-art methods.'},\n",
       " '10.1016/j.eswa.2024.123781': {'title': 'What can rhetoric bring us? Incorporating rhetorical structure into neural related work generation',\n",
       "  'abstract': 'The ever-increasing volume of research literature poses challenges for researchers in keeping up with related works in their fields. Automating the generation of related work section holds promise for saving time and effort. However, current models often fall short of producing coherent and logically correct related work with multiple sentences, a phenomenon we refer to as rhetorical structure chaos. Rhetorical structure describes how adjacent spans of units are connected to each other, and logically correct rhetorical structure is essential for a well-structured related work. Hence, to tackle the rhetorical structure chaos issue, this paper explicitly incorporates rhetorical structure information into related work generation. Firstly, we conduct the first rhetorical structure analysis for related work section, which provides insights into understanding the organization and arrangement of contents within related work. Then, based on two preliminary studies on rhetorical structure, we present a novel related work generation model called RSGen, which incorporates rhetorical structure at both the encoding and decoding stages. The encoding stage is facilitated with a rhetorical structure-based graph encoder, while the decoding process is guided by a rhetorical plan — ordered sequence of rhetorical functions of the related work. We conduct extensive experiments on three related work generation datasets to evaluate the performance of our model. The results show that our approach achieves state-of-the-art performance on ROUGE metrics. An ablation study and more analyses further highlight the remarkable efficacy of introducing rhetorical structure into both the encoding and decoding stages.'},\n",
       " '10.1016/j.patcog.2020.107514': {'title': 'Dirichlet Variational Autoencoder',\n",
       "  'abstract': 'This paper proposes Dirichlet Variational Autoencoder (DirVAE) using a Dirichlet prior. To infer the parameters of DirVAE, we utilize the stochastic gradient method by approximating the inverse cumulative distribution function of the Gamma distribution, which is a component of the Dirichlet distribution. This approximation on a new prior led an investigation on the component collapsing, and DirVAE revealed that the component collapsing originates from two problem sources: decoder weight collapsing and latent value collapsing. The experimental results show that 1) DirVAE generates the result with the best log-likelihood compared to the baselines; 2) DirVAE produces more interpretable latent values with no collapsing issues which the baselines suffer from; 3) the latent representation from DirVAE achieves the best classification accuracy in the (semi-)supervised classification tasks on MNIST, OMNIGLOT, COIL-20, SVHN, and CIFAR-10 compared to the baseline VAEs; and 4) the DirVAE augmented topic models show better performances in most cases.'},\n",
       " '10.1007/s13218-020-00631-4': {'title': 'Active and Incremental Learning with Weak Supervision',\n",
       "  'abstract': 'Abstract Large amounts of labeled training data are one of the main contributors to the great success that deep models have achieved in the past. Label acquisition for tasks other than benchmarks can pose a challenge due to requirements of both funding and expertise. By selecting unlabeled examples that are promising in terms of model improvement and only asking for respective labels, active learning can increase the efficiency of the labeling process in terms of time and cost. In this work, we describe combinations of an incremental learning scheme and methods of active learning. These allow for continuous exploration of newly observed unlabeled data. We describe selection criteria based on model uncertainty as well as expected model output change (EMOC). An object detection task is evaluated in a continuous exploration context on the PASCAL VOC dataset. We also validate a weakly supervised system based on active and incremental learning in a real-world biodiversity application where images from camera traps are analyzed. Labeling only 32 images by accepting or rejecting proposals generated by our method yields an increase in accuracy from 25.4 to 42.6%.'},\n",
       " '10.1186/s12859-017-1805-7': {'title': 'CNN-based ranking for biomedical entity normalization',\n",
       "  'abstract': 'Most state-of-the-art biomedical entity normalization systems, such as rule-based systems, merely rely on morphological information of entity mentions, but rarely consider their semantic information. In this paper, we introduce a novel convolutional neural network (CNN) architecture that regards biomedical entity normalization as a ranking problem and benefits from semantic information of biomedical entities.The CNN-based ranking method first generates candidates using handcrafted rules, and then ranks the candidates according to their semantic information modeled by CNN as well as their morphological information. Experiments on two benchmark datasets for biomedical entity normalization show that our proposed CNN-based ranking method outperforms traditional rule-based method with state-of-the-art performance.We propose a CNN architecture that regards biomedical entity normalization as a ranking problem. Comparison results show that semantic information is beneficial to biomedical entity normalization and can be well combined with morphological information in our CNN architecture for further improvement.'},\n",
       " '10.1007/978-3-662-44848-9_11': {'title': 'Open Question Answering with Weakly Supervised Embedding Models',\n",
       "  'abstract': 'Building computers able to answer questions on any subject is a long standing goal of artificial intelligence. Promising progress has recently been achieved by methods that learn to map questions to logical forms or database queries. Such approaches can be effective but at the cost of either large amounts of human-labeled data or by defining lexicons and grammars tailored by practitioners. In this paper, we instead take the radical approach of learning to map questions to vectorial feature representations. By mapping answers into the same space one can query any knowledge base independent of its schema, without requiring any grammar or lexicon. Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine-tuning step using the weak supervision provided by blending automatically and collaboratively generated resources. We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex, the only existing method able to be trained on similar weakly labeled data.'},\n",
       " '10.1016/j.neunet.2024.106178': {'title': 'SCMEA: A stacked co-enhanced model for entity alignment based on multi-aspect information fusion and bidirectional contrastive learning',\n",
       "  'abstract': 'Entity alignment refers to discovering the entity pairs with the same realistic meaning in different knowledge graphs. This technology is of great significance for completing and fusing knowledge graphs. Recently, methods based on knowledge representation learning have achieved remarkable achievements in entity alignment. However, most existing approaches do not mine hidden information in the knowledge graph as much as possible. This paper suggests SCMEA, a novel cross-lingual entity alignment framework based on multi-aspect information fusion and bidirectional contrastive learning. SCMEA initially adopts diverse representation learning models to embed multi-aspect information of entities and integrates them into a unified embedding space with an adaptive weighted mechanism to overcome the missing information and the problem of different-aspect information are not uniform. Then, we propose a stacked relation-entity co-enhanced model to further improve the representations of entities, wherein relation representation is modeled using an Entity Collector with Global Entity Attention. Finally, a combined loss function based on improved bidirectional contrastive learning is introduced to optimize model parameters and entity representation, effectively mitigating the hubness problem and accelerating model convergence. We conduct extensive experiments to evaluate the alignment performance of SCMEA. The overall experimental results, ablation studies, and analysis performed on five cross-lingual datasets demonstrate that our model achieves varying degrees of performance improvement and verifies the effectiveness and robustness of the model.'},\n",
       " '10.1007/978-3-642-25073-6_18': {'title': 'LogMap: Logic-Based and Scalable Ontology Matching',\n",
       "  'abstract': 'In this paper, we present LogMap—a highly scalable ontology matching system with ‘built-in’ reasoning and diagnosis capabilities. To the best of our knowledge, LogMap is the only matching system that can deal with semantically rich ontologies containing tens (and even hundreds) of thousands of classes. In contrast to most existing tools, LogMap also implements algorithms for ‘on the fly’ unsatisfiability detection and repair. Our experiments with the ontologies NCI, FMA and SNOMED CT confirm that our system can efficiently match even the largest existing bio-medical ontologies. Furthermore, LogMap is able to produce a ‘clean’ set of output mappings in many cases, in the sense that the ontology obtained by integrating LogMap’s output mappings with the input ontologies is consistent and does not contain unsatisfiable classes.'},\n",
       " '10.1016/0004-3702(88)90002-1': {'title': \"Quantifying inductive bias: AI learning algorithms and Valiant's learning framework\",\n",
       "  'abstract': \"We show that the notion of inductive bias in concept learning can be quantified in a way that directly relates to learning performance in the framework recently introduced by Valiant. Our measure of bias is based on the growth function introduced by Vapnik and Chervonenkis, and on the Vapnik-Chervonenkis dimension. We measure some common language biases, including restriction to conjunctive concepts, conjunctive concepts with internal disjunction, k-DNF and k-CNF concepts. We also measure certain types of bias that result from a preference for simpler hypotheses. Using these bias measurements we analyze the performance of the classical learning algorithm for conjunctive concepts from the perspective of Valiant's learning framework. We then augment this algorithm with a hypothesis simplification routine that uses a greedy heuristic and show how this improves learning performance on simpler target concepts. Improved learning algorithms are also developed for conjunctive concepts with internal disjunction, k-DNF and k-CNF concepts. We show that all our algorithms are within a logarithmic factor of optimal in terms of the number of examples they require to achieve a given level of learning performance in the Valiant framework. Our results hold for arbitrary attribute-based instance spaces defined by either tree-structured or linear attributes.\"},\n",
       " '10.1007/978-3-031-06981-9_21': {'title': 'QuoteKG: A Multilingual Knowledge Graph of Quotes',\n",
       "  'abstract': 'Abstract Quotes of public figures can mark turning points in history. A quote can explain its originator’s actions, foreshadowing political or personal decisions and revealing character traits. Impactful quotes cross language barriers and influence the general population’s reaction to specific stances, always facing the risk of being misattributed or taken out of context. The provision of a cross-lingual knowledge graph of quotes that establishes the authenticity of quotes and their contexts is of great importance to allow the exploration of the lives of important people as well as topics from the perspective of what was actually said. In this paper, we present QuoteKG, the first multilingual knowledge graph of quotes. We propose the QuoteKG creation pipeline that extracts quotes from Wikiquote, a free and collaboratively created collection of quotes in many languages, and aligns different mentions of the same quote. QuoteKG includes nearly one million quotes in 55 languages, said by more than 69, 000 people of public interest across a wide range of topics. QuoteKG is publicly available and can be accessed via a SPARQL endpoint.'},\n",
       " '10.1140/epjds/s13688-021-00260-3': {'title': 'Generalized word shift graphs: a method for visualizing and explaining pairwise comparisons between texts',\n",
       "  'abstract': 'Abstract A common task in computational text analyses is to quantify how two corpora differ according to a measurement like word frequency, sentiment, or information content. However, collapsing the texts’ rich stories into a single number is often conceptually perilous, and it is difficult to confidently interpret interesting or unexpected textual patterns without looming concerns about data artifacts or measurement validity. To better capture fine-grained differences between texts, we introduce generalized word shift graphs, visualizations which yield a meaningful and interpretable summary of how individual words contribute to the variation between two texts for any measure that can be formulated as a weighted average. We show that this framework naturally encompasses many of the most commonly used approaches for comparing texts, including relative frequencies, dictionary scores, and entropy-based measures like the Kullback–Leibler and Jensen–Shannon divergences. Through a diverse set of case studies ranging from presidential speeches to tweets posted in urban green spaces, we demonstrate how generalized word shift graphs can be flexibly applied across domains for diagnostic investigation, hypothesis generation, and substantive interpretation. By providing a detailed lens into textual shifts between corpora, generalized word shift graphs help computational social scientists, digital humanists, and other text analysis practitioners fashion more robust scientific narratives.'},\n",
       " '10.1016/j.ipm.2024.103647': {'title': 'From words to gender: Quantitative analysis of body part descriptions within literature in Portuguese',\n",
       "  'abstract': 'This article presents a quantitative analysis of gender representation within literature in Portuguese, focusing on the descriptions of male and female body parts. We investigate a corpus of 34 literary works from our 80,000-sized dataset. By leveraging Natural Language Processing techniques, we analyze over 50 body part descriptions of 315 unique characters identified through predetermined lists from Wikipedia and Todo Estudo. To assess gender, we consider two different gender detection approaches that achieve F1 scores above 90%. Overall, our analyses quantify the frequency, specificity, and objectification of body part descriptions and provide empirical evidence of gender portrayal in literature written in Portuguese. The findings reveal specific differences in the frequency and choice of adjectives used for male and female body parts, shedding light on prevalent gender stereotypes in literary works. This research advances the discourse on gender representation, employing quantitative methods to expand our understanding of gender dynamics within a distinct literary dataset. It may further serve as a resource for gender studies, literature analysis, and computational linguistics.'},\n",
       " '10.26597/MOD.0086': {'title': 'Social Network Analysis and the Scale of Modernist Fiction',\n",
       "  'abstract': 'Does the size of a novel determine the scale of the social world it represents? In the terms that increasingly frame our own social world, do long novels contain larger or more complex social networks than short ones? Caroline Levine suggests as much in her reading of network form in Victorian novels like Dickens’s Bleak House. Levine argues that the “sheer length” of such'},\n",
       " '10.1007/978-3-658-21742-6_52': {'title': 'Granovetter (1973): The Strength of Weak Ties',\n",
       "  'abstract': 'Arbeitskontext des Aufsatzes ist Granovetters 1970 vorgelegte Dissertation, aus der dann die bekannte Studie zum Arbeitsmarkt (→ Granovetter, 1974) entstand. Die Argumentation Granovetters ist jedoch über den direkt untersuchten Bereich hinaus breiter angelegt. Ziel ist es, eine Mikro-Makro Brücke aufzuzeigen.'},\n",
       " '10.1215/00295132-1722989': {'title': \"Network Theory Circa 1800: Charles Brockden Brown's<i>Arthur Mervyn</i>\",\n",
       "  'abstract': \"This essay investigates an early instance of “network theory” in order to argue that such theories did not, as most scholars suggest, emerge exclusively in the digital age. Charles Brockden Brown's Arthur Mervyn (1799–1800) attempts to theorize the information networks of the early American republic by comparing the spread of information to the spread of yellow fever. Unlike other novels that focus on the spread of contagious disease (such as Dickens's Bleak House), Arthur Mervyn refuses to trace a clear path of transmission from person to person. Instead, the randomness of the fever's spread gives Brown a stark, dramatic way of visualizing the unpredictability built into all such chains of transmission. Rather than a mark of nostalgia for an earlier age of “face-to-face” communication, this interest in casual and ephemeral channels of communication (and indifference to print) is a mark of the text's modernity. What Brown recognizes in his analysis of emergent networks is the power of the city to reorder social connection, enabling individuals to bypass official sources of information, play a role in the process of transmission, and become (often unwitting) participants in a transformed public sphere. In Arthur Mervyn, the yellow fever epidemic works as a fantasy of exposure, an impossible kind of social transparency that ultimately serves as a map for comprehending the mysterious workings of a “connected age.”\"},\n",
       " '10.1007/978-3-642-21286-4_10': {'title': 'Efficient Generation of Networks with Given Expected Degrees',\n",
       "  'abstract': 'We present an efficient algorithm to generate random graphs with a given sequence of expected degrees. Existing algorithms run in $\\\\mathcal{O}(N^2)$ time where N is the number of nodes. We prove that our algorithm runs in $\\\\mathcal{O}(N+M)$ expected time where M is the expected number of edges. If the expected degrees are chosen from a distribution with finite mean, this is $\\\\mathcal{O}(N)$ as N → ∞.'},\n",
       " '10.1038/s41598-022-22308-8': {'title': 'Quadratic multiple regression model and spectral relaxation approach for carreau nanofluid inclined magnetized dipole along stagnation point geometry',\n",
       "  'abstract': 'Abstract Researchers across the world have tried to explore the impact of non-Newtonian liquid flowing via an extendable surface with the inclusion of various effects due to its industrial and engineering applications like polymer production, paper production, filament extrusion from a dye, etc. This study investigates the behavior of stagnation point flow of Carreau liquid attached with inclined magnetic effect and spectral relaxation approach is utilized here for the numerical outcome. In this study, a few other vital features are attached like the quadratic multiple regression model for Nusselt number evaluation, passive control of nanoparticles, viscus heating thermophoresis, Brownian motion, and mixed convection, etc. Velocity disbursement visibility is analyzed by placing an inclined magnetic field. Physical model generates collection of partial differential equations (PDEs) and these PDEs are moved into ordinary differential equations by a similarity transformations scheme. Further for numerical process, spectral relaxation method is used. Growth in K causes a reduction in velocity because this parameter K creates the impedance to flowing resulting in confines the movement of liquid in restricted the plate. Direct relation is found between $$Ec$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mrow> <mml:mi>Ec</mml:mi> </mml:mrow> </mml:math> and the energy file. In the case of S &gt; 1, physically it is a representation of Joule and viscous dissipations. This article is novel in its sense that the influence of oblique magnetic force and second order velocity slippage on Carreau nano liquid and its numerical computation with help of the spectral relaxation method has never been done before. Furthermore, the quadratic multiple regression model has been employed to find the heat transition rate in the status of the Nusselt number.'},\n",
       " '10.1016/J.LAA.2012.02.023': {'title': 'Bounds for the spectral radius of a graph when nodes are removed',\n",
       "  'abstract': 'We present a new type of lower bound for the spectral radius of a graph in which m nodes are removed. As a corollary, Cioabă’s theorem [4], which states that the maximum normalized principal eigenvector component in any graph never exceeds 12 (with equality for the star), appears as a special case of our more general result.'},\n",
       " '10.1007/s10115-012-0520-y': {'title': 'Threshold conditions for arbitrary cascade models on arbitrary networks',\n",
       "  'abstract': \"Given a network of who-contacts-whom or who-links-to-whom, will a contagious virus/product/meme spread and 'take over' (cause an epidemic) or die out quickly? What will change if nodes have partial, temporary or permanent immunity? The epidemic threshold is the minimum level of virulence to prevent a viral contagion from dying out quickly and determining it is a fundamental question in epidemiology and related areas. Most earlier work focuses either on special types of graphs or on specific epidemiological/cascade models. We are the first to show the G2-threshold (twice generalized) theorem, which nicely de-couples the effect of the topology and the virus model. Our result unifies and includes as special case older results and shows that the threshold depends on the first eigenvalue of the connectivity matrix, (a) for any graph and (b) for all propagation models in standard literature (more than 25, including H.I.V.). Our discovery has broad implications for the vulnerability of real, complex networks and numerous applications, including viral marketing, blog dynamics, influence propagation, easy answers to 'what-if' questions, and simplified design and evaluation of immunization policies. We also demonstrate our result using extensive simulations on real networks, including on one of the biggest available social-contact graphs containing more than 31 million interactions among more than 1 million people representing the city of Portland, Oregon, USA.\"},\n",
       " '10.1016/J.LAA.2004.01.020': {'title': 'On the spectral radius of graphs',\n",
       "  'abstract': 'Let G be a simple undirected graph. For v∈V(G), the 2-degree of v is the sum of the degrees of the vertices adjacent to v. Denote by ρ(G) and μ(G) the spectral radius of the adjacency matrix and the Laplacian matrix of G, respectively. In this paper, we present two lower bounds of ρ(G) and μ(G) in terms of the degrees and the 2-degrees of vertices.'},\n",
       " '10.1007/978-1-4612-4438-7_1': {'title': 'Matrix Perturbation Theory',\n",
       "  'abstract': '(1.1.1) $$X = {X_0} + \\\\varepsilon {X_1} + {\\\\varepsilon ^2}{X_2} + \\\\cdots $$ which acts in the n-dimensional (complex) vector space R.'},\n",
       " '10.1016/j.neucom.2024.127667': {'title': 'Adaptive Gradient-based Word Saliency for adversarial text attacks',\n",
       "  'abstract': 'Natural Language Processing (NLP) models are known vulnerable to adversarial text attacks. Various word-level attacks have been proposed to modify input words by a pre-calculated word saliency order or the heuristic optimization algorithm. However, the predefined fixed order usually leads to a low attack success ratio, and the heuristic algorithm is often inefficient due to many model queries. In this paper, an Adaptive Gradient-based Word Saliency (AGWS) is proposed to improve the query-efficiency and simultaneously preserve a high attack success ratio for the word-level adversarial text attack. Firstly, the AGWS calculates the word saliency with a one-time gradient to all words instead of iterative queries, so the query-efficiency is enhanced. Secondly, the AGWS adaptively updates the word saliency via the variable neighborhood search algorithm to avoid the fixed modification order, which is significant in improving the attack success ratio. Additionally, the AGWS collect substitutes with a hybrid sememe and synonym strategy to enlarge adversary options. Extensive experiments and ablation studies manifest that the AGWS achieves the highest or second highest attack success ratio with lowest word perturbation percentage and improves the query-efficiency compared with baselines. Besides, the AGWS also shows superiorities in adversarial training and transferability.'},\n",
       " '10.1016/j.dsp.2022.103764': {'title': 'Bridging the cross-modal gap using adversarial training for speech-to-text translation',\n",
       "  'abstract': 'The end-to-end speech translation (ST) model usually adopts the encoder-decoder structure, which takes the speech of the source language as input and directly outputs its translation result in the target language. Since the model performs cross-modal translation, it needs to extract semantically rich representations from speech. Compared with text, speech is fine-grained and contains more noise, which puts a great burden on the encoder of the ST model. The modal gap between speech and text usually causes the ST model to perform inferior to the corresponding machine translation (MT) model. To bridge the cross-modal gap, this paper proposes to use adversarial training to relieve the burden on the ST encoder by providing internal supervision signals. In this approach, the encoder in the ST model can extract representations that contain rich semantics, which greatly improves performance. Experiments on the datasets of Augmented Librispeech English-French and MuST-C English-German show the effectiveness of our method. Further analysis indicates that our proposed method can perform well in low-resource conditions compared to strong baselines.'},\n",
       " '10.1093/BIOMET/34.1-2.28': {'title': \"THE GENERALIZATION OF ‘STUDENT'S’ PROBLEM WHEN SEVERAL DIFFERENT POPULATION VARLANCES ARE INVOLVED\",\n",
       "  'abstract': \"Journal Article THE GENERALIZATION OF ‘STUDENT'S’ PROBLEM WHEN SEVERAL DIFFERENT POPULATION VARLANCES ARE INVOLVED Get access B. L. WELCH, B.A., PH.D. B. L. WELCH, B.A., PH.D. Search for other works by this author on: Oxford Academic Google Scholar Biometrika, Volume 34, Issue 1-2, January 1947, Pages 28–35, https://doi.org/10.1093/biomet/34.1-2.28 Published: 01 January 1947\"},\n",
       " '10.1007/978-3-030-34146-6_22': {'title': 'Representing the Filter Bubble: Towards a Model to Diversification in News',\n",
       "  'abstract': 'Filtering techniques like recommender systems are commonly employed to help people selecting items that best fit their conceptual needs. Although many benefits, recommender systems can put the user inside a filter-bubble given their high focus on similarity measures. This effect tends to limit user experiences, discovering new things, and so on. In the news domain, filter-bubbles are quite critical once they are means of changing people opinions. Therefore we propose a diversification approach to pop the bubble through a representation model based on points of view.'},\n",
       " '10.1111/J.1468-0149.1981.TB02709.X': {'title': '<i>Naming and necessity</i>.',\n",
       "  'abstract': 'Philosophical BooksVolume 22, Issue 1 p. 36-37 Naming and necessity. J. E. J. ALTHAM, J. E. J. ALTHAM GONVILLE AND CAIUS COLLEGE CAMBRIDGESearch for more papers by this author J. E. J. ALTHAM, J. E. J. ALTHAM GONVILLE AND CAIUS COLLEGE CAMBRIDGESearch for more papers by this author First published: January 1981 https://doi.org/10.1111/j.1468-0149.1981.tb02709.xRead the full textAboutPDF ToolsRequest permissionExport citationAdd to favoritesTrack citation ShareShare Give accessShare full text accessShare full-text accessPlease review our Terms and Conditions of Use and check box below to share full-text version of article.I have read and accept the Wiley Online Library Terms and Conditions of UseShareable LinkUse the link below to share a full-text version of this article with your friends and colleagues. Learn more.Copy URL Share a linkShare onFacebookTwitterLinked InRedditWechat No abstract is available for this article. Volume22, Issue1January 1981Pages 36-37 RelatedInformation'},\n",
       " '10.1007/s10579-012-9179-y': {'title': 'Multilingual and cross-domain temporal tagging',\n",
       "  'abstract': 'Extraction and normalization of temporal expressions from documents are important steps towards deep text understanding and a prerequisite for many NLP tasks such as information extraction, question answering, and document summarization. There are different ways to express (the same) temporal information in documents. However, after identifying temporal expressions, they can be normalized according to some standard format. This allows the usage of temporal information in a term- and language-independent way. In this paper, we describe the challenges of temporal tagging in different domains, give an overview of existing annotated corpora, and survey existing approaches for temporal tagging. Finally, we present our publicly available temporal tagger HeidelTime, which is easily extensible to further languages due to its strict separation of source code and language resources like patterns and rules. We present a broad evaluation on multiple languages and domains on existing corpora as well as on a newly created corpus for a language/domain combination for which no annotated corpus has been available so far.'},\n",
       " '10.1007/978-3-030-01267-0_10': {'title': 'Visual Coreference Resolution in Visual Dialog Using Neural Module Networks',\n",
       "  'abstract': 'Visual dialog entails answering a series of questions grounded in an image, using dialog history as context. In addition to the challenges found in visual question answering (VQA), which can be seen as one-round dialog, visual dialog encompasses several more. We focus on one such problem called visual coreference resolution that involves determining which words, typically noun phrases and pronouns, co-refer to the same entity/object instance in an image. This is crucial, especially for pronouns (e.g., ‘it’), as the dialog agent must first link it to a previous coreference (e.g., ‘boat’), and only then can rely on the visual grounding of the coreference ‘boat’ to reason about the pronoun ‘it’. Prior work (in visual dialog) models visual coreference resolution either (a) implicitly via a memory network over history, or (b) at a coarse level for the entire question; and not explicitly at a phrase level of granularity. In this work, we propose a neural module network architecture for visual dialog by introducing two novel modules—Refer and Exclude—that perform explicit, grounded, coreference resolution at a finer word level. We demonstrate the effectiveness of our model on MNIST Dialog, a visually simple yet coreference-wise complex dataset, by achieving near perfect accuracy, and on VisDial, a large and challenging visual dialog dataset on real images, where our model outperforms other approaches, and is more interpretable, grounded, and consistent qualitatively.'},\n",
       " '10.1007/978-3-030-01228-1_24': {'title': 'Connecting Gaze, Scene, and Attention: Generalized Attention Estimation via Joint Modeling of Gaze and Scene Saliency',\n",
       "  'abstract': 'This paper addresses the challenging problem of estimating the general visual attention of people in images. Our proposed method is designed to work across multiple naturalistic social scenarios and provides a full picture of the subject’s attention and gaze. In contrast, earlier works on gaze and attention estimation have focused on constrained problems in more specific contexts. In particular, our model explicitly represents the gaze direction and handles out-of-frame gaze targets. We leverage three different datasets using a multi-task learning approach. We evaluate our method on widely used benchmarks for single-tasks such as gaze angle estimation and attention-within-an-image, as well as on the new challenging task of generalized visual attention prediction. In addition, we have created extended annotations for the MMDB and GazeFollow datasets which are used in our experiments, which we will publicly release.'},\n",
       " '10.1186/S13640-017-0235-9': {'title': 'Gated spatio and temporal convolutional neural network for activity recognition: towards gated multimodal deep learning',\n",
       "  'abstract': 'Human activity recognition requires both visual and temporal cues, making it challenging to integrate these important modalities. The usual schemes for integration are averaging and fixing the weights of both features for all samples. However, how much weight is needed for each sample and modality, is still an open question. A mixture of experts via a gating Convolutional Neural Network (CNN) is one promising architecture for adaptively weighting every sample within a dataset. In this paper, rather than just averaging or using fixed weights, we investigate how a natural associative cortex such as a network integrates expert networks to form a gating CNN scheme. Starting from Red Green Blue color model (RGB) values and optical flows, we show that with proper treatment, the gating CNN scheme works well, indicating future approaches to information integration in future activity recognition.'},\n",
       " '10.1007/s10462-023-10471-x': {'title': 'A systematic review of the use of topic models for short text social media analysis',\n",
       "  'abstract': 'Abstract Recently, research on short text topic models has addressed the challenges of social media datasets. These models are typically evaluated using automated measures. However, recent work suggests that these evaluation measures do not inform whether the topics produced can yield meaningful insights for those examining social media data. Efforts to address this issue, including gauging the alignment between automated and human evaluation tasks, are hampered by a lack of knowledge about how researchers use topic models. Further problems could arise if researchers do not construct topic models optimally or use them in a way that exceeds the models’ limitations. These scenarios threaten the validity of topic model development and the insights produced by researchers employing topic modelling as a methodology. However, there is currently a lack of information about how and why topic models are used in applied research. As such, we performed a systematic literature review of 189 articles where topic modelling was used for social media analysis to understand how and why topic models are used for social media analysis. Our results suggest that the development of topic models is not aligned with the needs of those who use them for social media analysis. We have found that researchers use topic models sub-optimally. There is a lack of methodological support for researchers to build and interpret topics. We offer a set of recommendations for topic model researchers to address these problems and bridge the gap between development and applied research on short text topic models.'},\n",
       " '10.1007/978-3-030-97546-3_30': {'title': 'Beyond Topics: Discovering Latent Healthcare Objectives from Event Sequences',\n",
       "  'abstract': \"A meaningful understanding of clinical protocols and patient pathways helps improve healthcare outcomes. Electronic health records (EHR) reflect real-world treatment behaviours that are used to enhance healthcare management but present challenges; protocols and pathways are often loosely defined and with elements frequently not recorded in EHRs, complicating the enhancement. To solve this challenge, healthcare objectives associated with healthcare management activities can be indirectly observed in EHRs as latent topics. Topic models, such as Latent Dirichlet Allocation (LDA), are used to identify latent patterns in EHR data. However, they do not examine the ordered nature of EHR sequences, nor do they appraise individual events in isolation. Our novel approach, the Categorical Sequence Encoder (CaSE) addresses these shortcomings. The sequential nature of EHRs is captured by CaSE's event-level representations, revealing latent healthcare objectives. In synthetic EHR sequences, CaSE outperforms LDA by up to 37% at identifying healthcare objectives. In the real-world MIMIC-III dataset, CaSE identifies meaningful representations that could critically enhance protocol and pathway development.\"},\n",
       " '10.1007/978-3-031-33617-1': {'title': 'Generative Methods for Social Media Analysis',\n",
       "  'abstract': 'This book provides a broad overview of the state of the art of the research in generative methods for the analysis of social media data.'},\n",
       " '10.1016/j.ins.2024.120217': {'title': 'Federated distillation and blockchain empowered secure knowledge sharing for Internet of medical Things',\n",
       "  'abstract': 'With the development of Internet of Things (IoT) and Artificial Intelligence (AI) technologies, smart services have penetrated into every aspect of our daily lives, including the medical treatment and healthcare fields. However, due to security and privacy issues, medical data cannot be easily shared, which may lead to the situation of the so-called data silos. Challenges in existing approaches when building medical data sharing models can be summarized as: i) It is very challenging to ensure that the privacy of the medical data is protected and to identify the ownership of medical data; ii) Their models always result in poor performance or have the problem of excessive communication overhead due to the large amount of model parameters; iii) The current scenario of combining federated learning and blockchain generally ignores the load on nodes, which may easily lead to a lack of efficiency and fairness during the consensus process. In this study, we propose a Federated Distillation and Blockchain empowered Secure Knowledge Sharing (FDBC-SKS) model, which transforms the data sharing problem into a collaborative model knowledge sharing problem, aiming to provide a lightweight distributed deep learning framework in Internet of Medical Things (IoMT) environments. A peer-to-peer federated distillation mechanism is designed to enable a decentralized federated learning with better model flexibility and less communication consumption, based on the better knowledge utilization from each local model. A reinforcement learning enhanced consensus mechanism for blockchain is devised to improve the model convergence performance, alleviate the problem of low computational efficiency, while enhancing the fairness in terms of node load balancing during the node selection and block generation process. Experiment and evaluation results based on two real-world datasets demonstrate the usefulness of our proposed model toward secure and effective data sharing in IoMT oriented smart application development compared with other similar methods.'},\n",
       " '10.1016/j.jisa.2023.103621': {'title': 'Insights into security and privacy issues in smart healthcare systems based on medical images',\n",
       "  'abstract': 'The advent of the fourth industrial revolution along with developments in other emerging technologies, such as Internet of Things, big data, artificial intelligence as well as cloud and quantum computing, smart healthcare systems (SHS) are becoming ubiquitous in our daily lives. Meanwhile, patients, doctors, and other medical personnel rely on the safe and efficient storage, transmission, and analysis of medical images and electronic health records for successful diagnosis, treatment, and management of different ailments. Moreover since, for various reasons, medical images are always the target of different illicit criminal activities, studies to utilise advanced information technologies to safeguard the confidentiality, integrity, and availability of such data have become a major priority in all SHS platforms. Our study evaluates recent efforts to deploy emerging technologies to design, secure, and enhance the efficiency of SHS that are based on medical images. It is hoped that this work will stimulate further interest aimed at the pursuit of more advanced algorithms and frameworks covering all aspects of security and privacy in emerging and future smart healthcare applications.'},\n",
       " '10.1038/s41467-023-38794-x': {'title': 'Differentially private knowledge transfer for federated learning',\n",
       "  'abstract': 'Extracting useful knowledge from big data is important for machine learning. When data is privacy-sensitive and cannot be directly collected, federated learning is a promising option that extracts knowledge from decentralized data by learning and exchanging model parameters, rather than raw data. However, model parameters may encode not only non-private knowledge but also private information of local data, thereby transferring knowledge via model parameters is not privacy-secure. Here, we present a knowledge transfer method named PrivateKT, which uses actively selected small public data to transfer high-quality knowledge in federated learning with privacy guarantees. We verify PrivateKT on three different datasets, and results show that PrivateKT can maximally reduce 84% of the performance gap between centralized learning and existing federated learning methods under strict differential privacy restrictions. PrivateKT provides a potential direction to effective and privacy-preserving knowledge transfer in machine intelligent systems.'},\n",
       " '10.1007/s10618-023-00946-4': {'title': 'MrTF: model refinery for transductive federated learning',\n",
       "  'abstract': 'We consider a real-world scenario in which a newly-established pilot project needs to make inferences for newly-collected data with the help of other parties under privacy protection policies. Current federated learning (FL) paradigms are devoted to solving the data heterogeneity problem without considering the to-be-inferred data. We propose a novel learning paradigm named transductive federated learning to simultaneously consider the structural information of the to-be-inferred data. On the one hand, the server could use the pre-available test samples to refine the aggregated models for robust model fusion, which tackles the data heterogeneity problem in FL. On the other hand, the refinery process incorporates test samples into training and could generate better predictions in a transductive manner. We propose several techniques including stabilized teachers, rectified distillation, and clustered label refinery to facilitate the model refinery process. Abundant experimental studies verify the superiorities of the proposed Model refinery framework for Transductive Federated learning. The source code is available at https://github.com/lxcnju/MrTF .'},\n",
       " '10.1038/s41467-023-44383-9': {'title': 'Selective knowledge sharing for privacy-preserving federated distillation without a good teacher',\n",
       "  'abstract': 'Abstract While federated learning (FL) is promising for efficient collaborative learning without revealing local data, it remains vulnerable to white-box privacy attacks, suffers from high communication overhead, and struggles to adapt to heterogeneous models. Federated distillation (FD) emerges as an alternative paradigm to tackle these challenges, which transfers knowledge among clients instead of model parameters. Nevertheless, challenges arise due to variations in local data distributions and the absence of a well-trained teacher model, which leads to misleading and ambiguous knowledge sharing that significantly degrades model performance. To address these issues, this paper proposes a selective knowledge sharing mechanism for FD, termed Selective-FD , to identify accurate and precise knowledge from local and ensemble predictions, respectively. Empirical studies, backed by theoretical insights, demonstrate that our approach enhances the generalization capabilities of the FD framework and consistently outperforms baseline methods. We anticipate our study to enable a privacy-preserving, communication-efficient, and heterogeneity-adaptive federated training framework.'},\n",
       " '10.1038/s41598-023-27481-y': {'title': 'Evaluation of the portability of computable phenotypes with natural language processing in the eMERGE network',\n",
       "  'abstract': 'The electronic Medical Records and Genomics (eMERGE) Network assessed the feasibility of deploying portable phenotype rule-based algorithms with natural language processing (NLP) components added to improve performance of existing algorithms using electronic health records (EHRs). Based on scientific merit and predicted difficulty, eMERGE selected six existing phenotypes to enhance with NLP. We assessed performance, portability, and ease of use. We summarized lessons learned by: (1) challenges; (2) best practices to address challenges based on existing evidence and/or eMERGE experience; and (3) opportunities for future research. Adding NLP resulted in improved, or the same, precision and/or recall for all but one algorithm. Portability, phenotyping workflow/process, and technology were major themes. With NLP, development and validation took longer. Besides portability of NLP technology and algorithm replicability, factors to ensure success include privacy protection, technical infrastructure setup, intellectual property agreement, and efficient communication. Workflow improvements can improve communication and reduce implementation time. NLP performance varied mainly due to clinical document heterogeneity; therefore, we suggest using semi-structured notes, comprehensive documentation, and customization options. NLP portability is possible with improved phenotype algorithm performance, but careful planning and architecture of the algorithms is essential to support local customizations.'},\n",
       " '10.1016/j.eswa.2022.119216': {'title': 'A distributed joint extraction framework for sedimentological entities and relations with federated learning',\n",
       "  'abstract': 'Sedimentological knowledge graphs can be used to identify natural resources in earth layers, which may help geologists analyze the distribution of oil crude in earth, and therefore locating the oilfield that is unknown. The building of such knowledge graphs mainly counts on the methods of joint extraction for pairwise entities and the corresponding relations on large-scale data. However, the whole sedimentological data is fairly owned by the different parties with the possibly inconsistent format. Centralized processing on sedimentological data as a whole will be either securely or structurally impractical. Therefore, this paper proposes a framework of distributed joint extraction in order to harvest knowledge triplets on distributed sedimentological corpus that are from many disparate sources without data transmission. The experimental studies demonstrate our methods not only approach the previous state-of-the-art but also protect the data privacy and security for data holders.'},\n",
       " '10.1016/j.knosys.2022.109459': {'title': 'Federated knowledge graph completion via embedding-contrastive learning',\n",
       "  'abstract': 'Recently, the research about knowledge graphs (KGs) which contain a large number of triples, has gained massive attention. Many knowledge graph embedding methods are proposed to tackle the knowledge graph completion task. In real applications, knowledge graphs are applied not only in a centralized way but also in a decentralized manner. We study the problem of learning knowledge graph embeddings for a set of federated knowledge graphs, where their raw triples are not allowed to be collected together. We propose a federated learning framework FedEC. In our framework, a local training procedure is responsible for learning knowledge graph embeddings on each client based on a specific embedding learner. We apply embedding-contrastive learning to limit the embedding update for tackling data heterogeneity. Moreover, a global update procedure is used for sharing and averaging entity embeddings on the master server. Furthermore, we design embedding ensemble procedures to take full advantage of knowledge learned from different aspects. Finally, we conduct extensive experiments on datasets derived from KGE benchmark datasets, and the results show the effectiveness of our proposed model.'},\n",
       " '10.1007/s10489-022-04431-1': {'title': 'FedDKD: Federated learning with decentralized knowledge distillation',\n",
       "  'abstract': 'The heterogeneity of the data distribution generally influences federated learning performance in neural networks. For a well-performing global model, taking a weighted average of the local models, as in most existing federated learning algorithms, may not guarantee consistency with local models in the space of neural network maps. In this paper, we highlight the significance of the space of neural network maps to relieve the performance decay produced by data heterogeneity and propose a novel federated learning framework equipped with the decentralized knowledge distillation process (FedDKD). In FedDKD, we introduce a decentralized knowledge distillation (DKD) module to distill the knowledge of local models to teach the global model approaching the neural network map average by optimizing the divergence defined in the loss function, other than only averaging parameters as in the literature. Numerical experiments on various heterogeneous datasets reveal that FedDKD outperforms the state-of-the-art methods, especially on some extremely heterogeneous datasets.'},\n",
       " '10.1038/s41467-022-29763-x': {'title': 'Communication-efficient federated learning via knowledge distillation',\n",
       "  'abstract': 'Federated learning is a privacy-preserving machine learning technique to train intelligent models from decentralized data, which enables exploiting private data by communicating local model updates in each iteration of model learning rather than the raw data. However, model updates can be extremely large if they contain numerous parameters, and many rounds of communication are needed for model training. The huge communication cost in federated learning leads to heavy overheads on clients and high environmental burdens. Here, we present a federated learning method named FedKD that is both communication-efficient and effective, based on adaptive mutual knowledge distillation and dynamic gradient compression techniques. FedKD is validated on three different scenarios that need privacy protection, showing that it maximally can reduce 94.89% of communication cost and achieve competitive results with centralized model learning. FedKD provides a potential to efficiently deploy privacy-preserving intelligent systems in many scenarios, such as intelligent healthcare and personalization.'},\n",
       " '10.1007/s10796-021-10144-6': {'title': 'FedDPGAN: Federated Differentially Private Generative Adversarial Networks Framework for the Detection of COVID-19 Pneumonia',\n",
       "  'abstract': 'Existing deep learning technologies generally learn the features of chest X-ray data generated by Generative Adversarial Networks (GAN) to diagnose COVID-19 pneumonia. However, the above methods have a critical challenge: data privacy. GAN will leak the semantic information of the training data which can be used to reconstruct the training samples by attackers, thereby this method will leak the privacy of the patient. Furthermore, for this reason, that is the limitation of the training data sample, different hospitals jointly train the model through data sharing, which will also cause privacy leakage. To solve this problem, we adopt the Federated Learning (FL) framework, a new technique being used to protect data privacy. Under the FL framework and Differentially Private thinking, we propose a Federated Differentially Private Generative Adversarial Network (FedDPGAN) to detect COVID-19 pneumonia for sustainable smart cities. Specifically, we use DP-GAN to privately generate diverse patient data in which differential privacy technology is introduced to make sure the privacy protection of the semantic information of the training dataset. Furthermore, we leverage FL to allow hospitals to collaboratively train COVID-19 models without sharing the original data. Under Independent and Identically Distributed (IID) and non-IID settings, the evaluation of the proposed model is on three types of chest X-ray (CXR)images dataset (COVID-19, normal, and normal pneumonia). A large number of truthful reports make the verification of our model can effectively diagnose COVID-19 without compromising privacy.'},\n",
       " '10.1007/978-3-030-89847-2_4': {'title': 'A Federated Multigraph Integration Approach for Connectional Brain Template Learning',\n",
       "  'abstract': 'The connectional brain template (CBT) is a compact representation (i.e., a single connectivity matrix) multi-view brain networks of a given population. CBTs are especially very powerful tools in brain dysconnectivity diagnosis as well as holistic brain mapping if they are learned properly – i.e., occupy the center of the given population. Even though accessing large-scale datasets is much easier nowadays, it is still challenging to upload all these clinical datasets in a server altogether due to the data privacy and sensitivity. Federated learning, on the other hand, has opened a new era for machine learning algorithms where different computers are trained together via a distributed system. Each computer (i.e., a client) connected to a server, trains a model with its local dataset and sends its learnt model weights back to the server. Then, the server aggregates these weights thereby outputting global model weights encapsulating information drawn from different datasets in a privacy-preserving manner. Such a pipeline endows the global model with a generalizability power as it implicitly benefits from the diversity of the local datasets. In this work, we propose the first federated connectional brain template learning (Fed-CBT) framework to learn how to integrate multi-view brain connectomic datasets collected by different hospitals into a single representative connectivity map. First, we choose a random fraction of hospitals to train our global model. Next, all hospitals send their model weights to the server to aggregate them. We also introduce a weighting method for aggregating model weights to take full benefit from all hospitals. Our model to the best of our knowledge is the first and only federated pipeline to estimate connectional brain templates using graph neural networks. Our Fed-CBT code is available at https://github.com/basiralab/Fed-CBT.'},\n",
       " '10.1016/j.jbi.2015.03.002': {'title': 'Extracting drug–drug interactions from literature using a rich feature-based linear kernel approach',\n",
       "  'abstract': 'Identifying unknown drug interactions is of great benefit in the early detection of adverse drug reactions. Despite existence of several resources for drug-drug interaction (DDI) information, the wealth of such information is buried in a body of unstructured medical text which is growing exponentially. This calls for developing text mining techniques for identifying DDIs. The state-of-the-art DDI extraction methods use Support Vector Machines (SVMs) with non-linear composite kernels to explore diverse contexts in literature. While computationally less expensive, linear kernel-based systems have not achieved a comparable performance in DDI extraction tasks. In this work, we propose an efficient and scalable system using a linear kernel to identify DDI information. The proposed approach consists of two steps: identifying DDIs and assigning one of four different DDI types to the predicted drug pairs. We demonstrate that when equipped with a rich set of lexical and syntactic features, a linear SVM classifier is able to achieve a competitive performance in detecting DDIs. In addition, the one-against-one strategy proves vital for addressing an imbalance issue in DDI type classification. Applied to the DDIExtraction 2013 corpus, our system achieves an F1 score of 0.670, as compared to 0.651 and 0.609 reported by the top two participating teams in the DDIExtraction 2013 challenge, both based on non-linear kernel methods.'},\n",
       " '10.1186/s12859-015-0472-9': {'title': 'Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research',\n",
       "  'abstract': 'Current biomedical research needs to leverage and exploit the large amount of information reported in scientific publications. Automated text mining approaches, in particular those aimed at finding relationships between entities, are key for identification of actionable knowledge from free text repositories. We present the BeFree system aimed at identifying relationships between biomedical entities with a special focus on genes and their associated diseases. By exploiting morpho-syntactic information of the text, BeFree is able to identify gene-disease, drug-disease and drug-target associations with state-of-the-art performance. The application of BeFree to real-case scenarios shows its effectiveness in extracting information relevant for translational research. We show the value of the gene-disease associations extracted by BeFree through a number of analyses and integration with other data sources. BeFree succeeds in identifying genes associated to a major cause of morbidity worldwide, depression, which are not present in other public resources. Moreover, large-scale extraction and analysis of gene-disease associations, and integration with current biomedical knowledge, provided interesting insights on the kind of information that can be found in the literature, and raised challenges regarding data prioritization and curation. We found that only a small proportion of the gene-disease associations discovered by using BeFree is collected in expert-curated databases. Thus, there is a pressing need to find alternative strategies to manual curation, in order to review, prioritize and curate text-mining data and incorporate it into domain-specific databases. We present our strategy for data prioritization and discuss its implications for supporting biomedical research and applications. BeFree is a novel text mining system that performs competitively for the identification of gene-disease, drug-disease and drug-target associations. Our analyses show that mining only a small fraction of MEDLINE results in a large dataset of gene-disease associations, and only a small proportion of this dataset is actually recorded in curated resources (2%), raising several issues on data prioritization and curation. We propose that joint analysis of text mined data with data curated by experts appears as a suitable approach to both assess data quality and highlight novel and interesting information.'},\n",
       " '10.1016/j.jbi.2012.04.004': {'title': 'The EU-ADR corpus: Annotated drugs, diseases, targets, and their relationships',\n",
       "  'abstract': 'Corpora with specific entities and relationships annotated are essential to train and evaluate text-mining systems that are developed to extract specific structured information from a large corpus. In this paper we describe an approach where a named-entity recognition system produces a first annotation and annotators revise this annotation using a web-based interface. The agreement figures achieved show that the inter-annotator agreement is much better than the agreement with the system provided annotations. The corpus has been annotated for drugs, disorders, genes and their inter-relationships. For each of the drug-disorder, drug-target, and target-disorder relations three experts have annotated a set of 100 abstracts. These annotated relationships will be used to train and evaluate text-mining software to capture these relationships in texts.'},\n",
       " '10.1080/10273660600818264': {'title': 'Computational and Mathematical Methods in Medicine',\n",
       "  'abstract': 'This issue sees the launch of a new look and philosophy to publishing research in the broad area of mathematical modelling in medicine.In its previous format, the \"Journal of Theoretical Medicine\" aimed to provide a forum for the dissemination of original research emanating from collaborations between theoreticians and experimentalists.While the Journal has run successfully since 1997, it has become apparent in recent years that the broad umbrella of theoretical medicine has expanded and diversified to incorporate not only areas of traditional mathematical biology but also into areas such as proteomics and systems biology.In addition, this activity has called for a deeper understanding of mathematical models and the techniques used for their analysis.'},\n",
       " '10.1016/j.eswa.2023.122936': {'title': 'Lexicon-based prompt for financial dimensional sentiment analysis',\n",
       "  'abstract': 'Financial sentiment analysis attempts to identify the sentiment of a sentence using dimensional or categorical approaches. The dimensional approach represents affective states as continuous numerical values and can provide more fine-grained (real-valued) sentiment analysis than the categorical approach, which represents affective states as several discrete classes (e.g., positive and negative). Although categorical approaches have been studied extensively over the past decade, the lack of domain-specific data makes it challenging to use dimensional approaches in financial domains. To solve this problem, we propose a lexicon-based prompt method for domains with no labeled data by introducing domain-specific lexicons to correct mispredicted words. As this method does not apply domain-adaptation techniques, it can be combined with domain-adaptation methods to improve the generalizability of domain-specific sentiment analysis further. Experiments on various pre-training language modes in the finance domain show that the proposed lexicon-based prompt method outperforms common domain adaptation methods, and the best performance is achieved by combining multi-task fine-tuning and domain adaptation methods.'},\n",
       " '10.1016/j.jksuci.2023.101799': {'title': 'BDBRC: A Chinese military entity recognition model combining context contribution and residual dilatation convolutional networks',\n",
       "  'abstract': 'Military information is gradually overloaded due to the diversity of sources and the exponential growth in quantity, which greatly affects the accuracy of intelligence personnel in extracting and analyzing military information. The modern warfare approach has also evolved from the traditional physical domain to the cognitive domain, and competing for advantages in the cognitive domain has become a key objective of combat. Therefore, constructing domain knowledge graphs and mining the relationships between data play an important role in cognitive domain analysis. In this paper, we propose a convolutional network recognition method based on improved two-layer bi-directional BiLSTM networks named the BERT-α BiLSTMs-RECNN-CRF (BDBRC) model. For the difficulties of military entities generally having long names and low extraction accuracy, as well as the existence of a large number of composite entities that are difficult to recognize, an improved two-layer BiLSTM model is devised first. In view of the fact that the BiLSTMs model always extracts features equally in long-distance text sequences without actually considering the different influences of different sentence contexts, contribution factor a is added to extract the contribution of the above and below to the target entity in different sentences respectively. Then, aiming at the strong problem of the domain of military news texts and the high level of inter-entity ambiguity, we propose a method that utilizes a modified convolutional network (RECNN) for partial feature extraction and jointly with a modified two-layer BiLSTM network for entity recognition. The experiment on the self-constructed dataset shows that the F1 value of the model proposed in this paper reaches 93.18%, and the F1 value, P, and H of our model are all better than the baseline model, which verifies the performance of the model. At the same time, we use public data sets MSRA and CLUB2020, and the experimental results show that the model proposed in this paper also has a good performance in the public data set, verifying the universality of the model. It can provide methodological support for the construction of the military knowledge graph.'},\n",
       " '10.1016/j.ins.2022.12.049': {'title': 'Chinese named entity recognition method for the finance domain based on enhanced features and pretrained language models',\n",
       "  'abstract': 'For some named entities in the Chinese finance domain that are long, with difficult to delineate boundaries and diverse forms of expression, we propose a method based on pretrained language models for named entity recognition with enhanced features. First, the method considers entity boundary delineation and entity classification as two separate tasks and learns enhanced Chinese character features by introducing a gating-based multi-channel attention mechanism to delineate financial entity boundaries on the basis of a pretrained language model. Then, the boundary demarcation results are input into the pretrained language model in the form of mask units for data enhancement. Subsequently, document-level entity-based enhancement features are introduced to construct a finance entity classification model. We experimentally identified the best-performing Chinese pretrained language model from several state-of-the-art models and then embedded it into our method to compare against other benchmark models. The experimental results showed that our model is superior to other benchmark models on the named entity recognition task in the finance domain.'},\n",
       " '10.1016/j.engappai.2022.105460': {'title': 'UD_BBC: Named entity recognition in social network combined BERT-BiLSTM-CRF with active learning',\n",
       "  'abstract': 'With the rapid growth of Internet penetration, more and more people choose the Internet to express their views on topics of interest. In recent years, named entity recognition (NER) is becoming a popular task for the public to obtain structured information from public opinion text. At present, NER models with good results, such as deep learning model, need a lot of labeled data for training. However, this will give rise to a problem: labeling a large amount of data requires a lot of human resources, which is thankless in some areas. Therefore, in this paper, we propose a NER model combining active learning and deep learning methods. Firstly, the active learning method can solve the above problem. The strategy combines uncertainty-based sampling and diversity-based sampling to estimate the information of data. We use highly informative data as the initial training dataset. Secondly, this paper uses a deep learning model combining bidirectional encoder representations from Transformers, bidirectional long–short-term memory and conditional random field (BERT-BiLSTM-CRF). BERT extracts the semantic features of data, and BiLSTM predicts the probability distribution of entity labels. We use the CRF for decoding the probability distribution into corresponding entity labels. Finally, we use the initial training dataset for training BERT-BiLSTM-CRF. This model predicts the entity labels of the unlabeled data. Then, we judge if the machine-labeled data is highly reliable and expand the highly reliable data to the initial training dataset. The updated dataset retrains the NER model, so that the trained model has higher precision than the previous model. The results show that our model performs well without a large number of labeled datasets. The model achieves a precision value of 70.31%, recall rate of 74.93% and F1 score of 72.55% in the named entity recognition task, which proves the effectiveness of our model. Besides, the F1 score of BERT-BiLSTM-CRF with uncertainty-based sampling and diversity-based sampling (UD_BBC) is higher than the BiLSTM-CRF based on maximum normalized log-probability (MNLP_BiLSTM-CRF) by 9.00%, when recognizing overall entity categories. It provides a solution to the problem of named entity recognition in educational public opinion.'},\n",
       " '10.1016/j.jbi.2022.104144': {'title': 'Multi-level semantic fusion network for Chinese medical named entity recognition',\n",
       "  'abstract': 'Medical named entity recognition (MNER) is a fundamental component of understanding the unstructured medical texts in electronic health records, and it has received widespread attention in both academia and industry. However, the previous approaches of MNER do not make full use of hierarchical semantics from morphology to syntactic relationships like word dependency. Furthermore, extracting entities from Chinese medical texts is a more complex task because it usually contains for example homophones or pictophonetic characters. In this paper, we propose a multi-level semantic fusion network for Chinese medical named entity recognition, which fuses semantic information on morphology, character, word and syntactic level. We take radical as morphology semantic, pinyin and character dictionary as character semantic, word dictionary as word semantic, and these semantic features are fused by BiLSTM to get the contextualized representation. Then we use a graph neural network to model word dependency as syntactic semantic to enhance the contextualized representation. The experimental results show the effectiveness of the proposed model on two public datasets and robustness in real-world scenarios.'},\n",
       " '10.1016/j.neucom.2022.06.019': {'title': 'Why KDAC? A general activation function for knowledge discovery',\n",
       "  'abstract': \"Deep learning oriented named entity recognition (DNER) has gradually become the paradigm of knowledge discovery, which greatly promotes domain intelligence. However, the activation function of DNER fails to treat gradient vanishing, no negative output or non-differentiable existence, which may impede the exploration of knowledge due to the omission and incomplete representation of the latent semantic. To break through the dilemma, we present a novel activation function termed KDAC. Detailly, KDAC is an aggregation function with multiple conversion modes. The backbone is the interaction between exponent and linearity, and the both ends are extended through adaptive linear divergence, which can surmount the gradient vanishing and no negative output. Crucially, the non-differentiable points can be alerted and eliminated by an approximate smoothing algorithm. KDAC has a series of brilliant properties, such as nonlinear, stable near-linear transformation and derivative, as well as dynamic style, etc. We perform experiments based on BERT-BiLSTM-CNN-CRF model on six benchmark datasets containing different domain knowledge, such as Weibo, Clinical, E-commerce, Resume, HAZOP and People's daily. The evaluation results show that KDAC is advanced and effective, and can provide more generalized activation to stimulate the performance of DNER. We hope that KDAC can be exploited as a promising activation function to devote itself to the construction of knowledge.\"},\n",
       " '10.1016/j.compbiomed.2019.04.002': {'title': 'Document-level attention-based BiLSTM-CRF incorporating disease dictionary for disease named entity recognition',\n",
       "  'abstract': 'Disease named entity recognition (NER) plays an important role in biomedical research. There are a significant number of challenging issues to be addressed; among these, the identification of rare diseases and complex disease names and the problem of tagging inconsistency (i.e., if an entity is tagged differently in a document) are attracting substantial research attention.We propose a new neural network method named Dic-Att-BiLSTM-CRF (DABLC) for disease NER. DABLC applies an efficient exact string matching method to match disease entities with a disease dictionary; here, the dictionary is constructed based on the Disease Ontology. Furthermore, DABLC constructs a dictionary attention layer by incorporating a disease dictionary matching method and document-level attention mechanism. Finally, a bidirectional long short-term memory network and conditional random field (BiLSTM-CRF) with a dictionary attention layer is proposed to combine the disease dictionary to develop disease NER.Extensive experiments are conducted on two widely-used corpora: the NCBI disease corpus and the BioCreative V CDR corpus. We apply each test on 10 executions of each model, with a 95% confidence interval. DABLC achieves the highest F1 scores (NCBI: Precision = 0.883, Recall = 0.89, F1 = 0.886; BioCreative V CDR: Precision = 0.891, Recall = 0.875, F1 = 0.883), outperforming the state-of-the-art methods.DABLC combines the advantages of both external dictionary resources and deep attention neural networks. This aids the identification of rare diseases and complex disease names; moreover, it reduces the impact of tagging inconsistency. Special disease NER and deep learning models addressing long sentences are noteworthy areas for future examination.'},\n",
       " '10.1007/978-3-642-14932-0_78': {'title': 'Chinese Named Entity Recognition with a Sequence Labeling Approach: Based on Characters, or Based on Words?',\n",
       "  'abstract': 'Named Entity Recognition (NER), an important problem of Natural Language Processing, is the basis for other applications, such as Data Mining and Relation Extraction. With a sequence labeling approach, this paper wants to answer which kind of tokens that should be taken as the graininess in NER task, characters or words. Meanwhile, we use not only local context features within a sentence, but also global knowledge features extracting from other occurrences of each word in the whole corpus. The results show that without the global features the person names and the location names have good result based on characters, but the organization names are more suitable based on words. When global features are added, the performance of based on words improved significantly.'},\n",
       " '10.1016/j.ijhcs.2009.03.004': {'title': 'Interacting meaningfully with machine learning systems: Three experiments',\n",
       "  'abstract': 'Although machine learning is becoming commonly used in today\\'s software, there has been little research into how end users might interact with machine learning systems, beyond communicating simple \"right/wrong\" judgments. If the users themselves could work hand-in-hand with machine learning systems, the users\\' understanding and trust of the system could improve and the accuracy of learning systems could be improved as well. We conducted three experiments to understand the potential for rich interactions between users and machine learning systems. The first experiment was a think-aloud study that investigated users\\' willingness to interact with machine learning reasoning, and what kinds of feedback users might give to machine learning systems. We then investigated the viability of introducing such feedback into machine learning systems, specifically, how to incorporate some of these types of user feedback into machine learning systems, and what their impact was on the accuracy of the system. Taken together, the results of our experiments show that supporting rich interactions between users and machine learning systems is feasible for both user and machine. This shows the potential of rich human–computer collaboration via on-the-spot interactions as a promising direction for machine learning systems and users to collaboratively share intelligence.'},\n",
       " '10.1007/978-3-030-28954-6_10': {'title': 'Layer-Wise Relevance Propagation: An Overview',\n",
       "  'abstract': 'For a machine learning model to generalize well, one needs to ensure that its decisions are supported by meaningful patterns in the input data. A prerequisite is however for the model to be able to explain itself, e.g. by highlighting which input features it uses to support its prediction. Layer-wise Relevance Propagation (LRP) is a technique that brings such explainability and scales to potentially highly complex deep neural networks. It operates by propagating the prediction backward in the neural network, using a set of purposely designed propagation rules. In this chapter, we give a concise introduction to LRP with a discussion of (1) how to implement propagation rules easily and efficiently, (2) how the propagation procedure can be theoretically justified as a ‘deep Taylor decomposition’, (3) how to choose the propagation rules at each layer to deliver high explanation quality, and (4) how LRP can be extended to handle a variety of machine learning scenarios beyond deep neural networks.'},\n",
       " '10.1007/s13369-021-05691-8': {'title': 'An Enhanced Gated Recurrent Unit with Auto-Encoder for Solving Text Classification Problems',\n",
       "  'abstract': 'Classification has become an important task for automatically categorizing documents based on their respective group. The purpose of classification is to assign the pre-specified group or class to an instance based on the observed features related to that instance. For accurate text classification, feature selection techniques are normally used to identify important features and to remove irrelevant, undesired and noisy features for minimizing the dimensionality of feature space. Therefore, in this research, a new model namely Encoder Simplified GRU (ES-GRU) is proposed to reduce dimension of data using an auto-encoder (AE). Gated Recurrent Unit (GRU) is a deep learning algorithm that contains update gate and reset gate, which is considered as one of the most efficient text classification technique, specifically on sequential datasets. Accordingly, the reset gate is replaced with an update gate in order to reduce the redundancy and complexity in the standard GRU. The proposed model has been evaluated on five benchmark text datasets and compared with six baseline well-known text classification approaches, which includes standard GRU, AE, Long Short-Term Memory, Convolutional Neural Network, Support Vector Machine, and Naïve Bayes. Based on various types of performance evaluation parameters, a considerable amount of improvement has been observed in the performance of the proposed model as compared to state-of-the-art approaches.'},\n",
       " '10.1016/j.nlp.2024.100067': {'title': 'Ensemble learning with soft-prompted pretrained language models for fact checking',\n",
       "  'abstract': 'The infectious diseases, such as COVID-19 pandemic, has led to a surge of information on the internet, including misinformation, necessitating fact-checking tools. However, fact-checking infectious diseases related claims pose challenges due to informal claims versus formal evidence and the presence of multiple aspects in a claim. To address these issues, we propose a soft prompt-based ensemble learning framework for COVID-19 fact checking. To understand complex assertions in informal social media texts, we explore various soft prompt structures to take advantage of the T5 language model, and ensemble these prompt structures together. Soft prompts offer flexibility and better generalization compared to hard prompts. The ensemble model captures linguistic cues and contextual information in COVID-19-related data, and thus enhances generalization to new claims. Experimental results demonstrate that prompt-based ensemble learning improves fact-checking accuracy and provides a promising approach to combat misinformation during the pandemic. In addition, the method also shows great zero-shot learning capability and thus can be applied to various fact checking problems.'},\n",
       " '10.1038/s44168-023-00072-3': {'title': 'Broadening scientific engagement and inclusivity in IPCC reports through collaborative technology platforms',\n",
       "  'abstract': 'Abstract The growing number of scientific publications on climate change has outstripped the capacity of individuals to keep up with the literature, even when confined to selected sub-topics such as chapter sections of IPCC reports. The IPCC would benefit from the assistance of modern technology, the engagement and insights of a far larger pool of experts, and more frequent updates. Here we describe how technology can be tailored to provide asynchronous and connected platforms that can enhance expert’s collaborations through their potential for scalability and inclusivity, and help keep assessments up-to-date. We detail our experience with the ScienceBrief.org platform, which was developed and used during 2017–2021. We show that the timely release of short scientific briefs (e.g. on wildfires), made possible by the platform, led to broad and accurate coverage of science in mainstream and social media, including policy-oriented websites, and therefore served to broaden public exposure and understanding of science, and counter climate misinformation. While a good visual interface and user flow were necessary, incentives were key for expert’s engagement with the platform, which, while positive, remained low. We suggest that a collaborative technology platform like ScienceBrief, tailored to support a modernised process of elaborating IPCC reports, could greatly enhance IPCC assessments by making them more open and accessible, further increasing transparency. It would also enable the comprehensive inclusion of evidence and facilitate broad and high-quality scientific engagement, including from early careers and scientists from around the world. This could first be tested at the scoping stage.'},\n",
       " '10.1007/s40747-022-00806-6': {'title': 'Scholarly knowledge graphs through structuring scholarly communication: a review',\n",
       "  'abstract': 'Abstract The necessity for scholarly knowledge mining and management has grown significantly as academic literature and its linkages to authors produce enormously. Information extraction, ontology matching, and accessing academic components with relations have become more critical than ever. Therefore, with the advancement of scientific literature, scholarly knowledge graphs have become critical to various applications where semantics can impart meanings to concepts. The objective of study is to report a literature review regarding knowledge graph construction, refinement and utilization in scholarly domain. Based on scholarly literature, the study presents a complete assessment of current state-of-the-art techniques. We presented an analytical methodology to investigate the existing status of scholarly knowledge graphs (SKG) by structuring scholarly communication. This review paper investigates the field of applying machine learning, rule-based learning, and natural language processing tools and approaches to construct SKG. It further presents the review of knowledge graph utilization and refinement to provide a view of current research efforts. In addition, we offer existing applications and challenges across the board in construction, refinement and utilization collectively. This research will help to identify frontier trends of SKG which will motivate future researchers to carry forward their work.'},\n",
       " '10.31590/ejosat.1043441': {'title': 'Designing An Information Framework For Semantic Search',\n",
       "  'abstract': 'New generation information retrieval procedures provide complex tools to remodel the design of search engines.Even though semantic analysis is gradually adopted by corporations, complex behavior of knowledge behind the information entails subsequent data learning models.Text models are currently in use through lexical features.Search engines with lexical methods lack contextual and semantic information.This barrier has been overcome with the development of deep learning methods.More accurate results can be retrieved by obtaining contextual information of different types of content such as text, image, video with neural models.In this study, a broad perspective of search engines was considered through lexical and semantic features.Semantic search methods were experimented then compared with lexical methods in data sets consisting of scientific documents.Since scientific documents are relatively well-formatted datasets and do not contain irrelevant content, the focus was on comparing semantic search methods and neural models throughout the study, without dealing with out-of-context data and semantic conflicts.As a result, semantic search methods performed better than lexical search.We conclude that current search-retrieval tasks require new perspectives in semantics where multimodal information is handled with deep learning strategies.'},\n",
       " '10.1016/j.joi.2022.101262': {'title': 'Distinguishing transformative from incremental clinical evidence: A classifier of clinical research using textual features from abstracts and citing sentences',\n",
       "  'abstract': 'In clinical research and clinical decision-making, it is important to know if a study changes or only supports the current standards of care for specific disease management. We define such a change as transformative and a support as incremental research. It usually requires a huge amount of domain expertise and time for humans to finish such tasks. Faculty Opinions provides us with a well-annotated corpus on whether a research challenges or only confirms established research. In this study, a machine learning approach is proposed to distinguishing transformative from incremental clinical evidence. The texts from both abstract and a 2-year window of citing sentences are collected for a training set of clinical studies recommended and labeled by Faculty Opinions experts. We achieve the best performance with an average AUC of 0.755 (0.705–0.875) using Random Forest as the classifier and citing sentences as the feature. The results showed that transformative research has more typical language patterns in citing sentences than abstract sentences. We provide an efficient tool for identifying those clinical evidence challenging or only confirming established claims for clinicians and researchers.'},\n",
       " '10.1007/978-3-031-13643-6_28': {'title': 'Overview of the CLEF 2022 SimpleText Lab: Automatic Simplification of Scientific Texts',\n",
       "  'abstract': 'Although citizens agree on the importance of objective scientific information, yet they tend to avoid scientific literature due to access restrictions, its complex language or their lack of prior background knowledge. Instead, they rely on shallow information on the web or social media often published for commercial or political incentives rather than the correctness and informational value. This paper presents an overview of the CLEF 2022 SimpleText track addressing the challenges of text simplification approaches in the context of promoting scientific information access, by providing appropriate data and benchmarks, and creating a community of IR and NLP researchers working together to resolve one of the greatest challenges of today. The track provides a corpus of scientific literature abstracts and popular science requests. It features three tasks. First, content selection (what is in, or out?) challenges systems to select passages to include in a simplified summary in response to a query. Second, complexity spotting (what is unclear?) given a passage and a query, aims to rank terms/concepts that are required to be explained for understanding this passage (definitions, context, applications). Third, text simplification (rewrite this!) given a query, asks to simplify passages from scientific abstracts while preserving the main content.'},\n",
       " '10.1186/s13643-019-1074-9': {'title': 'Toward systematic review automation: a practical guide to using machine learning tools in research synthesis',\n",
       "  'abstract': 'Technologies and methods to speed up the production of systematic reviews by reducing the manual labour involved have recently emerged. Automation has been proposed or used to expedite most steps of the systematic review process, including search, screening, and data extraction. However, how these technologies work in practice and when (and when not) to use them is often not clear to practitioners. In this practical guide, we provide an overview of current machine learning methods that have been proposed to expedite evidence synthesis. We also offer guidance on which of these are ready for use, their strengths and weaknesses, and how a systematic review team might go about using them in practice.'},\n",
       " '10.1007/978-3-319-98932-7_32': {'title': 'Overview of the CLEF-2018 CheckThat! Lab on Automatic Identification and Verification of Political Claims',\n",
       "  'abstract': 'We present an overview of the CLEF-2018 CheckThat! Lab on Automatic Identification and Verification of Political Claims. In its starting year, the lab featured two tasks. Task 1 asked to predict which (potential) claims in a political debate should be prioritized for fact-checking; in particular, given a debate or a political speech, the goal was to produce a ranked list of its sentences based on their worthiness for fact-checking. Task 2 asked to assess whether a given check-worthy claim made by a politician in the context of a debate/speech is factually true, half-true, or false. We offered both tasks in English and in Arabic. In terms of data, for both tasks, we focused on debates from the 2016 US Presidential Campaign, as well as on some speeches during and after the campaign (we also provided translations in Arabic), and we relied on comments and factuality judgments from factcheck.org and snopes.com , which we further refined manually. A total of 30 teams registered to participate in the lab, and 9 of them actually submitted runs. The evaluation results show that the most successful approaches used various neural networks (esp. for Task 1) and evidence retrieval from the Web (esp. for Task 2). We release all datasets, the evaluation scripts, and the submissions by the participants, which should enable further research in both check-worthiness estimation and automatic claim verification.'},\n",
       " '10.1186/s13643-018-0740-7': {'title': 'Making progress with the automation of systematic reviews: principles of the International Collaboration for the Automation of Systematic Reviews (ICASR)',\n",
       "  'abstract': 'Systematic reviews (SR) are vital to health care, but have become complicated and time-consuming, due to the rapid expansion of evidence to be synthesised. Fortunately, many tasks of systematic reviews have the potential to be automated or may be assisted by automation. Recent advances in natural language processing, text mining and machine learning have produced new algorithms that can accurately mimic human endeavour in systematic review activity, faster and more cheaply. Automation tools need to be able to work together, to exchange data and results. Therefore, we initiated the International Collaboration for the Automation of Systematic Reviews (ICASR), to successfully put all the parts of automation of systematic review production together. The first meeting was held in Vienna in October 2015. We established a set of principles to enable tools to be developed and integrated into toolkits. This paper sets out the principles devised at that meeting, which cover the need for improvement in efficiency of SR tasks, automation across the spectrum of SR tasks, continuous improvement, adherence to high quality standards, flexibility of use and combining components, the need for a collaboration and varied skills, the desire for open source, shared code and evaluation, and a requirement for replicability through rigorous and open evaluation. Automation has a great potential to improve the speed of systematic reviews. Considerable work is already being done on many of the steps involved in a review. The ‘Vienna Principles’ set out in this paper aim to guide a more coordinated effort which will allow the integration of work by separate teams and build on the experience, code and evaluations done by the many teams working across the globe.'},\n",
       " '10.1186/2046-4053-3-74': {'title': 'Systematic review automation technologies',\n",
       "  'abstract': 'Systematic reviews, a cornerstone of evidence-based medicine, are not produced quickly enough to support clinical practice. The cost of production, availability of the requisite expertise and timeliness are often quoted as major contributors for the delay. This detailed survey of the state of the art of information systems designed to support or automate individual tasks in the systematic review, and in particular systematic reviews of randomized controlled clinical trials, reveals trends that see the convergence of several parallel research projects. We surveyed literature describing informatics systems that support or automate the processes of systematic review or each of the tasks of the systematic review. Several projects focus on automating, simplifying and/or streamlining specific tasks of the systematic review. Some tasks are already fully automated while others are still largely manual. In this review, we describe each task and the effect that its automation would have on the entire systematic review process, summarize the existing information system support for each task, and highlight where further research is needed for realizing automation for the task. Integration of the systems that automate systematic review tasks may lead to a revised systematic review workflow. We envisage the optimized workflow will lead to system in which each systematic review is described as a computer program that automatically retrieves relevant trials, appraises them, extracts and synthesizes data, evaluates the risk of bias, performs meta-analysis calculations, and produces a report in real time.'},\n",
       " '10.1016/j.eswa.2023.122918': {'title': 'Multi-modal semantics fusion model for domain relation extraction via information bottleneck',\n",
       "  'abstract': 'Domain relation extraction (DRE) aims to understand domain semantics of unstructured text to mine structural knowledge. However, most existing DRE models may fail to fully represent the domain entity that is usually absent in the corpus of pre-trained language models. In addition, almost all these models directly use contextual semantics for relation classification that ignore purifying the task relevant features. To address these challenging problems, we propose a novel and effective Multi-Modal Semantics Fusion (MMSF) model, which can automatically capture domain semantics to discover the important semantics contained in images, thus enhancing the representations of the domain entity by exploiting the multi-modal semantics. Afterwards, we introduce heterogeneous graph neural networks to learn contextual semantics. To obtain the task relevant features for DRE, we design a new purified feature architecture by exploring the mutual information between contextual semantics and the labels of domain relation. With the enhanced representations of the domain entity and purified the task relevant features, the satisfactory results of relation classification can be guaranteed. Extensive experiments on two real domain relation extraction datasets demonstrate the superiority of our proposed model over several state-of-the-art models. The source code and experiment details of this paper can be obtained from https://github.com/SWT-AITeam/MMSF.'},\n",
       " '10.1016/j.ijmedinf.2024.105385': {'title': 'Unlocking Human-Like Conversations: Scoping Review of Automation Techniques for Personalized Healthcare Interventions using Conversational Agents',\n",
       "  'abstract': 'Conversational agents (CAs) offer a sustainable approach to deliver personalized interventions and improve health outcomes.To review how human-like communication and automation techniques of CAs in personalized healthcare interventions have been implemented. It is intended for designers and developers, computational scientists, behavior scientists, and biomedical engineers who aim at developing CAs for healthcare interventions.A scoping review was conducted in accordance with PRISMA Extension for Scoping Review. A search was performed in May 2023 in Web of Science, Pubmed, Scopus and IEEE databases. Search results were extracted, duplicates removed, and the remaining results were screened. Studies that contained personalized and automated CAs within the healthcare domain were included. Information regarding study characterization, and human-like communication and automation techniques was extracted from articles that met the eligibility criteria.Twenty-three studies were selected. These articles described the development of CAs designed for patients to either self-manage their diseases (such as diabetes, mental health issues, cancer, asthma, COVID-19, and other chronic conditions) or to enhance healthy habits. The human-like communication characteristics studied encompassed aspects like system flexibility, personalization, and affective characteristics. Seven studies used rule-based models, eleven applied retrieval-based techniques for content delivery, five used AI models, and six integrated affective computing.The increasing interest in employing CAs for personalized healthcare interventions is noteworthy. The adaptability of dialogue structures and personalization features is still limited. Unlocking human-like conversations may encompass the use of affective computing and generative AI to help improve user engagement. Future research should focus on the integration of holistic methods to describe the end-user, and the safe use of generative models.'},\n",
       " '10.1007/978-3-031-47240-4_5': {'title': 'Textual Entailment for Effective Triple Validation in Object Prediction',\n",
       "  'abstract': 'Knowledge base population seeks to expand knowledge graphs with facts that are typically extracted from a text corpus. Recently, language models pretrained on large corpora have been shown to contain factual knowledge that can be retrieved using cloze-style strategies. Such approach enables zero-shot recall of facts, showing competitive results in object prediction compared to supervised baselines. However, prompt-based fact retrieval can be brittle and heavily depend on the prompts and context used, which may produce results that are unintended or hallucinatory. We propose to use textual entailment to validate facts extracted from language models through cloze statements. Our results show that triple validation based on textual entailment improves language model predictions in different training regimes. Furthermore, we show that entailment-based triple validation is also effective to validate candidate facts extracted from other sources including existing knowledge graphs and text passages where named entities are recognized.'},\n",
       " '10.1007/978-3-030-88361-4_19': {'title': 'Generative Relation Linking for Question Answering over Knowledge Bases',\n",
       "  'abstract': 'Relation linking is essential to enable question answering over knowledge bases. Although there are various efforts to improve relation linking performance, the current state-of-the-art methods do not achieve optimal results, therefore, negatively impacting the overall end-to-end question answering performance. In this work, we propose a novel approach for relation linking framing it as a generative problem facilitating the use of pre-trained sequence-to-sequence models. We extend such sequence-to-sequence models with the idea of infusing structured data from the target knowledge base, primarily to enable these models to handle the nuances of the knowledge base. Moreover, we train the model with the aim to generate a structured output consisting of a list of argument-relation pairs, enabling a knowledge validation step. We compared our method against the existing relation linking systems on four different datasets derived from DBpedia and Wikidata. Our method reports large improvements over the state-of-the-art while using a much simpler model that can be easily adapted to different knowledge bases.'},\n",
       " '10.1007/978-3-030-62419-4_23': {'title': 'Leveraging Semantic Parsing for Relation Linking over Knowledge Bases',\n",
       "  'abstract': 'Knowledge base question answering systems are heavily dependent on relation extraction and linking modules. However, the task of extracting and linking relations from text to knowledge bases faces two primary challenges; the ambiguity of natural language and lack of training data. To overcome these challenges, we present SLING, a relation linking framework which leverages semantic parsing using Abstract Meaning Representation (AMR) and distant supervision. SLING integrates multiple approaches that capture complementary signals such as linguistic cues, rich semantic representation, and information from the knowledge base. The experiments on relation linking using three KBQA datasets, QALD-7, QALD-9, and LC-QuAD 1.0 demonstrate that the proposed approach achieves state-of-the-art performance on all benchmarks.'},\n",
       " '10.1016/j.clsr.2023.105904': {'title': 'An entity-centric approach to manage court judgments based on Natural Language Processing',\n",
       "  'abstract': 'In this paper, we present an entity-centric infrastructure to manage legal documents, especially court judgments, based on the organization of a textual document repository and on the annotation of these documents to serve a variety of downstream tasks. Documents are pre-processed and then iteratively annotated using a set of NLP services that combine complementary approaches based on machine learning and syntactic rules. We present a framework that has been designed to be developed and maintained in a sustainable way, allowing for multiple services and uses of the annotated document repository and considering the scarcity of annotated data as an intrinsic challenge for its development. The design activity is the result of a cooperative project where a scientific team, institutional bodies, and companies appointed to implement the final system are involved in co-design activities. We describe experiments to demonstrate the feasibility of the solution and discuss the main challenges to scaling the system at a national level. In particular, we report the results we obtained in annotating data with different low-resource methods and with solutions designed to combine these approaches in a meaningful way. An essential aspect of the proposed solution is a human-in-the-loop approach to control the output of the annotation algorithms in agreement with the organizational processes in place in Italian courts. Based on these results we advocate for the feasibility of the proposed approach and discuss the challenges that must be addressed to ensure the scalability and robustness of the proposed solution.'},\n",
       " '10.1007/978-3-031-30672-3_42': {'title': 'Class-Dynamic and Hierarchy-Constrained Network for Entity Linking',\n",
       "  'abstract': 'Entity Linking (EL) aims to map mentions in a text to corresponding entities in a knowledge base. Existing EL methods usually rely on sufficient labeled data to achieve the best performance. However, the massive investment in data makes EL systems viable only to a limited audience. There is ample evidence that introducing entity types can provide the model prior knowledge to maintain the model performance in low-data regimes. Unfortunately, current low-data EL methods usually employ entity types by rule constraints, which are in a shallow manner. Furthermore, they usually ignore fine-grained interaction between mention and its context, resulting in insufficient semantic information of mention representation in low-data regimes. To this end, we propose a Class-Dynamic and Hierarchy-Constrained Network (CDHCN) for entity linking. Specifically, we propose a dynamic class scheme to learn a more effective representation for each entity type. Besides, we formulate a hierarchical constraint scheme to reduce the matching difficulty of the given mention and corresponding candidate entities by utilizing entity types. In addition, we propose an auxiliary task called mention position prediction (MPP) to obtain an informative mention representation in low-data regimes. Finally, extensive in-domain and out-of-domain experiments demonstrate the effectiveness of our method.'},\n",
       " '10.1007/978-3-031-11609-4_35': {'title': 'Knowledge Graph Population with Out-of-KG Entities',\n",
       "  'abstract': 'Existing knowledge graphs are incomplete. A lot of unstructured documents are hiding valuable information. But extracting and structuring that information is expensive. To help, the knowledge graphs can be populated (semi-) automatically. But knowledge graph population methods often assumes existing entities, yet, this is not the reality. To solve this, missing entities need to be detected and distinguished. To support an incoming stream of documents the out-of-KG entities are incrementally modelled. The first goal of the thesis is hence to create a novel entity linking method able to detect, distinguish and incrementally model out-of-KG entities. While the identification and modelling of potential out-of-KG entities are a step in the right direction, they still need to be included in the knowledge graph. To simplify the process, another goal is to generate short descriptions of newly identified entities. To accomplish that, a method building upon the representation of out-of-KG entities will be created which combines the properties of both graph-to-text and abstractive summarization methods. For training and evaluation, two silver-standard datasets, as well as one gold-standard dataset, will be created.'},\n",
       " '10.1007/978-3-030-86517-7_17': {'title': 'Balancing Speed and Accuracy in Neural-Enhanced Phonetic Name Matching',\n",
       "  'abstract': 'Automatic co-text free name matching has a variety of important real-world applications, ranging from fiscal compliance to border control. Name matching systems use a variety of engines to compare two names for similarity, with one of the most critical being phonetic name similarity. In this work, we re-frame existing work on neural sequence-to-sequence transliteration such that it can be applied to name matching. Subsequently, for performance reasons, we then build upon this work to utilize an alternative, non-recurrent neural encoder module. This ultimately yields a model which is 63% faster while still maintaining a 16% improvement in averaged precision over our baseline model.'},\n",
       " '10.1007/s11280-018-0598-6': {'title': 'Neural personalized response generation as domain adaptation',\n",
       "  'abstract': 'One of the most crucial problem on training personalized response generation models for conversational robots is the lack of large scale personal conversation data. To address the problem, we propose a two-phase approach, namely initialization then adaptation, to first pre-train an optimized RNN encoder-decoder model (LTS model) in a large scale conversational data for general response generation and then fine-tune the model in a small scale personal conversation data to generate personalized responses. For evaluation, we propose a novel human aided method, which can be seen as a quasi-Turing test, to evaluate the performance of the personalized response generation models. Experimental results show that the proposed personalized response generation model outperforms the state-of-the-art approaches to language model personalization and persona-based neural conversation generation on the automatic evaluation, offline human judgment and the quasi-Turing test.'},\n",
       " '10.1016/j.knosys.2019.105030': {'title': 'Word Sense Disambiguation: A comprehensive knowledge exploitation framework',\n",
       "  'abstract': 'Word Sense Disambiguation (WSD) has been a basic and on-going issue since its introduction in natural language processing (NLP) community. Its application lies in many different areas including sentiment analysis, Information Retrieval (IR), machine translation and knowledge graph construction. Solutions to WSD are mostly categorized into supervised and knowledge-based approaches. In this paper, a knowledge-based method is proposed, modeling the problem with semantic space and semantic path hidden behind a given sentence. The approach relies on the well-known Knowledge Base (KB) named WordNet and models the semantic space and semantic path by Latent Semantic Analysis (LSA) and PageRank respectively. Experiments has proven the method’s effectiveness, achieving state-of-the-art performance in several WSD datasets.'},\n",
       " '10.1007/3-540-45715-1_11': {'title': 'An Adapted Lesk Algorithm for Word Sense Disambiguation Using WordNet',\n",
       "  'abstract': 'This paper presents an adaptation of Lesk’s dictionarybased word sense disambiguation algorithm. Rather than using a standard dictionary as the source of glosses for our approach, the lexical database WordNet is employed. This provides a rich hierarchy of semantic relations that our algorithm can exploit. This method is evaluated using the English lexical sample data from the Senseval-2 word sense disambiguation exercise, and attains an overall accuracy of 32%. This represents a significant improvement over the 16% and 23% accuracy attained by variations of the Lesk algorithm used as benchmarks during the SENSEVAL-2 comparative exercise among word sense disambiguation systems.'},\n",
       " '10.1016/j.ipm.2023.103409': {'title': 'Plan and generate: Explicit and implicit variational augmentation for multi-document summarization of scientific articles',\n",
       "  'abstract': 'Multi-Document Summarization of Scientific articles (MDSS) is a challenging task that aims to generate concise and informative summaries for multiple scientific articles on a particular topic. However, despite recent advances in abstractive models for MDSS, grammatical correctness and contextual coherence remain challenging issues. In this paper, we introduce EDITSum, a novel abstractive MDSS model that leverages sentence-level planning to guide summary generation. Our model incorporates neural topic model information as explicit guidance and sequential latent variables information as implicit guidance under a variational framework. We propose a hierarchical decoding strategy that generates the sentence-level planning by a sentence decoder and then generates the final summary conditioned on the planning by a word decoder. Experimental results show that our model outperforms previous state-of-the-art models by a significant margin on ROUGE-1 and ROUGE-L metrics. Ablation studies demonstrate the effectiveness of the individual modules proposed in our model, and human evaluations provide strong evidence that our model generates more coherent and error-free summaries. Our work highlights the importance of high-level planning in addressing intra-sentence errors and inter-sentence incoherence issues in MDSS.'},\n",
       " '10.4000/narratologie.14024': {'title': 'Modèles narratifs, modèles numériques : vers un rapprochement',\n",
       "  'abstract': \"Malgré la présence du numérique à la fois comme nouveau terrain d'étude et comme nouvel outillage d'analyse, la possibilité d'adopter une approche fondamentalement computationnelle de l'étude des récits semble très peu explorée, alors même que les modèles computationnels de récit existent, notamment en informatique. Après un survol de ces modèles, nous esquissons la perspective d'adopter une démarche scientifique de modélisation/simulation des récits dans l'optique d'une consolidation des modèles narratologiques existants, tout en mentionnant quelques difficultés inhérentes à une telle approche.\"},\n",
       " '10.1016/j.psychres.2024.115896': {'title': 'Enhancing Psychiatric Rehabilitation Outcomes through a Multimodal Multitask Learning Model based on BERT and TabNet: An Approach for Personalized Treatment and Improved Decision-Making',\n",
       "  'abstract': \"Evaluating the rehabilitation status of individuals with serious mental illnesses (SMI) necessitates a comprehensive analysis of multimodal data, including unstructured text records and structured diagnostic data. However, progress in the effective assessment of rehabilitation status remains limited. Our study develops a deep learning model integrating Bidirectional Encoder Representations from Transformers (BERT) and TabNet through a late fusion strategy to enhance rehabilitation prediction, including referral risk, dangerous behaviors, self-awareness, and medication adherence, in patients with SMI. BERT processes unstructured textual data, such as doctor's notes, whereas TabNet manages structured diagnostic information. The model's interpretability function serves to assist healthcare professionals in understanding the model's predictive decisions, improving patient care. Our model exhibited excellent predictive performance for all four tasks, with an accuracy exceeding 0.78 and an area under the curve of 0.70. In addition, a series of tests proved the model's robustness, fairness, and interpretability. This study combines multimodal and multitask learning strategies into a model and applies it to rehabilitation assessment tasks, offering a promising new tool that can be seamlessly integrated with the clinical workflow to support the provision of optimized patient care.\"},\n",
       " '10.1016/j.cmpb.2023.107783': {'title': 'TGRA-P: Task-driven model predicts 90-day mortality from ICU clinical notes on mechanical ventilation',\n",
       "  'abstract': \"With the outbreak and spread of COVID-19 worldwide, limited ventilators fail to meet the surging demand for mechanical ventilation in the ICU. Clinical models based on structured data that have been proposed to rationalize ventilator allocation often suffer from poor ductility due to fixed fields and laborious normalization processes. The advent of pre-trained models and downstream fine-tuning methods allows for learning large amounts of unstructured clinical text for different tasks. But the hardware requirements of large-scale pre-trained models and purposeless networks downstream have led to a lack of promotion in the clinical domain. In this study, an innovative architecture of a task-driven predictive model is proposed and a Task-driven Gated Recurrent Attention Pool model (TGRA-P) is developed based on the architecture. TGRA-P predicts early mortality risk from patients' clinical notes on mechanical ventilation in the ICU, which is used to assist clinicians in diagnosis and decision-making. Specifically, a Task-Specific Embedding Module is proposed to fine-tune the embedding with task labels and save it as static files for downstream calls. It serves the task better and prevents GPU overload. The Gated Recurrent Attention Unit (GRA) is proposed to further enhance the dependency of the information preceding and following the text sequence with fewer parameters. In addition, we propose a Residual Max Pool (RMP) to avoid ignoring words in common text classification tasks by incorporating all word-level features of the notes for prediction. Finally, we use a fully connected decoding network as a classifier to predict the mortality risk. The proposed model shows very promising results with an AUROC of 0.8245±0.0096, an AUPRC of 0.7532±0.0115, an accuracy of 0.7422±0.0028 and F1-score of 0.6612±0.0059 for 90-day mortality prediction using clinical notes of ICU mechanically ventilated patients on the MIMIC-III dataset, all of which are better than previous studies. Moreover, the superiority of the proposed model in comparison with other baseline models is also statistically validated through the calculated Cohen's d effect sizes. The experimental results show that TGRA-P based on the innovative task-driven prognostic architecture obtains state-of-the-art performance. In future work, we will build upon the provided code and investigate its applicability to different datasets. The model balances performance and efficiency, not only reducing the cost of early mortality risk prediction but also assisting physicians in making timely clinical interventions and decisions. By incorporating textual records that are challenging for clinicians to utilize, the model serves as a valuable complement to physicians' judgment, enhancing their decision-making process.\"},\n",
       " '10.1038/s41598-023-41423-8': {'title': 'Selective UMLS knowledge infusion for biomedical question answering',\n",
       "  'abstract': 'Abstract One of the artificial intelligence applications in the biomedical field is knowledge-intensive question-answering. As domain expertise is particularly crucial in this field, we propose a method for efficiently infusing biomedical knowledge into pretrained language models, ultimately targeting biomedical question-answering. Transferring all semantics of a large knowledge graph into the entire model requires too many parameters, increasing computational cost and time. We investigate an efficient approach that leverages adapters to inject Unified Medical Language System knowledge into pretrained language models, and we question the need to use all semantics in the knowledge graph. This study focuses on strategies of partitioning knowledge graph and either discarding or merging some for more efficient pretraining. According to the results of three biomedical question answering finetuning datasets, the adapters pretrained on semantically partitioned group showed more efficient performance in terms of evaluation metrics, required parameters, and time. The results also show that discarding groups with fewer concepts is a better direction for small datasets, and merging these groups is better for large dataset. Furthermore, the metric results show a slight improvement, demonstrating that the adapter methodology is rather insensitive to the group formulation.'},\n",
       " '10.1002/hcs2.61': {'title': 'Large language models in health care: Development, applications, and challenges',\n",
       "  'abstract': 'Abstract Recently, the emergence of ChatGPT, an artificial intelligence chatbot developed by OpenAI, has attracted significant attention due to its exceptional language comprehension and content generation capabilities, highlighting the immense potential of large language models (LLMs). LLMs have become a burgeoning hotspot across many fields, including health care. Within health care, LLMs may be classified into LLMs for the biomedical domain and LLMs for the clinical domain based on the corpora used for pre‐training. In the last 3 years, these domain‐specific LLMs have demonstrated exceptional performance on multiple natural language processing tasks, surpassing the performance of general LLMs as well. This not only emphasizes the significance of developing dedicated LLMs for the specific domains, but also raises expectations for their applications in health care. We believe that LLMs may be used widely in preconsultation, diagnosis, and management, with appropriate development and supervision. Additionally, LLMs hold tremendous promise in assisting with medical education, medical writing and other related applications. Likewise, health care systems must recognize and address the challenges posed by LLMs.'},\n",
       " '10.1007/s11257-023-09369-8': {'title': 'Non-binary evaluation of next-basket food recommendation',\n",
       "  'abstract': 'Next-basket recommendation (NBR) is a recommendation task that predicts a basket or a set of items a user is likely to adopt next based on his/her history of basket adoption sequences. It enables a wide range of novel applications and services from predicting next basket of items for grocery shopping to recommending food items a user is likely to consume together in the next meal. Even though much progress has been made in the algorithmic NBR research over the years, little research has been done to broaden knowledge about the evaluation of NBR methods, which is largely based on the offline evaluation experiments and binary relevance paradigm. Specifically, we argue that recommended baskets which are more similar to ground truth baskets are better recommendations than those that share little resemblance to the ground truth, and therefore, they should be granted some partial credits. Based on this notion of non-binary relevance assessment, we propose new evaluation metrics for NBR by adapting and extending similarity metrics from natural language processing (NLP) and text classification research. To validate the proposed metrics, we conducted two user studies on the next-meal food recommendation using numerous state-of-the-art NBR methods in both online and offline evaluation settings. Our findings show that the offline performance assessment based on the proposed non-binary evaluation metrics is more representative of the online evaluation performance than that of the standard evaluation metrics.'},\n",
       " '10.1038/s41368-023-00239-y': {'title': 'ChatGPT for shaping the future of dentistry: the potential of multi-modal large language model',\n",
       "  'abstract': 'The ChatGPT, a lite and conversational variant of Generative Pretrained Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large Language Models (LLMs) with billions of parameters. LLMs have stirred up much interest among researchers and practitioners in their impressive skills in natural language processing tasks, which profoundly impact various fields. This paper mainly discusses the future applications of LLMs in dentistry. We introduce two primary LLM deployment methods in dentistry, including automated dental diagnosis and cross-modal dental diagnosis, and examine their potential applications. Especially, equipped with a cross-modal encoder, a single LLM can manage multi-source data and conduct advanced natural language reasoning to perform complex clinical operations. We also present cases to demonstrate the potential of a fully automatic Multi-Modal LLM AI system for dentistry clinical application. While LLMs offer significant potential benefits, the challenges, such as data privacy, data quality, and model bias, need further study. Overall, LLMs have the potential to revolutionize dental diagnosis and treatment, which indicates a promising avenue for clinical application and research in dentistry.'},\n",
       " '10.1186/s12911-022-01996-2': {'title': 'Identify diabetic retinopathy-related clinical concepts and their attributes using transformer-based natural language processing methods',\n",
       "  'abstract': \"Diabetic retinopathy (DR) is a leading cause of blindness in American adults. If detected, DR can be treated to prevent further damage causing blindness. There is an increasing interest in developing artificial intelligence (AI) technologies to help detect DR using electronic health records. The lesion-related information documented in fundus image reports is a valuable resource that could help diagnoses of DR in clinical decision support systems. However, most studies for AI-based DR diagnoses are mainly based on medical images; there is limited studies to explore the lesion-related information captured in the free text image reports.In this study, we examined two state-of-the-art transformer-based natural language processing (NLP) models, including BERT and RoBERTa, compared them with a recurrent neural network implemented using Long short-term memory (LSTM) to extract DR-related concepts from clinical narratives. We identified four different categories of DR-related clinical concepts including lesions, eye parts, laterality, and severity, developed annotation guidelines, annotated a DR-corpus of 536 image reports, and developed transformer-based NLP models for clinical concept extraction and relation extraction. We also examined the relation extraction under two settings including 'gold-standard' setting-where gold-standard concepts were used-and end-to-end setting.For concept extraction, the BERT model pretrained with the MIMIC III dataset achieve the best performance (0.9503 and 0.9645 for strict/lenient evaluation). For relation extraction, BERT model pretrained using general English text achieved the best strict/lenient F1-score of 0.9316. The end-to-end system, BERT_general_e2e, achieved the best strict/lenient F1-score of 0.8578 and 0.8881, respectively. Another end-to-end system based on the RoBERTa architecture, RoBERTa_general_e2e, also achieved the same performance as BERT_general_e2e in strict scores.This study demonstrated the efficiency of transformer-based NLP models for clinical concept extraction and relation extraction. Our results show that it's necessary to pretrain transformer models using clinical text to optimize the performance for clinical concept extraction. Whereas, for relation extraction, transformers pretrained using general English text perform better.\"},\n",
       " '10.1016/j.knosys.2022.109460': {'title': 'Pre-trained language models with domain knowledge for biomedical extractive summarization',\n",
       "  'abstract': 'Biomedical text summarization is a critical task for comprehension of an ever-growing amount of biomedical literature. Pre-trained language models (PLMs) with transformer-based architectures have been shown to greatly improve performance in biomedical text mining tasks. However, existing methods for text summarization generally fine-tune PLMs on the target corpora directly and do not consider how fine-grained domain knowledge, such as PICO elements used in evidence-based medicine, can help to identify the context needed for generating coherent summaries. To fill the gap, we propose KeBioSum, a novel knowledge infusion training framework, and experiment using a number of PLMs as bases, for the task of extractive summarization on biomedical literature. We investigate generative and discriminative training techniques to fuse domain knowledge (i.e., PICO elements) into knowledge adapters and apply adapter fusion to efficiently inject the knowledge adapters into the basic PLMs for fine-tuning the extractive summarization task. Experimental results from the extractive summarization task on three biomedical literature datasets show that existing PLMs (BERT, RoBERTa, BioBERT, and PubMedBERT) are improved by incorporating the KeBioSum knowledge adapters, and our model outperforms the strong baselines.'},\n",
       " '10.1016/j.aap.2022.106727': {'title': 'ARTCDP: An automated data platform for monitoring emerging patterns concerning road traffic crashes in China',\n",
       "  'abstract': 'Online media reports provide valuable information for road traffic injury prevention, but technical challenges concerning data acquisition and processing limit analysis and interpretation of such data. Integrating injury epidemiology theory and big data technology, we developed a data platform consisting of four layers (data acquisition, data processing, application and data storage) to automatically collect reports from online Chinese media concerning road traffic crashes every 24 h. We built a text classification model using 20,000 manually annotated news stories based on the Bidirectional Encoder Representations from Transformers (BERT) and then used natural language processing algorithms to extract data concerning 27 structured variables from the news sources. The accuracy of the BERT-based text classification model was 0.9271, with information extraction accuracy exceeding 80% for 22 variables. As of November 30, 2021, the data platform collected 244,650 eligible media reports covering all 333 prefecture-level divisions in China. These reports were from 37,073 websites or social media accounts, which were geographically located in all 31 provinces and over 98% of prefecture-level divisions. Data availability varied greatly from 0.9% to 100% across the 27 structured variables. Additionally, the platform identified 645,787 potentially relevant keywords when applying natural language processing techniques to the textual media reports. Platform data were highly correlated with road police data in province-based road traffic crash statistics (crashes, rs = 0.799; non-fatal injuries, rs = 0.802; deaths, rs = 0.775). In particular, the platform offers valuable data (like crashes involving electric vehicles) that are not included in official road traffic crash statistics. The new automated data platform shows great potential for timely detection of emerging characteristics of road traffic crashes. Further research is needed to improve the platform and apply it to real-time monitoring and analysis of road traffic injuries.'},\n",
       " '10.1007/978-3-030-88483-3_13': {'title': 'GeoCQA: A Large-Scale Geography-Domain Chinese Question Answering Dataset from Examination',\n",
       "  'abstract': \"We present GeoCQA, the largest multiple-choice Chinese Question answering dataset in the geographic domain, evaluating the high-level reading ability of logic reasoning and prior geographic domain knowledge integration of a question answering (QA) model. GeoCQA contains 58,940 questions from real-world scenarios and has been collected from the high school geography examination which aims to evaluate students' mastery of the geographic concept and their ability to use geographic knowledge to solve problems. To investigate the challenges of GeoCQA to existing methods, we implement both rule-based and best neural methods and find that the current best method can achieve 71.90% of test accuracy, while unskilled humans and skilled humans can reach 80% and 96% accuracy respectively, which shows that GeoCQA is challenging to the current methods and the performance still has space to improve. We will release GeoCQA and our baselines to bring more data sources to the community and hope that it can help to promote much stronger Chinese QA models in the future (https://github.com/db12138/GeoCQA).\"},\n",
       " '10.1186/s12859-019-3119-4': {'title': 'A question-entailment approach to question answering',\n",
       "  'abstract': \"One of the challenges in large-scale information retrieval (IR) is to develop fine-grained and domain-specific methods to answer natural language questions. Despite the availability of numerous sources and datasets for answer retrieval, Question Answering (QA) remains a challenging problem due to the difficulty of the question understanding and answer extraction tasks. One of the promising tracks investigated in QA is to map new questions to formerly answered questions that are `similar'. In this paper, we propose a novel QA approach based on Recognizing Question Entailment (RQE) and we describe the QA system and resources that we built and evaluated on real medical questions. First, we compare machine learning and deep learning methods for RQE using different kinds of datasets, including textual inference, question similarity and entailment in both the open and clinical domains. Second, we combine IR models with the best RQE method to select entailed questions and rank the retrieved answers. To study the end-to-end QA approach, we built the MedQuAD collection of 47,457 question-answer pairs from trusted medical sources, that we introduce and share in the scope of this paper. Following the evaluation process used in TREC 2017 LiveQA, we find that our approach exceeds the best results of the medical task with a 29.8% increase over the best official score. The evaluation results also support the relevance of question entailment for QA and highlight the effectiveness of combining IR and RQE for future QA efforts. Our findings also show that relying on a restricted set of reliable answer sources can bring a substantial improvement in medical QA.\"},\n",
       " '10.1186/1472-6963-8-236': {'title': 'Disease knowledge after an educational program in patients with GERD – a randomized controlled trial',\n",
       "  'abstract': \"Patient education has proved beneficial in several but not all chronic disease. Inconsistent findings may rely on varying educational effects of various programs and differential effects on subgroups of patients. Patients' increase in disease knowledge may serve as a feedback to the educator on how well the education program works - but may not be associated to relevant clinical outcomes like quality of life (QoL). This study aimed to investigate the effects of a group based education program for patients with gastroesophageal reflux disease (GERD) on disease knowledge and the association between knowledge and QoL.Patients with GERD were randomly allocated to education (102 patients) or control (109 patients). The education program was designed as a structured dialogue conveying information about pathophysiology, pharmacological and non-pharmacological treatment of GERD, patients' rights and use of healthcare. Outcomes were a 24 item knowledge test on GERD (score 0-24) 2 and 12 months after the educational program and disease specific and general QoL (Digestive symptoms and disease impact, DSIQ, and General Health Questionnaire, GHQ).Patients allocated to education achieved higher knowledge test scores than controls at 2 months (17.0 vs. 13.1, p<0.001) and at 12 months (17.1 vs. 14.0, p<0.001) follow-up. Knowledge test score was positively associated with having completed advanced school and inversely related to psychiatric illness and poor QoL as perceived by the patients at the time of inclusion. Overall, changes in knowledge test score were not associated with change in QoL.A group based education program for patients with GERD designed as a structured dialogue increased patients' disease knowledge, which was retained after 1 year. Changes in GERD-knowledge were not associated with change in QoL.ClinicalTrials.gov: NCT0061850.\"},\n",
       " '10.1080/00207543.2023.2276811': {'title': 'From natural language to simulations: applying AI to automate simulation modelling of logistics systems',\n",
       "  'abstract': 'Our research strives to examine how simulation models of logistics systems can be produced automatically from verbal descriptions in natural language and how human experts and artificial intelligence (AI)-based systems can collaborate in the domain of simulation modelling. We demonstrate that a framework constructed upon the refined GPT-3 Codex is capable of generating functionally valid simulations for queuing and inventory management systems when provided with a verbal explanation. As a result, the language model could produce simulation models for inventory and process control. These results, along with the rapid improvement of language models, enable a significant simplification of simulation model development. Our study offers guidelines and a design of a natural language processing-based framework on how to build simulation models of logistics systems automatically, given the verbal description. In generalised terms, our work offers a technological underpinning of human-AI collaboration for the development of simulation models.'},\n",
       " '10.1016/j.neucom.2023.126385': {'title': 'An data augmentation method for source code summarization',\n",
       "  'abstract': 'Code comments improve the readability and intelligibility of codes, Unfortunately, code comments are often missing, or outdated in software projects, which negatively affects the efficiency of developers to infer the functionality from source code and affect the efficiency of software maintenance and evolution. To solve this problem, many source code summarization algorithms have been proposed, which automatically generate code comments from source code. However, these methods usually try to collect a large data set which contains the mapping between code comments and source code to train models. However, there are two limitations for the training sets: the insufficient data collection limitation (i.e., generate a large amount of noises-free training data) and data distribution bias limitation (i.e., generate training data for infrequently used methods). To address this issues, we have proposed a data augmentation method for code comments, named CDA-CS. Training models on the augmented dataset, the state-of-the-art algorithms can easily get a further 1.37% to 2.24% improvement in terms of different evaluation metrics (i.e., BLUE-4, METEOR, ROUGH_L).'},\n",
       " '10.1049/cit2.12207': {'title': 'DeepOCL: A deep neural network for Object Constraint Language generation from unrestricted nature language',\n",
       "  'abstract': 'Abstract Object Constraint Language (OCL) is one kind of lightweight formal specification, which is widely used for software verification and validation in NASA and Object Management Group projects. Although OCL provides a simple expressive syntax, it is hard for the developers to write correctly due to lacking knowledge of the mathematical foundations of the first‐order logic, which is approximately half accurate at the first stage of development. A deep neural network named DeepOCL is proposed, which takes the unrestricted natural language as inputs and automatically outputs the best‐scored OCL candidates without requiring a domain conceptual model that is compulsively required in existing rule‐based generation approaches. To demonstrate the validity of our proposed approach, ablation experiments were conducted on a new sentence‐aligned dataset named OCLPairs. The experiments show that the proposed DeepOCL can achieve state of the art for OCL statement generation, scored 74.30 on BLEU, and greatly outperformed experienced developers by 35.19%. The proposed approach is the first deep learning approach to generate the OCL expression from the natural language. It can be further developed as a CASE tool for the software industry.'},\n",
       " '10.1016/j.eswa.2023.120073': {'title': 'Who evaluates the evaluators? On automatic metrics for assessing AI-based offensive code generators',\n",
       "  'abstract': 'AI-based code generators are an emerging solution for automatically writing programs starting from descriptions in natural language, by using deep neural networks (Neural Machine Translation, NMT). In particular, code generators have been used for ethical hacking and offensive security testing by generating proof-of-concept attacks. Unfortunately, the evaluation of code generators still faces several issues. The current practice uses output similarity metrics, i.e., automatic metrics that compute the textual similarity of generated code with ground-truth references. However, it is not clear what metric to use, and which metric is most suitable for specific contexts. This work analyzes a large set of output similarity metrics on offensive code generators. We apply the metrics on two state-of-the-art NMT models using two datasets containing offensive assembly and Python code with their descriptions in the English language. We compare the estimates from the automatic metrics with human evaluation and provide practical insights into their strengths and limitations.'},\n",
       " '10.1016/j.ifacol.2023.10.1572': {'title': 'Do Natural Language Processing models understand simulations? Application of GPT-3 to translate simulation source code to English',\n",
       "  'abstract': \"The need for modeling inventory management systems and associated processes is critical. However, the emphasized complexity, along with nonlinear behavior, high dimensionality, and stochasticity, frequently leads to analytic intractability. Simulation modeling does not possess this disadvantage allowing one to describe an inventory management system with all its details and take into account nonlinearity, uncertainty, and complexity. However, simulation modeling has several disadvantages, including technical complexity and the need for the back-and-forth information exchange between the domain experts and simulation engineers, which may significantly increase the project's duration and budget. Our study explores how the latest advancements in Natural Language Processing can be applied to assist in the development of a simulation model of the inventory management system. Our study mainly focuses on the proof of concept that state-of-the-art NLP systems are capable of understanding both the core principles behind the simulations of inventory management systems and the domain-specific context.\"},\n",
       " '10.1016/j.iswa.2023.200271': {'title': 'DSG-GAN: Multi-turn text-to-image synthesis via dual semantic-stream guidance with global and local linguistics',\n",
       "  'abstract': \"Multi-turn text-to-image synthesis task aims to manipulate desired visual content according to the user's intention step by step, which has recently attracted a lot of research interest in the community of language and vision. Different from traditional text-to-image synthesis, multi-turn text-to-image synthesis is more challenging as 1) it needs to continuously recognize the user's intention from spoken instruction and perceive the visual information from the source image; 2) it requires reasoning about the position, appearance, and characteristics of fresh modifications in target images as well as connecting objects in instructions with visual components in source images. To deal with this issue, in this paper, we propose a Dual Semantic-stream Guidance with global and local linguistics Generative Adversarial Network (DSG-GAN), which reasons and learns the user's intention from text description and iteratively manipulates visual information. Specifically, we design a novel dual semantic-stream discriminator, which combines with a hierarchical instruction encoder to evaluate the logic and quality between human intention in linguistic instruction and generates visual content from the perspective of global and fine-grained consistency matching. Meanwhile, the discriminator's backpropagation gradient is used to optimize the instruction encoder, which incentivizes it to purify the user's intention into global and local information that is consistent with the manipulation's visual representation. Extensive experiments show that even when producing high-resolution images and making deep iterative turns, our method performs significantly better due to local fine-grained linguistic information being combined with cross-modal correlation.\"},\n",
       " '10.1007/978-3-031-20059-5_41': {'title': 'Language-Driven Artistic Style Transfer',\n",
       "  'abstract': 'Despite having promising results, style transfer, which requires preparing style images in advance, may result in lack of creativity and accessibility. Following human instruction, on the other hand, is the most natural way to perform artistic style transfer that can significantly improve controllability for visual effect applications. We introduce a new task—language-driven artistic style transfer (LDAST)—to manipulate the style of a content image, guided by a text. We propose contrastive language visual artist (CLVA) that learns to extract visual semantics from style instructions and accomplish LDAST by the patch-wise style discriminator. The discriminator considers the correlation between language and patches of style images or transferred results to jointly embed style instructions. CLVA further compares contrastive pairs of content images and style instructions to improve the mutual relativeness. The results from the same content image can preserve consistent content structures. Besides, they should present analogous style patterns from style instructions that contain similar visual semantics. The experiments show that our CLVA is effective and achieves superb transferred results on LDAST.'},\n",
       " '10.1016/j.asoc.2024.111553': {'title': 'Sentiment analysis on a low-resource language dataset using multimodal representation learning and cross-lingual transfer learning',\n",
       "  'abstract': 'Affect Sensing is a rapidly growing field with the potential to revolutionize human–computer interaction, healthcare, and many more applications. Multimodal Sentiment Analysis (MSA) is a recent research area that exploits the multimodal nature of video data for affect sensing. However, the success of a multimodal framework depends on addressing the challenges associated with integrating diverse modalities and selecting informative features. We propose a novel multimodal representation learning framework using multimodal autoencoders that learns a comprehensive representation of the underlying heterogeneous modalities. Affect Sensing is even more challenging in low-resource languages because annotated video datasets and language-specific models are limited. To address this concern, we introduce Multimodal Sentiment Analysis Corpus in Tamil (MSAT), a small-sized dataset in the Tamil language for MSA, and exhibit how a novel technique involving cross-lingual transfer learning in a multimodal setting, leverages the knowledge gained by training the model on a larger English MSA dataset to fine-tune a much smaller Tamil MSA dataset. Our transfer learning model achieves significant gain in the Tamil dataset by a large margin. Our experiments demonstrate that we can build efficient, generalized models for low-resource languages by using the existing MSA datasets.'},\n",
       " '10.1016/j.csi.2024.103856': {'title': 'Spanish MEACorpus 2023: A multimodal speech-text corpus for emotion analysis in Spanish from natural environments',\n",
       "  'abstract': \"In human–computer interaction, emotion recognition provides a deeper understanding of the user's emotions, enabling empathetic and effective responses based on the user's emotional state. While deep learning models have improved emotion recognition solutions, it is still an active area of research. One important limitation is that most emotion recognition systems use only text as input, ignoring features such as voice intonation. Another limitation is the limited number of datasets available for multimodal emotion recognition. In addition, most published datasets contain emotions that are simulated by professionals and produce limited results in real-world scenarios. In other languages, such as Spanish, hardly any datasets are available. Therefore, our contributions to emotion recognition are as follows. First, we compile and annotate a new corpus for multimodal emotion recognition in Spanish (Spanish MEACorpus 2023), which contains 13.16 h of speech divided into 5,129 segments labeled by considering Ekman's six basic emotions. The dataset is extracted from YouTube videos in natural environments. Second, we explore several deep learning models for emotion recognition using text- and audio-based features. Third, we evaluate different multimodal techniques to build a multimodal recognition system that improves the results of unimodal models, achieving a Macro F1-score of 87.745%, using late fusion with concatenation strategy approach.\"},\n",
       " '10.1016/j.inffus.2023.02.028': {'title': 'Multimodal sentiment analysis based on fusion methods: A survey',\n",
       "  'abstract': 'Sentiment analysis is an emerging technology that aims to explore people’s attitudes toward an entity. It can be applied in a variety of different fields and scenarios, such as product review analysis, public opinion analysis, psychological disease analysis, and risk assessment analysis. Traditional sentiment analysis only includes the text modality and extracts sentiment information by inferring the semantic relationship within sentences. However, some special expressions, such as irony and exaggeration, are difficult to detect via text alone. Multimodal sentiment analysis contains rich visual and acoustic information in addition to text, and uses fusion analysis to more accurately infer the implied sentiment polarity (positive, neutral, negative). The main challenge in multimodal sentiment analysis is the integration of cross-modal sentiment information, so we focus on introducing the framework and characteristics of different fusion methods. In addition, this article discusses the development status of multimodal sentiment analysis, popular datasets, feature extraction algorithms, application areas, and existing challenges. It is hoped that our work can help researchers understand the current state of research in the field of multimodal sentiment analysis, and be inspired by the useful insights provided in the article to develop effective models.'},\n",
       " '10.1016/j.inffus.2022.09.025': {'title': 'Multimodal sentiment analysis: A systematic review of history, datasets, multimodal fusion methods, applications, challenges and future directions',\n",
       "  'abstract': 'Sentiment analysis (SA) has gained much traction In the field of artificial intelligence (AI) and natural language processing (NLP). There is growing demand to automate analysis of user sentiment towards products or services. Opinions are increasingly being shared online in the form of videos rather than text alone. This has led to SA using multiple modalities, termed Multimodal Sentiment Analysis (MSA), becoming an important research area. MSA utilises latest advancements in machine learning and deep learning at various stages including for multimodal feature extraction and fusion and sentiment polarity detection, with aims to minimize error rate and improve performance. This survey paper examines primary taxonomy and newly released multimodal fusion architectures. Recent developments in MSA architectures are divided into ten categories, namely early fusion, late fusion, hybrid fusion, model-level fusion, tensor fusion, hierarchical fusion, bi-modal fusion, attention-based fusion, quantum-based fusion and word-level fusion. A comparison of several architectural evolutions in terms of MSA fusion categories and their relative strengths and limitations are presented. Finally, a number of interdisciplinary applications and future research directions are proposed.'},\n",
       " '10.1038/s42256-022-00550-z': {'title': 'Visual speech recognition for multiple languages in the wild',\n",
       "  'abstract': 'Visual speech recognition (VSR) aims to recognize the content of speech based on lip movements, without relying on the audio stream. Advances in deep learning and the availability of large audio-visual datasets have led to the development of much more accurate and robust VSR models than ever before. However, these advances are usually due to the larger training sets rather than the model design. Here we demonstrate that designing better models is equally as important as using larger training sets. We propose the addition of prediction-based auxiliary tasks to a VSR model, and highlight the importance of hyperparameter optimization and appropriate data augmentations. We show that such a model works for different languages and outperforms all previous methods trained on publicly available datasets by a large margin. It even outperforms models that were trained on non-publicly available datasets containing up to to 21 times more data. We show, furthermore, that using additional training data, even in other languages or with automatically generated transcriptions, results in further improvement. Recognition of speech from lip movements is still a challenging problem and much effort is concentrated on the English language. Ma et al. have used auxiliary tasks to train a model such that it works for a range of different languages, including Mandarin, Spanish, Italian, French and Portuguese.'},\n",
       " '10.3389/fpsyg.2018.01109': {'title': 'Why We Should Study Multimodal Language',\n",
       "  'abstract': 'OPINION article Front. Psychol., 28 June 2018Sec. Language Sciences Volume 9 - 2018 | https://doi.org/10.3389/fpsyg.2018.01109'},\n",
       " '10.1007/s10579-017-9394-7': {'title': 'Spanish sentiment analysis in Twitter at the TASS workshop',\n",
       "  'abstract': 'This paper describes a support vector machine-based approach to different tasks related to sentiment analysis in Twitter for Spanish. We focus on parameter optimization of the models and the combination of several models by means of voting techniques. We evaluate the proposed approach in all the tasks that were defined in the five editions of the TASS workshop, between 2012 and 2016. TASS has become a framework for sentiment analysis tasks that are focused on the Spanish language. We describe our participation in this competition and the results achieved, and then we provide an analysis of and comparison with the best approaches of the teams who participated in all the tasks defined in the TASS workshops. To our knowledge, our results exceed those published to date in the sentiment analysis tasks of the TASS workshops.'},\n",
       " '10.1007/978-3-319-47955-2_12': {'title': 'Is This a Joke? Detecting Humor in Spanish Tweets',\n",
       "  'abstract': 'While humor has been historically studied from a psychological, cognitive and linguistic standpoint, its study from a computational perspective is an area yet to be explored in Computational Linguistics. There exist some previous works, but a characterization of humor that allows its automatic recognition and generation is far from being specified. In this work we build a crowdsourced corpus of labeled tweets, annotated according to its humor value, letting the annotators subjectively decide which are humorous. A humor classifier for Spanish tweets is assembled based on supervised learning, reaching a precision of 84% and a recall of 69%.'},\n",
       " '10.1007/978-3-319-07983-7_28': {'title': 'Cross-Domain Sentiment Analysis Using Spanish Opinionated Words',\n",
       "  'abstract': 'A common issue of most of NLP tasks is the lack of linguistic resources in languages different from English. In this paper is described a new corpus for Sentiment Analysis composed by hotel reviews written in Spanish. We use the corpus to carry out a set of experiments for unsupervised polarity detection using different lexicons. But, in addition, we want to check the adaptability to a domain for the lists of opinionated words. The obtained results are very promising and encourage us to continue investigating in this line.'},\n",
       " '10.1007/978-3-642-00525-1_26': {'title': 'Recognition of Emotions in German Speech Using Gaussian Mixture Models',\n",
       "  'abstract': 'The contribution describes experiments with recognition of emotions in German speech signal based on the same principle as recognition of speakers. The most robust algorithm for speaker recognition is based on Gaussian Mixture Models (GMM). We examine three parameter sets: the first contains suprasegmental features, in the second are segmental features and the last is a combination of the two previous parameter sets. Further we want to explore the dependency of the classification accuracy on the number of GMM model components. The aim of this contribution is a recommendation for the number of GMM components and the optimal selection of speech parameters for emotion recognition in German speech.'},\n",
       " '10.1007/S10579-008-9076-6': {'title': 'IEMOCAP: interactive emotional dyadic motion capture database',\n",
       "  'abstract': 'Since emotions are expressed through a combination of verbal and non-verbal channels, a joint analysis of speech and gestures is required to understand expressive human communication. To facilitate such investigations, this paper describes a new corpus named the “interactive emotional dyadic motion capture database” (IEMOCAP), collected by the Speech Analysis and Interpretation Laboratory (SAIL) at the University of Southern California (USC). This database was recorded from ten actors in dyadic sessions with markers on the face, head, and hands, which provide detailed information about their facial expressions and hand movements during scripted and spontaneous spoken communication scenarios. The actors performed selected emotional scripts and also improvised hypothetical scenarios designed to elicit specific types of emotions (happiness, anger, sadness, frustration and neutral state). The corpus contains approximately 12 h of data. The detailed motion capture information, the interactive setting to elicit authentic emotions, and the size of the database make this corpus a valuable addition to the existing databases in the community for the study and modeling of multimodal and expressive human communication.'},\n",
       " '10.1016/S0167-6393(97)00020-4': {'title': 'Parabolic spectral parameter — A new method for quantification of the glottal flow',\n",
       "  'abstract': \"This study presents a new frequency domain parameter, Parabolic Spectral Parameter (PSP), for the quantification of the glottal volume velocity waveform. PSP is based on fitting a parabolic function to the low-frequency part of a pitch-synchronously computed spectrum of the estimated glottal flow. PSP gives a single numerical value that describes how the spectral decay of an obtained glottal flow behaves with respect to a theoretical limit corresponding to maximal spectral decay. By analyzing speech signals of different phonation types the performance of the new parameter is compared to three commonly used time-based parameters and to one previously developed frequency domain method. In dieser Studie wird zur Quantifizierung des glottalen Wellenform ein neuer Parameter vorgelegt: der parabolische Spektralparameter (PSP). PSP ist basiert auf einem Näherungsverfahren, in welchem eine parabolische Funktion dem tieffrequenten Anteil eines pitch-synchron berechneten Spektrums des glottalen Luftstroms angenähert wird. PSP resultiert in einem einzigen numerischen Wert, der angibt, wie der sprektrale Abfall des so erhaltenen glottalen Luftstroms sich im Hinblick auf eine theoretisch festgelegte Grenze, die dem maximalen spektralen Abfall entspricht, verhält. Durch Analyse von Sprachsignalen mit unterschiedlichen Phonationstypen wird die Wirkungsweise des neuen Parameters mit der von drei gebräuchlichen zeitabhängigen Parametern und mit einer vorher entwickelten Methode im Frequenzbereich verglichen. On présente ici un nouveau paramètre de fréquence, PSP (Parabolic Spectral Parameter), pour la quantification de la vélocité de volume de l'onde glottique. PSP est basé sur l'adaptation d'une fonction parabolique à la partie basse-fréquence du spectre pitch-synchrone du flux glottique estimé. PSP donne une valeur numérique qui décrit comment la décroissance spectrale d'un flux glottique obtenu se comporte par rapport à la limite théorique correspondant à la décroissance spectrale maximale. Les performances de ce nouveau paramètre, pour l'analyse de signaux de parole caractéristiques de différents types de phonation, sont comparées à celles de trois paramètres d'usage courant, basés sur le temps, ainsi qu'à une méthode fréquentielle développée antérieurement.\"},\n",
       " '10.1016/0167-6393(92)90005-R': {'title': 'Glottal wave analysis with Pitch Synchronous Iterative Adaptive Inverse Filtering',\n",
       "  'abstract': \"A new glottal wave analysis method, Pitch Synchronous Iterative Adaptive Inverse Filtering (PSIAIF) is presented. The algorithm is based on a previously developed method, Iterative Adaptive Inverse Filtering (IAIF). In the IAIF-method the glottal contribution to the speech spectrum is first estimated with an iterative structure. The vocal tract transfer function is modeled after eliminating the average glottal contribution. The glottal excitation is obtained by cancelling the effects of the vocal tract and lip radiation by inverse filtering. In the new PSIAIF-method the glottal pulseform is computed by applying the IAIF-algorithm twice to the same signal. The first IAIF-analysis gives as a result a glottal excitation that spans over several pitch periods. This pulseform is used in order to determine positions and lengths of frames for the pitch synchronous analysis. The final result is obtained by analysing the original speech signal with the IAIF-algorithm one fundamental period at a time. The PSIAIF-algorithm was applied in glottal wave analysis using both synthetic and natural vowels. The results show that the method is able to give a fairly accurate estimate for the glottal flow excluding the analysis of vowels with a low first formant that are produced with a pressed phonation type. Im vorliegenden Artikel wird ein neues Verfahren zur Analyse des Glottissignals vorgestellt, das Pitch Synchronous Iterative Adaptive Inverse Filtering (PSIAIF). Der Algorithmus basiert auf einer vorher entwickelten Methode (IAIF). Bei der IAIF-Methode wird zunächst der glottale Beitrag zum Sprachspektrum mit einem iterativen Verfahren geschätzt. Die Übertragungsfunktion des Vokaltraktes wird anschlieβend nach Eliminierung des mittleren Glottalbeitrags modelliert. Die Anregung der Glottis wird ermittelt, indem die Einflüsse von Vokaltrakt und Lippenabstrahlung mittels inverser Filterung beseitigt werden. In der neuen PSIAIF-Methode wird die glottale Pulsform dadurch bestimmt, daβ der IAIF-Algorithmus zweimal auf dasselbe Signal angewendet wird. Die erste IAIF-Analyse liefert als Ergebnis die Glottisanregung über mehrere Grundperioden. Diese Pulsform wird dann dazu benutzt, Rahmenpositionen und -längen für die grundperioden-synchrone Analyse zu ermitteln. Das endgültige Ergebnis erhält man, indem das ursprüngliche Sprachsignal in jeweils einer Periode mit dem IAIF-Algorithmus analysiert wird. Der PSIAIF-Algorithmus wurde sowohl unter Verwendung von synthetischen als auch natürlichen Vokalen erprobt. Die Ergebnisse zeigen, daβ das Verfahren dazu in der Lage ist, eine hinreichend genaue Schätzung des Glottissignals anzugeben, mit Ausnahme von Vokalen mit einer niedrigen Frequenz des ersten Formanten und welche durch eine gepresste Aussprache erzeugt werden. On présente une nouvelle méthode d'analyse du flux glottique: le PSIAIF (Pitch Synchronous Iterative Adaptive Inverse Filtering). Cet algorithme se base sur une méthode (IAIF) développée précédemment. La contribution glottique totale au spectre de la parole y était tout d'abord évaluée itérativement. La fonction de transfert du conduit vocal était obtenue après élimination de la contribution glottique moyenne tandis que l'excitation glottique l'était en annulant les effets du conduit vocal et de la radiation labiale par filtrage inverse. Dans la nouvelle méthode, l'onde glottique est calculée en appliquant deux fois l'algorithme IAIF au même signal. La première analyse donne une estimation de l'excitation glottique qui s'étend sur plusieurs périodes. L'onde ainsi obtenue est utilisée ensuite pour déterminer les positions et les longueurs des fenêtres d'analyse synchronisées. Pour obtenir le résultat final, il ne rest plus qu'à analyser le signal original de la parole, période fondamentale par période fondamentale, avec l'algorithme IAIF. L'algorithme PSIAIF a été appliqué à l'analyse du signal glottique, dans le cas de voyelles naturelles et synthétiques. Les résultats montrent que la méthode est capable de fournir une estimation relativement précise de flux glottique, si l'on exclut l'analyse des voyelles à premier formant bas produites par un type de phonation pressée.\"},\n",
       " '10.1007/s10579-005-7880-9': {'title': 'Annotating Expressions of Opinions and Emotions in Language',\n",
       "  'abstract': 'This paper describes a corpus annotation project to study issues in the manual annotation of opinions, emotions, sentiments, speculations, evaluations and other private states in language. The resulting corpus annotation scheme is described, as well as examples of its use. In addition, the manual annotation process and the results of an inter-annotator agreement study on a 10,000-sentence corpus of articles drawn from the world press are presented.'},\n",
       " '10.1007/s42001-023-00227-6': {'title': 'A high-dimensional approach to measuring online polarization',\n",
       "  'abstract': 'Abstract Polarization, ideological and psychological distancing between groups, can cause dire societal fragmentation. Of chief concern is the role of social media in enhancing polarization through mechanisms like facilitating selective exposure to information. Researchers using user-generated content to measure polarization typically focus on direct communication, suggesting echo chamber-like communities indicate the most polarization. However, this operationalization does not account for other dimensions of intergroup conflict that have been associated with polarization. We address this limitation by introducing a high-dimensional network framework to evaluate polarization based on three dimensions: social, knowledge, and knowledge source. Following an extensive review of the psychological and social mechanisms of polarization, we specify five sufficient conditions for polarization to occur that can be evaluated using our approach. We analyze six existing network-based polarization metrics in our high-dimensional network framework through a virtual experiment and apply our proposed methodology to discussions around COVID-19 vaccines on Twitter. This work has implications for detecting polarization on social media using user-generated content, quantifying the effects of offline divides or de-polarization efforts online, and comparing community dynamics across contexts.'},\n",
       " '10.1016/j.ipm.2022.103070': {'title': 'Is my stance the same as your stance? A cross validation study of stance detection datasets',\n",
       "  'abstract': 'Stance detection identifies a person’s evaluation of a subject, and is a crucial component for many downstream applications. In application, stance detection requires training a machine learning model on an annotated dataset and applying the model on another to predict stances of text snippets. This cross-dataset model generalization poses three central questions, which we investigate using stance classification models on 7 publicly available English Twitter datasets ranging from 297 to 48,284 instances. (1) Are stance classification models generalizable across datasets? We construct a single dataset model to train/test dataset-against-dataset, finding models do not generalize well (avg F1=0.33). (2) Can we improve the generalizability by aggregating datasets? We find a multi dataset model built on the aggregation of datasets has an improved performance (avg F1=0.69). (3) Given a model built on multiple datasets, how much additional data is required to fine-tune it? We find it challenging to ascertain a minimum number of data points due to the lack of pattern in performance. Investigating possible reasons for the choppy model performance we find that texts are not easily differentiable by stances, nor are annotations consistent within and across datasets. Our observations emphasize the need for an aggregated dataset as well as consistent labels for the generalizability of models.'},\n",
       " '10.1007/978-3-030-28577-7_4': {'title': 'Stance Detection in Web and Social Media: A Comparative Study',\n",
       "  'abstract': 'Online forums and social media platforms are increasingly being used to discuss topics of varying polarities where different people take different stances. Several methodologies for automatic stance detection from text have been proposed in literature. To our knowledge, there has not been any systematic investigation towards their reproducibility, and their comparative performances. In this work, we explore the reproducibility of several existing stance detection models, including both neural models and classical classifier-based models. Through experiments on two datasets -- (i)~the popular SemEval microblog dataset, and (ii)~a set of health-related online news articles -- we also perform a detailed comparative analysis of various methods and explore their shortcomings. Implementations of all algorithms discussed in this paper are available at https://github.com/prajwal1210/Stance-Detection-in-Web-and-Social-Media.'},\n",
       " '10.1007/978-3-319-98539-8_29': {'title': 'Debate Stance Classification Using Word Embeddings',\n",
       "  'abstract': 'Online debate sites act as a popular platform for users to express and form opinions. In this paper, we propose a novel unsupervised approach to perform stance classification of two-sided online debate posts. We propose the use of word embeddings to address the problem of identifying the preferred target of each aspect. We also use word embeddings to train a supervised classifier for selecting only target related aspects. The aspect-target preference information is used to model the stance classification task as an integer linear programming problem. The classifier gives an average aspect classification accuracy of 84% on multiple datasets. Our word embedding based stance classification approach gives 19.80% higher user stance classification accuracy (F1-score) compared to the existing methods. Our results suggest that the use of word embeddings improves accuracy and enables us to perform stance classification without the need for external domain-specific information.'},\n",
       " '10.1007/978-3-319-76941-7_40': {'title': 'Topical Stance Detection for Twitter: A Two-Phase LSTM Model Using Attention',\n",
       "  'abstract': 'The topical stance detection problem addresses detecting the stance of the text content with respect to a given topic: whether the sentiment of the given text content is in favor of (positive), is against (negative), or is none (neutral) towards the given topic. Using the concept of attention, we develop a two-phase solution. In the first phase, we classify subjectivity - whether a given tweet is neutral or subjective with respect to the given topic. In the second phase, we classify sentiment of the subjective tweets (ignoring the neutral tweets) - whether a given subjective tweet has a favor or against stance towards the topic. We propose a Long Short-Term memory (LSTM) based deep neural network for each phase, and embed attention at each of the phases. On the SemEval 2016 stance detection Twitter task dataset [7], we obtain a best-case macro F-score of 68.84% and a best-case accuracy of 60.2%, outperforming the existing deep learning based solutions. Our framework, T-PAN, is the first in the topical stance detection literature, that uses deep learning within a two-phase architecture.'},\n",
       " '10.1017/CBO9780511802034': {'title': 'Argumentation Schemes',\n",
       "  'abstract': 'This book provides a systematic analysis of many common argumentation schemes and a compendium of 96 schemes. The study of these schemes, or forms of argument that capture stereotypical patterns of human reasoning, is at the core of argumentation research. Surveying all aspects of argumentation schemes from the ground up, the book takes the reader from the elementary exposition in the first chapter to the latest state of the art in the research efforts to formalize and classify the schemes, outlined in the last chapter. It provides a systematic and comprehensive account, with notation suitable for computational applications that increasingly make use of argumentation schemes.'},\n",
       " '10.1016/j.ipm.2024.103677': {'title': 'Improving extractive summarization with semantic enhancement through topic-injection based BERT model',\n",
       "  'abstract': 'In the field of text summarization, extractive techniques aim to extract key sentences from a document to form a summary. However, traditional methods are not sensitive enough to obtain the core semantics of the text, resulting in summaries that contain complicate comprehension. Recently, topic extraction technology extracts core semantics from text, enabling accurate summaries of the main points of a document. In this paper, we introduce the Topic-Injected Bidirectional Encoder Representations from Transformers (TP-BERT), a novel neural auto-encoder model designed explicitly for extractive summarization. TP-BERT integrates document-related topic words into sentences, improving contextual understanding and more accurately aligning summaries with a document’s main theme, addressing a key shortfall in traditional extractive methods. Another major innovation of TP-BERT is the use of contrastive learning during training. This method enhances summarization efficiency by giving prominence to key sentences and minimizing peripheral information. Additionally, we conducted ablation studies and parameter studies of TP-BERT conducted on the CNN/DailyMail, WikiHow, and XSum datasets. In our two main experiments, the average ROUGE-F1 score improved by 2.69 and 0.45 across the three datasets. In comparison to baseline methods, TP-BERT has demonstrated better performance based on the increase in ROUGE-F1 scores on three datasets. Moreover, the semantic differentiation between sentence representations has also contributed positively to the performance enhancements.'},\n",
       " '10.1007/s44196-023-00251-4': {'title': 'A Study of Chinese News Headline Classification Based on Keyword Feature Expansion',\n",
       "  'abstract': 'Abstract Existing work generally classifies news headlines as a matter of short text classification. However, due to the strong domain nature and limited text length of news headlines, their classification results are usually determined by several specific keywords, which makes the traditional short text classification method ineffective. In this paper, we propose a new method to identify keywords in news headlines and expand their features from sentence level and word level respectively, and finally use convolutional neural networks (CNN) to extract and classify their features. The proposed model was tested on the Sogou News Corpus dataset and achieved 93.42 $$\\\\%$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:mo>%</mml:mo> </mml:math> accuracy.'},\n",
       " '10.1016/j.ipm.2022.103215': {'title': 'Graph neural topic model with commonsense knowledge',\n",
       "  'abstract': \"Traditional topic models are based on the bag-of-words assumption, which states that the topic assignment of each word is independent of the others. However, this assumption ignores the relationship between words, which may hinder the quality of extracted topics. To address this issue, some recent works formulate documents as graphs based on word co-occurrence patterns. It assumes that if two words co-occur frequently, they should have the same topic. Nevertheless, it introduces noise edges into the model and thus hinders topic quality since two words co-occur frequently do not mean that they are on the same topic. In this paper, we use the commonsense relationship between words as a bridge to connect the words in each document. Compared to word co-occurrence, the commonsense relationship can explicitly imply the semantic relevance between words, which can be utilized to filter out noise edges. We use a relational graph neural network to capture the relation information in the graph. Moreover, manifold regularization is utilized to constrain the documents' topic distributions. Experimental results on a public dataset show that our method is effective at extracting topics compared to baseline methods.\"},\n",
       " '10.1007/s10462-022-10254-w': {'title': 'Short text topic modelling approaches in the context of big data: taxonomy, survey, and analysis',\n",
       "  'abstract': 'Social media platforms such as (Twitter, Facebook, and Weibo) are being increasingly embraced by individuals, groups, and organizations as a valuable source of information. This social media generated information comes in the form of tweets or posts, and normally characterized as short text, huge, sparse, and low density. Since many real-world applications need semantic interpretation of such short texts, research in Short Text Topic Modeling (STTM) has recently gained a lot of interest to reveal unique and cohesive latent topics. This article examines the current state of the art in STTM algorithms. It presents a comprehensive survey and taxonomy of STTM algorithms for short text topic modelling. The article also includes a qualitative and quantitative study of the STTM algorithms, as well as analyses of the various strengths and drawbacks of STTM techniques. Moreover, a comparative analysis of the topic quality and performance of representative STTM models is presented. The performance evaluation is conducted on two real-world Twitter datasets: the Real-World Pandemic Twitter (RW-Pand-Twitter) dataset and Real-world Cyberbullying Twitter (RW-CB-Twitter) dataset in terms of several metrics such as topic coherence, purity, NMI, and accuracy. Finally, the open challenges and future research directions in this promising field are discussed to highlight the trends of research in STTM. The work presented in this paper is useful for researchers interested in learning state-of-the-art short text topic modelling and researchers focusing on developing new algorithms for short text topic modelling.'},\n",
       " '10.1007/978-3-030-99736-6_32': {'title': 'Topic Modeling on Podcast Short-Text Metadata',\n",
       "  'abstract': 'Podcasts have emerged as a massively consumed online content, notably due to wider accessibility of production means and scaled distribution through large streaming platforms. Categorization systems and information access technologies typically use topics as the primary way to organize or navigate podcast collections. However, annotating podcasts with topics is still quite problematic because the assigned editorial genres are broad, heterogeneous or misleading, or because of data challenges (e.g. short metadata text, noisy transcripts). Here, we assess the feasibility to discover relevant topics from podcast metadata, titles and descriptions, using topic modeling techniques for short text. We also propose a new strategy to leverage named entities (NEs), often present in podcast metadata, in a Non-negative Matrix Factorization (NMF) topic modeling framework. Our experiments on two existing datasets from Spotify and iTunes and Deezer, a new dataset from an online service providing a catalog of podcasts, show that our proposed document representation, NEiCE, leads to improved topic coherence over the baselines. We release the code for experimental reproducibility of the results ( https://github.com/deezer/podcast-topic-modeling ).'},\n",
       " '10.1007/s11280-021-00963-7': {'title': 'Hierarchical neural topic modeling with manifold regularization',\n",
       "  'abstract': 'Topic models have been widely used for learning the latent explainable representation of documents, but most of the existing approaches discover topics in a flat structure. In this study, we propose an effective hierarchical neural topic model with strong interpretability. Unlike the previous neural topic models, we explicitly model the dependency between layers of a network, and then combine latent variables of different layers to reconstruct documents. Utilizing this network structure, our model can extract a tree-shaped topic hierarchy with low redundancy and good explainability by exploiting dependency matrices. Furthermore, we introduce manifold regularization into the proposed method to improve the robustness of topic modeling. Experiments on real-world datasets validate that our model outperforms other topic models in several widely used metrics with much fewer computation costs.'},\n",
       " '10.1016/j.asoc.2021.107440': {'title': 'Topic-level sentiment analysis of social media data using deep learning',\n",
       "  'abstract': 'Due to the inception of Web 2.0 and freedom to facilitate the dissemination of information, sharing views, expressing opinions with regards to current world level events, services, products, etc. social media platforms have been mainly contributing to user-generated content. Such social media data consist of various themes discussed online and are associated with sentiments of the users. To catch up with the speed of streaming data at which it generates on social media platforms, it is crucial to detect the topics being discussed on social media platforms and analyze the sentiments of users towards those topics in an online manner to make timely decisions. Motivated by the same, this paper proposes a deep learning based topic-level sentiment analysis model. The novelty of the proposed approach is that it works at the sentence level to extract the topic using online latent semantic indexing with regularization constraint and then applies topic-level attention mechanism in long short-term memory network to perform sentiment analysis. The proposed model is unique in the sense that it supports scalable and dynamic topic modeling over streaming short text data and performs sentiment analysis at topic-level. For SemEval-2017 Task 4 Subtask B dataset as a case of in-domain topic-level sentiment analysis, average recall of 0.879 has been achieved, whereas, for out-of-domain data, average recall of 0.846, 0.824 and 0.794 has been achieved for newly developed datasets collected under the hashtags #ethereum, #bitcoin and #facebook from Twitter. To assess the performance of the model for scalability, we analyzed the model in terms of average time in milliseconds for creation of feature vectors, throughput in terms of topics detected per second and average response time in seconds to handle the sentiment analysis queries. The experimental results are significant enough to enable large scale topic modeling over streaming data and perform topic-level sentiment analysis. • Continuous streaming data from social media platform require online learning. • Proposed online latent semantic indexing model to extract the topics. • Applied topic-level attention mechanism with LSTM on streaming data. • Performed sentiment analysis at topic-level on streaming data. • Scalable to large streaming data and supports out-of-domain sentiment analysis.'},\n",
       " '10.1007/978-3-030-60450-9_66': {'title': 'Learning Multilingual Topics with Neural Variational Inference',\n",
       "  'abstract': 'Multilingual topic models are one of the most popular methods for revealing common latent semantics of cross-lingual documents. However, traditional approximation methods adopted by existing probabilistic models sometimes do not effectively lead to high-quality multilingual topics. Besides, as the generative processes of these models become more expressive, the difficulty of performing fast and accurate inference methods over parameters grows. In this paper, to address these issues, we propose a new multilingual topic model that permits training by backpropagation in the framework of neural variational inference. We propose to infer topic distributions via a shared inference network to capture common word semantics and an incorporating module to incorporate the topic-word distribution from another language through a novel transformation method. Thus, the networks of cross-lingual corpora are coupled together. With jointly training the coupled networks, our model can infer more interpretable multilingual topics and discriminative topic distributions. Experimental results on real-world datasets show the superiority of our model both in terms of topic quality and text classification performance.'},\n",
       " '10.1007/978-3-642-28997-2_32': {'title': 'Classification of Short Texts by Deploying Topical Annotations',\n",
       "  'abstract': 'We propose a novel approach to the classification of short texts based on two factors: the use of Wikipedia-based annotators that have been recently introduced to detect the main topics present in an input text, represented via Wikipedia pages, and the design of a novel classification algorithm that measures the similarity between the input text and each output category by deploying only their annotated topics and the Wikipedia link-structure. Our approach waives the common practice of expanding the feature-space with new dimensions derived either from explicit or from latent semantic analysis. As a consequence it is simple and maintains a compact intelligible representation of the output categories. Our experiments show that it is efficient in construction and query time, accurate as state-of-the-art classifiers (see e.g. Phan et al. WWW ’08), and robust with respect to concept drifts and input sources.'},\n",
       " '10.1016/j.neunet.2024.106222': {'title': 'MuLAN: Multi-level attention-enhanced matching network for few-shot knowledge graph completion',\n",
       "  'abstract': 'Recent years have witnessed increasing interest in the few-shot knowledge graph completion due to its potential to augment the coverage of few-shot relations in knowledge graphs. Existing methods often use the one-hop neighbors of the entity to enhance its embedding and match the query instance and support set at the instance level. However, such methods cannot handle inter-neighbor interaction, local entity matching and the varying significance of feature dimensions. To bridge this gap, we propose the Multi-Level Attention-enhanced matching Network (MuLAN) for few-shot knowledge graph completion. In MuLAN, a multi-head self-attention neighbor encoder is designed to capture the inter-neighbor interaction and learn the entity embeddings. Then, entity-level attention and instance-level attention are responsible for matching the query instance and support set from the local and global perspectives, respectively, while feature-level attention is utilized to calculate the weights of the feature dimensions. Furthermore, we design a consistency constraint to ensure the support instance embeddings are close to each other. Extensive experiments based on two well-known datasets (i.e., NELL-One and Wiki-One) demonstrate significant advantages of MuLAN over 11 state-of-the-art competitors. Compared to the best-performing baseline, MuLAN achieves 14.5% higher MRR and 13.3% higher Hits@K on average.'},\n",
       " '10.1016/j.compbiomed.2024.107936': {'title': 'A few-shot link prediction framework to drug repurposing using multi-level attention network',\n",
       "  'abstract': 'Drug repurposing is a strategy aiming at uncovering novel medical indications of approved drugs. This process of discovery can be effectively represented as a link prediction task within a medical knowledge graph by predicting the missing relation between the disease entity and the drug entity. Typically, the links to be predicted pertain to rare types, thereby necessitating the task of few-shot link prediction. However, the sparsity of neighborhood information and weak triplet interactions result in less effective representations, which brings great challenges to the few-shot link prediction. Therefore, in this paper, we proposed a meta-learning framework based on a multi-level attention network (MLAN) to capture valuable information in the few-shot scenario for drug repurposing. First, the proposed method utilized a gating mechanism and a graph attention network to effectively filter noise information and highlight the valuable neighborhood information, respectively. Second, the proposed commonality relation learner, employing a set transformer, effectively captured triplet-level interactions while remaining insensitive to the size of the support set. Finally, a model-agnostic meta-learning training strategy was employed to optimize the model quickly on each meta task. We conducted validation of the proposed method on two datasets specifically designed for few-shot link prediction in medical field: COVID19-One and BIOKG-One. Experimental results showed that the proposed model had significant advantages over state-of-the-art few-shot link prediction methods. Results also highlighted the valuable insights of the proposed method, which successfully integrated the components within a unified meta-learning framework for drug repurposing.'},\n",
       " '10.1016/j.eswa.2023.121725': {'title': 'Complete feature learning and consistent relation modeling for few-shot knowledge graph completion',\n",
       "  'abstract': 'Few-shot knowledge graph completion focuses on predicting unseen facts of long-tail relations in knowledge graphs with only few reference sets. The key challenge for tackling this task is how to represent the complete entity features under low data regime conditions and further build the relation scoring function of the triplet for prediction. However, existing works mainly focus on aggregating entity representations and seriously ignore the process of consistent relation modeling, resulting in unsatisfactory performance on sparse neighbors and complex relations modeling. To address the issues, this paper designs a two-branch feature extractor to capture complementary and complete representation of entities for differentiating the few examples, where each branch focuses on diverse aspect of the entity features. Furthermore, we apply a diversity loss based on the minimization of cosine similarity is applied between the two-branch feature extractors to encourage the two-branch to learn complementary features. Conditioned on the entity features, we further incorporate the structural relation representation into the semantic relation learning to keep the consistent with triplet scoring function, and consider the consistency issue of various structural relation modeling between training and test generalization. Empirical results on two public benchmark datasets NELL-One and Wiki-One demonstrate that our approach outperforms the state-of-the-art results, with relative improvements on Hits@10 for 1-shot of 4.8% and 4.4%, respectively, and achieves new state-of-the-art results. Additionally, Extensive experiments also show proficiency in dealing with complex relations and sparse neighbors.'},\n",
       " '10.1007/s41019-023-00230-x': {'title': 'Few-Shot Relation Prediction of Knowledge Graph via Convolutional Neural Network with Self-Attention',\n",
       "  'abstract': 'Abstract Knowledge graph (KG) has become the vital resource for various applications like question answering and recommendation system. However, several relations in KG only have few observed triples, which makes it necessary to develop the method for few-shot relation prediction. In this paper, we propose the C onvolutional Neural Network with Self- A ttention R elation P rediction (CARP) model to predict new facts with few observed triples. First, to learn the relation property features, we build a feature encoder by using the convolutional neural network with self-attention from the few observed triples rather than background knowledge. Then, by incorporating the learned features, we give an embedding network to learn the representation of incomplete triples. Finally, we give the loss function and training algorithm of our CARP model. Experimental results on three real-world datasets show that our proposed method improves Hits@10 by 48% on average over the state-of-the-art competitors.'},\n",
       " '10.1016/j.ipm.2023.103418': {'title': 'Meta-learning adaptation network for few-shot link prediction in heterogeneous social networks',\n",
       "  'abstract': 'Link prediction, which aims to predict future or missing links among nodes, is a crucial research problem in social network analysis. A unique few-shot challenge is link prediction on newly emerged link types without sufficient verification information in heterogeneous social networks, such as commodity recommendation on new categories. Most of current approaches for link prediction rely heavily on sufficient verified link samples, and almost ignore the shared knowledge between different link types. Hence, they tend to suffer from data scarcity in heterogeneous social networks and fail to handle newly emerged link types where has no sufficient verified link samples. To overcome this challenge, we propose a model based on meta-learning, called the meta-learning adaptation network (MLAN), which acquires transferable knowledge from historical link types to improve the prediction performance on newly emerged link types. MLAN consists of three main components: a subtask slicer, a meta migrator, and an adaptive predictor. The subtask slicer is responsible for generating community subtasks for the link prediction on historical link types. Subsequently, the meta migrator simultaneously completes multiple community subtasks from different link types to acquire transferable subtask-shared knowledge. Finally, the adaptive predictor employs the parameters of the meta migrator to fuse the subtask-shared knowledge from different community subtasks and learn the task-specific knowledge of newly emerged link types. Experimental results conducted on real-world social media datasets prove that our proposed MLAN outperforms state-of-the-art models in few-shot link prediction in heterogeneous social networks.'},\n",
       " '10.1016/j.eswa.2023.121086': {'title': 'Incorporating global–local neighbors with Gaussian mixture embedding for few-shot knowledge graph completion',\n",
       "  'abstract': 'Few-shot knowledge graph completion (FKGC) aims to predict the missing parts of the query triplet based on a small number of known samples. To solve the above task, many existing approaches enhance entity embedding by encoding local neighbor information and obtain few-shot relational representations by encoding support triples. Although these previous studies have achieved promising results, they still suffer from the following two challenges: (1) Remote neighbor contains rich semantic information, how to effectively encode remote neighbor information is the first challenge? (2) Low-frequency relations and complex relations in the knowledge graph lead to uncertainty in the semantics of the relation, how to effectively model the uncertainty of the few-shot relation is the second challenge? For the former issue, we propose a global–local neighbor encoding module, where global encoder captures remote neighbor features based on relation paths and local encoder uses the task-aware attention mechanism to capture local neighbor features. For the latter issue, we employee the adaptive gaussian mixture model to model few-shot relation, which can adapt to different queries by dynamically adjusting component weights. Link prediction experiments are conducted on two benchmark datasets NELL-One and Wiki-One, and the proposed model achieved 14.0% and 7.8% improvement in the evaluation metric Hits@1 respectively, compared to the strong baseline model FAAN.'},\n",
       " '10.1007/s40747-023-01146-9': {'title': 'Few-shot temporal knowledge graph completion based on meta-optimization',\n",
       "  'abstract': 'Abstract Knowledge Graphs (KGs) have become an increasingly important part of artificial intelligence, and KGs have been widely used in artificial intelligence fields such as intelligent answering questions and personalized recommendation. Previous knowledge graph completion methods require a large number of samples for each relation. But in fact, in KGs, many relationships are long-tail relationships, and the existing researches on few-shot completion mainly focus on static knowledge graphs. In this paper, we consider few-shot completion in Temporal Knowledge Graphs (TKGs) where the event may only hold for a specific timestamp, and propose a model abbreviated as FTMO based on meta-optimization. In this model, we combine the time-based relational-aware heterogeneous neighbor encoder, the cyclic automatic aggregation network, and the matching network to complete the few-shot temporal knowledge graph. We compare our model with the baseline models, and the experimental results demostrate the performance advantages of our model.'},\n",
       " '10.1007/978-3-031-33380-4_8': {'title': 'Relation-Aware Network with Attention-Based Loss for Few-Shot Knowledge Graph Completion',\n",
       "  'abstract': 'Few-shot knowledge graph completion (FKGC) task aims to predict unseen facts of a relation with few-shot reference entity pairs. Current approaches randomly select one negative sample for each reference entity pair to minimize a margin-based ranking loss, which easily leads to a zero-loss problem if the negative sample is far away from the positive sample and then out of the margin. Moreover, the entity should have a different representation under a different context. To tackle these issues, we propose a novel Relation-Aware Network with Attention-Based Loss (RANA) framework. Specifically, to better utilize the plentiful negative samples and alleviate the zero-loss issue, we strategically select relevant negative samples and design an attention-based loss function to further differentiate the importance of each negative sample. The intuition is that negative samples more similar to positive samples will contribute more to the model. Further, we design a dynamic relation-aware entity encoder for learning a context-dependent entity representation. Experiments demonstrate that RANA outperforms the state-of-the-art models on two benchmark datasets.'},\n",
       " '10.1016/j.neunet.2023.04.041': {'title': 'Capsule neural tensor networks with multi-aspect information for Few-shot Knowledge Graph Completion',\n",
       "  'abstract': 'Few-shot Knowledge Graph Completion (FKGC) has recently attracted significant research interest due to its ability to expand few-shot relation coverage in Knowledge Graphs. Prevailing FKGC approaches focus on exploiting the one-hop neighbor information of entities to enhance few-shot relation embedding. However, these methods select one-hop neighbors randomly and neglect the rich multi-aspect information of entities. Although some methods have attempted to leverage Long Short-Term Memory (LSTM) to learn few-shot relation embedding, they are sensitive to the input order. To address these limitations, we propose the Capsule Neural Tensor Networks with Multi-Aspect Information approach (short for InforMix-FKGC). InforMix-FKGC employs a one-hop neighbor selection strategy based on how valuable they are and encodes multi-aspect information of entities, including one-hop neighbors, attributes and literal description. Then, a capsule network is responsible for integrating the support set and deriving few-shot relation embedding. Moreover, a neural tensor network is used to match the query set with the support set. In this way, InforMix-FKGC can learn few-shot relation embedding more precisely so as to enhance the accuracy of FKGC. Extensive experiments on the NELL-One and Wiki-One datasets demonstrate that InforMix-FKGC significantly outperforms ten state-of-the-art methods in terms of Mean Reciprocal Rank and [email protected].'},\n",
       " '10.1016/j.bdr.2023.100394': {'title': 'Meta-Learning Based Dynamic Adaptive Relation Learning for Few-Shot Knowledge Graph Completion',\n",
       "  'abstract': 'As artificial intelligence gradually steps into cognitive intelligence stage, knowledge graphs (KGs) play an increasingly important role in many natural language processing tasks. Due to the prevalence of long-tail relations in KGs, few-shot knowledge graph completion (KGC) for link prediction of long-tail relations has gradually become a hot research topic. Current few-shot KGC methods mainly focus on the static representation of surrounding entities to explore the potential semantic features of entities, while ignoring the dynamic properties among entities and the special influence of the long-tail relation on link prediction. In this paper, a new meta-learning based dynamic adaptive relation learning model (DARL) is proposed for few-shot KGC. For obtaining better semantic information of the meta knowledge, the proposed DARL model applies a dynamic neighbor encoder to incorporate neighbor relations into entity embedding. In addition, DARL builds attention mechanism based fusion strategy for different attributes of the same relation to further enhance the relation-meta learning ability. We evaluate our DARL model on two public benchmark datasets NELL-One and WIKI-One for link prediction. Extensive experimental results indicate that our DARL outperforms the state-of-the-art models with an average relative improvement about 23.37%, 32.46% in MRR and Hits@1 on NELL-One, respectively.'},\n",
       " '10.1016/j.jksuci.2023.03.008': {'title': 'Knowledge graph representation learning model based on meta-information and logical rule enhancements',\n",
       "  'abstract': 'Existing knowledge graph representation learning (KGRL) models rely on explicit semantic information of triple structure and cannot fully mine the implicit semantic information in the knowledge graph (KG). Aiming to improve KGRL model performance and accuracy, making up for the disadvantages of existing research, we propose Melo (Meta-information and Logical rules), a novel KGRL model that leverages meta-information and logical rules of entities and relations. Melo first utilizes neighborhood structures of entities to obtain meta-information and ontological information, then it mines logical rules from the KG to infer high-confidence triples and expand the training samples. Finally, Melo realizes accurate and reliable representations of entities and relations with help of meta-, logical, and triple structure information. Experimental results on regular and sparse datasets show its enhanced performance when compared with baselines in terms of multiple evaluation metrics. Visualization methods are also utilized to demonstrate how meta-information, logical rules, and triple structure mutually and separately enhance training.'},\n",
       " '10.1016/j.neucom.2023.03.049': {'title': 'TransAM: Transformer appending matcher for few-shot knowledge graph completion',\n",
       "  'abstract': 'Few-shot knowledge graph completion (FSKGC) refers to predicting new facts for a new relation with only few-shot observed entity pairs (triples) as support set. Existing solutions to FSKGC mainly conduct the matching process over entity pair representations. Although effective, a major concern of these models is that the entity interactions are not fully explored, based on the observation that they usually generate the pair representation before the matching stage. Such a design inherently overlooks the fine-grained information from entity interactions, leading to performance decrements in one or three shot, which require matching models to capture more sufficient semantic meanings for prediction. To remedy this issue, in this paper, we explore the entity interactions within and between different instances, i.e., the co-occurrence of two entities, for FSKGC and propose our model named TransAM, Transformer Appending Matcher. TransAM solves the FSKGC problem by computing the probability of entity sequence with a well-designed transformer matching network. Specifically, TransAM appends query entity pair to serialized reference entity sequence and utilizes transformer to calculate the probability by capturing intra- and inter- triple entity interactions. To bridge the gap between transformer and the triple structure, TransAM introduces rotary operation to preserve the head and tail roles of entity within the triple and distinguishes different triples by a separated triple position encoding. Empirical studies on two public benchmark datasets NELL-One and Wiki-One show that TransAM outperforms existing metric-learning solutions in MRR and Hits@1 with both one- and three- shot settings, and achieves comparable results on five-shot setting. Datasets and code will be public available at https://github.com/gawainx/TransAM.'},\n",
       " '10.1016/j.patcog.2022.108830': {'title': 'Heterogeneous representation learning and matching for few-shot relation prediction',\n",
       "  'abstract': 'The recent explosive development of knowledge graphs (KGs) in artificial intelligence tasks coupled with incomplete or partial information has triggered considerable research interest in relation prediction. However, many challenges still remain unsolved: (i) the previous relation prediction methods require a significant amount of training instances (i.e., head-tail entity pairs) for every relation, which is infeasible in practical scenarios; and (ii) the representation learning of entities and relations always assumes that all local neighbors and their features contribute equally to the embedding, not sufficiently considering the heterogeneity of the information; and (iii) the state-of-the-art methods usually require a lot of training time, resulting in a high cost in real-world applications. To overcome these challenges, we propose a heterogeneous representation learning and matching approach, Multi-metric Feature Extraction Network (MFEN for short), for few-shot relation prediction in KGs. Our method focuses on knowledge graphs to sufficiently explore the topological structure and node content in graphs. Rather than taking the average of the embeddings of all relational neighbors, a heterogeneity-aware representation learning method is proposed to generate high-expressive embeddings, which capture the heterogenous roles of the relational neighbors of given entity and all of their features via a convolutional encoder. To learn the expressive representations efficiently, a single-layer CNN architecture with multi-scale filters is devised. In addition, multiple heuristic metrics are combined to efficiently improve the accuracy of similarity calculation. The proposed MFEN model is evaluated on two representative benchmark datasets NELL and Wiki. Extensive experiments have demonstrated that our method gets more than 5% accuracy improvement and three times speedup to state-of-the-art models. Code is available on https://github.com/summer-funny/MFEN.'},\n",
       " '10.1016/j.ipm.2024.103705': {'title': 'ProMvSD: Towards unsupervised knowledge graph anomaly detection via prior knowledge integration and multi-view semantic-driven estimation',\n",
       "  'abstract': 'Knowledge graphs (KGs) have found extensive applications within intelligent systems, such as information retrieval. Much of the research has predominantly focused on completing missing knowledge, with little consideration given to examining errors. Unfortunately, during customizing KGs, diverse unpredictable errors are virtually unavoidable to be introduced, and these anomalies significantly impact the performance of applications. Detecting erroneous knowledge presents a formidable challenge due to the costly acquisition of ground-truth labels. In this work, we develop an unsupervised anomaly detection framework named ProMvSD, aiming to adapt KGs of varying scales via serialization components. To overcome the insufficient contextual information provided by the topological structure, we introduce the large language model as a reasoner to extract prior knowledge from extensive pre-trained textual data, thereby enhancing the understanding of KGs. Anomalous triple may result in a larger semantic gap between the head and tail neighborhoods. To uncover latent anomalies effectively, we propose a multi-view semantic-driven model (MvSD) based on the assumptions of self-consistency and information stability. MvSD jointly estimates the suspiciousness of triples from three hyperviews: node-view semantic contradiction, triple-view semantic gap, and pathway-view semantic gap. Extensive experiments on three English benchmark KGs and a Chinese medical KG demonstrate that, for the top 1% of the most suspicious triples, we can detect real anomalies with at most 99.9% accuracy. Furthermore, ProMvSD significantly outperforms state-of-the-art representation learning baselines, achieving a 29.2% improvement in detecting all anomalies.'},\n",
       " '10.1007/978-3-031-26390-3_11': {'title': 'MULTIFORM: Few-Shot Knowledge Graph Completion via Multi-modal Contexts',\n",
       "  'abstract': 'Knowledge Graphs (KGs) have been applied to many downstream applications such as semantic web, recommender systems, and natural language processing. Previous research on Knowledge Graph Completion (KGC) usually requires a large number of training instances for each relation. However, considering the accelerated growth of online information, there can be some relations that do not have enough training examples. In fact, in most real-world knowledge graph datasets, instance frequency obeys a long-tail distribution. Existing knowledge embedding approaches suffer from the lack of training instances. One approach to alleviating this issue is to incorporate few-shot learning. Despite the progress they bring, they sorely depend on entities’ local graph structure and ignore the multi-modal contexts, which could make up for the lack of training information in the few-shot scenario. To this end, we propose a multi-modal few-shot relational learning framework, which utilizes the entities’ multi-modal contexts to connect few instances to the knowledge graphs. For the first stage, we encode entities’ images, text descriptions, and neighborhoods to acquire well-learned entity representations. In the second stage, our framework learns a matching metric to match the query triples with few-shot reference examples. The experimental results on two newly constructed datasets show the superiority of our framework against various baselines.'},\n",
       " '10.1007/978-3-030-18579-4_19': {'title': 'Adaptive Attention-Aware Gated Recurrent Unit for Sequential Recommendation',\n",
       "  'abstract': \"Due to the dynamic and evolutionary characteristics of user interests, sequential recommendation plays a significant role in recommender systems. A fundamental problem in the sequential recommendation is modeling dynamic user preference. Recurrent Neural Networks (RNNs) are widely adopted in the sequential recommendation, especially attention-based RNN becomes the state-of-the-art solution. However the existing fixed attention mechanism is insufficient to model the dynamic and evolutionary characteristics of user sequential preferences. In this work, we propose a novel solution, Adaptive Attention-Aware Gated Recurrent Unit (3AGRU), to learn adaptive user sequential representations for sequential recommendation. Specifically, we adopt an attention mechanism to adapt the representation of user sequential preference, and learn the interaction between steps and items from data. Moreover, in the first level of 3AGRU, we construct adaptive attention network to describe the relevance between input and the candidate item. In this way, a new input based on adaptive attention can reflect users' diverse interests. Then, the second level of 3AGRU applies adaptive attention network to hidden state level to learn a deep user representation which is able to express diverse interests of the user. Finally, we evaluate the proposed model using three real-world datasets from various application scenarios. Our experimental results show that our model significantly outperforms the state-of-the-art approaches on sequential recommendation.\"},\n",
       " '10.1016/j.knosys.2022.108488': {'title': 'GCN-based document representation for keyphrase generation enhanced by maximizing mutual information',\n",
       "  'abstract': 'Keyphrase generation is an important fundamental task of natural language processing, which can help users quickly obtain valuable information from a large number of documents especially when they are facing with informal social media text. Existing Recurrent Neural Network (RNN) based keyphrase generation approaches cannot properly model the dependency structure of the informal text, which is often implicit between those distant words and plays an important role in extracting salient information. To obtain core features of text, we apply Graph Convolutional Network (GCN) on document-level graph to capture dependency structure information. The GCN-based node representations are further fed into a predictor network to provide potential candidates for copying mechanism. Moreover, we utilize a novel variational selector network to determine the final selection probability of each word in a phrase, which relies on its probabilities of copying from a given document and being generated from a vocabulary. Eventually, we introduce an enhancement mechanism to maximize the mutual information between document and generated keyphrase, thus ensuring the consistency between them. Experiment results show that our model outperforms previous state-of-the-art baselines on three social datasets, including Weibo, Twitter and StackExchange.'},\n",
       " '10.1016/0004-3702(90)90084-D': {'title': 'Pragmatics and natural language generation',\n",
       "  'abstract': \"This paper addresses the question “why and how is it that we say the same thing differently to different people, or even to the same person in different circumstances?” We vary the content and form of our text in order to convey more information than is contained in the literal meanings of our words. This information expresses the speaker's interpersonal goals toward the hearer and, in general, his or her perception of the pragmatic aspects of the conversation. This paper discusses two insights that arise when one studies this question: the existence of a level of organization that mediates between communicative goals and generator decisions, and the interleaved planning-realization regime and associated monitoring required for generation. To illustrate these ideas, a computer program is described which contains plans and strategies to produce stylistically appropriate texts from a single representation under various settings that model pragmatic circumstances.\"},\n",
       " '10.1016/0004-3702(85)90082-7': {'title': 'Discourse strategies for generating natural-language text',\n",
       "  'abstract': 'If a generation system is to produce text in response to a given communicative goal, it must be able to determine what to include in its text and how to organize this information so that it can be easily understood. In this paper, a computational model of discourse strategies is presented that can be used to guide the generation process in its decisions about what to say next. The model is based on an analysis of naturally occurring texts and represents strategies that can be used for three communicative goals: define, compare, and describe. We show how this model has been implemented in text, a system which generates paragraph-length responses to questions about database structure.'},\n",
       " '10.1007/978-1-4757-5945-7_3': {'title': 'Approaches to the Planning of Coherent Text',\n",
       "  'abstract': 'This paper discusses the planning of multisentential text by computer. In order to construct coherent paragraphs, we have been using relations from Rhetorical Structure Theory (RST) operationalized as plans. The paper first describes, in some detail, the current method of planning a paragraph using operationalized RST relation/plans. It then makes two points that illustrate why RST relation/plans are an ideal tool for planning paragraphs. First, these relation/plans can be shown to combine the best features of paragraph-sized schemas and clause-sized planning rules under a top-down planning regime in a way which affords much flexibility to the user. Second, RST relation/plans can support both standard top-down planning and open-ended conversation-like behavior; a small difference in treatment gives rise to either paradigm.'},\n",
       " '10.1016/j.engappai.2024.108148': {'title': 'DCDSum: An interpretable extractive summarization framework based on contrastive learning method',\n",
       "  'abstract': 'As the phenomenon of knowledge overload becomes more and more obvious, the automatic summarization technology still needs to break through the bottleneck in order to improve the application value and expand the scope of the application. Traditional training paradigms for extractive summarization systems suffer from the inconsistency in training and evaluation. In this paper, we propose an innovative and interpretable contrastive learning based framework for extractive summarization called DCDSum, which comprises a Diverse Oracle evaluator, a Contrastive learning extractor, and a Dynamic Top-k selector. Different from previous models that consider the extractive summarization task as a sequence labeling problem, our contrastive learning extractor treats it as a sentence reranking problem and introduces contrastive loss to achieve it, which can bridge the gap between objective function and evaluation metrics. The experimental results demonstrate the outstanding performance of our approach on the CNN/DailyMail, XSum, and PubMed datasets, achieving highly competitive results. In particular, our method achieves ROUGE-1 of 44.65, ROUGE-2 of 21.32, and ROUGE-L of 40.87 on the CNN/DailyMail dataset. The outcomes across various evaluation metrics substantiate that the Diverse Oracle extraction algorithm adeptly captures a broader array of sentences with reduced redundancy, consequently enhancing the interpretability of the DCDSum framework.'},\n",
       " '10.1007/978-3-030-88480-2_8': {'title': 'Contrastive Learning for Machine Translation Quality Estimation',\n",
       "  'abstract': 'Machine translation quality estimation (QE) aims to evaluate the result of translation without reference. Existing approaches require large amounts of training data or model-related features, leading to impractical applications in real world. In this work, we propose a contrastive learning framework to train QE model with limited parallel data. Concretely, we use denoising autoencoder to create negative samples based on sentence reconstruction. Then the QE model is trained to distinguish the golden pair from the negative samples in a contrastive manner. To this end, we propose two contrastive learning architectures, namely Contrastive Classification and Contrastive Ranking. Experiments on four language pairs of MLQE dataset show that our method achieves strong results in both zero-shot and supervised settings. To the best of our knowledge, this is the first trial of contrastive learning on QE.'},\n",
       " '10.1007/s10586-022-03707-y': {'title': 'Popular deep learning algorithms for disease prediction: a review',\n",
       "  'abstract': 'Due to its automatic feature learning ability and high performance, deep learning has gradually become the mainstream of artificial intelligence in recent years, playing a role in many fields. Especially in the medical field, the accuracy rate of deep learning even exceeds that of doctors. This paper introduces several deep learning algorithms: Artificial Neural Network (NN), FM-Deep Learning, Convolutional NN and Recurrent NN, and expounds their theory, development history and applications in disease prediction; we analyze the defects in the current disease prediction field and give some current solutions; our paper expounds the two major trends in the future disease prediction and medical field-integrating Digital Twins and promoting precision medicine. This study can better inspire relevant researchers, so that they can use this article to understand related disease prediction algorithms and then make better related research.'},\n",
       " '10.1007/978-3-319-99501-4_24': {'title': 'Densely Connected Bidirectional LSTM with Applications to Sentence Classification',\n",
       "  'abstract': 'Deep neural networks have recently been shown to achieve highly competitive performance in many computer vision tasks due to their abilities of exploring in a much larger hypothesis space. However, since most deep architectures like stacked RNNs tend to suffer from the vanishing-gradient and overfitting problems, their effects are still understudied in many NLP tasks. Inspired by this, we propose a novel multi-layer RNN model called densely connected bidirectional long short-term memory (DC-Bi-LSTM) in this paper, which essentially represents each layer by the concatenation of its hidden state and all preceding layers hidden states, followed by recursively passing each layers representation to all subsequent layers. We evaluate our proposed model on five benchmark datasets of sentence classification. DC-Bi-LSTM with depth up to 20 can be successfully trained and obtain significant improvements over the traditional Bi-LSTM with the same or even fewer parameters. Moreover, our model has promising performance compared with the state-of-the-art approaches.'},\n",
       " '10.1016/j.ins.2016.08.084': {'title': 'Attention pooling-based convolutional neural network for sentence modelling',\n",
       "  'abstract': 'Convolutional neural network has been proven to be a powerful semantic composition model for modelling sentences. A standard convolutional neural network usually consists of several convolutional and pooling layers at the bottom of a linear or non-linear classifier. In this paper, a new pooling scheme termed Attention Pooling is proposed to retain the most significant information at the pooling stage. An intermediate sentence representation generated by the bidirectional long short-term memory is used as a reference for local representations produced by the convolutional layer to obtain attention weights. The sentence representation is formed by combining local representations using obtained attention weights. The intermediate sentence representation is used as an input to the top classifier as well in the testing phase. The salient features of the proposed attention pooling-based convolutional neural network are: (1) The model can be trained end-to-end with limited hyper-parameters; (2) Comprehensive information is extracted by the new pooling scheme and the combination of the convolutional layer and the bidirectional long-short term memory; (3) The model can implicitly separate the sentences from different classes. Experimental results demonstrate that the new model outperforms the state-of-the-art approaches on seven benchmark datasets for text classification. The learning capability of the proposed method is greatly improved and the classification accuracy is even enhanced significantly by over 2% on some datasets. The robustness of the proposed model is evidenced by some statistical tests.'},\n",
       " '10.1016/j.ipm.2023.103511': {'title': 'Deep purified feature mining model for joint named entity recognition and relation extraction',\n",
       "  'abstract': 'Table filling based joint named entity recognition and relation extraction task aims to share representation of subtasks in a table to extract structured knowledge. However, most of existing studies need additional labels and dedicated deep neural networks to learn shared representation, imposing heavy burdens to decoders. More seriously, almost all these models suffer from feature confusion problem, failing to capture purified task-specific features from shared representation to perform subtasks. To address these challenging problems, in this paper we propose a novel and effective Deep puRified fEAture Mining (DREAM) model for joint named entity recognition and relation extraction task, which can automatically capture purified task-specific features to improve the classification performance of subtasks. Specifically, unlike introducing additional labels or dedicated network architectures, we design a new lightweight shared representation learning (LSRL) module by the plainest labels of joint task and thus encodes context by the hybrid convolutional neural networks. Afterwards, a task-aware information bottleneck (TIB) module is proposed to explore the relation between the mutual information of the joint distribution of each subtask and its task-specific features. With the above two modules well obtain shared representation and purified task-specific features, the satisfactory classification results of both subtasks can be guaranteed. Experiment results show that the proposed model is highly effective, obtaining the promising results on three different benchmarks: CoNNL04 (general text), ADE (biomedical text) and SciERC (scientific text). For example, DREAM respectively achieves F1-scores of 78.18%, 80.28% and 44.60% in performing the relation extraction subtask on the CoNNL04, ADE and SciERC datasets. The promising performance indicates that the proposed model can be applied to many practical applications such as biomedical information extraction. The source code is publicly available at https://github.com/SWT-AITeam/DREAM.'},\n",
       " '10.1016/j.cogsys.2023.101153': {'title': 'Enhancing interaction representation for joint entity and relation extraction',\n",
       "  'abstract': 'Jointly extracting entities and their relations from texts is an important task in information extraction. Despite the great success, traditional models suffer from two problems. First, the same token embeddings are shared in two subtasks. It ignores the difference between semantic granularities, in which named entities are more dependent on local features and relations are semantic expressions relevant a whole sentence. Second, the interaction between two subtasks is rarely considered, which is important to encode semantic dependencies relevant to two named entities. To address the above problems, we presents a novel joint entity and relation extraction model. It constructs two independent token embedding modules for encoding features about entities and relations respectively. It enables to encode semantic representations with different granularities for named entities and entity relations. Then, a cross-attention is used to capture the interaction between two subtasks for learning semantic dependencies in a relation instance. The experimental results demonstrate that our model outperforms previous state-of-art models on several public datasets. Extensive additional experiments further confirm the effectiveness of our model.'},\n",
       " '10.1016/j.eswa.2023.120182': {'title': 'Automatic information extraction in the AI chip domain using gated interactive attention and probability matrix encoding method',\n",
       "  'abstract': 'Artificial intelligence (AI) that utilizes neural networks (NNs) has a broad range of applications. However, NNs necessitate significant amounts of computation and data storage, which imposes considerable hardware demands and drives the need for AI chip research. To address this need, AI chip researchers must delve into extensive literature for entity information on hardware issues, architectures, optimizations, performances, and applications. Nevertheless, the influx of relevant papers has far surpassed their ability to read and absorb all the information. In this article, automatic information extraction in the AI chip domain using entity recognition techniques is conducted to alleviate the burden of paper reading for AI chip researchers. Our approach involves creating a manually annotated dataset called the ACER dataset to support automatic information extraction from literature in the field of AI chips. To address the challenge of recognizing entities with complex structures and lacking explicit features, the GIA-PME model is proposed, which utilizes a gated interaction attention mechanism and probability-matrix encoding. Our proposed approach enhances entity cognition by utilizing the keyword sequence of each entity type as prior knowledge. It also incorporates a dedicated embedding to learn the eigenvectors of entity structures. Finally, it combines the prior knowledge with eigenvectors using a designed gated interactive attention mechanism to assist with recognition. In addition, the proposed probability matrix encoding is used to detect nested entities to avoid information loss. Experimental results show that our GIA-PME model achieves the best performance compared to existing models, thus improving the strict/relaxed F1-score to 70.9/81.7 (+5.3 ∼ 9.1) on the ACER dataset.'},\n",
       " '10.1007/978-3-031-18315-7_11': {'title': 'A Multi-Gate Encoder for Joint Entity and Relation Extraction',\n",
       "  'abstract': 'Named entity recognition and relation extraction are core sub-tasks of relational triple extraction. Recent studies have used parameter sharing or joint decoding to create interaction between these two tasks. However, ensuring the specificity of task-specific traits while the two tasks interact properly is a huge difficulty. We propose a multi-gate encoder that models bidirectional task interaction while keeping sufficient feature specificity based on gating mechanism in this paper. Precisely, we design two types of independent gates: task gates to generate task-specific features and interaction gates to generate instructive features to guide the opposite task. Our experiments show that our method increases the state-of-the-art (SOTA) relation F1 scores on ACE04, ACE05 and SciERC datasets to 63.8% (+1.3%), 68.2% (+1.4%), 39.4% (+1.0%), respectively, with higher inference speed over previous SOTA model.'},\n",
       " '10.1016/j.knosys.2023.110957': {'title': 'Efficient dynamic feature adaptation for cross language sentiment analysis with biased adversarial training',\n",
       "  'abstract': 'Fine-tuning a large multi-lingual pretrained language model demonstrates impressive results in cross-language understanding. However, it still suffers when the training and test data have different distributions owing to various languages and domains. On one hand, annotating target data for different languages or domains is time-consuming or infeasible. On the other hand, fine-tuning a large language model often incurs high computational costs. In this paper, we aim to develop an efficient and effective adaptation framework for cross-language sentiment analysis based on a fixed pretrained multi-lingual model. Specifically, we propose a Dynamic Feature Adaptation (DFA) module to fully leverage the features from different layers of the pretrained model such that its large backbone is not involved during adaptation training. Furthermore, we observe that traditional adversarial domain adaptation training could compromise the discriminative information of the model by pushing source and target features towards each other. The source features obtained with supervised training preserved the discriminability of the model, which should be less affected. Therefore, we propose a novel Biased Adversarial Training (BAT) method, that encourages only the target features towards source features. Extensive experimental results on various cross-lingual and cross-lingual-and-domain sentiment analysis tasks demonstrate the superiority of the proposed framework. Additionally, several ablation studies are conducted to validate the effectiveness of each proposed module.'},\n",
       " '10.1016/j.ipm.2022.102964': {'title': 'AdaSL: An Unsupervised Domain Adaptation framework for Arabic multi-dialectal Sequence Labeling',\n",
       "  'abstract': 'Dialectal Arabic (DA) refers to varieties of everyday spoken languages in the Arab world. These dialects differ according to the country and region of the speaker, and their textual content is constantly growing with the rise of social media networks and web blogs. Although research on Natural Language Processing (NLP) on standard Arabic, namely Modern Standard Arabic (MSA), has witnessed remarkable progress, research efforts on DA are rather limited. This is due to numerous challenges, such as the scarcity of labeled data as well as the nature and structure of DA. While some recent works have reached decent results on several DA sentence classification tasks, other complex tasks, such as sequence labeling, still suffer from weak performances when it comes to DA varieties with either a limited amount of labeled data or unlabeled data only. Besides, it has been shown that zero-shot transfer learning from models trained on MSA does not perform well on DA. In this paper, we introduce AdaSL, a new unsupervised domain adaptation framework for Arabic multi-dialectal sequence labeling, leveraging unlabeled DA data, labeled MSA data, and existing multilingual and Arabic Pre-trained Language Models (PLMs). The proposed framework relies on four key components: (1) domain adaptive fine-tuning of multilingual/MSA language models on unlabeled DA data, (2) sub-word embedding pooling, (3) iterative self-training on unlabeled DA data, and (4) iterative DA and MSA distribution alignment. We evaluate our framework on multi-dialectal Named Entity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The overall results show that the zero-shot transfer learning, using our proposed framework, boosts the performance of the multilingual PLMs by 40.87% in macro-F1 score for the NER task, while it boosts the accuracy by 6.95% for the POS tagging task. For the Arabic PLMs, our proposed framework increases performance by 16.18% macro-F1 for the NER task and 2.22% accuracy for the POS tagging task, and thus, achieving new state-of-the-art zero-shot transfer learning performance for Arabic multi-dialectal sequence labeling.'},\n",
       " '10.1007/978-3-030-01219-9_18': {'title': 'Unsupervised Domain Adaptation for Semantic Segmentation via Class-Balanced Self-training',\n",
       "  'abstract': 'Recent deep networks achieved state of the art performance on a variety of semantic segmentation tasks. Despite such progress, these models often face challenges in real world “wild tasks” where large difference between labeled training/source data and unseen test/target data exists. In particular, such difference is often referred to as “domain gap”, and could cause significantly decreased performance which cannot be easily remedied by further increasing the representation power. Unsupervised domain adaptation (UDA) seeks to overcome such problem without target domain labels. In this paper, we propose a novel UDA framework based on an iterative self-training (ST) procedure, where the problem is formulated as latent variable loss minimization, and can be solved by alternatively generating pseudo labels on target data and re-training the model with these labels. On top of ST, we also propose a novel class-balanced self-training (CBST) framework to avoid the gradual dominance of large classes on pseudo-label generation, and introduce spatial priors to refine generated labels. Comprehensive experiments show that the proposed methods achieve state of the art semantic segmentation performance under multiple major UDA settings.'},\n",
       " '10.1007/978-3-319-46493-0_36': {'title': 'Deep Reconstruction-Classification Networks for Unsupervised Domain Adaptation',\n",
       "  'abstract': 'In this paper, we propose a novel unsupervised domain adaptation algorithm based on deep learning for visual object recognition. Specifically, we design a new model called Deep Reconstruction-Classification Network (DRCN), which jointly learns a shared encoding representation for two tasks: (i) supervised classification of labeled source data, and (ii) unsupervised reconstruction of unlabeled target data. In this way, the learnt representation not only preserves discriminability, but also encodes useful information from the target domain. Our new DRCN model can be optimized by using backpropagation similarly as the standard neural networks. We evaluate the performance of $$ DRCN $$ on a series of cross-domain object recognition tasks, where $$ DRCN $$ provides a considerable improvement (up to $$\\\\sim $$ 8 $$\\\\%$$ in accuracy) over the prior state-of-the-art algorithms. Interestingly, we also observe that the reconstruction pipeline of $$ DRCN $$ transforms images from the source domain into images whose appearance resembles the target dataset. This suggests that $$ DRCN $$ ’s performance is due to constructing a single composite representation that encodes information about both the structure of target images and the classification of source images. Finally, we provide a formal analysis to justify the algorithm’s objective in domain adaptation context.'},\n",
       " '10.1007/s10994-009-5152-4': {'title': 'A theory of learning from different domains',\n",
       "  'abstract': 'Discriminative learning methods for classification perform well when training and test data are drawn from the same distribution. Often, however, we have plentiful labeled training data from a source domain but wish to learn a classifier which performs well on a target domain with a different distribution and little or no labeled training data. In this work we investigate two questions. First, under what conditions can a classifier trained from source data be expected to perform well on target data? Second, given a small amount of labeled target data, how should we combine it during training with the large amount of labeled source data to achieve the lowest target error at test time? We address the first question by bounding a classifier’s target error in terms of its source error and the divergence between the two domains. We give a classifier-induced divergence measure that can be estimated from finite, unlabeled samples from the domains. Under the assumption that there exists some hypothesis that performs well in both domains, we show that this quantity together with the empirical source error characterize the target error of a source-trained classifier. We answer the second question by bounding the target error of a model which minimizes a convex combination of the empirical source and target errors. Previous theoretical work has considered minimizing just the source error, just the target error, or weighting instances from the two domains equally. We show how to choose the optimal combination of source and target error as a function of the divergence, the sample sizes of both domains, and the complexity of the hypothesis class. The resulting bound generalizes the previously studied cases and is always at least as tight as a bound which considers minimizing only the target error or an equal weighting of source and target errors.'},\n",
       " '10.1016/j.cub.2013.11.064': {'title': 'Dynamic Facial Expressions of Emotion Transmit an Evolving Hierarchy of Signals over Time',\n",
       "  'abstract': 'Designed by biological [1Susskind J.M. Lee D.H. Cusi A. Feiman R. Grabski W. Anderson A.K. Expressing fear enhances sensory acquisition.Nat. Neurosci. 2008; 11: 843-850Crossref PubMed Scopus (320) Google Scholar, 2Andrew R.J. Evolution of Facial Expression.Science. 1963; 142: 1034-1041Crossref PubMed Scopus (150) Google Scholar] and social [3Darwin C. The Expression of the Emotions in Man and Animals.Third Edition. Fontana Press, London1999Google Scholar] evolutionary pressures, facial expressions of emotion comprise specific facial movements [4Jack R.E. Garrod O.G.B. Yu H. Caldara R. Schyns P.G. Facial expressions of emotion are not culturally universal.Proc. Natl. Acad. Sci. USA. 2012; 109: 7241-7244Crossref PubMed Scopus (466) Google Scholar, 5Ekman P. Sorenson E.R. Friesen W.V. Pan-cultural elements in facial displays of emotion.Science. 1969; 164: 86-88Crossref PubMed Scopus (1035) Google Scholar, 6Tomkins S.S. Affect Imagery Consciousness. Volume 1. Springer, New York1962Google Scholar, 7Tomkins S.S. Affect Imagery Consciousness. Volume 2. Springer, New York1963Google Scholar, 8Ekman P. Friesen W. Hagar J.C. Facial Action Coding System Investigators Guide. Research Nexus, Salt Lake City1978Google Scholar] to support a near-optimal system of signaling and decoding [9Schyns P.G. Petro L.S. Smith M.L. Transmission of facial expressions of emotion co-evolved with their efficient decoding in the brain: behavioral and brain evidence.PLoS ONE. 2009; 4: e5625Crossref PubMed Scopus (93) Google Scholar, 10Smith J.M. Evolution and the Theory of Games. Cambridge University Press, Cambridge1993Google Scholar]. Although highly dynamical [11Jiang B. Valstar M. Martinez B. Pantic M. A dynamic appearance descriptor approach to facial actions temporal modeling.IEEE Trans Cybern. 2013; (Published online April 19, 2013)https://doi.org/10.1109/TCYB.2013.2249063Crossref PubMed Scopus (113) Google Scholar, 12Krumhuber E.G. Kappas A. Manstead A.S. Effects of dynamic aspects of facial expressions: a review.Emot. Rev. 2013; 5: 41-46Crossref Scopus (249) Google Scholar], little is known about the form and function of facial expression temporal dynamics. Do facial expressions transmit diagnostic signals simultaneously to optimize categorization of the six classic emotions, or sequentially to support a more complex communication system of successive categorizations over time? Our data support the latter. Using a combination of perceptual expectation modeling [13Yu H. Garrod O.G.B. Schyns P.G. Perception-driven facial expression synthesis.Comput. Graph. 2012; 36: 152-162Crossref Scopus (82) Google Scholar, 14Ahumada A. Lovell J. Stimulus features in signal detection.J. Acoust. Soc. Am. 1971; 49: 1751-1756Crossref Scopus (244) Google Scholar, 15Dotsch R. Wigboldus D.H.J. Langner O. van Knippenberg A. Ethnic out-group faces are biased in the prejudiced mind.Psychol. Sci. 2008; 19: 978-980Crossref PubMed Scopus (137) Google Scholar], information theory [16Shannon C.E. A mathematical theory of communication.SIGMOBILE Mob. Comput. Commun. Rev. 2001; 5: 3-55Crossref Google Scholar, 17Magri C. Whittingstall K. Singh V. Logothetis N.K. Panzeri S. A toolbox for the fast information analysis of multiple-site LFP, EEG and spike train recordings.BMC Neurosci. 2009; 10: 81Crossref PubMed Scopus (155) Google Scholar], and Bayesian classifiers, we show that dynamic facial expressions of emotion transmit an evolving hierarchy of “biologically basic to socially specific” information over time. Early in the signaling dynamics, facial expressions systematically transmit few, biologically rooted face signals [1Susskind J.M. Lee D.H. Cusi A. Feiman R. Grabski W. Anderson A.K. Expressing fear enhances sensory acquisition.Nat. Neurosci. 2008; 11: 843-850Crossref PubMed Scopus (320) Google Scholar] supporting the categorization of fewer elementary categories (e.g., approach/avoidance). Later transmissions comprise more complex signals that support categorization of a larger number of socially specific categories (i.e., the six classic emotions). Here, we show that dynamic facial expressions of emotion provide a sophisticated signaling system, questioning the widely accepted notion that emotion communication is comprised of six basic (i.e., psychologically irreducible) categories [18Ekman P. Friesen W. Ellsworth P. What emotion categories or dimensions can observers judge from facial behavior?.in: Ekman P. Emotion in the Human Face. Cambridge University Press, New York1982: 39-55Google Scholar], and instead suggesting four.Video AbstracteyJraWQiOiI4ZjUxYWNhY2IzYjhiNjNlNzFlYmIzYWFmYTU5NmZmYyIsImFsZyI6IlJTMjU2In0.eyJzdWIiOiJmZDAzNzQzOTIxYmVkN2RiZjY3MmMyODE1ZDczZWY5YSIsImtpZCI6IjhmNTFhY2FjYjNiOGI2M2U3MWViYjNhYWZhNTk2ZmZjIiwiZXhwIjoxNjc4MTIzNzcwfQ.fwkzCbYr7PMw1Sm4qZ_PQX500sYPyMAoqUhGArJCpo64Fxkmc6RzZ-HRUmkYLYMSOcpzDVTmG4dHeC1kgB0rYHyrMCF-KpFhVuX7CAKL9oWSfa5LiYaycyQmwCBfFwW4hC-W8FEzhs1I3IfjqWDCppImVK_p6b3og9hp2NL_zUMTz2a7EijxVU2c3zpisrXXqFS9iOlZ-YVKkb75_GqGxWam9D59rHSppROfX6l5WxoCg572QYAf4ZuBbLfeyWhLw1mC7bXJY_O63ngvmOwP9MsBgo9-3iLjHfCx9LS7z5xq7yLRBxUDVRcqBjawYseHzqOA1oqRXbdoLjaCtnShSw(mp4, (42.36 MB) Download video'},\n",
       " '10.1016/j.cogsys.2006.10.001': {'title': 'Employing emotions to drive plot generation in a computer-based storyteller',\n",
       "  'abstract': 'Emotions are an integral part of the creative process; however, it is hard to find computer models of creativity where emotions play a fundamental role. This paper describes a computer model for plot generation based on emotions and tensions between characters. In particular, the document illustrates how emotions are employed to progress a story in a coherent way and generate novel situations, and how the dramatic tension of the story in progress can be employed to evaluate its interestingness. The model is implemented in a computer program named MEXICA [Pérez y Pérez, R., & Sharples, M. (2001). MEXICA: a computer model of a cognitive account of creative writing. Journal of Experimental and Theoretical Artificial Intelligence, 13(2), 119–139]; this work concentrates on the role of emotions in plot generation. The main claim is that a story can be represented as a cluster or group of emotional links and tensions between characters that progresses over story-time; story-actions work as operators that modify such clusters. I present results showing how story generation is affected by various model parameters. This approach means the program is flexible, as it avoids using predefined story-structures or characters’ goals to drive story generation. Furthermore, evaluation of computer generated stories showed that MEXICA’s stories were most often selected as the best story. This suggests that the story-generation mechanisms within MEXICA are sufficiently rich to generate interesting and novel stories.'},\n",
       " '10.3758/BF03195918': {'title': 'The effect of a protagonist’s emotional shift on situation model construction',\n",
       "  'abstract': \"We examined whether readers monitored protagonists' emotional shifts and whether reader engagement influenced situation model construction. Participants read narratives that included an emotional shift in the middle of the story. In Experiment 1, participants were instructed to read stories appreciatively and to empathize with the protagonists. In Experiment 2, readers were instructed to read the stories normally, as if they were reading novels. The results from the two experiments suggest that readers monitor temporal and causal shifts as well as protagonists' emotional shifts in stories. Moreover, in Experiment 1 readers detected temporal and causal shifts regardless of the degree of their engagement during the empathetic reading, while in Experiment 2 the high ego involvement group detected causal shifts during the normal reading. Thus, these results show both that readers monitor protagonists' emotional states and that reader emotional engagement can influence situation model construction with normal reading.\"},\n",
       " '10.1016/j.knosys.2004.10.011': {'title': 'Story plot generation based on CBR',\n",
       "  'abstract': 'In this paper we present a system for automatic story generation that reuses existing stories to produce a new story that matches a given user query. The plot structure is obtained by a case-based reasoning (CBR) process over a case base of tales and an ontology of explicitly declared relevant knowledge. The resulting story is generated as a sketch of a plot described in natural language by means of natural language generation (NLG) techniques.'},\n",
       " '10.1007/978-3-540-27797-2_13': {'title': 'Emotional Characters for Automatic Plot Creation',\n",
       "  'abstract': 'The Virtual Storyteller is a multi-agent framework for automatic story generation. In this paper we describe how plots emerge from the actions of semi-autonomous character agents, focusing on the influence of the characters’ emotions on plot development.'},\n",
       " '10.1016/0749-596X(85)90030-0': {'title': 'Prominent characters and events organize narrative understanding',\n",
       "  'abstract': 'Readers understand a narrative by constructing a representation from a sequence of sentences. They must identify which parts of the narrative are most prominent in order to assign the appropriate referents to referring expressions and construct a coherent representation. The present experiments demonstrate that properties of the characters and events expressed by narratives are often more important for guiding referent assignment than the order in which these parts of narratives are mentioned. In particular, in congruent narratives, where the protagonist (i.e., the most important character of the narrative) participates in a foreground event (i.e., part of the narrative plot) and the nonprotagonist participates in a background event, readers chose the protagonist as referent for a subsequent pronoun, regardless of the order of mention of the events the two characters participated in. However, in incongruent narratives, where the protagonist participates in the background event and the nonprotagonist in the foreground event, readers were less confident and relied on the order of mention and status of events, choosing the nonprotagonist in a last mentioned foreground event and favoring neither character when the foreground event with nonprotagonist was mentioned first. When narratives more sharply delineated foregrounded from backgrounded events, readers were less confused and chose characters from foregrounded events. When narratives contained pronouns that referred to places rather than characters, readers chose referents from the last mentioned place regardless of the kind of character or event it was associated with. The results suggest that readers combine information about the characters, events, and places that narratives express with information about their order of mention in order to assign referents and that this process is part of the process of constructing a model that represents the world described by the narrative.'},\n",
       " '10.1007/978-3-319-27478-2_15': {'title': 'On the Use of Character Affinities for Story Plot Generation',\n",
       "  'abstract': \"One of the aspects that is used to keep the reader's interest in a story is the network of relationships among the characters that take part in that story. We can model the relationship between two characters using their mutual affinities, which allow us to define which interactions are possible between two characters. In this paper we present a model to represent characters' affinities and we describe how we have implemented this model using a multi-agent system that is used to generate stories. We also present the result of one experiment to measure the evolution of the affinities between two characters throughout a story.\"},\n",
       " '10.1007/978-3-642-35085-6_6': {'title': 'ConceptNet 5: A Large Semantic Network for Relational Knowledge',\n",
       "  'abstract': 'ConceptNet is a knowledge representation project, providing a large semantic graph that describes general human knowledge and how it is expressed in natural language. Here we present the latest iteration, ConceptNet 5, with a focus on its fundamental design decisions and ways to interoperate with it.'},\n",
       " '10.1007/978-3-319-00065-7_33': {'title': 'Interpreting and Executing Recipes with a Cooking Robot',\n",
       "  'abstract': 'The creation of a robot chef represents a grand challenge for the field of robotics. Cooking is one of the most important activities that takes place in the home, and a robotic chef capable of following arbitrary recipes would have many applications in both household and industrial environments. The kitchen environment is a semi-structured proving ground for algorithms in robotics. It provides many computational challenges, such as accurately perceiving ingredients in cluttered environments, manipulating objects, and engaging in complex activities such as mixing and chopping.'},\n",
       " '10.1007/s42001-023-00225-8': {'title': 'Bridging the offline and online: 20 years of offline meeting data of the German-language Wikipedia',\n",
       "  'abstract': 'Abstract Wikipedia is one of the most visited websites worldwide. Thousands of volunteers are contributing to it daily, making it an example of how productive non-market collaboration on a very wide scale is not only viable but also sustainable. Wikipedia’s freely available data on the online actions conducted make it a popular source of data, particularly for computer scientists and computational social scientists. This data brief will present the dewiki meetup dataset which covers the offline component of the German-language version of the online encyclopaedia Wikipedia: informal offline gatherings between Wikipedia contributors. These gatherings are organised online and information about who is attending them, where they take place and what has happened at these meetings is shared publicly. The dewiki meetup dataset covers almost 20 years of offline activity of the German-language Wikipedia, containing 4418 meetups that have been organised with information on attendees, apologies, date and place of meeting, and minutes recorded. It is a valuable source of data for social science research: it captures the development of the offline network over time of one of the largest and most sustainable online public goods and communities. The data can easily be merged with online activity data on Wikipedia which allows us to bridge the gap between offline and online behaviour.'},\n",
       " '10.1007/11562214_75': {'title': 'Automatically Inducing a Part-of-Speech Tagger by Projecting from Multiple Source Languages Across Aligned Corpora',\n",
       "  'abstract': 'We implement a variant of the algorithm described by Yarowsky and Ngai in [21] to induce an HMM POS tagger for an arbitrary target language using only an existing POS tagger for a source language and an unannotated parallel corpus between the source and target languages. We extend this work by projecting from multiple source languages onto a single target language. We hypothesize that systematic transfer errors from differing source languages will cancel out, improving the quality of bootstrapped resources in the target language. Our experiments confirm the hypothesis. Each experiment compares three cases: (a) source data comes from a single language A, (b) source data comes from a single language B, and (c) source data comes from both A and B, but half as much from each. Apart from the source language, other conditions are held constant in all three cases – including the total amount of source data used. The null hypothesis is that performance in the mixed case would be an average of performance in the single-language cases, but in fact, mixed-case performance always exceeds the maximum of the single-language cases. We observed this effect in all six experiments we ran, involving three different source-language pairs and two different target languages.'},\n",
       " '10.1016/0885-2308(92)90019-Z': {'title': 'Robust part-of-speech tagging using a hidden Markov model',\n",
       "  'abstract': 'A system for part-of-speech tagging is described. It is based on a hidden Markov model which can be trained using a corpus of untagged text. Several techniques are introduced to achieve robustness while maintaining high performance. Word equivalence classes are used to reduce the overall number of parameters in the model, alleviating the problem of obtaining reliable estimates for individual words. The context for category prediction is extended selectively via predefined networks, rather than using a uniformly higher-order conditioning which requires exponentially more parameters with increasing context. The networks are embedded in a first-order model and network structure is developed by analysis of erros, and also via linguistic considerations. To compensate for incomplete dictionary coverage, the categories of unknown words are predicted using both local context and suffix information to aid in disambiguation. An evaluation was performed using the Brown corpus and different dictionary arrangements were investigated. The techniques result in a model that correctly tags approximately 96% of the text. The flexibility of the methods is illustrated by their use in a tagging program for French.'},\n",
       " '10.1016/j.rser.2023.114199': {'title': 'Geospatial and socioeconomic prediction of value-driven clean cooking uptake',\n",
       "  'abstract': 'Understanding the community-specific values and needs of consumers is essential for effective targeting and planning of energy services such as clean cooking. Many clean cooking programmes do not however consider these values and needs in targeting, as they can be difficult and time-consuming to ascertain. This work therefore explores whether community needs and values related to cooking can be predicted, using a novel approach that understands the relationship between socioeconomic, demographic, and geospatial data. Specifically, this study investigates (i) which values are most closely linked to cookstoves in rural Uganda; and (ii) whether it is possible to predict cookstove prioritisation and related values using openly-available data. Using machine-learning approaches, user-perceived value data from 199 rural low-income households in Uganda are mapped against socioeconomic, demographic, and geospatial data to identify correlations and intersections. The values most closely related to cookstoves were found to be food security, time benefit, accessibility to services, fixed costs, and being healthy. The most important parameters in predicting who would hold these values were found to be: the number of people living in a house; age; quintile 2 of the wealth index; annual accumulated precipitation; forest density; night time luminance; and distance to water source, nearest forest within ten kilometers, and nearest road. This study takes a first step towards enabling energy service providers to target areas with a greater likelihood of uptake based on open-source datasets. While cooking in Uganda is analysed herein, the proposed method can be applied for different geographies and energy services.'},\n",
       " '10.1016/j.iedeen.2022.100211': {'title': 'Evaluation of non-financial information and its contribution to advancing the sustainable development goals within the Spanish banking sector',\n",
       "  'abstract': \"Non-financial information and its contribution to the achievement of each Sustainable Development Goal (SDG) are assuming great relevance in the business world, in which it is not enough to be economically sustainable without also being sustainable from ethical, environmental, and social points of view. An analysis of how the financial sector contributes to the achievement of the SDGs is crucial in two ways. Firstly, due to the relevance and the magnitude of this sector itself; secondly, and more importantly in our view, because of the financial leverage of the banking sector that has a mandate to facilitate the transition of all economic sectors towards sustainability, guided by the 2030 Agenda. However, despite the expectations placed on banking entities, there is a research gap on their disclosure practices and on the SDG-related information that they report. In addition, the academic literature centered on the analysis of SDG-related disclosures through artificial intelligence is very scarce. To fill this gap, the objective of our study is, on the one hand, to analyze whether there is greater homogeneity in the disclosure of non-financial information in the Spanish banking sector following the transposition of Directive 2014/95/EU into Spanish Law. On the other hand, it is to evaluate the contribution of banking entities to the SDGs. To do so, the non-financial information reports of 12 Spanish banks are analyzed, completing a comparative evaluation and using artificial intelligence to identify mentions of each SDG and its targets. The Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) was also used to rank the banking entities in accordance with their contribution to each SDG. The results reflected the plurality, in both breadth and quality, in the disclosure of non-financial information and in the contribution to the SDGs. The only point in common between all the entities that were studied was the use of the GRI disclosure framework and the identification of the priority SDGs, positioning SDGs 8, 13, and 4 in priority positions. The banks with higher bank capitalization levels occupied the top of the ranking of contributions to the SDGs. Differences were presented for all other aspects, even to the point of highlighting that some entities or independent verifiers had not offered all the information. In conclusion, greater efforts to improve the quality of non-financial reporting and further development of the common regulatory framework will be fundamental for better comparability between the reports from banking entities. Furthermore, this study shows that natural language processing can be applied to better measure companies' alignment with the SDGs based on the text of their non-financial reports.\"},\n",
       " '10.1016/j.erss.2021.102379': {'title': 'The power of language: Exploring values, empowerment dynamics and communication strategies for gender-inclusive energy service design in rural Uganda',\n",
       "  'abstract': 'Understanding consumer needs and values is crucial to the sustainable delivery and uptake of energy access projects in Low-and Middle-Income Countries (LMICs). Nevertheless, many energy projects aim to empower women without first assessing gendered roles, needs, values, and relations for both men and women in project communities. Neglecting these can be detrimental to the end-users of energy projects, exacerbating conflict within households rather than empowering vulnerable groups. We propose a value-based approach to elicit the varying priorities and values of men and women and assess how these may shape energy access project design and communication in LMICs. Data from 84 qualitative individual interviews, equally split between men and women, and 28 gender-disaggregated focus-group discussions in seven rural Ugandan communities were used. We find that men and women in rural Uganda held largely the same high-priority underlying values focused on basic human needs such as income, healthcare, information services, food security, and water security. However, the language used to communicate these values differed in small but significant ways. Based on this, we offer two potential solutions for a more balanced gender-inclusive approach to energy service project design and communication: (1) Design projects and messaging based on underlying values of both genders while avoiding inadvertently reproducing patriarchal norms; and (2) use gender-specific messaging and vocabulary1 linking energy projects to underlying values to increase buy-in. This work constitutes a first step in better understanding the importance of gender-disaggregated data in decision-making for energy access initiatives in LMICs.'},\n",
       " '10.1016/j.dib.2021.107734': {'title': 'Perceived value interviews and socio-economic survey data for communities in rural Uganda',\n",
       "  'abstract': \"This article describes a dataset of perceived values and socioeconomic indicators collected in rural Ugandan communities. The data were collected in interviews which employed: (1) the User-Perceived Value game, which solicits verbal data using graphical prompts and 'why'-probing; and (2) socio-economic surveys, which collected demographic data. The dataset constitutes 119 interviews conducted between 2014 and 2015 in seven rural Ugandan villages. Interviews were conducted in various settings (e.g. individual/group, women/men/mixed) and in seven different local languages (which were subsequently translated into English). These interviews were part of a research project aiming to better understand what is important to rural communities in Uganda, and to investigate decision-making as a function of different demographics. This dataset can be used by researchers and practitioners in various fields such as sustainable development (e.g. to analyze how development initiatives may be designed to match community values) and natural language processing (e.g. to automatically perform perceived value classification from the expert-annotated interviews).\"},\n",
       " '10.14220/9783737009867.197': {'title': '4. Edition',\n",
       "  'abstract': 'No Access4. Editionhttps://doi.org/10.14220/9783737009867.197SectionsPDF/EPUB ToolsAdd to favoritesDownload CitationsTrack Citations ShareShare onFacebookTwitterLinkedInRedditEmail About Previous chapter Next chapter FiguresReferencesRelatedDetails Download book coverOttoman Studies / Osmanistische Studien.Volume 6 1. AuflageISBN: 978-3-8471-0986-0 eISBN: 978-3-7370-0986-7HistoryPublished online:August 2019 PDF download'},\n",
       " '10.1038/d41586-019-00746-1': {'title': 'AI empowers conservation biology',\n",
       "  'abstract': 'Faced with mountains of image and audio data, researchers are turning to artificial intelligence to answer pressing ecological questions. Faced with mountains of image and audio data, researchers are turning to artificial intelligence to answer pressing ecological questions.'},\n",
       " '10.1016/J.RSER.2016.08.037': {'title': 'Identifying the needs of communities in rural Uganda: A method for determining the ‘User-Perceived Value’ of rural electrification initiatives',\n",
       "  'abstract': 'This research paper describes the use of a ‘User-Perceived Value Game’ to explore the value of development initiatives as perceived by villagers in 119 interview settings in seven Ugandan villages. Based on the findings from the game, a ‘User-Perceived Value Framework’ is developed, consisting of 64 value categories. This is depicted graphically as a ‘User-Perceived Value Wheel’ supported by a ‘Key Phrase Wheel’, both can be modified using computer-assisted software developed by one of the authors. The aim is to understand the reasons why something is perceived by the end user to be important. This will lead to an improved understanding of how a development initiative can be better tailored for lower-income markets. The initiative can then be marketed appropriately, which will result in user acceptance because the initiative will be perceived to have personal value to the user and therefore the user will care for its upkeep. The paper concludes with a brief application of the ‘User-Perceived Value Wheel’ to demonstrate how this tool can be used to better understand the true sustainability drivers behind rural electrification development initiatives.'},\n",
       " '10.1038/534320a': {'title': 'Policy: Map the interactions between Sustainable Development Goals',\n",
       "  'abstract': 'Måns Nilsson, Dave Griggs and Martin Visbeck present a simple way of rating relationships between the targets to highlight priorities for integrated policy.'},\n",
       " '10.1007/978-3-319-08010-9_49': {'title': 'Sarcasm Detection in Social Media Based on Imbalanced Classification',\n",
       "  'abstract': 'Sarcasm is a pervasive linguistic phenomenon in online documents that express subjective and deeply-felt opinions. Detection of sarcasm is of great importance and beneficial to many NLP applications, such as sentiment analysis, opinion mining and advertising. Current studies consider automatic sarcasm detection as a simple text classification problem. They do not use explicit features to detect sarcasm and ignore the imbalance between sarcastic and non-sarcastic samples in real applications. In this paper, we first explore the characteristics of both English and Chinese sarcastic sentences and introduce a set of features specifically for detecting sarcasm in social media. Then, we propose a novel multi-strategy ensemble learning approach(MSELA) to handle the imbalance problem. We evaluate our proposed model on English and Chinese data sets. Experimental results show that our ensemble approach outperforms the state-of-the-art sarcasm detection approaches and popular imbalanced classification methods.'},\n",
       " '10.1016/J.RSER.2014.03.005': {'title': 'The user-value of rural electrification: An analysis and adoption of existing models and theories',\n",
       "  'abstract': 'User-value is a determining factor for product acceptance in product design. Research on rural electrification to date, however, does not draw sufficient attention to the importance of user-value with regard to the overall success of a project. This is evident from the analysis of project reports and applicable indicators from agencies active in the sector. Learning from the design, psychology and sociology literatures, it is important that rural electrification projects incorporate the value perception of the end-user and extend their success beyond the commonly used criteria of financial value, the appropriateness of the technology, capacity building and technology uptake. Creating value for the end-user is particularly important for project acceptance and the sustainability of a scheme once it has been handed over to the local community. In this research paper, existing theories and models of value-theory are transposed and applied to community operated rural electrification schemes and a user-value framework is developed. Furthermore, the importance of value to the end-user is clarified. Current literature on product design reveals that user-value has different properties, many of which are applicable to rural electrification. Five value pillars and their sub-categories important for the users of rural electrification projects are identified, namely: functional; social significance; epistemic; emotional; and cultural values. These pillars provide the main structure for the conceptual framework developed in this research paper. It is proposed that by targeting the values of the end-user, the key factors of user-value applicable to rural electrification projects will be identified and the sustainability of the project will be better ensured.'},\n",
       " '10.1016/J.SBSPRO.2014.02.114': {'title': 'Satellite Remote Sensing as a Tool in Disaster Management and Sustainable Development: Towards a Synergistic Approach',\n",
       "  'abstract': 'Disasters have become an issue of growing concern throughout the world, whether it is natural hazards or through human factors. The frequency, as well as magnitude, of disasters threatening large population living in diverse environments is increasing in recent years across the world. These disasters also have far-reaching implications on sustainable development through social, economic and environmental impacts. It is highly imperative to develop effective tools for disaster management. Remote sensing systems have been playing a great role in disaster management in such areas as flooding, cyclones, drought, earthquake and tsunami. Satellite remote sensing is largely adopted due to its cost effectiveness, short temporal orbiting and large area of coverage. Remote sensing technologies have been used in disaster management especially during the preparedness/warning and response/monitoring stages. Despite the capabilities of remote sensing technologies in natural and human disaster management, there are still some limitations in its deployment due to the divide between developed and developing countries, data accessibility (especially high resolution imagery) and technological limitations. This paper examines the recent developments in the application of remote sensing in disaster management such as the proliferation of data through unprecedented sources (Google Earth, crowdsourcing, Global Land Cover) and improvement in data resolutions and integration of technologies. It examines how recent developments can help in overcoming the limitations of using remotely sensed data in disaster management. There is a need for more collaborative and interdisciplinary frameworks to fully utilize the capabilities of remote sensing in hazard and disaster management.'},\n",
       " '10.1186/1478-4491-11-13': {'title': 'Aspirations for quality health care in Uganda: How do we get there?',\n",
       "  'abstract': 'Despite significant investments and reforms, health care remains poor for many in Africa. To design an intervention to improve access and quality of health care at health facilities in eastern Uganda, we aimed to understand local priorities for qualities in health care, and factors that enable or prevent these qualities from being enacted. In 2009 to 2010, we carried out 69 in-depth interviews and 6 focus group discussions with 65 health workers at 17 health facilities, and 10 focus group discussions with 113 community members in Tororo District, Uganda. Health-care workers and seekers valued technical, interpersonal and resource qualities in their aspirations for health care. However, such qualities were frequently not enacted, and our analysis suggests that meeting aspirations required social and financial resources to negotiate various power structures. We argue that achieving aspirations for qualities valued in health care will require a genuine reorientation of focus by health workers and their managers toward patients, through renewed respect and support for these providers as professionals.'},\n",
       " '10.1038/495305a': {'title': 'Sustainable development goals for people and planet',\n",
       "  'abstract': 'Planetary stability must be integrated with United Nations targets to fight poverty and secure human well-being, argue David Griggs and colleagues.'},\n",
       " '10.1186/1748-5908-7-117': {'title': 'Knowledge translation in Uganda: a qualitative study of Ugandan midwives’ and managers’ perceived relevance of the sub-elements of the context cornerstone in the PARIHS framework',\n",
       "  'abstract': \"A large proportion of the annual 3.3 million neonatal deaths could be averted if there was a high uptake of basic evidence-based practices. In order to overcome this 'know-do' gap, there is an urgent need for in-depth understanding of knowledge translation (KT). A major factor to consider in the successful translation of knowledge into practice is the influence of organizational context. A theoretical framework highlighting this process is Promoting Action on Research Implementation in Health Services (PARIHS). However, research linked to this framework has almost exclusively been conducted in high-income countries. Therefore, the objective of this study was to examine the perceived relevance of the sub-elements of the organizational context cornerstone of the PARIHS framework, and also whether other factors in the organizational context were perceived to influence KT in a specific low-income setting.This qualitative study was conducted in a district of Uganda, where focus group discussions and semi-structured interviews were conducted with midwives (n = 18) and managers (n = 5) within the catchment area of the general hospital. The interview guide was developed based on the context sub-elements in the PARIHS framework (receptive context, culture, leadership, and evaluation). Interviews were transcribed verbatim, followed by directed content analysis of the data.The sub-elements of organizational context in the PARIHS framework-i.e., receptive context, culture, leadership, and evaluation-also appear to be relevant in a low-income setting like Uganda, but there are additional factors to consider. Access to resources, commitment and informal payment, and community involvement were all perceived to play important roles for successful KT.In further development of the context assessment tool, assessing factors for successful implementation of evidence in low-income settings-resources, community involvement, and commitment and informal payment-should be considered for inclusion. For low-income settings, resources are of significant importance, and might be considered as a separate sub-element of the PARIHS framework as a whole.\"},\n",
       " '10.1016/J.ESD.2012.05.002': {'title': 'Energy access programmes and sustainable development: A critical review and analysis',\n",
       "  'abstract': 'This paper provides an overview of the debate on energy access and development, and argues that despite some progress in enhancing energy access, the programmes promoting energy access are neither sustainable nor adequately contributing to development. The paper substantiates this argument by considering the experience of energy access and by performing a simple multi-dimensional sustainability analysis. There has been a disproportionate emphasis on electrification in the past, which can neither resolve the energy access problem nor address the sustainable development issue. Ensuring access to clean energies to meet the demand for cooking and heating energy and providing economically viable and affordable options remains the greatest challenge. The paper suggests that a rebalancing of approaches to energy access provision is required to ensure their sustainability.'},\n",
       " '10.1016/J.TOURMAN.2004.12.002': {'title': 'Value dimensions, perceived value, satisfaction and loyalty: an investigation of university students’ travel behaviour',\n",
       "  'abstract': \"Both marketing practitioners and academic researchers have traditionally recognised the major influence that perceived value has on consumer behaviour. Tourism and hospitality research have recently shown an interest in value; especially, when investigated with quality and/or satisfaction. The present study has two primary objectives. First, to investigate the dimensionality of consumer value in a travel-related context (students’ travel behaviour), adopting Holbrook's typology, and combining it with negative inputs of value. Second, to explore the relations between consumer perceptual constructs such as perceived value, satisfaction and loyalty. This dual objective is undertaken by providing an LISREL model. The results confirm the existence of a quality–value–satisfaction–loyalty chain and illustrate the complexity of value dimensions that have been shown to be highly sensitive to the tourism experience.\"},\n",
       " '10.1016/J.FOODQUAL.2004.05.012': {'title': 'Consumer research in the early stages of new product development: a critical review of methods and techniques',\n",
       "  'abstract': \"Incorporating the `voice of the consumer' in early stages of the new product development process has been identified as a critical success factor for new product development. Yet, this step is often ignored or poorly executed. This may be due to lack of familiarity on which methods are available, the use of disciplinary terminology, and difficulty in accessibility of papers on this subject. This paper reviews and categorises 10 of the most common methods in this area, in terms of what their key features are, and what strengths, weaknesses and appropriateness are. We develop a classification scheme based on three performance dimensions with specific criteria: (1) stimuli used as cue for need elicitation, (2) task format, and (3) need actionability. We provide guidelines for the appropriateness of these methods in the new product development process based on the newness strategy of the development process (radical versus incremental innovation) and identify which functional department (marketing versus R&D) the method should primarily support.\"},\n",
       " '10.4324/9780203010679-7': {'title': 'Value as excellence in the consumption experience',\n",
       "  'abstract': 'Indeed, consumers and researchers are of two minds about status; it’s the\\nphenomenon they have to acknowledge but love to hate. Status-seeking is what\\neveryone else does, perhaps because the status markers sought by others may seem\\nhollow or meaningless compared to those we ourselves value. The academic may\\ndeplore the executive’s penchant for expensive luxury cars. He turns up his nose at\\nthis materialistic excess, even as he is ensconced in his study eagerly reviewing the\\nlatest Social Science Citation Index report of other scholars who have cited his\\nwork on decision processes underlying car purchases. Simultaneously, an\\nautomotive engineer enjoys a reverie about the aesthetically pleasing design\\nmodification she made to a concept car-and, perhaps, fantasizes about the sizeable\\ncash bonus she will receive for this contribution. As Holbrook (1994) reminds us,\\nvirtually any consumption experience can take on the coloring of any kind of\\nvalue depending upon who is doing the consuming-and perhaps, who is assigning\\nthe value. Perhaps status (like beauty) is in the eye of the beholder.'},\n",
       " '10.1016/0148-2963(91)90050-8': {'title': 'Why we buy what we buy: A theory of consumption values',\n",
       "  'abstract': 'This article presents a theory developed to explain why consumers make the choices they do. The theory identifies five consumption values influencing consumer choice behavior. Three representative applications of the theory are illustrated pertaining to choices involving cigarette smoking. The illustrations examined include the choice to buy or not buy (or to use or not use) cigarettes, the choice of one type of cigarette over another, and the choice of one cigarette brand over another. Results of the operationalization of the theory suggest that it may be used to predict consumption behavior, as well as to describe and explain it.'},\n",
       " '10.1891/9780826190123.ap02': {'title': 'Transforming Our World: The 2030 Agenda for Sustainable Development',\n",
       "  'abstract': 'Information document of the Scoping meeting on collaboration between Regional Seas Programmes and Regional Fisheries Bodies in the Southwest Indian Ocean'},\n",
       " '10.1007/s40593-023-00374-x': {'title': 'Review on Neural Question Generation for Education Purposes',\n",
       "  'abstract': 'Abstract Questioning plays a vital role in education, directing knowledge construction and assessing students’ understanding. However, creating high-level questions requires significant creativity and effort. Automatic question generation is expected to facilitate the generation of not only fluent and relevant but also educationally valuable questions. While rule-based methods are intuitive for short inputs, they struggle with longer and more complex inputs. Neural question generation (NQG) has shown better results in this regard. This review summarizes the advancements in NQG between 2016 and early 2022. The focus is on the development of NQG for educational purposes, including challenges and research opportunities. We found that although NQG can generate fluent and relevant factoid-type questions, few studies focus on education. Specifically, there is limited literature using context in the form of multi-paragraphs, which due to the input limitation of the current deep learning techniques, require key content identification. The desirable key content should be important to specific topics or learning objectives and be able to generate certain types of questions. A further research opportunity is controllable NQG systems, which can be customized by taking into account factors like difficulty level, desired answer type, and other individualized needs. Equally important, the results of our review also suggest that it is necessary to create datasets specific to the question generation tasks with annotations that support better learning for neural-based methods.'},\n",
       " '10.1007/978-3-030-84186-7_10': {'title': 'Enhancing Question Generation with Commonsense Knowledge',\n",
       "  'abstract': 'Question generation (QG) is to generate natural and grammatical questions that can be answered by a specific answer for a given context. Previous sequence-to-sequence models suffer from a problem that asking high-quality questions requires commonsense knowledge as backgrounds, which in most cases can not be learned directly from training data, resulting in unsatisfactory questions deprived of knowledge. In this paper, we propose a multi-task learning framework to introduce commonsense knowledge into question generation process. We first retrieve relevant commonsense knowledge triples from mature databases and select triples with the conversion information from source context to question. Based on these informative knowledge triples, we design two auxiliary tasks to incorporate commonsense knowledge into the main QG model, where one task is Concept Relation Classification and the other is Tail Concept Generation. Experimental results on SQuAD show that our proposed methods are able to noticeably improve the QG performance on both automatic and human evaluation metrics, demonstrating that incorporating external commonsense knowledge with multi-task learning can help the model generate human-like and high-quality questions.'},\n",
       " '10.1007/978-3-540-74997-4_16': {'title': 'T2D: Generating Dialogues Between Virtual Agents Automatically from Text',\n",
       "  'abstract': 'The Text2Dialogue (T2D) system that we are developing allows digital content creators to generate attractive multi-modal dialogues presented by two virtual agents—by simply providing textual information as input. We use Rhetorical Structure Theory (RST) to decompose text into segments and to identify rhetorical discourse relations between them. These are then \"acted out\" by two 3D agents using synthetic speech and appropriate conversational gestures. In this paper, we present version 1.0 of the T2D system and focus on the novel technique that it uses for mapping rhetorical relations to question–answer pairs, thus transforming (monological) text into a form that supports dialogues between virtual agents.'},\n",
       " '10.1527/tjsai.37-4_a-lc3': {'title': '日本語物語文を対象とする空所穴埋め問題データセット',\n",
       "  'abstract': 'This paper describes our dataset of Japanese cloze questions designed for the evaluation of machine reading comprehension. The dataset consists of questions automatically generated from Aozora Bunko, and each question is defined as a 4-tuple: a context passage, a query holding a slot, an answer character, and a set of possible answer characters. The query is generated from the original sentence, which appears immediately after the context passage on the target book, by replacing the answer character with the slot. The set of possible answer characters consists of the answer character and the other characters who appear in the context passage. Because the context passage and the query share the same context, a machine that precisely understands the context may select the correct answer from the set of possible answer characters. The unique point of our approach is that we focus on characters of target books as slots to generate queries from original sentences because they play important roles in narrative texts and a precise understanding of their relationship is necessary for reading comprehension. To extract characters from target books, manually created dictionaries of characters are employed because some characters appear as common nouns, not as named entities.'},\n",
       " '10.1038/s41598-023-48594-4': {'title': 'Improving long COVID-related text classification: a novel end-to-end domain-adaptive paraphrasing framework',\n",
       "  'abstract': 'Abstract The emergence of long COVID during the ongoing COVID-19 pandemic has presented considerable challenges for healthcare professionals and researchers. The task of identifying relevant literature is particularly daunting due to the rapidly evolving scientific landscape, inconsistent definitions, and a lack of standardized nomenclature. This paper proposes a novel solution to this challenge by employing machine learning techniques to classify long COVID literature. However, the scarcity of annotated data for machine learning poses a significant obstacle. To overcome this, we introduce a strategy called medical paraphrasing, which diversifies the training data while maintaining the original content. Additionally, we propose a Data-Reweighting-Based Multi-Level Optimization Framework for Domain Adaptive Paraphrasing, supported by a Meta-Weight-Network (MWN). This innovative approach incorporates feedback from the downstream text classification model to influence the training of the paraphrasing model. During the training process, the framework assigns higher weights to the training examples that contribute more effectively to the downstream task of long COVID text classification. Our findings demonstrate that this method substantially improves the accuracy and efficiency of long COVID literature classification, offering a valuable tool for physicians and researchers navigating this complex and ever-evolving field.'},\n",
       " '10.1016/j.eswa.2023.121925': {'title': 'Chinese engineering geological named entity recognition by fusing multi-features and data enhancement using deep learning',\n",
       "  'abstract': 'The engineering geology report serves as a comprehensive portrayal of the geological conditions and information within a surveyed region, making it highly valuable for extracting and mining engineering geology-related knowledge. Geological Named Entity Recognition (GNER), as a pivotal technology for information extraction and knowledge discovery, aims to identify geological objects that convey significant meanings within textual data. While general NER tools and existing approaches are commonly employed for recognizing generic entities, their effectiveness is constrained by the diverse language irregularities inherent in natural language texts, including nested entities, lengthy entities, and a scarcity of domain-specific annotated corpora. Adhering to established standards and principles governing engineering geology reports, we undertake an analysis of text structures and characteristics, as well as the linguistic descriptions and data attributes. By employing an Electronic Design Automation (EDA) enhancement method in conjunction with manual annotation, we construct an engineering GNER dataset. To address these linguistic irregularities, we propose a novel deep learning model that combines both the geological pre-training model (GeoBERT) and multiple features (pinyin, radical, and position vectors) to generate representations from byte sequences. These representations are subsequently fused and passed through a BiLSTM-Attention model for training. Finally, entity classification results are obtained using conditional random fields (CRF). Experimental evaluation demonstrates that the proposed model achieves an impressive F1 value of 79.60% on the constructed datasets, outperforming ten baseline models analyzed in this study.'},\n",
       " '10.1016/j.eswa.2022.117338': {'title': 'AI-based Twitter framework for assessing the involvement of government schemes in electoral campaigns',\n",
       "  'abstract': \"The government schemes (also known as programs and plans) or social welfare policies can be defined as the set of assistance and aids provided by the country's governance body. These schemes focus on the improved well-being of needful citizens. Some researchers have shown that introducing such policies and schemes has had an electoral impact in democratic countries. These earlier studies relied upon the post-poll and public survey data to reach conclusions. However, this data source has limitations and has to be collected manually, which makes it time-consuming and costly. The readily available internet inculcates the sharing of opinions freely on social media, facilitating government–citizen interactions. These interactions may show fluctuations in frequency and intensity on social media with the success and failure of some government schemes. Thus, this research proposes utilizing the Twitter data related to the government welfare schemes during the election duration to uncover the spatial and temporal relationships between the tweets' information diffusion pattern and political elections. To start with, we perform tweet classification to identify the target communities or groups and multiple user-engagements by employing deep learning-based pre-trained language representation (LR) models. The scarcity of labeled data limits the application of the supervised classification models on real-time data. Thus, we propose Mod-EDA, a text augmentation method to upscale the labeled data for reduced overfitting. Going further, we propose two modules, where the classified tweets are studied to investigate the scheme tweets' information diffusion pattern in correspondence to the election duration in terms of the voting phase and the electing parties, respectively. The proposed framework is evaluated for a case study of the 2019 Indian general elections. This study depicts that the voting phases and election duration trigger high government schemes related tweet generation. However, it is not affected by the location of the voting phase. The generation of complaints and negative tweets in one voting phase is covered with the positive news in subsequent voting phases. It is also seen that there is a strong influence of the ruling party on the scheme-related Twitter data generation.\"},\n",
       " '10.1016/j.eswa.2021.115797': {'title': 'Tracking social media during the COVID-19 pandemic: The case study of lockdown in New York State',\n",
       "  'abstract': 'Facing the COVID-19 pandemic, governments have implemented a wide range of policies to contain the spread of the virus. During the pandemic, large amounts of COVID-19-related tweets emerge every day. Real-time processing of daily tweets may offer insights for monitoring public opinion about intervention measures implemented. In this work, lockdown policy in New York State has been set as a target of public opinion research. This task includes two stages, stance detection and opinion monitoring. For the stance detection stage, we explored several combinations of different text representations and classification algorithms, finding that the combination of Long Short-Term Memory (LSTM) with Global Vectors for Word Representation (GloVe) outperforms others. Due to the shortage of labeled data, we adopted the data distillation method for the training data augmentation. The augmentation of the training data allows to improve the performance of the model with a very small amount of manually-labeled data. After applying the distillation method, the accuracy of the model has been significantly improved. Utilizing the enhanced model, automatically classified tweets are analyzed over time to monitor the public opinion. By exploring the tweets in New York from January 22nd until September 30th, 2020, we show the correlation of public opinion with COVID-19 cases and mortality data, and the effect of government responses on the opinion shift. These results demonstrate the capability of the presented method to effectively and efficiently monitor public opinion during a pandemic.'},\n",
       " '10.1016/S0140-6736(03)13415-0': {'title': 'Asking the right question',\n",
       "  'abstract': \"A 60-year-old engineer complained of fatigue for 12 weeks associated with diffuse myalgia. He had occasional low-grade fever (37.6–37.9°C). When seen in the outpatient clinic in November, 2001, the only abnormalities on examination were cardiac murmurs of mitral regurgitation (2/6) and aortic regurgitation (1/4): he was known to have mitral valve prolapse and a bicuspid aortic valve. His past medical history was otherwise unremarkable. Chest radiograph, electrocardiogram, blood tests, and urinalysis showed no abnormalities (ESR 18 mm/h; Hb 13 g/dL; WBC 7·7×10 3 Raoult D Fournier PE Vandenesch F et al. Outcome and treatment of Bartonella endocarditis. Arch Intern Med. 2003; 163: 226-230 Crossref PubMed Scopus (192) Google Scholar /μL), except for a rheumatoid factor (RF) titre of 31 IU (normal <30). Blood cultures and serology for brucella, chlamydia, mycoplasma, rickettsiae, and for HIV, herpes, and hepatitis viruses were negative. Transthoracic and transoesophageal echocardiograms showed only his valvular abnormalities. His symptoms continued. He now noted a weight loss of 2–3 kg. Blood tests in February, 2002, after 24 weeks of illness, were unchanged except for an increasing RF titre of 110 IU. Primary Sjögren's syndrome and occult hepatitis C were ruled out by appropriate tests. Anti-neutrophil cytoplasmic antibodies (c-ANCA) were discovered (anti-proteinase 3 antibodies by ELISA 76 IU, N<6), but an ear, nose, and throat examination, cerebral computed tomography, and biopsy of nasal mucosa showed no signs of Wegener's granulomatosis. We did protein immunoelectrophoresis of serum and urine, chest and abdominal CT, Gallium-67 whole-body scan, and searched for tuberculosis. All tests and repeated blood cultures were negative. He was admitted to hospital in April, 2002, with no new physical findings. Department of ErrorSchattner A, Zimhony O, Avidor B, Giladi M. Asking the right question. Lancet 2003; 361: 1786—In this Case Report (May 24, 2003), the causative agent should be listed as Bartonella koehlerae. Full-Text PDF\"},\n",
       " '10.1016/0378-2166(93)90014-G': {'title': 'Strategies in the discourse of advice',\n",
       "  'abstract': 'This paper reports the findings of a continuing investigation of advice in American English. Our purpose here was to identify and analyze action patterns (discourse strategies) which speakers use in requesting and giving advice in the context of radio advice programs. Three strategies found in the advising discourse were explanation, elaboration and narration. The data were collected from two radio advice programs broadcast by WOR radio in New York City: the Bernard Meltzer program and the Sally Jessy Raphaël program. Advice givers seem to have three major goals: to help callers clarify their problems, to help them explore their options, and to offer direction, usually regarding some action to be taken in the future.'},\n",
       " '10.1007/978-3-540-74889-2_19': {'title': 'How Rude Are You?: Evaluating Politeness and Affect in Interaction',\n",
       "  'abstract': 'Recent research on conversational agents emphasises the need to build affective conversational systems with social intelligence. Politeness is an integral part of socially appropriate and affective conversational behaviour, e.g. consider the difference in the pragmatic effect of realizing the same communicative goal with either \"Get me a glass of water mate!\" or \"I wonder if I could possibly have some water please?\" This paper presents POLLy (Politeness for Language Learning), a system which combines a spoken language generator with an artificial intelligence planner to model Brown and Levinson\\'s theory of politeness in collaborative task-oriented dialogue, with the ultimate goal of providing a fun and stimulating environment for learning English as a second language. An evaluation of politeness perceptions of POLLy\\'s output shows that: (1) perceptions are generally consistent with Brown and Levinson\\'s predictions for choice of form and for discourse situation, i.e. utterances to strangers need to be much more polite than those to friends; (2) our indirect strategies which should be the politest forms, are seen as the rudest; and (3) English and Indian native speakers of English have different perceptions of politeness.'},\n",
       " '10.1016/j.neucom.2024.127468': {'title': 'Sparsity in transformers: A systematic literature review',\n",
       "  'abstract': 'Transformers have become the state-of-the-art architectures for various tasks in Natural Language Processing (NLP) and Computer Vision (CV); however, their space and computational complexity present significant challenges for real-world applications. A promising approach to address these issues is the introduction of sparsity, which involves the deliberate removal of certain parameters or activations from the neural network. In this systematic literature review, we aimed to provide a comprehensive overview of current research on sparsity in transformers. We analyzed the different sparsity techniques applied to transformers, their impact on model performance, and their efficiency in terms of time and space complexity. Moreover, we identified the major gaps and challenges in the existing literature. Our study also highlighted the importance of investigating sparsity in transformers for computational efficiency, reduced resource requirements, scalability, environmental impact, and hardware-algorithm co-design. By synthesizing the current state of research on sparsity in transformer-based models, we also provided valuable insights into their efficiency, impact on model performance, and potential trade-offs, contributing to advancing the field further.'},\n",
       " '10.1007/s42514-023-00140-4': {'title': 'Sgap: towards efficient sparse tensor algebra compilation for GPU',\n",
       "  'abstract': 'Sparse compiler is a promising solution for sparse tensor algebra optimization. In compiler implementation, reduction in sparse-dense hybrid algebra plays a key role in performance. Though GPU provides various reduction semantics that can better utilize the parallel computing and memory bandwidth capacity, the central question is: how to elevate the flexible reduction semantics to sparse compilation theory that assumes serial execution. Specifically, we have to tackle two main challenges: (1) there are wasted parallelism by adopting static synchronization granularity (2) static reduction strategy limits optimization space exploration. We propose Sgap: s egment g roup and a tomic p arallelism to solve these problems. Atomic parallelism captures the flexible reduction semantics to systematically analyze the optimization space of sparse-dense hybrid algebra on GPU. It is a new optimization technique beyond current compiler-based and open-source runtime libraries. Segment group elevates the flexible reduction semantics to suitable levels of abstraction in the sparse compilation theory. It adopts changeable group size and user-defined reduction strategy to solve challenge (1) and (2), respectively. Finally, we use GPU sparse matrix-matrix multiplication (SpMM) on the TACO compiler as a use case to demonstrate the effectiveness of segment group in reduction semantics elevation. We achieve up to $$1.2\\\\,\\\\times$$ speedup over the original TACO’s SpMM kernels. We also apply new optimization techniques found by atomic parallelism to an open-source state-of-the-art SpMM library dgSPARSE. We achieve $$1.6 \\\\, \\\\times \\\\sim 2.3 \\\\, \\\\times$$ speedup on the algorithm tuned with atomic parallelism.'},\n",
       " '10.1016/J.AIOPEN.2021.05.003': {'title': \"Know what you don't need: Single-Shot Meta-Pruning for attention heads\",\n",
       "  'abstract': 'Deep pre-trained Transformer models have achieved state-of-the-art results over a variety of natural language processing (NLP) tasks. By learning rich language knowledge with millions of parameters, these models are usually overparameterized and significantly increase the computational overhead in applications. It is intuitive to address this issue by model compression. In this work, we propose a method, called Single-Shot Meta-Pruning, to compress deep pre-trained Transformers before fine-tuning. Specifically, we focus on pruning unnecessary attention heads adaptively for different downstream tasks. To measure the informativeness of attention heads, we train our Single-Shot Meta-Pruner (SMP) with a meta-learning paradigm aiming to maintain the distribution of text representations after pruning. Compared with existing compression methods for pre-trained models, our method can reduce the overhead of both fine-tuning and inference. Experimental results show that our pruner can selectively prune 50% of attention heads with little impact on the performance on downstream tasks and even provide better text representations. The source code is available at https://github.com/thunlp/SMP.'},\n",
       " '10.1007/978-3-031-20050-2_23': {'title': 'Scalable Learning to Optimize: A Learned Optimizer Can Train Big Models',\n",
       "  'abstract': \"Learning to optimize (L2O) has gained increasing attention since it demonstrates a promising path to automating and accelerating the optimization of complicated problems. Unlike manually crafted classical optimizers, L2O parameterizes and learns optimization rules in a data-driven fashion. However, the primary barrier, scalability, persists for this paradigm: as the typical L2O models create massive memory overhead due to unrolled computational graphs, it disables L2O's applicability to large-scale tasks. To overcome this core challenge, we propose a new scalable learning to optimize (SL2O) framework which (i) first constrains the network updates in a tiny subspace and (ii) then explores learning rules on top of it. Thanks to substantially reduced trainable parameters, learning optimizers for large-scale networks with a single GPU become feasible for the first time, showing that the scalability roadblock of applying L2O to training large models is now removed. Comprehensive experiments on various network architectures (i.e., ResNets, VGGs, ViTs) and datasets (i.e., CIFAR, ImageNet, E2E) across vision and language tasks, consistently validate that SL2O can achieve significantly faster convergence speed and competitive performance compared to analytical optimizers. For example, our approach converges 3.41 $$\\\\sim $$ 4.60 times faster on CIFAR-10/100 with ResNet-18, and 1.24 times faster on ViTs, at nearly no performance loss. Codes are in https://github.com/VITA-Group/Scalable-L2O .\"},\n",
       " '10.1007/978-3-030-01234-2_48': {'title': 'AMC: AutoML for Model Compression and Acceleration on Mobile Devices',\n",
       "  'abstract': 'Model compression is an effective technique to efficiently deploy neural network models on mobile devices which have limited computation resources and tight power budgets. Conventional model compression techniques rely on hand-crafted features and require domain experts to explore the large design space trading off among model size, speed, and accuracy, which is usually sub-optimal and time-consuming. In this paper, we propose AutoML for Model Compression (AMC) which leverages reinforcement learning to efficiently sample the design space and can improve the model compression quality. We achieved state-of-the-art model compression results in a fully automated way without any human efforts. Under 4 $$\\\\times $$ FLOPs reduction, we achieved 2.7% better accuracy than the hand-crafted model compression method for VGG-16 on ImageNet. We applied this automated, push-the-button compression pipeline to MobileNet-V1 and achieved a speedup of 1.53 $$\\\\times $$ on the GPU (Titan Xp) and 1.95 $$\\\\times $$ on an Android phone (Google Pixel 1), with negligible loss of accuracy.'},\n",
       " '10.1016/j.datak.2024.102300': {'title': 'Time-Aware Structure Matching for Temporal Knowledge Graph Alignment',\n",
       "  'abstract': 'Entity alignment, aiming at identifying equivalent entity pairs across multiple knowledge graphs (KGs), serves as a vital step for knowledge fusion. As the majority of KGs undergo continuous evolution, existing solutions utilize graph neural networks (GNNs) to tackle entity alignment within temporal knowledge graphs (TKGs). However, this prevailing method often overlooks the consequential impact of relation embedding generation on entity embeddings through inherent structures. In this paper, we propose a novel model named Time-aware Structure Matching based on GNNs (TSM-GNN) that encompasses the learning of both topological and inherent structures. Our key innovation lies in a unique method for generating relation embeddings, which can enhance entity embeddings via inherent structure. Specifically, we utilize the translation property of knowledge graphs to obtain the entity embedding that is mapped into a time-aware vector space. Subsequently, we employ GNNs to learn global entity representation. To better capture the useful information from neighboring relations and entities, we introduce a time-aware attention mechanism that assigns different importance weights to different time-aware inherent structures. Experimental results on three real-world datasets demonstrate that TSM-GNN outperforms several state-of-the-art approaches for entity alignment between TKGs.'},\n",
       " '10.1016/j.ins.2024.120430': {'title': 'SANe: Space Adaptation Network for Temporal Knowledge Graph Completion',\n",
       "  'abstract': 'Temporal Knowledge Graphs (TKGs) model time-dependent facts as relations between entities at specific timestamps, making them well-suited for real-world scenarios. However, TKGs are susceptible to incompleteness, necessitating Temporal Knowledge Graph Completion (TKGC) to predict missing facts. Prior methods often struggle to effectively handle two critical properties of TKGs, time-variability and time-stability, simultaneously, which hinders their performance. In this paper, we propose Space Adaptation Network (SANe), a novel approach for TKGC. SANe adapts facts at different timestamps to distinct latent spaces, effectively addressing time-variability. Our model introduces Parameter Generation Network to produce separate neural networks for each snapshot, which are then encoded into different latent spaces. A dynamic convolutional neural network processes entities and relations, utilizing different learned parameters generated by parameter generation network with respect to timestamps. By handling different temporal snapshots separately, TKGC is transformed into static KGC, enabling the modeling of time-variability. Dynamic convolutional neural network efficiently learns collective knowledge over large periods and supplements more specific knowledge gradually in smaller periods, facilitating time-stability. To strike a balance between learning time-variability and time-stability, we introduce a time-aware parameter generator to produce parameters hierarchically based on year, month, and day timestamps. Long-term knowledge is effectively shared across adjacent snapshots within the same year or month, while short-term knowledge within a day is preserved in specific parameters. However, in unbalanced TKGs, where many facts occur in small intervals, the large number of parameters generated by time-aware parameter generator may remain underutilized. To address this, we propose Adaptive Parameter Generation with a partition tree, ensuring parameter load balancing while maintaining time-stability. We conduct extensive experiments on five benchmark datasets, demonstrating the superiority of SANe over existing methods for TKGC, achieving state-of-the-art performance. Our contributions include pioneering TKGC from the perspective of space adaptation, achieving a balance between time-variability and time-stability through latent space overlap constraints, and substantiating the effectiveness of our model through comprehensive experiments on rich temporal datasets.'},\n",
       " '10.1016/j.inffus.2024.102321': {'title': 'The survey on multi-source data fusion in cyber-physical-social systems: Foundational infrastructure for industrial metaverses and industries 5.0',\n",
       "  'abstract': 'As the concept of Industries 5.0 develops, industrial metaverses are expected to operate in parallel with the actual industrial processes to offer ``Human-Centric\" Safe, Secure, Sustainable, Sensitive, Service, and Smartness ``6S\" manufacturing solutions. Industrial metaverses not only visualize the process of productivity in a dynamic and evolutional way, but also provide an immersive laboratory experimental environment for optimizing and remodeling the process. Besides, the customized user needs that are hidden in social media data can be discovered by social computing technologies, which introduces an input channel for building the whole social manufacturing process including industrial metaverses. This makes the fusion of multi-source data cross Cyber-Physical-Social Systems (CPSS) the foundational and key challenge. This work firstly proposes a multi-source-data-fusion-driven operational architecture for industrial metaverses on the basis of conducting a comprehensive literature review on the state-of-the-art multi-source data fusion methods. The advantages and disadvantages of each type of method are analyzed by considering the fusion mechanisms and application scenarios. Especially, we combine the strengths of deep learning and knowledge graphs in scalability and parallel computation to enable our proposed framework the ability of prescriptive optimization and evolution. This integration can address the shortcomings of deep learning in terms of explainability and fact fabrication, as well as overcoming the incompleteness and the challenges of construction and maintenance inherent in knowledge graphs. The effectiveness of the proposed architecture is validated through a parallel weaving case study. In the end, we discuss the challenges and future directions of multi-source data fusion cross CPSS for industrial metaverses and social manufacturing in Industries 5.0.'},\n",
       " '10.1016/j.ins.2023.119857': {'title': 'Learning to compensate for lack of information: Extracting latent knowledge for effective temporal knowledge graph completion',\n",
       "  'abstract': 'The goal of temporal knowledge graph embedding (TKGE) is to represent the entities and relations in a given temporal knowledge graph (TKG) as low-dimensional vectors (i.e., embeddings), which preserve both semantic information and temporal dynamics of the factual information. In this paper, we posit that the intrinsic difficulty of existing TKGE methods lies in the lack of information in KG snapshots with timestamps, each of which contains the facts that co-occur at a specific timestamp. To address this challenge, we propose a novel self-supervised TKGE approach, THOR (Three-tower grapH cOnvolution netwoRks (GCNs)), which extracts latent knowledge from TKGs by jointly leveraging both temporal and atemporal dependencies between entities and the structural dependency between relations. THOR learns the embeddings of entities and relations, obtained from three-tower GCNs by (1) maximizing the likelihood of the facts in a TKG and (2) addressing the lack of information in a TKG based on the auxiliary supervision signals of each entity. Our experiments on three real-world datasets demonstrate that THOR significantly outperforms 17 competitors in terms of TKG completion tasks. THOR yields up to 9.37% higher accuracy than the best competitor.'},\n",
       " '10.1016/j.ins.2023.119853': {'title': 'Joint framework for tensor decomposition-based temporal knowledge graph completion',\n",
       "  'abstract': 'Knowledge graphs (KGs) usually contain a lot of missing information, static knowledge graph completion (KGC) is widely used to solve their incompleteness. In recently, since the incompleteness of temporal KGs which typically contain lots of temporal facts, like (Barack Obama, Is-president-of, USA, 2008), temporal knowledge graph completion (TKGC) is proposed to predict the missing part of (?, Is-president-of, USA, 2008) or (Barack Obama, Is-president-of, ?, 2008). In particular, tensor decomposition method has shown excellent performance in KGC and therefore many existing methods extend it to TKGC. One of the key challenges is how to make full use of static information and effectively fuse static (non-temporal) and temporal information for improving the performance of TKGC. The existing models usually concatenate or sum the static and temporal embeddings directly. Moreover, we observe that neighborhood information of temporal facts may be very useful for inferring the missing parts of temporal facts while has not been fully explored and utilized. To address these challenges, we propose a joint framework composed of temporal and static modules for tensor decomposition-based TKGC. In temporal module, we propose a new neighborhood time sharing technology for aggregating richer temporal semantic information. The static module is proposed as an auxiliary model to further learn embedding representation of static information based on our proposed two training strategies (named typed entity strategy and adjacent active entity strategy). Finally, we propose a novel way of fusing static and temporal information through joint learning of two modules based on our proposed entity sharing technology. A series of comparison and ablation experiments show that our model can make better and full use of static information while capturing richer temporal semantic information, coupled with an effective fusion method, thus achieving state-of-the-art (SOTA) performance compared to existing tensor decomposition-based TKGC methods on four benchmark datasets.'},\n",
       " '10.1016/j.eswa.2023.121267': {'title': 'Tensor decompositions for temporal knowledge graph completion with time perspective',\n",
       "  'abstract': 'Facts in the real world are often tied to time, such as the spread of diseases, and the state of military affairs. Therefore, knowledge graphs combined with temporal factors have gained growing attention. In the temporal knowledge graph, most researchers focus on the original facts and pay attention to their changes over time. The temporal factors are only used as auxiliary information for representation learning. In this paper, we try to observe from the perspective of time and find some interesting properties of temporal knowledge graph: (1) Simultaneousness. Various facts occur at the same time; (2) Aggregation. The facts may aggregately occur for a certain individual, organization, or location; (3) Associativity. Some specific relations tend to occur at specific times, such as celebrations at festivals. Based on the above three properties, we add a simple time-aware module to the existing tensor decomposition-based temporal knowledge graph model TComplEx (Lacroix et al., 2020), which obtains impressive improvements and achieves state-of-the-art results on four standard temporal knowledge graph completion benchmarks. Specifically, in terms of mean reciprocal rank (MRR), we advance the state-of-the-art by +24.0% on ICEWS14, +13.2% on ICEWS05-15, +31.9% on YAGO15k, and 4.7% on GDELT.'},\n",
       " '10.1016/j.procs.2022.09.117': {'title': 'Modelling Multi-relations for Convolutional-based Knowledge Graph Embedding',\n",
       "  'abstract': 'Representation learning of knowledge graphs aims to embed entities and relations into low-dimensional vectors. Most existing works only consider the direct relations or paths between an entity pair. It is considered that such approaches disconnect the semantic connection of multi-relations between an entity pair, and we propose a convolutional and multi-relational representation learning model, ConvMR. The proposed ConvMR model addresses the multi-relation issue in two aspects: (1) Encoding the multi-relations between an entity pair into a unified vector that maintains the semantic connection. (2) Since not all relations are necessary while joining multi-relations, we propose an attention-based relation encoder to automatically assign weights to different relations based on semantic hierarchy. Experimental results on two popular datasets, FB15k-237 and WN18RR, achieved consistent improvements on the mean rank. We also found that ConvMR is efficient to deal with less frequent entities.'},\n",
       " '10.1016/j.inffus.2024.102249': {'title': 'MvTuckER: Multi-view knowledge graphs represention learning based on tensor tucker model',\n",
       "  'abstract': 'Recently, more and more multi-view knowledge graphs with various important attributes are being constructed and applied, such as temporal information, geolocation, commonsense knowledge, multi-language and multi-modal. Knowledge graphs (KGs) have been widely applied in question answering systems, drug discovery, information retrieval, and so on. Knowledge graph representation learning (KGRL) is emerging as the most effective approach to tasks such as knowledge graph completion, entity alignment, knowledge reasoning and knowledge query. However, most previous work on KGs and KGRL are mainly designed for traditional KGs and only consider single-view, and the KGRL methods for special multi-view KGs faces the challenges of lacking a unified framework, insufficient interactive information and underutilizing important attributes. To bridge this gap, in this paper, we proposes a multi-view knowledge graphs (e.g., temporal KGs) represention learning method based on tensor tucker model (MvTuckER), which models the multi-view KGs from tuples to a nth-order binary tensor, and adopts the tensor n-mode product to capture complete interaction between and within different views. We also introduce low-rank and sparse approximations of core tensors to balance expressivity and complexity of MvTuckER. Moreover, we theoretically illustrate that our model is fully expressive for modeling multi-view KGs, discuss the working mechanism of MvTuckER from the perspective of logical operation, and explain how to migrate and extend our method to other types of views. We conducted extensive experiments on three multi-view knowledge graphs, and obtain 4.7%, 2.7%, and 5.3% effective improvement in Hit@1 respectively, which proves that the proposed MvTuckER can achieve state-of-the-art performance.'},\n",
       " '10.1007/978-3-031-00123-9_10': {'title': 'TRHyTE: Temporal Knowledge Graph Embedding Based on Temporal-Relational Hyperplanes',\n",
       "  'abstract': 'Temporal Knowledge Graph Embedding (TKGE) aims at encoding evolving facts with high-dimensional vectorial representations. Although a representative hyperplane-based TKGE approach, namely HyTE, has achieved remarkable performance, it still suffers from several problems including (i) ignorance of latent temporal properties and diversity of relations; (ii) neglect of temporal dependency between adjacent hyperplanes; (iii) inefficient static random negative sampling method; (iv) incomplete testing on partial time information. To address these issues, we propose TRHyTE, a novel Temporal-Relational Hyperplane based TKGE model, which defines three typical properties, including interval, open-interval, and instantaneousness temporal, for relations and correspondingly constructs three relational sub-KGs, supporting distinguishing learning for facts. Within each sub-KG, TRHyTE transforms entities into relation space first, and then explicitly projects transformed entities and relations into temporal-relational hyperplanes to learn time-relation-aware embeddings. Moreover, Gate Recurrent Unit is leveraged to simulate TKG evolution so as to capture temporal dependency between adjacent hyperplanes. Additionally, we develop a dynamic negative samples mechanism for robust training. In testing phase, an expand-and-best-merge strategy is crafted to realize a complete testing on all valid time intervals. Extensive experiments on two well-known benchmarks verify the effectiveness of our proposals.'},\n",
       " '10.1016/j.patcog.2019.107000': {'title': 'Dynamic graph convolutional networks',\n",
       "  'abstract': 'Many different classification tasks need to manage structured data, which are usually modeled as graphs. Moreover, these graphs can be dynamic, meaning that the vertices/edges of each graph may change during time. Our goal is to jointly exploit structured data and temporal information through the use of a neural network model. To the best of our knowledge, this task has not been addressed using these kind of architectures. For this reason, we propose two novel approaches, which combine Long Short-Term Memory networks and Graph Convolutional Networks to learn long short-term dependencies together with graph structure. The quality of our methods is confirmed by the promising results achieved.'},\n",
       " '10.1038/s41598-018-24271-9': {'title': 'Recurrent Neural Networks for Multivariate Time Series with Missing Values',\n",
       "  'abstract': 'Abstract Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU - D , as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval , and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results. Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provide useful insights for better understanding and utilization of missing values in time series analysis.'},\n",
       " '10.1016/j.ipm.2022.102977': {'title': 'Identifying humanitarian information for emergency response by modeling the correlation and independence between text and images',\n",
       "  'abstract': 'Information residing in multiple modalities (e.g., text, image) of social media posts can jointly provide more comprehensive and clearer insights into an ongoing emergency. To identify information valuable for humanitarian aid from noisy multimodal data, we first clarify the categories of humanitarian information, and define a multi-label multimodal humanitarian information identification task, which can adapt to the label inconsistency issue caused by modality independence while maintaining the correlation between modalities. We proposed a Multimodal Humanitarian Information Identification Model that simultaneously captures the Correlation and Independence between modalities (CIMHIM). A tailor-made dataset containing 4,383 annotated text-image pairs was built to evaluate the effectiveness of our model. The experimental results show that CIMHIM outperforms both unimodal and multimodal baseline methods by at least 0.019 in macro-F1 and 0.022 in accuracy. The combination of OCR text, object-level features, and the decision rule based on label correlations enhances the overall performance of CIMHIM. Additional experiments on a similar dataset (CrisisMMD) also demonstrate the robustness of CIMHIM. The task, model, and dataset proposed in this study contribute to the practice of leveraging multimodal social media resources to support effective emergency response.'},\n",
       " '10.1007/978-3-319-46493-0_38': {'title': 'Identity Mappings in Deep Residual Networks',\n",
       "  'abstract': 'Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which makes training easier and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10 (4.62 % error) and CIFAR-100, and a 200-layer ResNet on ImageNet. Code is available at: https://github.com/KaimingHe/resnet-1k-layers .'},\n",
       " '10.1007/978-3-319-46478-7_28': {'title': 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering',\n",
       "  'abstract': 'We address the problem of Visual Question Answering (VQA), which requires joint image and language understanding to answer a question about a given photograph. Recent approaches have applied deep image captioning methods based on convolutional-recurrent networks to this problem, but have failed to model spatial inference. To remedy this, we propose a model we call the Spatial Memory Network and apply it to the VQA task. Memory networks are recurrent neural networks with an explicit attention mechanism that selects certain parts of the information stored in memory. Our Spatial Memory Network stores neuron activations from different spatial regions of the image in its memory, and uses attention to choose regions relevant for computing the answer. We propose a novel question-guided spatial attention architecture that looks for regions relevant to either individual words or the entire question, repeating the process over multiple recurrent steps, or “hops”. To better understand the inference process learned by the network, we design synthetic questions that specifically require spatial inference and visualize the network’s attention. We evaluate our model on two available visual question answering datasets and obtain improved results.'},\n",
       " '10.1186/s12967-023-04011-y': {'title': 'Precision information extraction for rare disease epidemiology at scale',\n",
       "  'abstract': 'Abstract Background The United Nations recently made a call to address the challenges of an estimated 300 million persons worldwide living with a rare disease through the collection, analysis, and dissemination of disaggregated data. Epidemiologic Information (EI) regarding prevalence and incidence data of rare diseases is sparse and current paradigms of identifying, extracting, and curating EI rely upon time-intensive, error-prone manual processes. With these limitations, a clear understanding of the variation in epidemiology and outcomes for rare disease patients is hampered. This challenges the public health of rare diseases patients through a lack of information necessary to prioritize research, policy decisions, therapeutic development, and health system allocations. Methods In this study, we developed a newly curated epidemiology corpus for Named Entity Recognition (NER), a deep learning framework, and a novel rare disease epidemiologic information pipeline named EpiPipeline4RD consisting of a web interface and Restful API. For the corpus creation, we programmatically gathered a representative sample of rare disease epidemiologic abstracts, utilized weakly-supervised machine learning techniques to label the dataset, and manually validated the labeled dataset. For the deep learning framework development, we fine-tuned our dataset and adapted the BioBERT model for NER. We measured the performance of our BioBERT model for epidemiology entity recognition quantitatively with precision, recall, and F1 and qualitatively through a comparison with Orphanet. We demonstrated the ability for our pipeline to gather, identify, and extract epidemiology information from rare disease abstracts through three case studies. Results We developed a deep learning model to extract EI with overall F1 scores of 0.817 and 0.878, evaluated at the entity-level and token-level respectively, and which achieved comparable qualitative results to Orphanet’s collection paradigm. Additionally, case studies of the rare diseases Classic homocystinuria, GRACILE syndrome, Phenylketonuria demonstrated the adequate recall of abstracts with epidemiology information, high precision of epidemiology information extraction through our deep learning model, and the increased efficiency of EpiPipeline4RD compared to a manual curation paradigm. Conclusions EpiPipeline4RD demonstrated high performance of EI extraction from rare disease literature to augment manual curation processes. This automated information curation paradigm will not only effectively empower development of the NIH Genetic and Rare Diseases Information Center (GARD), but also support the public health of the rare disease community.'},\n",
       " '10.1016/j.engappai.2024.108241': {'title': 'Shielding against online harm: A survey on text analysis to prevent cyberbullying',\n",
       "  'abstract': 'Cyberbullying poses a digital threat to society. In this survey, we explain what cyberbullying is and its various forms. We focus on social media platforms and instant messaging apps that are susceptible to cyberbullying, discussing how we can identify such behavior in these spaces. Moving on, we conduct a systematic review of publicly available datasets in different languages, exploring techniques for data preprocessing, feature representation, and methodologies used in textual analysis for cyberbullying detection. We specifically look at natural language-based and platform-specific preprocessing methods. We also cover popular feature representation techniques like sentiment analysis, user information, text summarization, symbols, images, and word embedding for detecting cyberbullying. Next, we categorize existing techniques, including machine learning and neural networks, highlighting research gaps. Additionally, we discuss the challenges associated with current datasets and methods. This survey aims to provide early researchers with insights into cyberbullying literature and guide them in exploring potential research directions.'},\n",
       " '10.1016/j.aiopen.2021.09.001': {'title': 'Heterogeneous graph knowledge enhanced stock market prediction',\n",
       "  'abstract': 'We focus on the task of stock market prediction based on financial text which contains information that could influence the movement of stock market. Previous works mainly utilize a single semantic unit of financial text, such as words, events, sentences, to predict the tendency of stock market. However, the interaction of different-grained information within financial text can be useful for context knowledge supplement and predictive information selection, and then improve the performance of stock market prediction. To facilitate this, we propose constructing a heterogeneous graph with different-grained information nodes from financial text for the task. A novel heterogeneous neural network is presented to aggregate multi-grained information. Experimental results demonstrate that our proposed approach reaches higher performance than baselines.'},\n",
       " '10.1007/978-3-319-71249-9_4': {'title': 'Sentiment Informed Cyberbullying Detection in Social Media',\n",
       "  'abstract': 'Cyberbullying is a phenomenon which negatively affects the individuals, the victims suffer from various mental issues, ranging from depression, loneliness, anxiety to low self-esteem. In parallel with the pervasive use of social media, cyberbullying is becoming more and more prevalent. Traditional mechanisms to fight against cyberbullying include the use of standards and guidelines, human moderators, and blacklists based on the profane words. However, these mechanisms fall short in social media and cannot scale well. Therefore, it is necessary to develop a principled learning framework to automatically detect cyberbullying behaviors. However, it is a challenging task due to short, noisy and unstructured content information and intentional obfuscation of the abusive words or phrases by social media users. Motivated by sociological and psychological findings on bullying behaviors and the correlation with emotions, we propose to leverage sentiment information to detect cyberbullying behaviors in social media by proposing a sentiment informed cyberbullying detection framework. Experimental results on two real-world, publicly available social media datasets show the superiority of the proposed framework. Further studies validate the effectiveness of leveraging sentiment information for cyberbullying detection.'},\n",
       " '10.1007/978-3-319-27433-1_4': {'title': 'Analyzing Labeled Cyberbullying Incidents on the Instagram Social Network',\n",
       "  'abstract': 'Cyberbullying is a growing problem affecting more than half of all American teens. The main goal of this paper is to study labeled cyberbullying incidents in the Instagram social network. In this work, we have collected a sample data set consisting of Instagram images and their associated comments. We then designed a labeling study and employed human contributors at the crowd-sourced CrowdFlower website to label these media sessions for cyberbullying. A detailed analysis of the labeled data is then presented, including a study of relationships between cyberbullying and a host of features such as cyberaggression, profanity, social graph features, temporal commenting behavior, linguistic content, and image content.'},\n",
       " '10.1016/j.ipm.2023.103586': {'title': 'Clause-aware extractive summarization with topical decoupled contrastive learning',\n",
       "  'abstract': 'The sentence-level extracted summary is inevitably mixed with redundant information due to the uninformative phrases or detailed expressions mixed in it. The extraction of fine-grained units is dedicated to retain the semantical integrity. To keep the balance between text redundancy and semantical integrity, we propose a novel clause-aware summarization model (TDCL-ClauseSum). We separate complex sentences into grammatically independent but semantically dependent clauses. The clause is regarded as the extraction unit and leverage graph neural network and topical information to capture clause-level relationship. Then a decoupled contrastive loss is stacked over the neural model to fill the gap between topic prediction and clause classification. The experiments of TDCL-ClauseSum are evaluated on two public benchmark datasets CNN/daily mail and New York Times, which contain 310574 and 150536 samples, respectively. Various experiments show that our method achieves remarkable performance on the two datasets (CNN/daily mail:43.94/20.65/40.75, New York Times:49.69/29.84/43.01, in ROUGE-1/ROUGE-2/ROUGE-L). Its promising performance demonstrates that the superiority of clause extraction.'},\n",
       " '10.1007/s11229-022-03931-4': {'title': 'Understanding models understanding language',\n",
       "  'abstract': 'Abstract Landgrebe and Smith (Synthese 198(March):2061–2081, 2021) present an unflattering diagnosis of recent advances in what they call language-centric artificial intelligence—perhaps more widely known as natural language processing: The models that are currently employed do not have sufficient expressivity, will not generalize, and are fundamentally unable to induce linguistic semantics, they say. The diagnosis is mainly derived from an analysis of the widely used Transformer architecture. Here I address a number of misunderstandings in their analysis, and present what I take to be a more adequate analysis of the ability of Transformer models to learn natural language semantics. To avoid confusion, I distinguish between inferential and referential semantics. Landgrebe and Smith (2021)’s analysis of the Transformer architecture’s expressivity and generalization concerns inferential semantics. This part of their diagnosis is shown to rely on misunderstandings of technical properties of Transformers. Landgrebe and Smith (2021) also claim that referential semantics is unobtainable for Transformer models. In response, I present a non-technical discussion of techniques for grounding Transformer models, giving them referential semantics, even in the absence of supervision. I also present a simple thought experiment to highlight the mechanisms that would lead to referential semantics, and discuss in what sense models that are grounded in this way, can be said to understand language. Finally, I discuss the approach Landgrebe and Smith (2021) advocate for, namely manual specification of formal grammars that associate linguistic expressions with logical form.'},\n",
       " '10.1186/s12889-022-12926-2': {'title': 'Detecting changes in help seeker conversations on a suicide prevention helpline during the COVID− 19 pandemic: in-depth analysis using encoder representations from transformers',\n",
       "  'abstract': 'Abstract Background Preventatives measures to combat the spread of COVID− 19 have introduced social isolation, loneliness and financial stress. This study aims to identify whether the COVID-19 pandemic is related to changes in suicide-related problems for help seekers on a suicide prevention helpline. Methods A retrospective cohort study was conducted using chat data from a suicide prevention helpline in the Netherlands. The natural language processing method BERTopic was used to detect common topics in messages from December 1, 2019 until June 1, 2020 ( N = 8589). Relative topic occurrence was compared before and during the lock down starting on March 23, 2020. The observed changes in topic usage were likewise analyzed for male and female, younger and older help seekers and help seekers living alone. Results The topic of the COVID-19 pandemic saw an 808% increase in relative occurrence after the lockdown. Furthermore, the results show that help seeker increased mention of thanking the counsellor (+ 15%), and male and young help seekers were grateful for the conversation (+ 45% and + 32% respectively). Coping methods such as watching TV (− 21%) or listening to music (− 15%) saw a decreased mention. Plans for suicide (− 9%) and plans for suicide at a specific location (− 15%) also saw a decreased mention. However, plans for suicide were mentioned more frequently by help seekers over 30 years old (+ 11%) or who live alone and (+ 52%). Furthermore, male help seekers talked about contact with emergency care (+ 43%) and panic and anxiety (+ 24%) more often. Negative emotions (+ 22%) and lack of self-confidence (+ 15%) were mentioned more often by help seekers under 30, and help seekers over 30 saw an increased mention of substance abuse (+ 9%). Conclusion While mentions of distraction, social interaction and plans for suicide decreased, expressions of gratefulness for the helpline increased, highlighting the importance of contact to help seekers during the lockdown. Help seekers under 30, male or who live alone, showed changes that negatively related to suicidality and should be monitored closely.'},\n",
       " '10.23915/DISTILL.00011': {'title': 'Feature-wise transformations',\n",
       "  'abstract': 'Many real-world problems require integrating multiple sources of information. Sometimes these problems involve multiple, distinct modalities of information\\u2009—\\u2009vision, language, audio, etc.\\u2009—\\u2009as is required to understand a scene in a movie or answer a question about an image. Other times, these problems involve multiple sources of the same kind of input, i.e. when summarizing several documents or drawing one image in the style of another.'},\n",
       " '10.1007/978-94-011-4359-2_5': {'title': 'Distributivity, Collectivity and Cumulativity',\n",
       "  'abstract': 'In the language of plurality introduced in this lecture, we will not yet incorporate a full treatment of verbs. So the language (and the analysis of plurality, in this respect) is poorer than Scha’s. For the moment, we won’t have functional abstraction, and we will have only one-place verbs, which -again for the moment - we will treat in the same way as nouns: as sets. We do have some plurality operators that Scha doesn’t have. In the next lecture, we will combine the present language of plurality with the language of events from lecture Two, to give a full treatment of verbs.'},\n",
       " '10.1016/B978-044481714-3/50023-0': {'title': 'Plurals and Collectivity',\n",
       "  'abstract': 'This chapter discusses the way a logical approach to natural language semantics best should be modified and extended to accommodate collective plural noun phrases (NPs). Distributive plural NPs and mass nouns are considered to bring out the similarities and differences between them and the collective plural NPs. There are languages with three different numbers — dual in addition to singular and plural — and languages with no numbers at all. The chapter shows the way the analysis of plurals interacts with some of the most fundamental questions concerning the relationship between logic and language. The basic intuition about an ambiguity between a collective and distributive reading of plural NPs yields an explosion in the number of readings for sentences containing several plural NPs. In the chapter, the semantics of plural NPs is interwoven with some fundamental problems related to the set theory and higher-order logic.'},\n",
       " '10.1016/j.inffus.2023.03.015': {'title': 'Finding hate speech with auxiliary emotion detection from self-training multi-label learning perspective',\n",
       "  'abstract': 'Hate Speech Detection (HSD) aims to identify whether a text contains hate speech content, which often refers to discrimination and is even associated with a hate crime. The mainstream methods jointly train the HSD problem with relevant auxiliary problems, e.g., emotion detection and sentiment analysis, under the paradigm of Multi-Task Learning (MTL). In this paper, we improve HSD by integrating it with emotion detection, since we take inspiration from the potential correlations between hate speech and certain negative emotion states, which have been studied theoretically and empirically. To be specific, we can concatenate their hateful labels and predicted emotion states as pseudo-multiple labels for hate speech samples, formulating a pseudo-Multi-Label Learning (MLL) problem. Beyond the existing MTL-HSD methods, we further incorporate this pseudo-MLL problem and solve it by capturing the correlations between hate speech and negative emotion states, so as to improve the performance of HSD. Based on these ideas, we propose a novel HSD method named the Emotion-correlated Hate Speech DetectOR (EHSor). We conduct extensive experiments to evaluate EHSor, and the results show that it can consistently outperform the existing HSD methods across benchmark datasets.'},\n",
       " '10.1140/epjds/s13688-022-00319-9': {'title': 'Tackling racial bias in automated online hate detection: Towards fair and accurate detection of hateful users with geometric deep learning',\n",
       "  'abstract': 'Abstract Online hate is a growing concern on many social media platforms, making them unwelcoming and unsafe. To combat this, technology companies are increasingly developing techniques to automatically identify and sanction hateful users. However, accurate detection of such users remains a challenge due to the contextual nature of speech, whose meaning depends on the social setting in which it is used. This contextual nature of speech has also led to minoritized users, especially African–Americans, to be unfairly detected as ‘hateful’ by the very algorithms designed to protect them. To resolve this problem of inaccurate and unfair hate detection, research has focused on developing machine learning (ML) systems that better understand textual context. Incorporating social networks of hateful users has not received as much attention, despite social science research suggesting it provides rich contextual information. We present a system for more accurately and fairly detecting hateful users by incorporating social network information through geometric deep learning. Geometric deep learning is a ML technique that dynamically learns information-rich network representations. We make two main contributions: first, we demonstrate that adding network information with geometric deep learning produces a more accurate classifier compared with other techniques that either exclude network information entirely or incorporate it through manual feature engineering. Our best performing model achieves an AUC score of 90.8% on a previously released hateful user dataset. Second, we show that such information also leads to fairer outcomes: using the ‘predictive equality’ fairness criteria, we compare the false positive rates of our geometric learning algorithm to other ML techniques and find that our best-performing classifier has no false positives among a subset of African–American users. A neural network without network information has the largest number of false positives at 26, while a neural network incorporating manual network features has 13 false positives among African–American users. The system we present highlights the importance of effectively incorporating social network features in automated hateful user detection, raising new opportunities to improve how online hate is tackled.'},\n",
       " '10.1016/j.eswa.2022.117571': {'title': 'Character-level HyperNetworks for Hate Speech Detection',\n",
       "  'abstract': 'The massive spread of hate speech, hateful content targeted at specific subpopulations, is a problem of critical social importance. Automated methods of hate speech detection typically employ state-of-the-art deep learning (DL)-based text classifiers—large pretrained neural language models of over 100 million parameters, adapting these models to the task of hate speech detection using relevant labeled datasets. Unfortunately, there are only a few public labeled datasets of limited size that are available for this purpose. We make several contributions with high potential for advancing this state of affairs. We present HyperNetworks for hate speech detection, a special class of DL networks whose weights are regulated by a small-scale auxiliary network. These architectures operate at character-level, as opposed to word or subword-level, and are several orders of magnitude smaller compared to the popular DL classifiers. We further show that training hate detection classifiers using additional large amounts of automatically generated examples is beneficial in general, yet this practice especially boosts the performance of the proposed HyperNetworks. We report the results of extensive experiments, assessing the performance of multiple neural architectures on hate detection using five public datasets. The assessed methods include the pretrained language models of BERT, RoBERTa, ALBERT, MobileBERT and CharBERT, a variant of BERT that incorporates character alongside subword embeddings. In addition to the traditional setup of within-dataset evaluation, we perform cross-dataset evaluation experiments, testing the generalization of the various models in conditions of data shift. Our results show that the proposed HyperNetworks achieve performance that is competitive, and better in some cases, than these pretrained language models, while being smaller by orders of magnitude.'},\n",
       " '10.1007/978-3-030-59065-9_20': {'title': 'Cyberbullying Detection in Social Networks Using Deep Learning Based Models',\n",
       "  'abstract': 'Cyberbullying is a disturbing online misbehaviour with troubling consequences. It appears in different forms, and in most of the social networks, it is in textual format. Automatic detection of such incidents requires intelligent systems. Most of the existing studies have approached this problem with conventional machine learning models and the majority of the developed models in these studies are adaptable to a single social network at a time. Recently deep learning based models have been used for similar objectives, claiming that they can overcome the limitations of the conventional models, and improve the detection performance. In this paper, we investigated the findings of a recent literature in this regard and validated their findings using the same datasets as they did. We further expanded the work by applying the developed methods on a new dataset. We aimed to further investigate the performance of the models in new social media platforms. Our findings show that the deep learning based models outperform the machine learning models previously applied to the same dataset. We believe that the deep learning based models can also benefit from integrating other sources of information and looking into the impact of profile information of the users in social networks.'},\n",
       " '10.1007/978-3-319-93417-4_48': {'title': 'Detecting Hate Speech on Twitter Using a Convolution-GRU Based Deep Neural Network',\n",
       "  'abstract': 'In recent years, the increasing propagation of hate speech on social media and the urgent need for effective counter-measures have drawn significant investment from governments, companies, and empirical research. Despite a large number of emerging scientific studies to address the problem, a major limitation of existing work is the lack of comparative evaluations, which makes it difficult to assess the contribution of individual works. This paper introduces a new method based on a deep neural network combining convolutional and gated recurrent networks. We conduct an extensive evaluation of the method against several baselines and state of the art on the largest collection of publicly available Twitter datasets to date, and show that compared to previously reported results on these datasets, our proposed method is able to capture both word sequence and order information in short texts, and it sets new benchmark by outperforming on 6 out of 7 datasets by between 1 and 13% in F1. We also extend the existing dataset collection on this task by creating a new dataset covering different topics.'},\n",
       " '10.1007/978-3-319-06483-3_25': {'title': 'Experts and Machines against Bullies: A Hybrid Approach to Detect Cyberbullies',\n",
       "  'abstract': 'Cyberbullying is becoming a major concern in online environments with troubling consequences. However, most of the technical studies have focused on the detection of cyberbullying through identifying harassing comments rather than preventing the incidents by detecting the bullies. In this work we study the automatic detection of bully users on YouTube. We compare three types of automatic detection: an expert system, supervised machine learning models, and a hybrid type combining the two. All these systems assign a score indicating the level of \"bulliness\" of online bullies. We demonstrate that the expert system outperforms the machine learning models. The hybrid classifier shows an even better performance.'},\n",
       " '10.1080/09544828.2023.2301230': {'title': 'Evolving to multi-modal knowledge graphs for engineering design: state-of-the-art and future challenges',\n",
       "  'abstract': 'With the support of advanced information and communication technologies and open innovative design platforms, the emerging and blooming paradigm of mass personalization drives the process of engineering design to include knowledge with higher heterogeneity and more complex modalities. To this end, Multi-Modal Knowledge Graphs (MMKG), evolved from semantic networks and knowledge graphs, provide a powerful technology system for more effectively organizing and utilizing this knowledge. To understand the state-of-the-art of key aspects that enables MMKG, and recognize the potential challenges for forefront applications in engineering design, a literature review of MMKG-related publications is conducted. With selected 131 representative papers together with other 32 supplementary studies (up to 11/11/2023), this article summarizes the technical and practical efforts of multi-modal knowledge extraction, fusion technology, and specific applications in the engineering design process. Meantime, the challenges that MMKG faces and its foreseeable development potentials are discussed, which is hoped to provide a basis for the futuristic explorations and implementations of MMKG-enhanced availability and productivity in engineering design.'},\n",
       " '10.1016/j.eswa.2023.122850': {'title': 'Exploring generative frameworks for product attribute value extraction',\n",
       "  'abstract': 'E-commerce platforms rely heavily on the attribute values of their products as they play a crucial role in various retail functions such as product search, recommendations, and question answering. Therefore, identifying the attribute values from unstructured product information is critical for any e-commerce retailer. This problem is challenging due to the diversity of product types and their attributes and values. Attribute value extraction deals with extracting the values of attributes from the product profile. Previous approaches for this task have formulated the attribute value extraction as a Named Entity Recognition task (NER) or a Question Answering (QA) task. In this paper, we propose to tackle the attribute value extraction task using generative frameworks. In the first task, the attribute name and the product title are used to generate the value of the attribute. In the second task, only the product title is utilized to extract both the attributes and the values jointly. The value extraction is formulated as a text-infilling task and an answer-generation task. For joint attribute value extraction, we present two types of generative paradigms, namely, word sequence-based paradigm and positional sequence-based paradigm. The pre-trained language models such as GPT-2, BART, T5, and FLAN-T5 are leveraged to perform these tasks. Our experiments show that a single general model effectively performs value extraction task over a broad set of product attributes. Experiments conducted on two datasets depict that the generative approaches achieve new state-of-the-art results, which indicates that the proposed frameworks are helpful for attribute value extraction tasks without additional tagging.'},\n",
       " '10.1007/s10479-022-04799-w': {'title': 'Intelligence customs declaration for cross-border e-commerce based on the multi-modal model and the optimal window mechanism',\n",
       "  'abstract': 'This paper aims to study the intelligent customs declaration of cross-border e-commerce commodities from algorithm design and implementation. The difficulty of this issue is the recognition of commodity names, materials, and processing processes. Because the process of recognizing these three kinds of commodity information is similar, this paper chooses to identify the commodity name as the experimental research object. The algorithm in this paper is based on the premise of pre-clustering, using an optimal window mechanism to obtain the best word embedding vector representation. The Vision Transformer model extracts image features instead of traditional CNN models, and then text features are fused with image features to generate a multi-modal semantically feature vector. Finally, a deep forest classifier replaces the conventional neural network classifiers to complete the commodity name recognition task. The experimental results show that, for more than 600 different commodities on the 120,000 data records, the precision is 0.85, the recall is 0.87, and the F $$_1$$ _score is 0.86. So, our algorithm can effectively and accurately recognize e-commerce commodity names and provide a new perspective on the research of e-commerce intelligence declarations.'},\n",
       " '10.21817/indjcse/2021/v12i3/211203165': {'title': 'Sensitive Keyword Detection on Textual Product Data: An Approximate Dictionary Matching and Context-score Approach',\n",
       "  'abstract': 'In this paper, we define and study a new problem in the field of natural language processing and data science called Sensitive Keyword Detection, which aims at detecting variants of keyword in each textual product.We propose a method using approximate dictionary matching algorithm and contextscore to solve this new text mining problem in a general way.Given a product data set, for each document will be dectected keyword-variant pairs, then to determine if they are similar in semantic, we compare the context score between them.We conduct experiments on 1.189.690textual sentences extracted from descriptions and titles of 300.000 products, each textual sentence contains an original keyword or a keyword variant.Experimental results show that important role of the context-score approach and the proposed method is effective when using context-score based on character and word embedding.'},\n",
       " '10.1016/j.jvcir.2022.103664': {'title': 'The encoding method of position embeddings in vision transformer',\n",
       "  'abstract': 'In contrast to Convolutional Neural Networks (CNNs), Vision Transformers (ViT) cannot capture sequence ordering of input tokens and require position embeddings. As a learnable fixed-dimension vector, the position embedding improves accuracy while limiting the migration of the model between different input sizes. Hence, this paper conducts an empirical study on position embeddings of pre-trained models, which mainly focuses on two questions: (1) What do the position embeddings learn from training? (2) How do the position embeddings affect the self-attention modules? This paper analyzes the pattern of position embedding in pre-trained models and finds that the linear combination of Gabor filters and edge markers can fit the learned position embeddings well. The Gabor filters and edge markers can occupy some channels to append the position information, and the edge markers have flowed to values in self-attention modules. The experimental results can guide future work to choose suitable position embeddings.'},\n",
       " '10.1038/s42256-023-00639-z': {'title': 'Regression Transformer enables concurrent sequence regression and generation for molecular language modelling',\n",
       "  'abstract': 'Abstract Despite tremendous progress of generative models in the natural sciences, their controllability remains challenging. One fundamentally missing aspect of molecular or protein generative models is an inductive bias that can reflect continuous properties of interest. To that end, we propose the Regression Transformer (RT), a method that abstracts regression as a conditional sequence modelling problem. This introduces a new direction for multitask language models, seamlessly bridging sequence regression and conditional sequence generation. We demonstrate that, despite using a nominal-scale training objective, the RT matches or surpasses the performance of conventional regression models in property prediction of small molecules, proteins and chemical reactions. Critically, priming the same model with continuous properties yields a competitive conditional generative model that outperforms specialized approaches in a substructure-constrained, property-driven molecule generation benchmark. Our dichotomous approach is facilitated by an alternating training scheme that enables the model to decorate seed sequences on the basis of desired property constraints, for example, to optimize reaction yield. We expect that the RT’s capability to jointly tackle predictive and generative tasks in biochemistry can find applications in property-driven, local exploration of the chemical or protein space. Such multitask approaches will pave the road towards foundation models in materials design.'},\n",
       " '10.1016/j.jag.2021.102651': {'title': 'SITS-Former: A pre-trained spatio-spectral-temporal representation model for Sentinel-2 time series classification',\n",
       "  'abstract': 'Sentinel-2 images provide a rich source of information for a variety of land cover, vegetation, and environmental monitoring applications due to their high spectral, spatial, and temporal resolutions. Recently, deep learning-based classification of Sentinel-2 time series becomes a popular solution to vegetation classification and land cover mapping, but it often demands a large number of manually annotated labels. Improving classification performance with limited labeled data is still a challenge in many real-world remote sensing applications. To address label scarcity, we present SITS-Former (SITS stands for Satellite Image Time Series and Former stands for Transformer), a pre-trained representation model for Sentinel-2 time series classification. SITS-Former adopts a Transformer encoder as the backbone and takes time series of image patches as input to learn spatio-spectral-temporal features. According to the principles of self-supervised learning, we pre-train SITS-Former on massive unlabeled Sentinel-2 time series via a missing-data imputation proxy task. Given an incomplete time series with some patches being masked randomly, the network is asked to regress the central pixels of these masked patches based on the residual ones. By doing so, the network can capture high-level spatial and temporal dependencies from the data to learn discriminative features. After pre-training, the network can adapt the learned features to a target classification task through fine-tuning. As far as we know, this is the first study that exploits self-supervised learning for patch-based representation learning and classification of SITS. We quantitatively evaluate the quality of the learned features by transferring them on two crop classification tasks, showing that SITS-Former outperforms state-of-the-art approaches and yields a significant improvement (2.64%∼3.30% in overall accuracy) over the purely supervised model. The proposed model provides an effective tool for SITS-related applications as it greatly reduces the burden of manual labeling. The source code will be released at https://github.com/linlei1214/SITS-Former upon publication.'},\n",
       " '10.1016/j.eswa.2022.119300': {'title': 'Long multispan prediction model for machine reading comprehension in healthcare domain',\n",
       "  'abstract': 'Machine reading comprehension (MRC) is a question answering task, in which a system provides appropriate answers to users queries in a given document. With large-scale language models and enough training datasets, recent MRC models have surpassed humans in well-designed intrinsic tests that require short and single span answers. However, they have performed poorly in real world applications that require long and multispan answers. In healthcare domain, users want to find long and detailed information (e.g., symptoms of an illness, causes of a disease, and effects of a drug) rather than short and simple ones (e.g., name of an illness, name of a virus, and date of discovery). To satisfy these needs, we propose an MRC model to extract nonconsecutive long text spans from a document. The proposed model detects long candidate answer spans consisting of sentences and determines multiple nonconsecutive spans by using a span matrix. In an experiment using long multispan datasets, namely, MASHQA (a healthcare domain dataset), the proposed model outperformed previous state of the art MRC models in terms of all evaluation parameters.'},\n",
       " '10.1016/j.knosys.2022.109146': {'title': 'Heterogenous affinity graph inference network for document-level relation extraction',\n",
       "  'abstract': 'Document-level relation extraction (Doc-level RE) is a more practical and challenging task, which provides a new perspective on obtaining factual knowledge from the more complex cross-sentence text. Recent Doc-level RE, based on pre-trained language models, uses graph neural networks to implicitly model relation reasoning in a document. However, it is not perfect that the model neglects explicit reasoning clues, leading to a weak ability and a lack of capability to model long-distance relationships. In this paper, we propose to explicitly model the heterogeneous affinity graph, HAG, including a mention graph (MG) and a coreference graph (CG). We first construct CG to cluster the expressions together as a coreference array. Then, MG and CG are incorporated to capture the reasoning clues from the adjacent affinity matrix. Moreover, HAG is aggregated into an isomorphic entity graph according to the noise suppression mechanism and RGCN. Finally, the classification is established on the normalized graph to infer the relations of entity pairs. Experimental results significantly outperform baselines by nearly 1.7% ∼ 2.0% in F1 on three public datasets, DocRED, DialogRE, and MPDD. We further conduct ablation experiments to demonstrate the effectiveness of the proposed approach.'},\n",
       " '10.1007/978-3-030-86523-8_35': {'title': 'NA-Aware Machine Reading Comprehension for Document-Level Relation Extraction',\n",
       "  'abstract': 'Document-level relation extraction aims to identify semantic relations between target entities from the document.Most of the existing work roughly treats the document as a long sequence and produces target-agnostic representation for relation prediction, limiting the model’s ability to focus on the relevant context of target entities. In this paper, we reformulate the document-level relation extraction task and propose a NA-aware machine Reading Comprehension (NARC) model to tackle this problem. Specifically, the input sequence formulated as the concatenation of a head entity and a document is fed into the encoder to obtain comprehensive target-aware representations for each entity. In this way, the relation extraction task is converted into a reading comprehension problem by taking all the tail entities as candidate answers. Then, we add an artificial answer \\\\(\\\\texttt {NO-ANSWER}\\\\) (NA) for each query and dynamically generate a NA score based on the decomposition and composition of all candidate tail entity features, which finally weighs the prediction results to alleviate the negative effect of having too many no-answer instances after task reformulation. Experimental results on DocRED with extensive analysis demonstrate the effectiveness of NARC.'},\n",
       " '10.1016/j.nlp.2024.100066': {'title': 'Claim detection for automated fact-checking: A survey on monolingual, multilingual and cross-lingual research',\n",
       "  'abstract': 'Automated fact-checking has drawn considerable attention over the past few decades due to the increase in the diffusion of misinformation on online platforms.This is often carried out as a sequence of tasks comprising (i) the detection of sentences circulating in online platforms which constitute claims needing verification, followed by (ii) the verification process of those claims.This survey focuses on the former, by discussing existing efforts towards detecting claims needing fact-checking, with a particular focus on multilingual data and methods.This is a challenging and fertile direction where existing methods are yet far from matching human performance due to the profoundly challenging nature of the issue.Especially, the dissemination of information across multiple social platforms, articulated in multiple languages and modalities demands more generalized solutions for combating misinformation.Focusing on multilingual misinformation, we present a comprehensive survey of existing multilingual claim detection research.We present state-of-the-art multilingual claim detection research categorized into three key factors of the problem, verifiability, priority, and similarity.Further, we present a detailed overview of the existing multilingual datasets along with the challenges and suggest possible future advancements.'},\n",
       " '10.1007/s12652-023-04619-4': {'title': 'Automatic detection of health misinformation: a systematic review',\n",
       "  'abstract': 'The spread of health misinformation has the potential to cause serious harm to public health, from leading to vaccine hesitancy to adoption of unproven disease treatments. In addition, it could have other effects on society such as an increase in hate speech towards ethnic groups or medical experts. To counteract the sheer amount of misinformation, there is a need to use automatic detection methods. In this paper we conduct a systematic review of the computer science literature exploring text mining techniques and machine learning methods to detect health misinformation. To organize the reviewed papers, we propose a taxonomy, examine publicly available datasets, and conduct a content-based analysis to investigate analogies and differences among Covid-19 datasets and datasets related to other health domains. Finally, we describe open challenges and conclude with future directions.'},\n",
       " '10.1016/j.ipm.2022.103206': {'title': 'Preventing profiling for ethical fake news detection',\n",
       "  'abstract': \"A news article's online audience provides useful insights about the article's identity. However, fake news classifiers using such information risk relying on profiling. In response to the rising demand for ethical AI, we present a profiling-avoiding algorithm that leverages Twitter users during model optimisation while excluding them when an article's veracity is evaluated. For this, we take inspiration from the social sciences and introduce two objective functions that maximise correlation between the article and its spreaders, and among those spreaders. We applied our profiling-avoiding algorithm to three popular neural classifiers and obtained results on fake news data discussing a variety of news topics. The positive impact on prediction performance demonstrates the soundness of the proposed objective functions to integrate social context in text-based classifiers. Moreover, statistical visualisation and dimension reduction techniques show that the user-inspired classifiers better discriminate between unseen fake and true news in their latent spaces. Our study serves as a stepping stone to resolve the underexplored issue of profiling-dependent decision-making in user-informed fake news detection.\"},\n",
       " '10.1007/s10458-022-09569-3': {'title': 'Towards an axiomatic approach to truth discovery',\n",
       "  'abstract': 'Abstract The problem of truth discovery , i.e., of trying to find the true facts concerning a number of objects based on reports from various information sources of unknown trustworthiness, has received increased attention recently. The problem is made interesting by the fact that the relative believability of facts depends on the trustworthiness of their sources, which in turn depends on the believability of the facts the sources report. Several algorithms for truth discovery have been proposed, but their evaluation has mainly been performed experimentally by computing accuracy against large datasets. Furthermore, it is often unclear how these algorithms behave on an intuitive level. In this paper we take steps towards a framework for truth discovery which allows comparison and evaluation of algorithms based instead on their theoretical properties. To do so we pose truth discovery as a social choice problem, and formulate various axioms that any reasonable algorithm should satisfy. Along the way we provide an axiomatic characterisation of the baseline ‘Voting’ algorithm—which leads to an impossibility result showing that a certain combination of the axioms cannot hold simultaneously—and check which axioms a particular well-known algorithm satisfies. We find that, surprisingly, our more fundamental axioms do not hold, and propose modifications to the algorithms to partially fix these problems.'},\n",
       " '10.1007/s11192-022-04602-4': {'title': 'SsciBERT: a pre-trained language model for social science texts',\n",
       "  'abstract': 'The academic literature of social sciences records human civilization and studies human social problems. With its large-scale growth, the ways to quickly find existing research on relevant issues have become an urgent demand for researchers. Previous studies, such as SciBERT, have shown that pre-training using domain-specific texts can improve the performance of natural language processing tasks. However, the pre-trained language model for social sciences is not available so far. In light of this, the present research proposes a pre-trained model based on the abstracts published in the Social Science Citation Index (SSCI) journals. The models, which are available on GitHub ( https://github.com/S-T-Full-Text-Knowledge-Mining/SSCI-BERT ), show excellent performance on discipline classification, abstract structure–function recognition, and named entity recognition tasks with the social sciences literature.'},\n",
       " '10.1007/978-3-031-47240-4_25': {'title': 'TemporalFC: A Temporal Fact Checking Approach over Knowledge Graphs',\n",
       "  'abstract': 'Verifying assertions is an essential part of creating and maintaining knowledge graphs. Most often, this task cannot be carried out manually due to the sheer size of modern knowledge graphs. Hence, automatic fact-checking approaches have been proposed over the last decade. These approaches aim to compute automatically whether a given assertion is correct or incorrect. However, most fact-checking approaches are binary classifiers that fail to consider the volatility of some assertions, i.e., the fact that such assertions are only valid at certain times or for specific time intervals. Moreover, the few approaches able to predict when an assertion was valid (i.e., time-point prediction approaches) rely on manual feature engineering. This paper presents TemporalFC, a temporal fact-checking approach that uses multiple sources of background knowledge to assess the veracity and temporal validity of a given assertion. We evaluate TemporalFC on two datasets and compare it to the state of the art in fact-checking and time-point prediction. Our results suggest that TemporalFC outperforms the state of the art on the fact-checking task by 0.13 to 0.15 in terms of Area Under the Receiver Operating Characteristic curve and on the time-point prediction task by 0.25 to 0.27 in terms of Mean Reciprocal Rank. Our code is open-source and can be found at https://github.com/dice-group/TemporalFC .'},\n",
       " '10.1007/978-3-031-19433-7_27': {'title': 'HybridFC: A Hybrid Fact-Checking Approach for Knowledge Graphs',\n",
       "  'abstract': 'We consider fact-checking approaches that aim to predict the veracity of assertions in knowledge graphs. Five main categories of fact-checking approaches for knowledge graphs have been proposed in the recent literature, of which each is subject to partially overlapping limitations. In particular, current text-based approaches are limited by manual feature engineering. Path-based and rule-based approaches are limited by their exclusive use of knowledge graphs as background knowledge, and embedding-based approaches suffer from low accuracy scores on current fact-checking tasks. We propose a hybrid approach—dubbed HybridFC—that exploits the diversity of existing categories of fact-checking approaches within an ensemble learning setting to achieve a significantly better prediction performance. In particular, our approach outperforms the state of the art by 0.14 to 0.27 in terms of Area Under the Receiver Operating Characteristic curve on the FactBench dataset. Our code is open-source and can be found at https://github.com/dice-group/HybridFC .'},\n",
       " '10.1007/s10115-024-02113-7': {'title': 'Semantic features analysis for biomedical lexical answer type prediction using ensemble learning approach',\n",
       "  'abstract': 'Abstract Lexical answer type prediction is integral to biomedical question–answering systems. LAT prediction aims to predict the expected answer’s semantic type of a factoid or list-type biomedical question. It also aids in the answer processing stage of a QA system to assign a high score to the most relevant answers. Although considerable research efforts exist for LAT prediction in diverse domains, it remains a challenging biomedical problem. LAT prediction for the biomedical field is a multi-label classification problem, as one biomedical question might have more than one expected answer type. Achieving high performance on this task is challenging as biomedical questions have limited lexical features. One biomedical question must be assigned multiple labels given these limited lexical features. In this paper, we develop a novel feature set (lexical, noun concepts, verb concepts, protein–protein interactions, and biomedical entities) from these lexical features. Using ensemble learning with bagging, we use the label power set transformation technique to classify multi-label. We evaluate the integrity of our proposed methodology on the publicly available multi-label biomedical questions dataset (MLBioMedLAT) and compare it with twelve state-of-the-art multi-label classification algorithms. Our proposed method attains a micro-F1 score of 77%, outperforming the baseline model by 25.5%.'},\n",
       " '10.1016/j.compeleceng.2022.108401': {'title': 'Multi-label disaster text classification via supervised contrastive learning for social media data',\n",
       "  'abstract': 'Social media is a crucial way to release information in a timely manner during disasters, which provides help to people who suffer from disasters. In this disaster information, each message may contain multiple labels. The single-label classification method cannot be adapted to a multi-label classification problem. In addition, there is a lack of representative baseline datasets due to the differences between disaster data sources. We propose a supervised contrastive learning based multi-label classification framework as a general framework for data processing and model training. Specifically, it learns features of disaster data and identifies different disaster type information, then trains a multi-label classification model of disaster texts in different dimensions. The results of empirical studies on three disaster text classification datasets show that this method can effectively improve the accuracy of the model and the representation ability of semantic information.'},\n",
       " '10.1007/s44196-021-00055-4': {'title': 'Research on Multi-label Text Classification Method Based on tALBERT-CNN',\n",
       "  'abstract': 'Abstract Single-label classification technology has difficulty meeting the needs of text classification, and multi-label text classification has become an important research issue in natural language processing (NLP). Extracting semantic features from different levels and granularities of text is a basic and key task in multi-label text classification research. A topic model is an effective method for the automatic organization and induction of text information. It can reveal the latent semantics of documents and analyze the topics contained in massive information. Therefore, this paper proposes a multi-label text classification method based on tALBERT-CNN: an LDA topic model and ALBERT model are used to obtain the topic vector and semantic context vector of each word (document), a certain fusion mechanism is adopted to obtain in-depth topic and semantic representations of the document, and the multi-label features of the text are extracted through the TextCNN model to train a multi-label classifier. The experimental results obtained on standard datasets show that the proposed method can extract multi-label features from documents, and its performance is better than that of the existing state-of-the-art multi-label text classification algorithms.'},\n",
       " '10.1016/j.neucom.2022.04.057': {'title': 'Examining and mitigating gender bias in text emotion detection task',\n",
       "  'abstract': 'Gender bias is an important problem that affects models of natural language, and the propagation of such biases could be harmful. Much research focuses on gender biases in word embeddings, and there are also some works on gender biases in subsequent tasks. However, very limited prior work has been done on gender issues in emotion detection tasks. In this paper, we investigate the effect of gender in text emotion detection. Existing methods for gender biases require gender balanced and gender-swapping data, and might influence the performance of the target task due to removing more information related to sensitive attributes. We present different solutions to measuring and mitigating gender bias in emotion detection. To measure gender bias, we first prepare datasets annotated with emotional classes and gender information. Then, we compare the performance of emotion recognition models from gender balanced samples, and also analyze gender prediction results from emotion related data. Our experiment results show that there exists gender bias in emotion detection: the models trained on the female data often achieve better results than the male models, and the female models and the male models report the opposite trends on the recognition of some emotions. We also attempt to mitigate gender bias by developing various approaches including products of experts, introducing weights and variants of focal loss, as well as adversarial training. Compared to other debiasing methods, adversarial trainings represent tpr reduction approximately 0.02–0.03 while simultaneously less harming performance by below 1.0 points on our prepared datasets. Further, we show that efficient parameters can lead to further improvements.'},\n",
       " '10.1007/s43674-021-00006-8': {'title': 'Generative adversarial networks for open information extraction',\n",
       "  'abstract': 'Open information extraction (Open IE) is a core task of natural language processing (NLP). Even many efforts have been made in this area, and there are still many problems that need to be tackled. Conventional Open IE approaches use a set of handcrafted patterns to extract relational tuples from the corpus. Secondly, many NLP tools are employed in their procedure; therefore, they face error propagation. To address these problems and inspired by the recent success of Generative Adversarial Networks (GANs), we employ an adversarial training architecture and name it Adversarial-OIE. In Adversarial-OIE, the training of the Open IE model is assisted by a discriminator, which is a (Convolutional Neural Network) CNN model. The goal of the discriminator is to differentiate the extraction result generated by the Open IE model from the training data. The goal of the Open IE model is to produce high-quality triples to cheat the discriminator. A policy gradient method is leveraged to co-train the Open IE model and the discriminator. In particular, due to insufficient training, the discriminator usually leads to the instability of GAN training. We use the distant supervision method to generate training data for the Adversarial-OIE model to solve this problem. To demonstrate our approach, an empirical study on two large benchmark dataset shows that our approach significantly outperforms many existing baselines.'},\n",
       " '10.1007/s11633-019-1211-x': {'title': 'Adversarial Attacks and Defenses in Images, Graphs and Text: A Review',\n",
       "  'abstract': 'Abstract Deep neural networks (DNN) have achieved unprecedented success in numerous machine learning tasks in various domains. However, the existence of adversarial examples raises our concerns in adopting deep learning to safety-critical applications. As a result, we have witnessed increasing interests in studying attack and defense mechanisms for DNN models on different data types, such as images, graphs and text. Thus, it is necessary to provide a systematic and comprehensive overview of the main threats of attacks and the success of corresponding countermeasures. In this survey, we review the state of the art algorithms for generating adversarial examples and the countermeasures against adversarial examples, for three most popular data types, including images, graphs and text.'},\n",
       " '10.1007/s00521-019-04144-6': {'title': 'Assessing gender bias in machine translation: a case study with Google Translate',\n",
       "  'abstract': 'Recently there has been a growing concern in academia, industrial research laboratories and the mainstream commercial media about the phenomenon dubbed as machine bias, where trained statistical models—unbeknownst to their creators—grow to reflect controversial societal asymmetries, such as gender or racial bias. A significant number of Artificial Intelligence tools have recently been suggested to be harmfully biased toward some minority, with reports of racist criminal behavior predictors, Apple’s Iphone X failing to differentiate between two distinct Asian people and the now infamous case of Google photos’ mistakenly classifying black people as gorillas. Although a systematic study of such biases can be difficult, we believe that automated translation tools can be exploited through gender neutral languages to yield a window into the phenomenon of gender bias in AI. In this paper, we start with a comprehensive list of job positions from the U.S. Bureau of Labor Statistics (BLS) and used it in order to build sentences in constructions like “He/She is an Engineer” (where “Engineer” is replaced by the job position of interest) in 12 different gender neutral languages such as Hungarian, Chinese, Yoruba, and several others. We translate these sentences into English using the Google Translate API, and collect statistics about the frequency of female, male and gender neutral pronouns in the translated output. We then show that Google Translate exhibits a strong tendency toward male defaults, in particular for fields typically associated to unbalanced gender distribution or stereotypes such as STEM (Science, Technology, Engineering and Mathematics) jobs. We ran these statistics against BLS’ data for the frequency of female participation in each job position, in which we show that Google Translate fails to reproduce a real-world distribution of female workers. In summary, we provide experimental evidence that even if one does not expect in principle a 50:50 pronominal gender distribution, Google Translate yields male defaults much more frequently than what would be expected from demographic data alone. We believe that our study can shed further light on the phenomenon of machine bias and are hopeful that it will ignite a debate about the need to augment current statistical translation tools with debiasing techniques—which can already be found in the scientific literature.'},\n",
       " '10.1016/j.ijhcs.2003.09.005': {'title': \"A field study of the impact of gender and user's technical experience on the performance of voice-activated medical tracking application\",\n",
       "  'abstract': \"Speech recognition is a particularly important technology for mobile computing since it provides a smaller, lighter interface than a keyboard. This paper investigates the impact of user's gender and user's computer experience on the performance of a speech recognition system. Using a field study of 33 users, voice-activated medical tracking application and a mobile healthcare fieldwork environment, we illustrate that the user's gender, user's computer experience and the interaction between the user's gender and computer experience has an impact on the performance of a speech recognition system.\"},\n",
       " '10.1016/j.nlp.2024.100060': {'title': 'Transformer-based text similarity and second language proficiency: A case of written production by learners of Korean',\n",
       "  'abstract': 'The present study applies two transformer models (BERT; GPT-2) to analyse argumentative essays produced by two first-language groups (Czech; English) of second-language learners of Korean and investigates how informative similarity scores of learner writing obtained by these models explain general language proficiency in Korean. Results show three major aspects on model performance. First, the relationships between the similarity scores and the proficiency scores differ from the tendencies between human rating scores and the proficiency scores. Second, the degree to which the similarity scores obtained by each model explain the proficiency scores is asymmetric and idiosyncratic. Third, the performance of the two models is affected by learners’ native language and essay topic. These findings invite the need for researchers and educators to pay attention to how computational algorithms operate, together with learner language characteristics and language-specific properties of the target language, in utilising Natural Language Processing methods and techniques for their research or instructional purposes.'},\n",
       " '10.1075/kl.00001.int': {'title': 'Introduction',\n",
       "  'abstract': 'Preview this article: Introduction, Page 1 of 1 < Previous page | Next page > /docserver/preview/fulltext/kl.00001.int-1.gif'},\n",
       " '10.1007/s12449-018-0056-3': {'title': 'Bonus',\n",
       "  'abstract': 'Een leuke sollicitant zit tegenover me en vraagt wat ik haar te bieden heb om haar over de streep te trekken bij ons te komen werken. Het is mij duidelijk dat ze niet de prachtige uitdaging van het werken met de jongeren bedoelt, of het geboden salaris met groeimogelijkheden. Enigszins verbouwereerd besef ik dat ze uit is op een bonus.'},\n",
       " '10.3758/BF03196727': {'title': 'Processing doubly quantified sentences: Evidence from eye movements',\n",
       "  'abstract': 'We investigated the processing of doubly quantified sentences, such asKelly showed a photo to every critic, that are ambiguous as to whether the indefinite (a photo) specifies single or multiple referents. Ambiguity resolution requires the computation of relative quantifier scope: Whether a or every takes wide scope, thereby determining how many entities or events are to be represented. In an eye-tracking experiment, we manipulated quantifier order and whether continuations were singular or plural, for constructions with the direct or the indirect object occurring first. We obtained effects consistent with the on-line processing of relative scope at the doubly quantified phrase and considered two possible explanations for a preference for singular continuations to the quantified sentence. We conclude that relative quantifier scope is computed on line during reading but may not be a prerequisite for the resolution of definite anaphors, unless required by secondary tasks.'},\n",
       " '10.1016/0010-0277(83)90012-4': {'title': 'What some concepts might not be',\n",
       "  'abstract': \"A discussion of the difficulties of prototype theories for describing compositional meaning motivates three experiments that inquire how well-defined concepts fare under paradigms that are commonly interpreted to support the prototype view. The stimulus materials include exemplars of prototype categories (sport, vehicle, fruit, vegetable) previously studied by others, and also exemplars of supposedly well-defined categories (odd number, even number, female, and plane geometry figure). Experiment I, using these materials, replicated the exemplar rating experiment of Rosch (1973). It showed that both the well-defined and prototypic categories yield graded responses, the supposed hall-mark of a family resemblance structure. Experiment II, using the same sorts of stimulus materials, replicated a verification-time paradigm, also from Rosch (1973). Again, the finding was that both well-defined and prototypic categories yielded results previously interpreted to support a family-resemblance description of those categories, with faster verification times for prototypical exemplars of each category. In Experiment III, new subjects were asked outright whether membership in the category of fruit, odd number, etc., is a matter of degree, or is not, and then these subjects were rerun in the Experiment I paradigm. Though subjects judged odd number, etc., to be well-defined, they provided graded responses to all categories once again. These findings highlight interpretive difficulties for the experimental literature on this topic. Part I of the discussion first outlines a dual theory of concepts and their identification procedures that seems to organize these outcomes. But Part II of the discussion argues that feature theories are too impoverished to describe mental categories, in general. Une discussion sur les problémes rencontrés par les théories des prototypes pour rendre compte de la compositionalitédes significations a entrainétrois expériences au cours desquelles on a recherchécomment les concepts bien définis conviennent aux paradigmes qui appuyent la position du prototype. Les stimuli incluent des catégories prototypes (sport, véhicule, fruit, légume) précédemmentétudiées ainsi que des examples de catégories supposées bien définies: nombre, pair, impair femelle, figures de géometrie plane. L'expérience I avec ce type de matériel réplique l'expérience de graduation de Rosch (1973). Les catégories prototypes et les catégories bien définies entrainent toutes deux des réponses graduées ce qui est l'apanage supposéd'une structure de ressemblance d'une famille. En utilisant le meˆme type de matériel l'Expérience II réplique un paradigme de temps de vérification issu de Rosch (1973). De nouveau on trouve que, toutes deux, les catégories bien définies et les catégories prototypes, donnent des résultats allant dans le sens d'une description en famille de ressemblance, avec des temps de vérification plus rapides pour les exemplaires prototypiques de chaque catégorie. Dans l'expérience III on demande carrémentàd'autres sujets si l'appartenance dans une catégorie de fruit, numéro impair, etc. est une question de degrés ou non. Les sujets sont remis ensuite dans la situation expérimentale I. Bien que les sujets jugent un numéro impair commeétant bien défini, ils donnent des résponses graduées pour toutes les catégories. Ces données montrent la difficultéd'interprétation de la littérature expérimentale. Dans la premiére partie de la discussion on présente une théorie duale des concepts et de leur procédure d'identification qui semble organiser les données, cependant dans la deuxième partie de la discussion on démontre que les théories des traits sont trop pauvres pour décrire les catégories mentales.\"},\n",
       " '10.1016/j.inffus.2024.102302': {'title': 'Enhancing multi-modal fusion in visual dialog via sample debiasing and feature interaction',\n",
       "  'abstract': 'Visual dialog aims to accomplish multiple rounds of dialog by fusing information extracted from images, captions, and previous question-answer pairs. As a vision-language task, visual dialog encounters challenges related to language bias and vision bias. These biases create an imbalance in multi-modal fusion, resulting in shortcut learning and significantly compromising the model’s robustness. Moreover, existing multi-modal fusion methods in visual dialog exhibit a low data interaction frequency, leading to insufficient fusion. To overcome the balance and sufficiency issues in multi-modal fusion, we propose a novel Parallel Attention Fusion visual dialog model with Counterfactual Sample debiasing (CS-PAF). Specifically, CS-PAF consists of two core ingredients: (i) a counterfactual sample generation module for model debiasing; and (ii) a parallel attention fusion network that enhances sufficiency in multi-modal data interaction. Notably, in contrast to other debiasing methods, our counterfactual sample generation applies contrastive learning to circumvent the high cost of manual annotations and ensure seamless integration with other models. Extensive comparisons with state-of-the-art approaches, along with comprehensive ablation and transferability studies across multiple datasets, substantiate the superiority and effectiveness of our CS-PAF. Our implement code is available at https://github.com/chenyulu2000/cspaf.'},\n",
       " '10.1016/j.patter.2023.100788': {'title': 'Toward human-level concept learning: Pattern benchmarking for AI algorithms',\n",
       "  'abstract': 'Artificial intelligence (AI) today is very successful at standard pattern-recognition tasks due to the availability of large amounts of data and advances in statistical data-driven machine learning. However, there is still a large gap between AI pattern recognition and human-level concept learning. Humans can learn amazingly well even under uncertainty from just a few examples and are capable of generalizing these concepts to solve new conceptual problems. The growing interest in explainable machine intelligence requires experimental environments and diagnostic/benchmark datasets to analyze existing approaches and drive progress in pattern analysis and machine intelligence. In this paper, we provide an overview of current AI solutions for benchmarking concept learning, reasoning, and generalization; discuss the state-of-the-art of existing diagnostic/benchmark datasets (such as CLEVR, CLEVRER, CLOSURE, CURI, Bongard-LOGO, V-PROM, RAVEN, Kandinsky Patterns, CLEVR-Humans, CLEVRER-Humans, and their extension containing human language); and provide an outlook of some future research directions in this exciting research domain.'},\n",
       " '10.1007/978-3-030-86365-4_37': {'title': 'Improving Visual Question Answering by Semantic Segmentation',\n",
       "  'abstract': 'Most recent visual question answering (VQA) methods extract object regions (bounding-boxes) by Faster R-CNN and use these region features in the visual encoder. Because extracted bounding-boxes are often located around things (countable objects), information on stuff (amorphous background regions such as grass and sky) is not reflected well in the visual encoder. Because stuff is amorphous and uncountable, it is common to use semantic segmentation to extract its features. In this work, we extend conventional thing-centric regions-of-interest (ROIs) by adding ROIs distributed around stuff regions and use semantic segmentation labels to encode stuff features in the visual encoder. The results of our experiments revealed that our method improved on existing VQA models and produced state-of-the-art results on VQA-v2 val, even though this dataset was not designed specifically for evaluating stuff, and most of its questions are thing-centric.'},\n",
       " '10.1038/nrmicro2536': {'title': 'Shifting the balance: antibiotic effects on host–microbiota mutualism',\n",
       "  'abstract': 'The use of antibiotics is making lasting alterations to the long-term relationship between a host and its microbiota. Willing, Russell and Finlay describe how these changes can result in the disruption of immune homeostasis and in increased susceptibility to disease. Antibiotics have been used effectively as a means to treat bacterial infections in humans and animals for over half a century. However, through their use, lasting alterations are being made to a mutualistic relationship that has taken millennia to evolve: the relationship between the host and its microbiota. Host–microbiota interactions are dynamic; therefore, changes in the microbiota as a consequence of antibiotic treatment can result in the dysregulation of host immune homeostasis and an increased susceptibility to disease. A better understanding of both the changes in the microbiota as a result of antibiotic treatment and the consequential changes in host immune homeostasis is imperative, so that these effects can be mitigated.'},\n",
       " '10.1016/j.knosys.2022.109855': {'title': 'Boosting aspect category detection with inference heuristics and knowledge enhancement',\n",
       "  'abstract': 'Aspect category detection (ACD) aims to identify the aspect categories from reviewers’ expressed opinions in a given sentence, where one or multiple predefined aspect categories are mentioned explicitly or implicitly. With the boom of the pretrained language model, related studies have achieved significant improvements in ACD. However, the studies usually follow the canonical method of fine-tuning and neglect deeply mining internal knowledge or incorporating external knowledge, which could lead to suboptimal results. To address this issue, we propose a novel multilevel knowledge-aware ACD model by innovatively converting ACD to a binary sentence-pair classification task from the viewpoint of natural language inference, which is effective and consists of four key components. The model first expands the predefined aspect categories by introducing terms with high semantic similarity scores from commonsense knowledge bases. Next, the model generates synthetic premise-hypothesis sentence pairs based on the aspect categories and an inference heuristic template. Then, the training data are effectively augmented and used for fine-tuning the proposed model. Moreover, the model designs a pooling strategy to mine the rich syntactic and semantic knowledge encoded in the internal layers of BERT. Finally, the pooled low-dimensional representation is fed to a linear classifier to detect aspect categories. Experimental results on the SemEval-2014 and SemEval-2016 benchmark datasets achieve F1-scores of 92.75% and 83.58%, respectively, which demonstrate the superiority of our proposed model compared with some strong baselines.'},\n",
       " '10.1007/978-3-031-05933-9_13': {'title': 'Aspect-Based Sentiment Analysis Through EDU-Level Attentions',\n",
       "  'abstract': 'A sentence may express sentiments on multiple aspects. When these aspects are associated with different sentiment polarities, a model’s accuracy is often adversely affected. We observe that multiple aspects in such hard sentences are mostly expressed through multiple clauses, or formally known as elementary discourse units (EDUs), and one EDU tends to express a single aspect with unitary sentiment towards that aspect. In this paper, we propose to consider EDU boundaries in sentence modeling, with attentions at both word and EDU levels. Specifically, we highlight sentiment-bearing words in EDU through word-level sparse attention. Then at EDU level, we force the model to attend to the right EDU for the right aspect, by using EDU-level sparse attention and orthogonal regularization. Experiments on three benchmark datasets show that our simple EDU-Attention model outperforms state-of-the-art baselines. Because EDU can be automatically segmented with high accuracy, our model can be applied to sentences directly without the need of manual EDU boundary annotation.'},\n",
       " '10.1007/978-3-030-88480-2_47': {'title': 'Locate and Combine: A Two-Stage Framework for Aspect-Category Sentiment Analysis',\n",
       "  'abstract': 'Aspect category sentiment classification aims at predicting the sentiment polarity of the given aspect category. Since the aspect category may not occur in the sentence, it is hard for the model to directly find the appropriate sentiment words for the aspect category and disregard unrelated ones. To address it, previous works have explored leveraging implicitly the information of the aspect term in the sentence and demonstrated the effectiveness of such information. Inspired by this conclusion, we propose a two-stage strategy named Locate-Combine(LC) to utilize the aspect term in a more straightforward way, which first locates the aspect term and then takes it as the bridge to find the related sentiment words. Specifically, in the \"Locate\" stage, we locate the aspect term corresponding to the given aspect category in the sentence, which can crystallize the target and further enable our model to focus on the target-related words. In the \"Combine\" stage, we first apply the graph convolutional network (GCN) over the dependency tree of the sentence to combine the information of the aspect term and related sentiment words and then take the output representation corresponding to the located aspect term to predict the sentiment polarity. The experimental results on the public datasets show that the proposed two-stage strategy is effective, which achieves state-of-the-art performance. Furthermore, our model can output explainable intermediate results for model analysis. (Code can be found at https://github.com/SCIR-MSA-Team/LC-ACSA)'},\n",
       " '10.1016/j.neucom.2012.08.001': {'title': 'Multi-instance multi-label image classification: A neural approach',\n",
       "  'abstract': 'In this paper, a multi-instance multi-label algorithm based on neural networks is proposed for image classification. The proposed algorithm, termed multi-instance multi-label neural network (MIMLNN), consists of two stages of MultiLayer Perceptrons (MLP). For multi-instance multi-label image classification, all the regional features are fed to the first-stage MLP, with one MLP copy processing one image region. After that, the MLP in the second stage incorporates the outputs of the first-stage MLPs to produce the final labels for the input image. The first-stage MLP is expected to model the relationship between regions and labels, while the second-stage MLP aims at capturing the label correlation for classification refinement. Error Back-Propagation (BP) approach is adopted to tune the parameters of MIMLNN. In view of that traditional gradient descent algorithm suffers from long-term dependency problem, a refined BP algorithm named Rprop is extended to effectively train MIMLNN. The experiments are conducted on a synthetic dataset and the Corel dataset. Experimental results demonstrate the superior performance of MIMLNN comparing with state-of-the-art algorithms for multi-instance multi-label image classification.'},\n",
       " '10.7551/mitpress/7503.003.0206': {'title': 'Multi-Instance Multi-Label Learning with Application to Scene Classification',\n",
       "  'abstract': 'In this paper, we formalize multi-instance multi-label learning, where each training example is associated with not only multiple instances but also multiple class labels. Such a problem can occur in many real-world tasks, e.g. an image usually contains multiple patches each of which can be described by a feature vector, and the image can belong to multiple categories since its semantics can be recognized in different ways. We analyze the relationship between multi-instance multi-label learning and the learning frameworks of traditional supervised learning, multi-instance learning and multi-label learning. Then, we propose the MIMLBOOST and MIMLSVM algorithms which achieve good performance in an application to scene classification.'},\n",
       " '10.1007/s13748-023-00295-9': {'title': 'Automatic question generation: a review of methodologies, datasets, evaluation metrics, and applications',\n",
       "  'abstract': \"Question generation in natural language has a wide variety of applications. It can be a helpful tool for chatbots for generating interesting questions as also for automating the process of question generation from a piece of text. Most modern-day systems, which are conversational, require question generation ability for identifying the user's needs and serving customers better. Generating questions in natural language is now, a more evolved task, which also includes generating questions for an image or video. In this review, we provide an overview of the research progress in automatic question generation. We also present a comprehensive literature review covering the classification of Question Generation systems by categorizing them into three broad use-cases, namely standalone question generation, visual question generation, and conversational question generation. We next discuss the datasets available for the same for each use-case. We further direct this review towards applications of question generation and discuss the challenges in this field of research.\"},\n",
       " '10.1007/978-3-031-56060-6_25': {'title': 'Simulating Follow-Up Questions in Conversational Search',\n",
       "  'abstract': 'Evaluating conversational search systems based on simulated user interactions is a potential approach to overcome one of the main problems of static conversational search test collections: the collections contain only very few of all the plausible conversations on a topic. Still, one of the challenges of user simulation is generating realistic follow-up questions on given outputs of a conversational system. We propose to address this challenge by using state-of-the-art language models and find that: (1) on two conversational search datasets, the tested models generate questions that are semantically similar to those in the datasets, especially when tuned for follow-up questions; (2) the generated questions are mostly valid, related, informative, and specific according to human assessment; and (3) for influencing the characteristics of the simulated questions, small changes to the prompt are insufficient.'},\n",
       " '10.1016/j.websem.2021.100698': {'title': 'Skeleton parsing for complex question answering over knowledge bases',\n",
       "  'abstract': 'Answering complex questions involving multiple relations over knowledge bases is a challenging task. Many previous works rely on dependency parsing. However, errors in dependency parsing would influence their performance, in particular for long complex questions. In this paper, we propose a novel skeleton grammar to represent the high-level structure of a complex question. This lightweight formalism and its BERT-based parsing algorithm help to improve the downstream dependency parsing. To show the effectiveness of skeleton, we develop two question answering approaches: skeleton-based semantic parsing (called SSP) and skeleton-based information retrieval (called SIR). In SSP, skeleton helps to improve structured query generation. In SIR, skeleton helps to improve path ranking. Experimental results show that, thanks to skeletons, our approaches achieve state-of-the-art results on three datasets: LC-QuAD 1.0, GraphQuestions, and ComplexWebQuestions 1.1.'},\n",
       " '10.1016/j.aiopen.2021.12.001': {'title': 'A review of deep learning in question answering over knowledge bases',\n",
       "  'abstract': 'Question answering over knowledge bases (KBQA) is a challenging task in natural language processing. It requires machines to answer natural language questions based on large-scale knowledge bases. Recent years have witnessed remarkable success of neural network models on many natural language processing tasks, including KBQA. In this paper, we first review the recent advances of deep learning methods on solving simple questions in two streams, the information extraction style and semantic parsing style. We then introduce how to extend the neural architectures to answer more complex questions with iteration and decomposition techniques, and summarize current research challenges.'},\n",
       " '10.1007/978-3-030-93758-4_22': {'title': 'Unsupervised Context-Driven Question Answering Based on Link Grammar',\n",
       "  'abstract': 'While general conversational intelligence (GCI) can be considered one of the core aspects of artificial general intelligence (AGI), there currently exists minimal overlap between the disciplines of AGI and natural language processing (NLP). Only a few AGI architectures can comprehend and generate natural language, and most NLP systems rely either on hardcoded, specialized rules and frameworks that cannot generalize to the various complex domains of human language or on heavily trained deep neural network models that cannot be interpreted, controlled, or made sense of. In this paper, we propose an interpretable “Contextual Generator” architecture for question answering (QA), built as an extension of the recently published “Generator” algorithm for sentence generation, that produces grammatically valid answers to queries structured as lists of seed words. We demonstrate the potential for this architecture to perform automated, closed-domain QA by detailing results on queries from SingularityNET’s “small world” POC-English corpus and from the Stanford Question Answering Dataset. Overall, our work may bring a greater degree of GCI to proto-AGI NLP pipelines. The proposed QA architecture is open-source and can be found on GitHub under the MIT License at https://github.com/aigents/aigents-java-nlp .'},\n",
       " '10.1007/978-3-030-00668-6_11': {'title': 'VoxEL: A Benchmark Dataset for Multilingual Entity Linking',\n",
       "  'abstract': 'The Entity Linking (EL) task identifies entity mentions in a text corpus and associates them with corresponding entities in a given knowledge base. While traditional EL approaches have largely focused on English texts, current trends are towards language-agnostic or otherwise multilingual approaches that can perform EL over texts in many languages. One of the obstacles to ongoing research on multilingual EL is a scarcity of annotated datasets with the same text in different languages. In this work we thus propose VoxEL: a manually-annotated gold standard for multilingual EL featuring the same text expressed in five European languages. We first motivate and describe the VoxEL dataset, using it to compare the behaviour of state of the art EL (multilingual) systems for five different languages, contrasting these results with those obtained using machine translation to English. Overall, our results identify how five state-of-the-art multilingual EL systems compare for various languages, how the results of different languages compare, and further suggest that machine translation of input text to English is now a competitive alternative to dedicated multilingual EL configurations.'},\n",
       " '10.1016/j.asoc.2023.110697': {'title': 'Dual adversarial network with meta-learning for domain-generalized few-shot text classification',\n",
       "  'abstract': 'Meta-learning-based methods prevail in few-shot text classification. Current methods perform meta-training and meta-testing on two parts of a dataset in the same or similar domains. This results in a significant limit in model performance when faced with data from different domains, limiting the generalization of few-shot models. To solve this problem, this study proposes a new setting, namely, domain-generalized few-shot text classification. First, meta-training is conducted on a multi-domain dataset to learn a generalizable model. Subsequently, the model is meta-tested on a target dataset. In addition, a domain-generalized model, namely, a dual adversarial network, is designed to improve the meta-learning-based methods under domain drift between different datasets and domains. Unlike previous meta-learning methods, two N-way-K-shot tasks were input from different domains for a dual adversarial network at each episode. Dual adversarial networks leverage the features from two different domains for adversarial training to improve the domain adaptability of the model. The proposed model utilizes a domain-knowledge generator during adversarial training to produce domain-specific knowledge, and a domain discriminator to recognize the domain label of the produced knowledge. Extensive experiments are conducted to verify the effectiveness of the proposed settings and model. The experimental results show that the model performance in our proposed setting is improved by an average of 3.84% compared to that in cross-domain few-shot text classification. Furthermore, the dual adversarial network significantly outperforms the five competitive baseline models, with an average improvement of 7.20%. The proposed model achieves an average performance improvement of 2.69% compared with the best baseline method.'},\n",
       " '10.1016/j.eswa.2023.120124': {'title': 'Constructing better prototype generators with 3D CNNs for few-shot text classification',\n",
       "  'abstract': 'Prototypical network is a key algorithm to solve few-shot problems. Previous prototypical network based methods average sentence embeddings of the same class to obtain corresponding class representation.1 However, this simple averaging fails to model the importance of word-level information to class representation effectively, thus limit the quality of prototype. In this work, we propose a 3D CNN2 based 3D Convolution Prototypical Network (3DCPN) which is mainly composed by two parts. To focus more effectively on the importance of word-level information from prototype perspective, firstly, we use a 3D CNN to process word embeddings of the same class. 3D CNNs are skilled at capturing semantic correlation from multiple objects. We utilize 3D CNNs to replace averaging to generate better class representation. Secondly, we construct a 2D semantic mining layer as the second part in 3DCPN to extract deep feature from query embeddings. Symmetric model structure is designed to ensure feature matching between class representation and query representation. After that, we obtain the similarity between the prototype representation and the query representation by a metric function. According to the calculated similarity matrix, we introduce a temperature coefficient based cross entropy as the objective function to optimize our model. Extensive experiments are conducted on four benchmarks. The results show that our model outperforms LaSAML by 1.88% and 2.28% on Banking77 under 10-way-5-shot and 15-way-5-shot respectively. For the other baselines, 3DCPN achieves average improvements of 4.90%, 4.53% and 8.81% on Clinc150, Hwu64 and Liu57 respectively.'},\n",
       " '10.1007/s10579-016-9343-x': {'title': 'The GUM corpus: creating multilayer resources in the classroom',\n",
       "  'abstract': 'This paper presents the methodology, design principles and detailed evaluation of a new freely available multilayer corpus, collected and edited via classroom annotation using collaborative software. After briefly discussing corpus design for open, extensible corpora, five classroom annotation projects are presented, covering structural markup in TEI XML, multiple part of speech tagging, constituent and dependency parsing, information structural and coreference annotation, and Rhetorical Structure Theory analysis. Layers are inspected for annotation quality and together they coalesce to form a richly annotated corpus that can be used to study the interactions between different levels of linguistic description. The evaluation gives an indication of the expected quality of a corpus created by students with relatively little training. A multifactorial example study on lexical NP coreference likelihood is also presented, which illustrates some applications of the corpus. The results of this project show that high quality, richly annotated resources can be created effectively as part of a linguistics curriculum, opening new possibilities not just for research, but also for corpora in linguistics pedagogy.'},\n",
       " '10.3758/BF03193020': {'title': 'Extracting semantic representations from word co-occurrence statistics: A computational study',\n",
       "  'abstract': 'The idea that at least some aspects of word meaning can be induced from patterns of word co-occurrence is becoming increasingly popular. However, there is less agreement about the precise computations involved, and the appropriate tests to distinguish between the various possibilities. It is important that the effect of the relevant design choices and parameter values are understood if psychological models using these methods are to be reliably evaluated and compared. In this article, we present a systematic exploration of the principal computational possibilities for formulating and validating representations of word meanings from word co-occurrence statistics. We find that, once we have identified the best procedures, a very simple approach is surprisingly successful and robust over a range of psychologically relevant evaluation measures.'},\n",
       " '10.1007/978-3-319-14206-7_3': {'title': 'PartTUT: The Turin University Parallel Treebank',\n",
       "  'abstract': 'In this paper, we introduce an ongoing project for the development of a parallel treebank for Italian, English and French. The treebank is annotated in a dependency format, namely the one designed in the Turin University Treebank (TUT), hence the choice to call such new resource Par(allel)TUT. The project aims at creating a resource which can be useful in particular for translation research. Therefore, beyond constantly enriching the treebank with new and heterogeneous data, so as to build a dynamic and balanced multilingual treebank, the current stage of the project is devoted to the design of a tool for the alignment of data, which takes into account syntactic knowledge as annotated in this kind of resource. The paper focuses in particular on the study of translational divergences and their implications for the development of the alignment tool. The paper provides an overview of the treebank, with its current content and the peculiarities of the annotation format, the description of the classes of translational divergences which could be encountered in the treebank, together with a proposal for their alignment.'},\n",
       " '10.1007/s10590-021-09284-y': {'title': 'Tag-less back-translation',\n",
       "  'abstract': 'An effective method to generate a large number of parallel sentences for training improved neural machine translation (NMT) systems is the use of the back-translations of the target-side monolingual data. The standard back-translation method has been shown to be unable to efficiently utilize the available huge amount of existing monolingual data because of the inability of translation models to differentiate between the authentic and synthetic parallel data during training. Tagging, or using gates, has been used to enable translation models to distinguish between synthetic and authentic data, improving standard back-translation and also enabling the use of iterative back-translation on language pairs that underperformed using standard back-translation. In this work, we approach back-translation as a domain adaptation problem, eliminating the need for explicit tagging. In the approach -- \\\\emph{tag-less back-translation} -- the synthetic and authentic parallel data are treated as out-of-domain and in-domain data respectively and, through pre-training and fine-tuning, the translation model is shown to be able to learn more efficiently from them during training. Experimental results have shown that the approach outperforms the standard and tagged back-translation approaches on low resource English-Vietnamese and English-German neural machine translation.'},\n",
       " '10.1016/j.neucom.2018.12.032': {'title': 'Effectively training neural machine translation models with monolingual data',\n",
       "  'abstract': 'Improving neural machine translation models (NMT) with monolingual data has aroused more and more interests in this area and back-translation for monolingual data augmentation Sennrich et al. (2016) has been taken as a promising development recently. While the naive back-translation approach improves the translation performance substantially, we notice that its usage for monolingual data is not so effective because traditional NMT models make no distinction between the true parallel corpus and the back translated synthetic parallel corpus. This paper proposes a gate-enhanced NMT model which makes use of monolingual data more effectively. The central idea is to separate the data flow of monolingual data and parallel data into different channels by the elegant designed gate, which enables the model to perform different transformations according to the type of the input sequence, i.e., monolingual data and parallel data. Experiments on Chinese-English and English-German translation tasks show that our approach achieves substantial improvements over strong baselines and the gate-enhanced NMT model can utilize the source-side and target-side monolingual data at the same time.'},\n",
       " '10.1016/j.csl.2017.01.014': {'title': 'On integrating a language model into neural machine translation',\n",
       "  'abstract': 'Recent advances in end-to-end neural machine translation models have achieved promising results on high-resource language pairs such as En→ Fr and En→ De. One of the major factor behind these successes is the availability of high quality parallel corpora. We explore two strategies on leveraging abundant amount of monolingual data for neural machine translation. We observe improvements by both combining scores from neural language model trained only on target monolingual data with neural machine translation model and fusing hidden-states of these two models. We obtain up to 2 BLEU improvement over hierarchical and phrase-based baseline on low-resource language pair, Turkish→ English. Our method was initially motivated towards tasks with less parallel data, but we also show that it extends to high resource languages such as Cs→ En and De→ En translation tasks, where we obtain 0.39 and 0.47 BLEU improvements over the neural machine translation baselines, respectively.'},\n",
       " '10.1016/j.jisa.2022.103199': {'title': 'Context-Aware Ontology-based Security Measurement Model',\n",
       "  'abstract': 'Security measurement models (SMMs) and quantitative security metrics (QSMs) are crucial pillars of systematic security measurement. How to design the enhanced SMMs and effective QSMs has been seriously considered in recent years. However, to the best of our knowledge, a desirable SMM has not yet been provided to measure the security effectiveness of a national-level network (NLN) due to its specific attributes. NLN has three main attributes, including plurality and diversity of network components, continuous changes, and simultaneous functionalities. These attributes cause three major challenges to designing a desirable SMM for NLN, including complexity, dynamic measurement, and multidimensionality. Hence, a desirable SMM for NLN should fulfill five desirability criteria to overcome the challenges, including simplicity, dynamics, comprehensiveness, scalability, and simultaneous overall and granular measurement. Considering the comparison of SMMs, such a desirable model should exclusively be a context-aware ontology-based SMM (CAO-SMM). In this paper, we propose a three layers CAO-SMM in which a comprehensive set of contextual dynamic QSMs are embedded. Our proposed SMM measures the security effectiveness component of network security situation relying on three indices: (1) deterrence against threats; (2) resiliency versus attacks; (3) survivability to impacts. First, an ontology-based SMM is designed. Then, the context-awareness feature is embedded to turn it into a CAO-SMM. Eventually, the desirability of our proposed CAO-SMM and its embedded QSMs are evaluated. CAO-SMM desirability along with the comprehensive coverage and distribution of its embedded QSMs enable us to precisely measure the security effectiveness across the whole network and its contextual components, including the network functionalities.'},\n",
       " '10.1007/978-3-030-86523-8_39': {'title': 'Augmenting Open-Domain Event Detection with Synthetic Data from GPT-2',\n",
       "  'abstract': 'Open-domain event detection (ODED) aims to identify event mentions of all possible types in text. A challenge for ODED research is the lack of large training datasets. In this work, we explore a novel method to overcome this challenge by fine-tuning the powerful pre-trained language model GPT-2 on existing datasets to automatically generate new training data for ODED. To address the noises presented in the generated data, we propose a novel teacher-student architecture where the teacher model is used to capture anchor knowledge on sentence representations and data type difference. The student model is then trained on the combination of the original and generated data and regularized to be consistent with the anchor knowledge from the teacher. We introduce novel regularization mechanism based on mutual information and optimal transport to achieve the knowledge consistency between the student and the teacher. Moreover, we propose a dynamic sample weighting technique for the generated examples based on optimal transport and data clustering. Our experiments on three benchmark datasets demonstrate the effectiveness of the propped model, yielding state-of-the-art performance for such datasets.'},\n",
       " '10.1016/J.IPM.2018.03.001': {'title': 'Real-time event detection from the Twitter data stream using the TwitterNews+ Framework',\n",
       "  'abstract': 'Detecting events in real-time from the Twitter data stream has gained substantial attention in recent years from researchers around the world. Different event detection approaches have been proposed as a result of these research efforts. One of the major challenges faced in this context is the high computational cost associated with event detection in real-time. We propose, TwitterNews+, an event detection system that incorporates specialized inverted indices and an incremental clustering approach to provide a low computational cost solution to detect both major and minor newsworthy events in real-time from the Twitter data stream. In addition, we conduct an extensive parameter sensitivity analysis to fine-tune the parameters used in TwitterNews+ to achieve the best performance. Finally, we evaluate the effectiveness of our system using a publicly available corpus as a benchmark dataset. The results of the evaluation show a significant improvement in terms of recall and precision over five state-of-the-art baselines we have used.'},\n",
       " '10.1016/J.ENG.2021.03.023': {'title': 'Progress in Machine Translation',\n",
       "  'abstract': 'After more than 70 years of evolution, great achievements have been made in machine translation. Especially in recent years, translation quality has been greatly improved with the emergence of neural machine translation (NMT). In this article, we first review the history of machine translation from rule-based machine translation to example-based machine translation and statistical machine translation. We then introduce NMT in more detail, including the basic framework and the current dominant framework, Transformer, as well as multilingual translation models to deal with the data sparseness problem. In addition, we introduce cutting-edge simultaneous translation methods that achieve a balance between translation quality and latency. We then describe various products and applications of machine translation. At the end of this article, we briefly discuss challenges and future research directions in this field.'},\n",
       " '10.1007/978-3-030-58621-8_45': {'title': 'Contrastive Multiview Coding',\n",
       "  'abstract': 'Humans view the world through many sensory channels, e.g., the long-wavelength light channel, viewed by the left eye, or the high-frequency vibrations channel, heard by the right ear. Each view is noisy and incomplete, but important factors, such as physics, geometry, and semantics, tend to be shared between all views (e.g., a “dog” can be seen, heard, and felt). We investigate the classic hypothesis that a powerful representation is one that models view-invariant factors. We study this hypothesis under the framework of multiview contrastive learning, where we learn a representation that aims to maximize mutual information between different views of the same scene but is otherwise compact. Our approach scales to any number of views, and is view-agnostic. We analyze key properties of the approach that make it work, finding that the contrastive loss outperforms a popular alternative based on cross-view prediction, and that the more views we learn from, the better the resulting representation captures underlying scene semantics. Code is available at: http://github.com/HobbitLong/CMC/ .'},\n",
       " '10.1016/j.tics.2007.05.005': {'title': 'The proactive brain: using analogies and associations to generate predictions',\n",
       "  'abstract': \"Rather than passively ‘waiting’ to be activated by sensations, it is proposed that the human brain is continuously busy generating predictions that approximate the relevant future. Building on previous work, this proposal posits that rudimentary information is extracted rapidly from the input to derive analogies linking that input with representations in memory. The linked stored representations then activate the associations that are relevant in the specific context, which provides focused predictions. These predictions facilitate perception and cognition by pre-sensitizing relevant representations. Predictions regarding complex information, such as those required in social interactions, integrate multiple analogies. This cognitive neuroscience framework can help explain a variety of phenomena, ranging from recognition to first impressions, and from the brain's ‘default mode’ to a host of mental disorders. Rather than passively ‘waiting’ to be activated by sensations, it is proposed that the human brain is continuously busy generating predictions that approximate the relevant future. Building on previous work, this proposal posits that rudimentary information is extracted rapidly from the input to derive analogies linking that input with representations in memory. The linked stored representations then activate the associations that are relevant in the specific context, which provides focused predictions. These predictions facilitate perception and cognition by pre-sensitizing relevant representations. Predictions regarding complex information, such as those required in social interactions, integrate multiple analogies. This cognitive neuroscience framework can help explain a variety of phenomena, ranging from recognition to first impressions, and from the brain's ‘default mode’ to a host of mental disorders. When we are immersed in the world of neuroscience findings, the brain might seem like a collection of many little modules, each expert in a specific task. Is it possible that, instead, one can account for much of the brain's operation using a small set of unifying principles? One such principle could be that the brain is proactive in that it regularly anticipates the future, a proposal that has been promoted in the past in different forms and contexts. Specifically, I propose that the cognitive brain relies on memory-based predictions, and these predictions are generated continually either based on gist information gleaned from the senses or driven by thought. The emphasis in this proposal is on the analogical link to memory and the role of associations in predictions, as well as on the idea that we use rudimentary information to generate these predictions efficiently. Furthermore, by developing this framework using a cognitive neuroscience approach and a minimalistic terminology, key concepts can directly be tested and used in empirical and theoretical future research. The proposed account integrates three primary components. The first is associations, which are formed by a lifetime of extracting repeating patterns and statistical regularities from our environment, and storing them in memory. The second is the concept of analogies, whereby we seek correspondence between a novel input and existing representations in memory (e.g. ‘what does this look like?’). Finally, these analogies activate associated representations that translate into predictions (Figure 1). Each of these key components – associations, analogies and predictions – has been the focus of rich and active research for a long time. By connecting these concepts in one unifying principle of memory-based predictions, the framework proposed here builds on this valuable background to emphasize the functional coherence between the three processes. To make the underlying mechanism more explicit, I will elaborate on each of the elements that mediate the generation of predictions. I will start with the proposal that the foundation of predictions is provided by the associative nature of memory organization. How does our experience translate into focused, testable predictions? The answer proposed is that memory is used to generate predictions via associative activation. In memory, our experiences are represented in structures that cluster together related information. For example, objects that tend to appear together are linked on some level, and these representations include properties that are inherent to and typical of that same experience. Such structures have been termed ‘context frames’ [1Bar M. Ullman S. Spatial context in recognition.Perception. 1996; 25: 343-352Crossref PubMed Scopus (168) Google Scholar, 2Bar M. Visual objects in context.Nat. Rev. Neurosci. 2004; 5: 617-629Crossref PubMed Scopus (1118) Google Scholar], which are reminiscent of earlier concepts such as schemata [3Mandler J.M. Johnson N.S. Some of the thousand words a picture is worth.J. Exp. Psychol. [Hum Learn]. 1976; 2: 529-540Crossref PubMed Scopus (113) Google Scholar], scripts [4Schank R.C. Using knowledge to understand.in: Schank R.C. Nash-Weber B. Theoretical Issues in Natural Language Processing. Tinlap Press, 1975: 117-121Google Scholar] and frames [5Minsky M. A framework for representing knowledge.in: Winston P.H. The Psychology of Computer Vision. McGraw-Hill, 1975: 211-277Google Scholar], which all imply a unified, global representation of perceptual and semantic associated attributes. The structure of these context frames enables co-activations that prime our subsequent perception, cognition and action by remaining ‘on-line’ and making available predictions of what to expect in the immediate environment. For example, placing a picture of a certain recognizable object next to an ambiguous object can make that object recognizable if it looks like something familiar that is contextually congruent with the clear object (i.e. an analogy) [1Bar M. Ullman S. Spatial context in recognition.Perception. 1996; 25: 343-352Crossref PubMed Scopus (168) Google Scholar]. This principle operates similarly in other domains. For example, contextual framing has a direct influence on our judgments of the emotions of others [6Mobbs D. et al.The Kuleshov Effect: the influence of contextual framing on emotional attributions.Soc. Cogn. Affect. Neurosci. 2006; 1: 95-106Crossref PubMed Scopus (100) Google Scholar]. Taken together, the associative nature of memory makes it possible to take advantage of frequent trends in the environment to help interpret and anticipate immediate and future events. One basis for this proposal is provided by the literature on priming, with its various types (e.g. perceptual, semantic and contextual). These studies support the idea that the perception of a certain stimulus co-activates the representations of related items [7Anderson J.R. Architecture of Cognition. Harvard University Press, 1983Google Scholar], although these items have not been experienced as part of the present physical environment. Indeed, recent neuroimaging studies demonstrate the involvement of associative predictions in cognitive facilitation [2Bar M. Visual objects in context.Nat. Rev. Neurosci. 2004; 5: 617-629Crossref PubMed Scopus (1118) Google Scholar]. The proposal promoted here is that the brain is continually engaged in generating predictions, and that these predictions rely on associative activation. Taken together, it is important to demonstrate that the brain is frequently busy with associative processing, an idea dating back to Plato, Aristotle, Hobbes and the Empiricists. Support for this idea comes from a recent link we have made [8Bar M. et al.The units of thought.Hippocampus. 2007; 17: 420-428Crossref PubMed Scopus (141) Google Scholar] between the neural underpinnings of associative processing and reports regarding the cortical activation that is considered to reflect the brain's ‘default’ mode [9Raichle M.E. et al.A default mode of brain function.Proc. Natl. Acad. Sci. U. S. A. 2001; 98: 676-682Crossref PubMed Scopus (9408) Google Scholar]. Specifically, we showed that significant parts of the default network, which refers to the collection of brain regions that are consistently activated when subjects are not engaged in a task-specific cognitive effort, overlap with the regions activated by tasks that recruit associative processing [8Bar M. et al.The units of thought.Hippocampus. 2007; 17: 420-428Crossref PubMed Scopus (141) Google Scholar] (Box 1). This remarkable overlap between the default network and activity attributable to contextual associative processing demonstrates that what people do when their mental capacity is not completely consumed by a specific task is to generate associations. In other words, associative activation is an integral process of the brain's mental ‘default’ mode. Given the proposal that predictions are derived from associations, this overlap is in agreement with the idea of a continuous generation of predictions.Box 1The brain's ‘default’ mode and associative processingA collection of cortical regions is consistently active when human subjects are not engaged in a goal-directed behavior. This network has been termed the ‘default network’ [9Raichle M.E. et al.A default mode of brain function.Proc. Natl. Acad. Sci. U. S. A. 2001; 98: 676-682Crossref PubMed Scopus (9408) Google Scholar], and is currently drawing a large amount of attention.The primary method of considering neuroimaging data is to subtract the signal elicited by one condition from the signal elicited by another condition. To look at the main effect of a single condition – how did this condition affect activity in the brain – one typically uses a ‘baseline’ condition in which a fixation cross is presented. The implicit assumption in the many studies that have used this method was that the brain uses these fixation intervals for resting. However, increasingly more imaging studies are reporting negative activations (‘deactivations’) when one condition is compared with the fixation ‘baseline’. Regions that demonstrate such deactivation are taken to have been more active during the fixation baseline then during the compared experimental condition, although what are the cognitive processes that are carried out by this network during rest is still unclear. This default network is remarkably similar, in its medial view, to the network activated by contextual associations (Figure I) [8Bar M. et al.The units of thought.Hippocampus. 2007; 17: 420-428Crossref PubMed Scopus (141) Google Scholar], supporting the proposal put forward here that the brain is continually engaged in the generation of associations-based predictions. A collection of cortical regions is consistently active when human subjects are not engaged in a goal-directed behavior. This network has been termed the ‘default network’ [9Raichle M.E. et al.A default mode of brain function.Proc. Natl. Acad. Sci. U. S. A. 2001; 98: 676-682Crossref PubMed Scopus (9408) Google Scholar], and is currently drawing a large amount of attention. The primary method of considering neuroimaging data is to subtract the signal elicited by one condition from the signal elicited by another condition. To look at the main effect of a single condition – how did this condition affect activity in the brain – one typically uses a ‘baseline’ condition in which a fixation cross is presented. The implicit assumption in the many studies that have used this method was that the brain uses these fixation intervals for resting. However, increasingly more imaging studies are reporting negative activations (‘deactivations’) when one condition is compared with the fixation ‘baseline’. Regions that demonstrate such deactivation are taken to have been more active during the fixation baseline then during the compared experimental condition, although what are the cognitive processes that are carried out by this network during rest is still unclear. This default network is remarkably similar, in its medial view, to the network activated by contextual associations (Figure I) [8Bar M. et al.The units of thought.Hippocampus. 2007; 17: 420-428Crossref PubMed Scopus (141) Google Scholar], supporting the proposal put forward here that the brain is continually engaged in the generation of associations-based predictions. Associations, therefore, provide the representational tool used for predictions. In the next section I will consider the mechanism that activates these associations, and how it does so most effectively such that only the associations and predictions that are most relevant and most helpful for a given situation are activated. I propose that our brains are equipped with the ability to extract gist, minimally analyzed information, from a situation and to use it to derive an analogy, mapping the novel input to similar representations in memory. Figure 2 depicts a simple example, where a new exemplar of a certain object class is analogically mapped to the corresponding prototype, and in Box 2 I describe a model of how such an analogy can be accomplished rapidly using coarse information.Box 2Top-down facilitation based on rudimentary informationIn the framework outlined here, the activation of a memory representation based on a sensory or internally generated input is a process of analogical mapping. A central question is how gist information, how ever defined, can be sufficient for mapping the input onto an analogous memory. One model (Figure I), from object recognition, postulates that rudimentary information in the image (i.e. low spatial frequencies), which is extracted rapidly, is sufficiently powerful to activate expectations about what the observed object might be [14Bar M. et al.Top-down facilitation of visual recognition.Proc. Natl. Acad. Sci. U. S. A. 2006; 103: 449-454Crossref PubMed Scopus (1159) Google Scholar, 75Bar M. A cortical mechanism for triggering top-down facilitation in visual object recognition.J. Cogn. Neurosci. 2003; 15: 600-609Crossref PubMed Scopus (700) Google Scholar]. A similar mechanism is proposed to be operating on multiple levels, although the representation of gist information on higher levels of analysis is yet to be defined (see Concluding remarks section). Note that the gist-based initial guess could elicit more than a single alternative. This ambiguity is resolved gradually as high-spatial frequencies arrive with the bottom-up streams. But it can also be resolved more quickly by incorporating other rapidly extracted sources of information, such as context [2Bar M. Visual objects in context.Nat. Rev. Neurosci. 2004; 5: 617-629Crossref PubMed Scopus (1118) Google Scholar], which would fine-tune this analogical mapping to have fewer alternatives and, thus, less ambiguity.Figure IA top-down facilitation model. A partially processed, low spatial frequency (LSF) image of the visual input is rapidly projected to OFC from the early visual cortex and/or from subcortical structures such as the amygdala, while detailed, slower analysis of the visual input is being performed along the ventral visual stream. This ‘gist’ image activates predictions about candidate objects that are similar to the image in their LSF appearance, which are fed back to the ventral object recognition regions to facilitate bottom-up processing. Reproduced with permission from Ref. [14Bar M. et al.Top-down facilitation of visual recognition.Proc. Natl. Acad. Sci. U. S. A. 2006; 103: 449-454Crossref PubMed Scopus (1159) Google Scholar].View Large Image Figure ViewerDownload (PPT) In the framework outlined here, the activation of a memory representation based on a sensory or internally generated input is a process of analogical mapping. A central question is how gist information, how ever defined, can be sufficient for mapping the input onto an analogous memory. One model (Figure I), from object recognition, postulates that rudimentary information in the image (i.e. low spatial frequencies), which is extracted rapidly, is sufficiently powerful to activate expectations about what the observed object might be [14Bar M. et al.Top-down facilitation of visual recognition.Proc. Natl. Acad. Sci. U. S. A. 2006; 103: 449-454Crossref PubMed Scopus (1159) Google Scholar, 75Bar M. A cortical mechanism for triggering top-down facilitation in visual object recognition.J. Cogn. Neurosci. 2003; 15: 600-609Crossref PubMed Scopus (700) Google Scholar]. A similar mechanism is proposed to be operating on multiple levels, although the representation of gist information on higher levels of analysis is yet to be defined (see Concluding remarks section). Note that the gist-based initial guess could elicit more than a single alternative. This ambiguity is resolved gradually as high-spatial frequencies arrive with the bottom-up streams. But it can also be resolved more quickly by incorporating other rapidly extracted sources of information, such as context [2Bar M. Visual objects in context.Nat. Rev. Neurosci. 2004; 5: 617-629Crossref PubMed Scopus (1118) Google Scholar], which would fine-tune this analogical mapping to have fewer alternatives and, thus, less ambiguity. Traditionally this process has been considered as recognition, classification, or even a type of memory retrieval, but in the present context I treat this process as analogy-making instead. In the process of recognition or retrieval, the task is to answer the ‘what is it?’ question, whereas, in analogy, the emphasis is on ‘what is it like?’ In other words, although it might seem like an issue of terminology, in recognition per se we recognize by linking to memory to interpret the input, whereas in analogy the input is linked to memory not only for the sake of interpretation, but also for the purpose of projecting attributes and generating predictions. Therefore, by using the term analogy, the emphasis is placed on the associations-based predictions that analogies elicit beyond mere recognition, and it is this extra step that is the focus of the proposed framework. Nevertheless, analogical mapping still serves to interpret the input: inferring what physical input caused a certain percept, an issue that has received a lot of attention [10Friston K. A theory of cortical responses.Philos. Trans. R. Soc. Lond. B Biol. Sci. 2005; 360: 815-836Crossref PubMed Scopus (2672) Google Scholar, 11French R.M. The computational modeling of analogy-making.Trends Cogn. Sci. 2002; 6: 200-205Abstract Full Text Full Text PDF PubMed Scopus (107) Google Scholar, 12Hummel J.E. Holyoak K.J. A symbolic-connectionist theory of relational inference and generalization.Psychol. Rev. 2003; 110: 220-264Crossref PubMed Scopus (379) Google Scholar]. Therefore, the analogy itself also provides an important top-down prediction regarding the identity of the input using initial bottom-up information [13Rao R.P. Ballard D.H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects.Nat. Neurosci. 1999; 2: 79-87Crossref PubMed Scopus (3012) Google Scholar, 14Bar M. et al.Top-down facilitation of visual recognition.Proc. Natl. Acad. Sci. U. S. A. 2006; 103: 449-454Crossref PubMed Scopus (1159) Google Scholar] (Box 2). However, the focus here is on the considerably less explored type of predictions: forecasting that pertains to what is about to happen, what is likely to appear in the same context, and what is the most beneficial action that needs to be taken given the specific input. In other words, the analogy in Figure 2 mediates interpretation, by linking input to memory, whereas forecasting predictions stem from the subsequent activation of information associated with that analogy (e.g. Figure 3). This principle is not limited to the realm of visual recognition, but rather encompasses a wide variety of domains where input can be linked to memory to generate predictions. For example, imagine meeting a new person. Our first impressions are rapid [15Bar M. et al.Very first impressions.Emotion. 2006; 6: 269-278Crossref PubMed Scopus (470) Google Scholar, 16Willis J. Todorov A. First impressions: making up your mind after a 100-ms exposure to a face.Psychol. Sci. 2006; 17: 592-598Crossref PubMed Scopus (1572) Google Scholar] and are based on rapidly extracted coarse information [15Bar M. et al.Very first impressions.Emotion. 2006; 6: 269-278Crossref PubMed Scopus (470) Google Scholar]. According to the present proposal, this process is mediated by linking the features of the new person to the most similar representation in memory; someone we know and that looks to some extent like this new person. We automatically project information such as personality attributes to the new person based simply on this analogy. Although this analogy is an approximated set of traits, it might be beneficial, at least under some circumstances, to not start interactions without any assumptions on that new person. Analogies can be based on similarity on various levels, including perceptual similarity (e.g. in shape or smell), abstract conceptual dimensions, and goals [12Hummel J.E. Holyoak K.J. A symbolic-connectionist theory of relational inference and generalization.Psychol. Rev. 2003; 110: 220-264Crossref PubMed Scopus (379) Google Scholar]. Analogy-based mappings of properties manifest themselves in processes ranging from perception and memory [17Song J.H. Jiang Y. Connecting the past with the present: how do humans match an incoming visual display with visual memory?.J. Vis. 2005; 5: 322-330Crossref PubMed Scopus (29) Google Scholar] to stereotypic judgments and prejudice [18Devine P.G. Stereotypes and prejudices: their automatic and controlled components.J. Pers. Soc. Psychol. 1989; 56: 5-18Crossref Scopus (3991) Google Scholar]. It is important to note that the input is rarely mapped with a single analogy directly to memory. Instead, the function of analogies can be based on the integration of multiple analogies that accumulate to complex mapping. For example, if you are trying to understand a conversation that is taking place on a screen when watching a new movie, you will have to map novel sounds to similar and familiar sounds in memory (which will then be connected with their associated linguistic meaning), to map the novel face appearances to similar and familiar face expressions (which will then be connected with the intentions associated with them), the context in which the conversation is taking place will be mapped to other similar contexts in memory and, when combined, these analogies can help map the complete, new situation to a collection of fragments in memory that together can allow you to understand the scene, and to forecast what is likely to be next. While our existing memories are used to derive analogies and activate predictions, they are constantly being updated. The analogical process, in addition to affording the interpretation of our environment, subsequently augments previous representations in a way that fosters increasingly flexible future analogies. Finally, the activation of associations for prediction will not be as useful if it simply activates automatically all the information associated with the linked representation(s) in memory. Instead, it needs to take into account the context in which this input is encountered, and selectively activate the most relevant associations [2Bar M. Visual objects in context.Nat. Rev. Neurosci. 2004; 5: 617-629Crossref PubMed Scopus (1118) Google Scholar]. For example, an object such as a hairdryer can be naturally encountered in several possible contexts: hair-salon, appliance store, bathroom, as well as associated with abstract contexts (Figure 3). If the hairdryer is encountered in the hair-salon context, there is no need to activate objects that are typically found in bathrooms and appliance stores, which would not only be wasteful but also generate incorrect predictions. By taking context cues into account, this switchboard-like mechanism will only activate the most relevant associations, which will result in the generation of the most accurate predictions. To summarize, analogies map novel inputs to representations in memory that most resemble this input. Subsequently, information associated with these representations is activated to provide predictions about what else might be expected in the same situation. By taking context into account in this associative activation, only the most relevant predictions are generated. In the next section I will describe possible neural underpinnings for associations, analogies and predictions. Many cortical projections that connect separate regions are known to be reciprocal [19Pandya D.N. Anatomy of the auditory cortex.Rev. Neurol. (Paris). 1995; 151: 486-494PubMed Google Scholar, 20Ghashghaei H.T. et al.Sequence of information processing for emotions based on the anatomic dialogue between prefrontal cortex and amygdala.Neuroimage. 2007; 34: 905-923Crossref PubMed Scopus (643) Google Scholar, 21Rockland K.S. Drash G.W. Collateralized divergent feedback connections that target multiple cortical areas.J. Comp. Neurol. 1996; 373: 529-548Crossref PubMed Scopus (57) Google Scholar, 22Ergenzinger E.R. et al.Cortically induced thalamic plasticity in the primate somatosensory system.Nat. Neurosci. 1998; 1: 226-229Crossref PubMed Scopus (133) Google Scholar], which suggests bi-directional cortical communication. According to some estimates, the number of feedback (top-down) projections might even exceed the number of feedforward (bottom-up) connections [23Salin P.A. Bullier J. Corticocortical connections in the visual system: structure and function.Physiol. Rev. 1995; 75: 107-154Crossref PubMed Scopus (478) Google Scholar]. Although this aspect of the anatomy is known, and the implication of omnipresent bi-directional flow consequently seems highly reasonable, this finding has not yet been sufficiently incorporated into contemporary thinking regarding cognitive processing. However, this ‘provocative’ anatomy implies something profound about how the brain works. Specifically, the reciprocal connections might provide the infrastructure that supports the continuous top-down involvement of internal representations with the interpretation of the world around us. There are three main components in this proposal: associations, analogies and predictions, and they interact with each other regularly. Associations have largely been found in the medial temporal lobe (MTL), in the hippocampus [24Eichenbaum H. A cortical-hippocampal system for declarative memory.Nat. Rev. Neurosci. 2000; 1: 41-50Crossref PubMed Scopus (1211) Google Scholar, 25Ranganath C. et al.Inferior temporal, prefrontal, and hippocampal contributions to visual working memory maintenance and associative memory retrieval.J. Neurosci. 2004; 24: 3917-3925Crossref PubMed Scopus (283) Google Scholar], and in the parahippocampal cortex (PHC) [26Aminoff E. et al.The parahippocampal cortex mediates spatial and nonspatial associations.Cereb. Cortex. 2006; https://doi.org/10.1093/cercor/bhl078Crossref PubMed Scopus (266) Google Scholar]. As reviewed above with regard to the overlap seen between associative processing and the default network, other medial regions, such as the medial prefrontal cortex (MPFC) and medial parietal cortex (MPC) are involved as well. Given the diverse types of possible associations, it is indeed expected that they will be mediated by a large collection of regions, depending on complexity, modality and purpose. For example, other types of associations, such as visuomotor associations, seem to be represented in other regions, such the basal ganglia. The brain regions that mediate analogical thinking are much less explored. Nevertheless, some types of analogical thinking have been found to activate the lateral and medial PFC [27Bunge S.A. et al.Analogical reasoning and prefrontal cortex: evidence for separable retrieval and integration mechanisms.Cereb. Cortex. 2005; 15: 239-249Crossref PubMed Scopus (286) Google Scholar, 28Waltz J.A. et al.The role of working memory in analogical mapping.Mem. Cognit. 2000; 28: 1205-1212Crossref PubMed Scopus (119) Google Scholar]. Regarding the neural regions that mediate predictions, there are multiple sub-processes that need to be considered: the generation of predictions, their verification, and their updating. Expectations-based preparatory activation has been observed in numerous domains. For example, anticipating a somatosensory stimulus activates the somatosensory cortex [29Carlsson K. et al.Tickling expectations: neural processing in anticipation of a sensory stimulus.J. Cogn. Neurosci. 2000; 12: 691-703Crossref PubMed Scopus (163) Google Scholar]; pictures of food activate gustatory cortices [30Simmons W.K. et al.Pictures of appetizing foods activate gustatory cortices for taste and reward.Cereb. Cortex. 2005; 15: 1602-1608Crossref PubMed Scopus (428) Google Scholar]; visual imagery, even if not in a directly predictive task, activates the visual cortex, and has even been shown to activate early visual cortex in a retinotopically organized manner [31Slotnick S.D. et al.Visual mental imagery induces retinotopically organized activation of early visual areas.Cereb. Cortex. 2005; 15: 1570-1583Crossref PubMed Scopus (256) Google Scholar]. We have previously proposed a neural mechanism in the domain of context-based predictions and visual recognition [2Bar M. Visual objects in context.Nat. Rev. Neurosci. 2004; 5: 617-629Crossref PubMed Scopus (1118) Google Scholar, 14Bar M. et al.Top-down facilitation of visual recognition.Proc. Natl. Acad. Sci. U. S. A. 2006; 103: 449-454Crossref PubMed Scopus (1159) Google Scholar, 36Bar M. Aminoff E. Cortical analysis of visual context.Neuron. 2003; 38: 347-358Abstract Full Text Full Text PDF PubMed Scopus (491) Google Scholar]. Briefly, the associations relevant to the present discussio\"},\n",
       " '10.1016/0306-4522(83)90010-6': {'title': 'Temporal contiguity requirements for long-term associative potentiation/depression in the hippocampus',\n",
       "  'abstract': 'A previous study utilizing the powerful ipsilateral and weak crossed projection from the entorhinal cortex to the dentate gyrus in the rat revealed that long-term potentiation is an associative process in these systems. If the weak crossed projection alone receives potentiating stimulation consisting of 8 high-frequency trains 17.5 ms in duration, it does not exhibit long-term potentiation. However, long-term potentiation can be induced in the crossed projection if it is activated concurrently with the converging ipsilateral system. The present study is designed to determine the degree of synchrony required for the associative interactions by varying the timing and order of the potentiating trains delivered to the two converging systems. The associative induction of long-term potentiation does not require perfectly synchronous activation of the converging systems. The order of the trains is crucial, however. Long-term potentiation of the crossed projection can be induced if activity in the ipsilateral system is concurrent with or follows activity in the crossed projection. Indeed, there can be as much as 20ms between the 17.5ms trains in the two systems, and long-term potentiation of the crossed projection is still induced. Activation of the ipsilateral system that precedes activation of the crossed system depresses the responses evoked by the crossed system. If potentiating stimulation of the ipsilateral system follows activation of the crossed projection by too long an interval (200 ms, for example), then the crossed projection is depressed rather than potentiated. These results are discussed with regard to the nature of the associative process permissive for the induction of long-term potentiation and lead us to the conclusion that perfect temporal contiguity is not a requirement of this prototypical elemental memory unit.'},\n",
       " '10.1016/0010-0285(73)90033-9': {'title': 'Availability: A heuristic for judging frequency and probability',\n",
       "  'abstract': 'This paper explores a judgmental heuristic in which a person evaluates the frequency of classes or the probability of events by availability, i.e., by the ease with which relevant instances come to mind. In general, availability is correlated with ecological frequency, but it is also affected by other factors. Consequently, the reliance on the availability heuristic leads to systematic biases. Such biases are demonstrated in the judged frequency of classes of words, of combinatorial outcomes, and of repeated events. The phenomenon of illusory correlation is explained as an availability bias. The effects of the availability of incidents and scenarios on subjective probability are discussed.'},\n",
       " '10.1016/j.ins.2022.07.178': {'title': 'DA-Net: Dual-attention network for multivariate time series classification',\n",
       "  'abstract': 'Multivariate time series classification is one of the increasingly important issues in machine learning. Existing methods focus on establishing the global long-range dependencies or discovering the local critical sequence fragments. However, they often ignore the combined information from both global and local features. In this paper, we propose a novel network (called DA-Net) based on dual attention to mine the local–global features for multivariate time series classification. Specifically, DA-Net consists of two distinctive layers, i.e., the Squeeze-Excitation Window Attention (SEWA) layer and the Sparse Self-Attention within Windows (SSAW) layer. For the SEWA layer, we capture the local window-wise information by explicitly establishing window dependencies to prioritize critical windows. For the SSAW layer, we preserve rich activate scores with less computation to widen the window scope for capturing global long-range dependencies. Based on the two elaborated layers, DA-Net can mine critical local sequence fragments in the process of establishing global long-range dependencies. The experimental results show that DA-Net is able to achieve competing performance with state-of-the-art approaches on the multivariate time series classification.'},\n",
       " '10.1016/J.IPM.2019.102067': {'title': 'A Deep Look into neural ranking models for information retrieval',\n",
       "  'abstract': 'Ranking models lie at the heart of research on information retrieval (IR). During the past decades, different techniques have been proposed for constructing ranking models, from traditional heuristic methods, probabilistic methods, to modern machine learning methods. Recently, with the advance of deep learning technology, we have witnessed a growing body of work in applying shallow or deep neural networks to the ranking problem in IR, referred to as neural ranking models in this paper. The power of neural ranking models lies in the ability to learn from the raw text inputs for the ranking problem to avoid many limitations of hand-crafted features. Neural networks have sufficient capacity to model complicated tasks, which is needed to handle the complexity of relevance estimation in ranking. Since there have been a large variety of neural ranking models proposed, we believe it is the right time to summarize the current status, learn from existing methodologies, and gain some insights for future development. In contrast to existing reviews, in this survey, we will take a deep look into the neural ranking models from different dimensions to analyze their underlying assumptions, major design principles, and learning strategies. We compare these models through benchmark tasks to obtain a comprehensive empirical understanding of the existing techniques. We will also discuss what is missing in the current literature and what are the promising and desired future directions.'},\n",
       " '10.1007/978-3-319-24261-3_7': {'title': 'Deep Metric Learning Using Triplet Network',\n",
       "  'abstract': 'Deep learning has proven itself as a successful set of models for learning useful semantic representations of data. These, however, are mostly implicitly learned as part of a classification task. In this paper we propose the triplet network model, which aims to learn useful representations by distance comparisons. A similar model was defined by Wang et al. (2014), tailor made for learning a ranking for image information retrieval. Here we demonstrate using various datasets that our model learns a better representation than that of its immediate competitor, the Siamese network. We also discuss future possible usage as a framework for unsupervised learning.'},\n",
       " '10.1016/j.ipm.2005.03.023': {'title': 'Automatic ranking of information retrieval systems using data fusion',\n",
       "  'abstract': 'Measuring effectiveness of information retrieval (IR) systems is essential for research and development and for monitoring search quality in dynamic environments. In this study, we employ new methods for automatic ranking of retrieval systems. In these methods, we merge the retrieval results of multiple systems using various data fusion algorithms, use the top-ranked documents in the merged result as the “(pseudo) relevant documents,” and employ these documents to evaluate and rank the systems. Experiments using Text REtrieval Conference (TREC) data provide statistically significant strong correlations with human-based assessments of the same systems. We hypothesize that the selection of systems that would return documents different from the majority could eliminate the ordinary systems from data fusion and provide better discrimination among the documents and systems. This could improve the effectiveness of automatic ranking. Based on this intuition, we introduce a new method for the selection of systems to be used for data fusion. For this purpose, we use the bias concept that measures the deviation of a system from the norm or majority and employ the systems with higher bias in the data fusion process. This approach provides even higher correlations with the human-based results. We demonstrate that our approach outperforms the previously proposed automatic ranking methods.'},\n",
       " '10.1007/978-3-030-92310-5_67': {'title': 'Associated Lattice-BERT for Spoken Language Understanding',\n",
       "  'abstract': 'Lattices are compact representations that can encode multiple speech recognition hypotheses in spoken language understanding tasks. Previous work has extended the pre-trained transformer to model lattice inputs and achieved significant improvements in natural language processing tasks. However, these models do not consider the global probability distribution of lattices path and the correlation among multiple speech recognition hypotheses. In this paper, we propose an associated Lattice-BERT, an extension of BERT that is tailored for spoken language understanding (SLU). Associated Lattice-BERT augments self-attention with positional relation representations and lattice scores to incorporate lattice structure. We further design a lattice confusion-aware attention mechanism in the prediction layer to push the model to learn from the association information between the lattice confusion paths, which mitigates the impact of the Automatic Speech Recognizer (ASR) errors on the model. We apply the proposed model to a spoken language understanding task, the experiments on the datasets of intention detection recognition show that our proposed method outperforms the strong baselines when evaluated on spoken inputs.'},\n",
       " '10.1007/s10579-007-9040-x': {'title': 'Unleashing the killer corpus: experiences in creating the multi-everything AMI Meeting Corpus',\n",
       "  'abstract': 'The AMI Meeting Corpus contains 100 h of meetings captured using many synchronized recording devices, and is designed to support work in speech and video processing, language engineering, corpus linguistics, and organizational psychology. It has been transcribed orthographically, with annotated subsets for everything from named entities, dialogue acts, and summaries to simple gaze and head movement. In this written version of an LREC conference keynote address, I describe the data and how it was created. If this is “killer” data, that presupposes a platform that it will “sell”; in this case, that is the NITE XML Toolkit, which allows a distributed set of users to create, store, browse, and search annotations for the same base data that are both time-aligned against signal and related to each other structurally.'},\n",
       " '10.21437/INTERSPEECH.2016-618': {'title': 'TheanoLM — An Extensible Toolkit for Neural Network Language Modeling',\n",
       "  'abstract': 'We present a new tool for training neural network language models (NNLMs), scoring sentences, and generating text. The tool has been written using Python library Theano, which allows researcher to easily extend it and tune any aspect of the training process. Regardless of the flexibility, Theano is able to generate extremely fast native code that can utilize a GPU or multiple CPU cores in order to parallelize the heavy numerical computations. The tool has been evaluated in difficult Finnish and English conversational speech recognition tasks, and significant improvement was obtained over our best back-off n-gram models. The results that we obtained in the Finnish task were compared to those from existing RNNLM and RWTHLM toolkits, and found to be as good or better, while training times were an order of magnitude shorter.'},\n",
       " '10.1016/j.jcss.2007.04.015': {'title': 'Case-factor diagrams for structured probabilistic modeling',\n",
       "  'abstract': 'We introduce a probabilistic formalism handling both Markov random fields of bounded tree width and probabilistic context-free grammars. Our models are based on case-factor diagrams (CFDs) which are similar to binary decision diagrams (BDDs) but are more concise for circuits of bounded tree width. A probabilistic model consists of a CFD defining a feasible set of Boolean assignments and a weight (or cost) for each individual Boolean variable. We give versions of the inside–outside algorithm and the Viterbi algorithm for these models.'},\n",
       " '10.1016/S0019-9958(80)90285-5': {'title': 'Inductive inference of formal languages from positive data',\n",
       "  'abstract': 'We consider inductive inference of formal languages, as defined by Gold (1967), in the case of positive data, i.e., when the examples of a given formal language are successive elements of some arbitrary enumeration of the elements of the language. We prove a theorem characterizing when an indexed family of nonempty recursive formal languages is inferrable from positive data. From this theorem we obtain other useful conditions for inference from positive data, and give several examples of their application. We give counterexamples to two variants of the characterizing condition, and investigate conditions for inference from positive data that avoids \"overgeneralization.\"'},\n",
       " '10.1016/j.jmsy.2023.08.006': {'title': 'Knowledge graph-based manufacturing process planning: A state-of-the-art review',\n",
       "  'abstract': 'Computer-aided process planning is the bridge between computer-aided design and computer-aided manufacturing. With the advent of the intelligent manufacturing era, process knowledge is important for process planning. Knowledge graph is a semantic representation method of knowledge that has attracted extensive attention from the industry and academia. Process planning using the process knowledge graph has become an important development direction for computer-aided process planning. From the analysis of the published reviews, there have been many computer-aided process planning reviews with different focuses. We focus on the techniques and applications of knowledge graph in manufacturing process planning. Therefore, this paper comprehensively reviews knowledge graphs in manufacturing process planning. We analyze the key technologies of process knowledge graph, including process knowledge representation, process knowledge extraction, process knowledge graph construction, process knowledge graph refinement, process knowledge graph validation, and process generation. We also explore the combination of process knowledge graphs and large language models. Finally, potential future research directions are proposed.'},\n",
       " '10.1016/j.jbi.2021.103834': {'title': 'KeMRE: Knowledge-enhanced medical relation extraction for Chinese medicine instructions',\n",
       "  'abstract': 'Medicine instructions usually contain rich medical relations, and extracting them is very helpful for many downstream tasks such as medicine knowledge graph construction and medicine side-effect prediction. Existing relation extraction (RE) methods usually predict relations between entities from their contexts and do not consider medical knowledge. However, understanding a part of medical relations may need some expert knowledge in the medical field, making it challenging for existing methods to achieve satisfying performances of medical RE. In this paper, we propose a knowledge-enhanced framework for medical RE, which can exploit medical knowledge of medicines to better conduct medical RE on Chinese medicine instructions. We first propose a BERT-CNN-LSTM based framework for text modeling and learn representations of characters from their contexts. Then we learn representations of each entity by aggregating representations of their characters. Besides, we propose a CNN-LSTM based framework for entity modeling and learn entity representations from their relatedness. In addition, there are usually many different instructions for the same medicine, which usually share general knowledge on this medicine. Thus, to obtain medical knowledge of medicines, we annotate relations on a randomly-sampled instruction of each medicine. Then we build knowledge embeddings to represent potential relations between entities from knowledge of medicines. Finally, we use an MLP network to predict relations between entities from their representations and knowledge embeddings. Extensive experiments on a real-world dataset show that our method can significantly outperform existing methods.'},\n",
       " '10.1016/j.jbi.2018.05.001': {'title': 'An effective neural model extracting document level chemical-induced disease relations from biomedical literature',\n",
       "  'abstract': 'Since identifying relations between chemicals and diseases (CDR) are important for biomedical research and healthcare, the challenge proposed by BioCreative V requires automatically mining causal relationships between chemicals and diseases which may span sentence boundaries. Although most systems explore feature engineering and knowledge bases to recognize document level CDR relations, feature learning automatically is limited only in a sentence. In this work, we proposed an effective model that automatically learns document level semantic representations to extract chemical-induced disease (CID) relations from articles by combining advantages of convolutional neural network and recurrent neural network. First, to purposefully collect contexts, candidate entities existing in multiple sentences of an article were masked to make the model have ability to discern candidate entities and general terms. Next, considering the contiguity and temporality among associated sentences as well as the topic of an article, a hierarchical network architecture was designed at the document level to capture semantic information of different types of text segments in an article. Finally, a softmax classifier performed the CID recognition. Experimental results on the CDR corpus show that the proposed model achieves a good overall performance compared with other state-of-the-art methods. Although only using two types of embedding vectors, our approach can perform well for recognizing not only intra-sentential but also inter-sentential CID relations.'},\n",
       " '10.1007/978-3-030-00671-6_12': {'title': 'QA4IE: A Question Answering Based Framework for Information Extraction',\n",
       "  'abstract': 'Information Extraction (IE) refers to automatically extracting structured relation tuples from unstructured texts. Common IE solutions, including Relation Extraction (RE) and open IE systems, can hardly handle cross-sentence tuples, and are severely restricted by limited relation types as well as informal relation specifications (e.g., free-text based relation tuples). In order to overcome these weaknesses, we propose a novel IE framework named QA4IE, which leverages the flexible question answering (QA) approaches to produce high quality relation triples across sentences. Based on the framework, we develop a large IE benchmark with high quality human evaluation. This benchmark contains 293K documents, 2M golden relation triples, and 636 relation types. We compare our system with some IE baselines on our benchmark and the results show that our system achieves great improvements.'},\n",
       " '10.1186/s13326-017-0168-3': {'title': 'Exploiting graph kernels for high performance biomedical relation extraction',\n",
       "  'abstract': 'Relation extraction from biomedical publications is an important task in the area of semantic mining of text. Kernel methods for supervised relation extraction are often preferred over manual feature engineering methods, when classifying highly ordered structures such as trees and graphs obtained from syntactic parsing of a sentence. Tree kernels such as the Subset Tree Kernel and Partial Tree Kernel have been shown to be effective for classifying constituency parse trees and basic dependency parse graphs of a sentence. Graph kernels such as the All Path Graph kernel (APG) and Approximate Subgraph Matching (ASM) kernel have been shown to be suitable for classifying general graphs with cycles, such as the enhanced dependency parse graph of a sentence. In this work, we present a high performance Chemical-Induced Disease (CID) relation extraction system. We present a comparative study of kernel methods for the CID task and also extend our study to the Protein-Protein Interaction (PPI) extraction task, an important biomedical relation extraction task. We discuss novel modifications to the ASM kernel to boost its performance and a method to apply graph kernels for extracting relations expressed in multiple sentences. Our system for CID relation extraction attains an F-score of 60%, without using external knowledge sources or task specific heuristic or rules. In comparison, the state of the art Chemical-Disease Relation Extraction system achieves an F-score of 56% using an ensemble of multiple machine learning methods, which is then boosted to 61% with a rule based system employing task specific post processing rules. For the CID task, graph kernels outperform tree kernels substantially, and the best performance is obtained with APG kernel that attains an F-score of 60%, followed by the ASM kernel at 57%. The performance difference between the ASM and APG kernels for CID sentence level relation extraction is not significant. In our evaluation of ASM for the PPI task, ASM performed better than APG kernel for the BioInfer dataset, in the Area Under Curve (AUC) measure (74% vs 69%). However, for all the other PPI datasets, namely AIMed, HPRD50, IEPA and LLL, ASM is substantially outperformed by the APG kernel in F-score and AUC measures. We demonstrate a high performance Chemical Induced Disease relation extraction, without employing external knowledge sources or task specific heuristics. Our work shows that graph kernels are effective in extracting relations that are expressed in multiple sentences. We also show that the graph kernels, namely the ASM and APG kernels, substantially outperform the tree kernels. Among the graph kernels, we showed the ASM kernel as effective for biomedical relation extraction, with comparable performance to the APG kernel for datasets such as the CID-sentence level relation extraction and BioInfer in PPI. Overall, the APG kernel is shown to be significantly more accurate than the ASM kernel, achieving better performance on most datasets.'},\n",
       " '10.1007/s10489-022-03161-8': {'title': 'Rethinking the framework constructed by counterfactual functional model',\n",
       "  'abstract': 'The causal inference represented by counterfactual inference technology breathes new life into the current field of artificial intelligence. Although the fusion of causal inference and artificial intelligence has an excellent performance in many various applications, some theoretical justifications have not been well resolved. In this paper, we focus on two fundamental issues in causal inference: probabilistic evaluation of counterfactual queries and the assumptions used to evaluate causal effects. Both of these issues are closely related to counterfactual inference tasks. Among them, counterfactual queries focus on the outcome of the inference task, and the assumptions provide the preconditions for performing the inference task. Counterfactual queries are to consider the question of what kind of causality would arise if we artificially apply the conditions contrary to the facts. In general, to obtain a unique solution, the evaluation of counterfactual queries requires the assistance of a functional model. We analyze the limitations of the original functional model when evaluating a specific query and find that the model arrives at ambiguous conclusions when the unique probability solution is 0. In the task of estimating causal effects, the experiments are conducted under some strong assumptions, such as treatment-unit additivity. However, such assumptions are often insatiable in real-world tasks, and there is also a lack of scientific representation of the assumptions themselves. We propose a mild version of the treatment-unit additivity assumption coined as M-TUA based on the damped vibration equation in physics to alleviate this problem. M-TUA reduces the strength of the constraints in the original assumptions with reasonable formal expression.'},\n",
       " '10.1007/978-3-030-92238-2_6': {'title': 'A Reinforcement Learning Approach for Abductive Natural Language Generation',\n",
       "  'abstract': \"Teaching deep learning models commonsense knowledge is a crucial yet challenging step towards building human-level artificial intelligence. Abductive Commonsense Reasoning (\\\\(\\\\mathcal {ART}\\\\)) is a benchmark that investigates model's ability on inferencing the most plausible explanation within the given context, which requires model using commonsense knowledge about the world. \\\\(\\\\mathcal {ART}\\\\) consists of two datasets, \\\\(\\\\alpha \\\\)NLG and \\\\(\\\\alpha \\\\)NLI, that challenge models from generative and discriminative settings respectively. Despite the fact that both of the datasets investigate the same ability, existing work solves them independently. In this work, we address \\\\(\\\\alpha \\\\)NLG in a teacher-student setting by getting help from another model with adequate commonsense knowledge fully-trained on \\\\(\\\\alpha \\\\)NLI. We fulfill this intuition by representing the desired optimal generation model as an Energy-Based Model and training it using a reinforcement learning algorithm. Experiment results showed that our model achieve state-of-the-art results on both automatic and human evaluation metrics, which have demonstrated the effectiveness and feasibility of our model (Code available in https://github.com/Huanghongru/commonsense-generation).\"},\n",
       " '10.1093/acprof:oso/9780199551330.003.0028': {'title': 'How we Reason',\n",
       "  'abstract': \"Abstract This chapter explains the heart of a human's reasoning. Mental models of possibilities are at the heart of this reasoning. The theory confronts two challenges that pull in opposite directions. It must account for the nature of the errors that are made in reasoning; and it must explain the potential for rationality. At the heart of human rationality are some simple principles that are recognized: a conclusion must be the case if it holds in all the possibilities compatible with the premises. The models that have been argued for here underlie deduction, induction, and abduction. The argument of this book is that reasoning depends on mental models, and that a conclusion can be comprehended which follows from premises if it holds for every model of the premises.\"},\n",
       " '10.1016/0004-3702(93)90015-4': {'title': 'Interpretation as abduction',\n",
       "  'abstract': 'Abduction is inference to the best explanation. In the TACITUS project at SRI we have developed an approach to abductive inference, called “weighted abduction”, that has resulted in a significant simplification of how the problem of interpreting texts is conceptualized. The interpretation of a text is the minimal explanation of why the text would be true. More precisely, to interpret a text, one must prove the logical form of the text from what is already mutually known, allowing for coercions, merging redundancies where possible, and making assumptions where necessary. It is shown how such “local pragmatics” problems as reference resolution, the interpretation of compound nominals, the resolution of syntactic ambiguity and metonymy, and schema recognition can be solved in this manner. Moreover, this approach of “interpretation as abduction” can be combined with the older view of “parsing as deduction” to produce an elegant and thorough integration of syntax, semantics, and pragmatics, one that spans the range of linguistic phenomena from phonology to discourse structure. Finally, we discuss means for making the abduction process efficient, possibilities for extending the approach to other pragmatics phenomena, and the semantics of the weights and costs in the abduction scheme.'},\n",
       " '10.1016/0004-3702(90)90101-5': {'title': 'Nonmonotonic reasoning, preferential models and cumulative logics',\n",
       "  'abstract': \"Many systems that exhibit nonmonotonic behavior have been described and studied already in the literature. The general notion of nonmonotonic reasoning, though, has almost always been described only negatively, by the property it does not enjoy, i.e. monotonicity. We study here general patterns of nonmonotonic reasoning and try to isolate properties that could help us map the field of nonmonotonic reasoning by reference to positive properties. We concentrate on a number of families of nonmonotonic consequence relations, defined in the style of Gentzen [13]. Both proof-theoretic and semantic points of view are developed in parallel. The former point of view was pioneered by Gabbay [10], while the latter has been advocated by Shoham [38]. Five such families are defined and characterized by representation theorems, relating the two points of view. One of the families of interest, that of preferential relations, turns out to have been studied by Adams [2]. The preferential models proposed here are a much stronger tool than Adams' probabilistic semantics. The basic language used in this paper is that of propositional logic. The extension of our results to first-order predicate calculi and the study of the computational complexity of the decision problems described in this paper will be treated in another paper.\"},\n",
       " '10.1038/1381037c0': {'title': 'Collected Papers of Charles Sanders Peirce',\n",
       "  'abstract': \"THIS valuable addition to the collection of Peirce's writings illustrates the extreme variety and creative power of the great American philosopher. Among the notable contributions contained in this volume are the series of articles which first appeared in the Monist and were so much appreciated by William James. These articles refer to the doctrines of Peirce on chance (tychism), on continuity (synechism) and on love (agapism). Around these articles, the editors have collected and published a wealth of notes, additions and studies ranging from logistics to telepathy, and showing the diverse interests of their author. This new volume will greatly assist the reader in forming an adequate judgment on Peirce's thought and on the historical background of contemporary logic and methodology. Collected Papers of Charles Sanders Peirce Charles Hartshorne Paul Weiss Edited by. Vol. 6: Scientific Metaphysics. Pp. x + 462. (Cambridge, Mass.: Harvard University Press; London: Oxford University Press, 1935.) 21s. net.\"},\n",
       " '10.1038/135131a0': {'title': 'Collected Papers of Charles Sanders Peirce',\n",
       "  'abstract': \"IT is difficult to deal adequately, even in a longer notice, with the extraordinary diversity of topics touched upon or discussed in these volumes. They fully support the editor's opinion that Peirce was “one of the most original and prolific logicians of the nineteenth century”. Vol. 3 contains mainly papers on the algebra of logic and the logic of relatives, in which several improvements on Boole's method are suggested. There is also an excellent paper on the logic of number, and an essay on “The Regenerated Logic” which contains some pertinent remarks about the relations between mathematics, logic and philosophy. For example, Peirce draws a distinction between logic and mathematics, to which he denies the character of a positive science in so far as it does not deal with any aspect of reality; while philosophy does deal with reality, if not through special observations, yet by the study of the universal phenomena of experience.\"},\n",
       " '10.1038/131639b0': {'title': 'Collected Papers of Charles Sanders Peirce',\n",
       "  'abstract': 'THE authorities of Harvard University are to be congratulated for their publication of the papers and notes left by Charles Sanders Peirce. A master mind and a pioneer in philosophical inquiry, Peirce had never an occasion of publishing a standard work embodying his views. So that the editing of his papers is in itself a feat which deserves the praise and gratitude of all scholars. We would do little justice to the philosophical vision of Peirce in estimating his work on the strength of the first two volumes, out of a series of ten, which are to be published. It will suffice at present to indicate the wide range of topics touched upon in the present volumes: the method of science, the classification of the sciences, the logic of mathematics, the categories, the character of logic, speculative grammar, critical logic, and the theory of probable inference. Collected Papers of Charles Sanders Peirce. Charles Hartshorne Paul Weiss Edited by. Vol. 1: Principles of Philosophy. Pp. xvi + 393. 21s. net. Vol. 2: Elements of Logic. Pp. xii + 535. 31s. net. (Cambridge, Mass.: Harvard University Press; London: Oxford University Press, 1932.)'},\n",
       " '10.1016/j.cognition.2022.105359': {'title': 'Heuristic interpretation as rational inference: A computational model of the N400 and P600 in language processing',\n",
       "  'abstract': 'Much inquiry in psycholinguistics has focused on evidence from the N400 and P600 components of the event-related potential (ERP) signal—and a central theoretical challenge in this area is accounting for the so-called “semantic P600”, which involves unexpected patterns in these components relative to traditional theories of the underlying mechanisms. In this paper we present a computational model of the language processing mechanisms underlying these ERP components, which builds on existing psycholinguistic theories in positing a heuristic interpretation stage of processing, but which deviates from existing theories in formulating this heuristic interpretation process as probabilistic selection via a noisy channel model, and in quantifying and accounting for fine-grained variation in statistical and representational properties of individual stimuli. Our model successfully simulates N400 and P600 patterns from eight psycholinguistic experiments, reflecting the full range of N400-only, P600-only, and biphasic N400-P600 effects, and its behaviors shed light on a number of key patterns that have presented challenges for existing theories. The model’s success indicates that a strong account for the processing mechanisms underlying these effects is one in which language comprehension involves a probabilistic heuristic interpretation stage resembling a noisy channel process, feeding into subsequent processes that assess target word fit and reconcile between heuristic and literal interpretations. The model’s success also indicates that these mechanisms are critically sensitive to statistical variation in individual stimuli, and that modeling the effects of this variation is essential to account for the full range of observed effects in language processing.'},\n",
       " '10.1016/S0364-0213(01)00034-9': {'title': 'Predication',\n",
       "  'abstract': 'In Latent Semantic Analysis (LSA) the meaning of a word is represented as a vector in a high-dimensional semantic space. Different meanings of a word or different senses of a word are not distinguished. Instead, word senses are appropriately modified as the word is used in different contexts. In N-VP sentences, the precise meaning of the verb phrase depends on the noun it is combined with. An algorithm is described to adjust the meaning of a predicate as it is applied to different arguments. In forming a sentence meaning, not all features of a predicate are combined with the features of the argument, but only those that are appropriate to the argument. Hence, a different “sense” of a predicate emerges every time it is used in a different context. This predication algorithm is explored in the context of four different semantic problems: metaphor interpretation, causal inferences, similarity judgments, and homonym disambiguation.'},\n",
       " '10.1016/j.jisa.2023.103512': {'title': 'V-A3tS: A rapid text steganalysis method based on position information and variable parameter multi-head self-attention controlled by length',\n",
       "  'abstract': 'Text length varies in social networks, such as IMDB long text, Twitter short text, and long–short mixed text. For these complex situations, the time series, convolution, or fine-tuned BERT models are used in existing text steganalysis methods almost. However, these methods do not simultaneously consider higher detection accuracy and lower training time at the same time. To alleviate this dilemma, this paper proposes a novel text steganalysis method. First, the proposed method maps words into a semantic space containing position information. Second, a variable parameter attention layer scaled appropriately according to text length is designed, it achieves the purpose that the entire parameter amount of the model is not redundant and can ensure effective detection. Finally, the steganalysis features are enhanced by the residual linear layer. For long, short, and mixed text datasets, comparing experiments show that the proposed method has higher detection accuracy, fewer parameters, and shorter training time than existing methods. Among them, the advantage of this method is more obvious for long and mixed texts.'},\n",
       " '10.1016/j.dcan.2023.04.002': {'title': 'A highly reliable encoding and decoding communication framework based on semantic information',\n",
       "  'abstract': 'Increasing research has focused on semantic communication, the goal of which is to convey accurately the meaning instead of transmitting symbols from the sender to the receiver. In this paper, we design a novel encoding and decoding semantic communication framework, which adopts the semantic information and the contextual correlations between items to optimize the performance of a communication system over various channels. On the sender side, the average semantic loss caused by the wrong detection is defined, and a semantic source encoding strategy is developed to minimize the average semantic loss. To further improve communication reliability, a decoding strategy that utilizes the semantic and the context information to recover messages is proposed in the receiver. Extensive simulation results validate the superior performance of our strategies over state-of-the-art semantic coding and decoding policies on different communication channels.'},\n",
       " '10.1007/10719724_5': {'title': 'Attacks on Steganographic Systems',\n",
       "  'abstract': 'The majority of steganographic utilities for the camouflage of confidential communication suffers from fundamental weaknesses. On the way to more secure steganographic algorithms, the development of attacks is essential to assess security. We present both visual attacks, making use of the ability of humans to clearly discern between noise and visual patterns, and statistical attacks which are much easier to automate. The visual attacks presented here exemplify that at least EzStego v2.0b3, Jsteg v4, Steganos v1.5, and S-Tools v4.0 suffer from the misassumption that least significant bits of image data are uncorrelated noise. Beyond that, this paper introduces more objective methods to detect steganography by statistical means.'},\n",
       " '10.1007/BFb0028489': {'title': 'Hiding the hidden: A software system for concealing ciphertext as innocuous text',\n",
       "  'abstract': 'In this paper we present a system for protecting the privacy of cryptograms to avoid detection by censors. The system transforms ciphertext into innocuous text which can be transformed back into the original ciphertext. The expandable set of tools allows experimentation with custom dictionaries, automatic simulation of writing style, and the use of Context-Free-Grammars to control text generation. The scope of this paper is to provide an overview of the basic transformation processes and to demonstrate the quality of the generated text.'},\n",
       " '10.1007/s40747-024-01449-5': {'title': 'A syntactic features and interactive learning model for aspect-based sentiment analysis',\n",
       "  'abstract': 'Abstract The aspect-based sentiment analysis (ABSA) consists of two subtasks: aspect term extraction (AE) and aspect term sentiment classification (ASC). Previous research on the AE task has not adequately leveraged syntactic information and has overlooked the issue of multi-word aspect terms in text. Current researchers tend to focus on one of the two subtasks, neglecting the connection between the AE and ASC tasks. Moreover, the problem of error propagation easily occurs between two independent subtasks when performing the complete ABSA task. To address these issues, we present a unified ABSA model based on syntactic features and interactive learning. The proposed model is called syntactic interactive learning based aspect term sentiment classification model (SIASC). To overcome the problem of extracting multi-word aspect terms, the model utilizes part-of-speech features, words features, and dependency features as textual information. Meanwhile, we designs a unified ABSA structure based on the end-to-end framework, reducing the impact of error propagation issues. Interaction learning in the model can establish a connection between the AE task and the ASC task. The information from interactive learning contributes to improving the model’s performance on the ASC task. We conducted an extensive array of experiments on the Laptop14, Restaurant14, and Twitter datasets. The experimental results show that the SIASC model achieved average accuracy of 84.11%, 86.65%, and 78.42% on the AE task, respectively. Acquiring average accuracy of 81.35%, 86.71% and 76.56% on the ASC task, respectively. The SIASC model demonstrates superior performance compared to the baseline model.'},\n",
       " '10.1016/j.eswa.2024.123735': {'title': 'A false emotion opinion target extraction model with two stage BERT and background information fusion',\n",
       "  'abstract': \"As social media has gradually become an indispensable part of people's life, more and more users begin to express their opinions on social media. These opinions contain rich emotional information, as well as many abnormal false emotion. And the opinion target rich in false emotion will have great potential value in the field of movie box office prediction, public opinion guidance and so on. Therefore, we propose a false emotion opinion target extraction task and two stage BERT+CRF model based on the concept of false emotion. Firstly, two stage BERT network includes C-BERT and W-BERT. We use C-BERT to learn the users comment feature, and W-BERT to learn the background content features of microblog. Then, we design five feature interaction fusion methods to fuse the features learned by C-BERT and W-BERT. At last, we transform the false emotion opinion target extraction task into a sequence labeling task, and use the CRF method to learn the label dependency of the context and output the optimal sequence among all candidate sequences. Due to the lack of false emotion opinion target datasets, we collate a false emotion opinion target dataset Weibo23. Comparing with the advanced models used in related research, including some sequence labeling models and named entity recognition models, two stage BERT+CRF model achieves an F1 score of 0.8834, which is about 10%–20% higher.\"},\n",
       " '10.1016/j.jksuci.2023.101908': {'title': 'Part-of-speech based label update network for aspect sentiment triplet extraction',\n",
       "  'abstract': 'Aspect sentiment triplet analysis (ASTE) is a nuanced task that entails the extraction of all triplets from a user comment, where each triplet consist of an aspect term, an opinion term, and the associated sentiment polarity of the aspect term. Recent research has brought forth a boundary-driven table-filling approach that adeptly tackles the persistent issues of inconsistent relationships and boundary insensitivity found in prior methods, but the improvement in performance is somewhat limited because this method overlook the wealth of information encapsulated within each word present in the sentence. To overcome these limitations, this study proposes a novel Part-of-speech Based Label Update Network (PBLUN) for aspect sentiment triplet extraction. Specifically, a POS-based label update module integrated with aspect term extraction (ATE) and opinion term extraction (OTE) tasks is devised to discern the existence of aspect or opinion words within the set adjacent search domain and update their labels. In addition, the proposed model leverages biaffine attention network to extract probability distribution denoting various relationships between words and effectively combine them with relation-level representation. Experiments conducted on four benchmark datasets have conclusively demonstrated the advantages of our proposed method when compared to strong baseline models.'},\n",
       " '10.1016/j.engappai.2023.106841': {'title': 'MOIT: A Novel task for mining opinions towards implicit targets',\n",
       "  'abstract': 'The extraction of opinions and their corresponding targets has gained significant interest recently, as it offers valuable insights into Opinion Mining (OM) at a granular level. Opinion and target terms to be extracted by existing OM tasks need to be explicitly present in reviews. Targets that are not present but implied in contextual semantics, are neglected by existing OM tasks, even though an investigation reported that about 60% of reviews contain implicit targets. To enable implicit target extraction, a novel task named Mining Opinions towards Implicit Targets (MOIT) under the fine-grained OM, is proposed to extract both opinions and their corresponding implicit targets, enabling a more comprehensive analysis of reviews. To set up the basis for follow-up research on MOIT, two large-scale datasets were constructed as resources in two languages, where the Chinese dataset was built from scratch via a standard human annotation process, and the English dataset was built semi-automatically through machine translation and manual checking. Furthermore, three baseline models adapting three representative paradigms of information extraction, namely sequence labeling, question answering, and text generation, were proposed to solve MOIT. Extensive experiments demonstrated the effectiveness of the models. The proposed MOIT task extends the field of OM research, and the datasets and models establish a foundation for future studies in this area.'},\n",
       " '10.1016/j.neucom.2023.126966': {'title': 'Span-based dependency-enhanced graph convolutional network for aspect sentiment triplet extraction',\n",
       "  'abstract': 'Aspect sentiment triplet extraction task detects three elements of fine-grained sentiment analysis from given sentence, including aspect and opinion terms and their sentiment polarity. Existing methods mainly include tagging-based and span-based methods, where the former show defects on handling overlapped triplets, and the latter could theoretically handle all overlapped triplets but lack of tailored inter-word dependency so that suffer from insufficient span semantic. In this paper, we propose a span-based dependency-enhanced graph convolutional network, which leverages contextual semantic and latent dependency to enrich span representations. Specifically, we devise a latent graph convolutional network to emphasize critical inter-word dependencies and cut off redundant connections in a learnable gating manner, improving the information flow during inter-word interaction. In addition, considering the problem of multi-word term sentiment consistency, we detect effective aspect and opinion terms derived from the output of span enumeration, and introduce term-level interactions by coupling, which meanwhile enables our model to deal with various types of triplets including many-to-one and one-to-many overlapped triplets. Extensive experiments over four benchmark datasets verify that the proposed method outperforms all the baselines with an average F1 improvement of up to 6.13%, and meanwhile shows fine interpretability. The experimental results demonstrate that effectively enhancing token-level and term-level interactions can significantly improve the aspect sentiment triplet extraction performance.'},\n",
       " '10.1016/j.neucom.2023.126730': {'title': 'Syntax-enhanced aspect-based sentiment analysis with multi-layer attention',\n",
       "  'abstract': 'As a key task of fine-grained sentiment analysis, aspect-based sentiment analysis aims to analyse people’s opinions at the aspect level from user-generated texts. Various sub-tasks have been defined according to different scenarios, extracting aspect terms, opinion terms, and the corresponding sentiment. However, most existing studies merely focus on a specific sub-task or a subset of sub-tasks, having many complicated models designed and developed. This hinders the practical applications of aspect-based sentiment analysis. Therefore, some unified frameworks are proposed to handle all the subtasks, but most of them suffer from two limitations. First, the syntactic features are neglected, but such features have been proven effective for aspect-based sentiment analysis. Second, very few efficient mechanisms are developed to leverage important syntactic features, e.g., dependency relations, dependency relation types, and part-of-speech tags. To address these challenges, in this paper, we propose a novel unified framework to handle all defined sub-tasks for aspect-based sentiment analysis. Specifically, based on the graph convolutional network, a multi-layer semantic model is designed to capture the semantic relations between aspect and opinion terms. Moreover, a multi-layer syntax model is proposed to learn explicit dependency relations from different layers. To facilitate the sub-tasks, the learned semantic features are propagated to the syntax model with better semantic guidance to learn the syntactic representations comprehensively. Different from the conventional syntactic model, the proposed framework introduces two attention mechanisms. One is to model dependency relation and type, and the other is to encode part-of-speech tags for detecting aspect and opinion term boundaries. Extensive experiments are conducted to evaluate the proposed novel unified framework, and the experimental results on four groups of real-world datasets explicitly demonstrate the superiority of the proposed framework over a range of baselines.'},\n",
       " '10.1007/s00500-022-07721-5': {'title': 'SpanMTL: a span-based multi-table labeling for aspect-oriented fine-grained opinion extraction',\n",
       "  'abstract': 'Aspect-oriented Fine-grained Opinion Extraction (AFOE) aims to extract the aspect terms, corresponding opinion terms and sentiment polarity in a target sentence. Most previous methods treat AFOE as word-level or span-level task, which ignore the complementarity of these two tasks. To integrate the merits of word-level and span-level information, we construct an end-to-end Span-based Multi-Table Labeling (SpanMTL) framework. SpanMTL combines word-based and span-based table labeling to tackle AFOE task. Specifically, in the proposed model, we use two separate BiLSTMs to encode the information of aspect and opinion terms into a word-based 2D representation table. Based on the table, we construct span-based table with CNN by associating the word-pair representations. At last, we integrate the table label distributions of word- and span-based table labeling to generate a multi-table labeling. The proposed method improves the performances of Opinion Pair Extraction (OPE) and Opinion Triplet Extraction (OTE) tasks by introducing span information, especially on the datasets with lots of spans. We have conducted various experiments on AFOE datasets to validate our method. The experimental results show that our method outperforms other baselines when the sentences having lots of span information.'},\n",
       " '10.1016/j.neucom.2022.07.067': {'title': 'Dependency graph enhanced interactive attention network for aspect sentiment triplet extraction',\n",
       "  'abstract': 'Aspect sentiment triplet extraction is an extremely daunting task designed to identify the triplets from comments, where each triplet is composed of an aspect term, the related opinion term, and the sentiment between them. Existing research efforts majorly construct a novel tagging scheme to avoid the disadvantages of pipeline methods. However, the improvement is limited due to neglecting the implicit grammatical relationships among the three elements in a triplet. To cope with this limitation, we put forward an innovative Dependency Graph Enhanced Interactive Attention Network, which explicitly introduces the syntactic and semantic relationships between words. Specifically, an interactive attention mechanism is conceived to jointly consider both the contextual features learned from Bi-directional Long Short-Term Memory and the syntactic dependencies learned from the correspondent dependency graph in an iterative interaction manner. In addition, we notice that words with different Part-of-Speech categories have different contributions to the semantic expression of sentences. Accordingly, the information of different Part-of-Speech categories is recognized during the modeling process to properly capture the semantic relationships. Experiments on the benchmark datasets originally derived from SemEval Challenges illustrate that our presented approach has superiority over strong baselines.'},\n",
       " '10.1016/j.neucom.2022.04.027': {'title': 'Complete quadruple extraction using a two-stage neural model for aspect-based sentiment analysis',\n",
       "  'abstract': 'Aspect-based sentiment analysis (ABSA) is a fine-grained task which aims to identify the emotional polarity of a specific aspect in a text or sentence. Aspect term extraction (ATE), opinion term extraction (OTE) and aspect polarity classification (APC) are three main subtasks of the ABSA task. Nowadays, researchers mainly focus on a single task or a joint task composed of these three subtasks, and such investigation on the sentiment analysis is not sufficient. In this paper, we firstly introduce a complete aspect sentiment analysis task, called Aspect Sentiment Quadruple Extraction, which also includes the category detection beside ATE, OTE and APC. Then we propose a two-stage neural network model composed of several modules, including BiLSTM, simple gated self-attention and position encoding for this joint task. In the first stage, the proposed model extracts aspect and opinion terms as well as their categories and polarities. Moreover, the second stage mainly includes a relation classifier to validate the aspect-opinion pairs and then finalizes the complete quadruple extraction. The experimental results, evaluated on a benchmark dataset of Chinese product reviews, show that our proposed model outperforms other baseline methods and achieves the start-of-art performance.'},\n",
       " '10.1016/j.knosys.2022.108366': {'title': 'A span-sharing joint extraction framework for harvesting aspect sentiment triplets',\n",
       "  'abstract': 'Aspect sentiment triplet extraction (ASTE) is the most recent subtask of aspect-based sentiment analysis (ABSA), and it aims to provide a complete solution for ABSA by extracting the triplets of aspect terms, opinion terms and their associated sentiments. However, previous pipeline approaches to ASTE suffer from error propagation in different subtasks, and previous tagging-based joint extraction approaches fail to deal with one-to-many and many-to-one relationship between aspect terms and opinion words in a sentence. To address this, we propose a span-sharing joint extraction (SSJE) framework to extract aspect sentiment triplets from sentences in an end-to-end fashion. In this framework, an aspect term and the corresponding opinion term(s), combined with the sentiment on the aspect, are identified simultaneously in the last step to avoid the error propagation. At the same time, all possible candidate spans are enumerated to be shared by aspect terms and opinion terms to deal with the problem of multiple-word entities and the complex relationship between aspect terms and opinion terms. To verify SSJE’s effectiveness, we conduct extensive experiments on two benchmark datasets. The experimental results demonstrate that the proposed SSJE achieves state-of-the-art performances not only for ASTE tasks but also for extracting aspect-opinion pairs.'},\n",
       " '10.1016/j.neucom.2022.01.021': {'title': 'A multi-task learning framework for end-to-end aspect sentiment triplet extraction',\n",
       "  'abstract': 'Aspect sentiment triplet extraction (ASTE) is a significant and challenging task in aspect-based sentiment analysis, which aims to summarize people’s opinions by extracting triplets consisting of opinion targets, opinion expressions, and sentiment polarities. In this paper, we propose a novel multi-task learning framework to achieve end-to-end ASTE. We decompose ASTE into three subtasks, namely target tagging, opinion tagging, and sentiment tagging. In target tagging and opinion tagging, we adopt the BIO tagging scheme to detect the boundaries of opinion targets and opinion expressions. In sentiment tagging, we introduce a target-aware tagging scheme, which utilizes a series of target-specific tag sequences to identify the correspondences between opinion targets and opinion expressions, and determine their sentiment polarities. We conduct extensive experiments on four benchmark datasets. The experimental results show that our framework achieves consistently superior results. Compared with existing methods, our method has better performance in extracting overlapping triplets and identifying long-range correspondences. Further analysis demonstrates the effectiveness of our framework.'},\n",
       " '10.1007/978-3-030-88480-2_46': {'title': 'Aspect-Sentiment-Multiple-Opinion Triplet Extraction',\n",
       "  'abstract': 'Aspect Sentiment Triplet Extraction (ASTE) aims to extract aspect term (aspect), sentiment and opinion term (opinion) triplets from sentences and can tell a complete story, i.e., the discussed aspect, the sentiment toward the aspect, and the cause of the sentiment. ASTE is a charming task, however, one triplet extracted by ASTE only includes one opinion of the aspect, but an aspect in a sentence may have multiple corresponding opinions and one opinion only provides part of the reason why the aspect has this sentiment, as a consequence, some triplets extracted by ASTE are hard to understand, and provide erroneous information for downstream tasks. In this paper, we introduce a new task, named Aspect Sentiment Multiple Opinions Triplet Extraction (ASMOTE). ASMOTE aims to extract aspect, sentiment and multiple opinions triplets. Specifically, one triplet extracted by ASMOTE contains all opinions about the aspect and can tell the exact reason that the aspect has the sentiment. We propose an Aspect-Guided Framework (AGF) to address this task. AGF first extracts aspects, then predicts their opinions and sentiments. Moreover, with the help of the proposed Sequence Labeling Attention (SLA), AGF improves the performance of the sentiment classification using the extracted opinions. Experimental results on multiple datasets demonstrate the effectiveness of our approach (Data and code can be found at https://github.com/l294265421/ASMOTE).'},\n",
       " '10.1016/j.procs.2023.12.030': {'title': 'Generative approach to Aspect Based Sentiment Analysis with GPT Language Models',\n",
       "  'abstract': 'Aspect Sentiment Triplet Extraction (ASTE) is a modern and effective form of sentiment analysis that enables the extraction of highly representative features of source textual data. Recent solutions rely on models built upon Bidirectional Encoder Representations from Transformers (BERT) embeddings and large manually-tagged datasets. This implies that usage of such methods requires large amounts of gold-tagged domain-specific data and is vulnerable to data drifts, while not being able to recognize segmented and summarize more complex terms. We propose an open-domain generative method for ASTE based on Generative pre-trained transformer (GPT) with few-shot and fine-tuning strategies. This method has shown to be applicable for the task, with the models being capable of consistent structuring of the output triplet, simplification of the terms without losing meaningful information, as well as successful analysis of data from unknown domains. Resulting models was tested on mixed domain Russian-language automatically tagged data with thorough manual editing by means of a large language model (LLM) with a few-shot approach and English data, which was only automatically tagged. The developed models have shown to take advantage of the ability to perform learning in a few-shot way, allowing knowledge distillation from larger to cardinally smaller ones. Models have also been tested on summarizing of large amounts of reviews and have shown results comparable to enterprise grade solutions.'},\n",
       " '10.1016/j.knosys.2018.02.034': {'title': 'Learning multi-grained aspect target sequence for Chinese sentiment analysis',\n",
       "  'abstract': 'Aspect-based sentiment analysis aims at identifying sentiment polarity towards aspect targets in a sentence. Previously, the task was modeled as a sentence-level sentiment classification problem that treated aspect targets as a hint. Such approaches oversimplify the problem by averaging word embeddings when the aspect target is a multi-word sequence. In this paper, we formalize the problem from a different perspective, i.e., that sentiment at aspect target level should be the main focus. Due to the fact that written Chinese is very rich and complex, Chinese aspect targets can be studied at three different levels of granularity: radical, character and word. Thus, we propose to explicitly model the aspect target and conduct sentiment classification directly at the aspect target level via three granularities. Moreover, we study two fusion methods for such granularities in the task of Chinese aspect-level sentiment analysis. Experimental results on a multi-word aspect target subset from SemEval2014 and four Chinese review datasets validate our claims and show the improved performance of our model over the state of the art.'},\n",
       " '10.1016/j.chb.2013.05.024': {'title': 'Sentiment analysis in Facebook and its application to e-learning',\n",
       "  'abstract': 'This paper presents a new method for sentiment analysis in Facebook that, starting from messages written by users, supports: (i) to extract information about the users’ sentiment polarity (positive, neutral or negative), as transmitted in the messages they write; and (ii) to model the users’ usual sentiment polarity and to detect significant emotional changes. We have implemented this method in SentBuk, a Facebook application also presented in this paper. SentBuk retrieves messages written by users in Facebook and classifies them according to their polarity, showing the results to the users through an interactive interface. It also supports emotional change detection, friend’s emotion finding, user classification according to their messages, and statistics, among others. The classification method implemented in SentBuk follows a hybrid approach: it combines lexical-based and machine-learning techniques. The results obtained through this approach show that it is feasible to perform sentiment analysis in Facebook with high accuracy (83.27%). In the context of e-learning, it is very useful to have information about the users’ sentiments available. On one hand, this information can be used by adaptive e-learning systems to support personalized learning, by considering the user’s emotional state when recommending him/her the most suitable activities to be tackled at each time. On the other hand, the students’ sentiments towards a course can serve as feedback for teachers, especially in the case of online learning, where face-to-face contact is less frequent. The usefulness of this work in the context of e-learning, both for teachers and for adaptive systems, is described too.'},\n",
       " '10.1007/978-3-642-39146-0_8': {'title': 'Predictive Sentiment Analysis of Tweets: A Stock Market Application',\n",
       "  'abstract': 'The application addressed in this paper studies whether Twitter feeds, expressing public opinion concerning companies and their products, are a suitable data source for forecasting the movements in stock closing prices. We use the term predictive sentiment analysis to denote the approach in which sentiment analysis is used to predict the changes in the phenomenon of interest. In this paper, positive sentiment probability is proposed as a new indicator to be used in predictive sentiment analysis in finance. By using the Granger causality test we show that sentiment polarity (positive and negative sentiment) can indicate stock price movements a few days in advance. Finally, we adapted the Support Vector Machine classification mechanism to categorize tweets into three sentiment categories (positive, negative and neutral), resulting in improved predictive power of the classifier in the stock market application.'},\n",
       " '10.1007/978-3-319-73004-2_6': {'title': 'Convolutional Neural Networks',\n",
       "  'abstract': 'This chapter introduces the first deep learning architecture of the book, convolutional neural networks. It starts with redefining the way a logistic regression accepts data, and defines 1D and 2D convolutional layers as a natural extension of the logistic regression. The chapter also details on how to connect the layers and dimensionality problems. The local receptive field is introduced as a core concept of any convolutional architecture and the connections with the vanishing gradient problem is explored. Also the idea of padding is introduced in the visual setting, as well as the stride of the local receptive field. Pooling is also explored in the general setting and as max-pooling. A complete convolutional neural network for classifying MNIST is then presented in Keras code, and all the details of the code are presented as comments and illustrations. The final section of the chapter presents modifications needed to adapt convolutional networks, which are primarily visual classificators, to work with text and language.'},\n",
       " '10.1016/J.DSS.2009.09.003': {'title': 'Using text mining and sentiment analysis for online forums hotspot detection and forecast',\n",
       "  'abstract': 'Text sentiment analysis, also referred to as emotional polarity computation, has become a flourishing frontier in the text mining community. This paper studies online forums hotspot detection and forecast using sentiment analysis and text mining approaches. First, we create an algorithm to automatically analyze the emotional polarity of a text and to obtain a value for each piece of text. Second, this algorithm is combined with K-means clustering and support vector machine (SVM) to develop unsupervised text mining approach. We use the proposed text mining approach to group the forums into various clusters, with the center of each representing a hotspot forum within the current time span. The data sets used in our empirical studies are acquired and formatted from Sina sports forums, which spans a range of 31 different topic forums and 220,053 posts. Experimental results demonstrate that SVM forecasting achieves highly consistent results with K-means clustering. The top 10 hotspot forums listed by SVM forecasting resembles 80% of K-means clustering results. Both SVM and K-means achieve the same results for the top 4 hotspot forums of the year.'},\n",
       " '10.1016/j.ins.2022.09.051': {'title': 'Aspect opinion routing network with interactive attention for aspect-based sentiment classification',\n",
       "  'abstract': 'Aspect-based sentiment classification task aims at discovering the sentiment polarity on a specific aspect term. Since a sentence often contains several sentiments for different aspects, it is very important to capture the correspondences between aspects and opinion words in a sentence. To this end, we propose an aspect opinion interactive attention routing network model, which adopts an interactive attention mechanism between specific aspect embeddings learned from graph convolutional network and opinion semantic embeddings learned from three bi-directional long short-term memory networks. Furthermore, dynamic routing is applied to the neural network so that its output values are constantly regulated during training to generate feature representations of specific aspects related to opinion word. Based on the above, our approach identifies opinion words feature information related to specific aspect words in context. Experimental results demonstrate that the model outperforms 16 existing methods in terms of accuracy and macro-average F1 score on most of the benchmark datasets.'},\n",
       " '10.1016/j.neucom.2022.10.071': {'title': 'Learn from structural scope: Improving aspect-level sentiment analysis with hybrid graph convolutional networks',\n",
       "  'abstract': 'Aspect-level sentiment analysis aims to determine the sentiment polarity towards a specific target in a sentence. The main challenge of this task is to effectively model the relation between targets and sentiments so as to filter out noisy opinion words from irrelevant targets. Most recent efforts capture relations through target-sentiment pairs or opinion spans from a word-level or phrase-level perspective. Based on the observation that targets and sentiments essentially establish relations following the grammatical hierarchy of phrase-clause-sentence structure, it is hopeful to exploit comprehensive syntactic information for better guiding the learning process. Therefore, we introduce the concept of Scope, which outlines a structural text region related to a specific target. To jointly learn structural Scope and predict the sentiment polarity, we propose a hybrid graph convolutional network (HGCN) to synthesize information from constituency tree and dependency tree, exploring the potential of linking two syntax parsing methods to enrich the representation. Experimental results on four public datasets illustrate that our HGCN model outperforms current state-of-the-art baselines.'},\n",
       " '10.1007/s10462-021-10134-9': {'title': 'KnowMIS-ABSA: an overview and a reference model for applications of sentiment analysis and aspect-based sentiment analysis',\n",
       "  'abstract': 'Abstract The analysis of the opinions of customers and users has been always of great interest in supporting decision-making in many fields, especially in marketing. Sentiment analysis (SA) is the umbrella term for techniques and approaches that analyze user’s sentiments, emotions, opinions in text or other media. The need for a better understanding of these opinions paved the way to novel approaches that focus on the analysis of the sentiment related to specific features of a product, giving birth to the field of aspect-based sentiment analysis (ABSA). Although the increasing interest in this discipline, there is still confusion regarding the basic concepts of ABSA: terms like sentiment, affect, emotion, opinion, are used as synonyms while they represent different concepts. This often leads to an incorrect analysis of the users’ opinions.This work presents an overview of the state-of-the-art techniques and approaches for ABSA, highlighting the main critical issues related to current trends in this field. Following this analysis, a new reference model for SA and ABSA, namely the KnowMIS-ABSA model, is proposed. The model is grounded on the consideration that sentiment, affect, emotion and opinion are very different concepts and that it is profoundly wrong to use the same metric and the same technique to measure them. Accordingly, we argue that different tools and metrics should be adopted to measure each of the dimensions of an opinion. A qualitative case study, regarding product reviews, is proposed to motivate the advantages of the KnowMIS-ABSA model.'},\n",
       " '10.1007/978-3-030-86380-7_54': {'title': 'Aspect-Based Sentiment Classification with Reinforcement Learning and Local Understanding',\n",
       "  'abstract': 'Aspect-based sentiment analysis is a fine-grained classification task in natural language processing. In this paper, we propose a new framework with reinforcement learning agent to assess the importance of words in the sentence for sentiment analysis and mask out insignificant ones. Our method emphasizes on local linguistic understanding and extracts aspect-agnostic background information as well as aspect-relevant information. Experiments on three common datasets show that the proposed method is effective and achieves substantial performance improvements over comparison models.'},\n",
       " '10.1007/978-3-030-91699-2_24': {'title': 'A Deep Learning Approach for Aspect Sentiment Triplet Extraction in Portuguese',\n",
       "  'abstract': 'Aspect Sentiment Triplet Extraction (ASTE) is an Aspect-Based Sentiment Analysis subtask (ABSA). It aims to extract aspect-opinion pairs from a sentence and identify the sentiment polarity associated with them. For instance, given the sentence “Large rooms and great breakfast”, ASTE outputs the triplet T = {(rooms, large, positive), (breakfast, great, positive)}. Although several approaches to ASBA have recently been proposed, those for Portuguese have been mostly limited to extracting only aspects without addressing ASTE tasks. This work aims to develop a framework based on Deep Learning to perform the Aspect Sentiment Triplet Extraction task in Portuguese. The framework uses BERT as a context-awareness sentence encoder, multiple parallel non-linear layers to get aspect and opinion representations, and a Graph Attention layer along with a Biaffine scorer to determine the sentiment dependency between each aspect-opinion pair. The comparison results show that our proposed framework significantly outperforms the baselines in Portuguese and is competitive with its counterparts in English.'},\n",
       " '10.1186/s40537-024-00903-y': {'title': 'Adapting transformer-based language models for heart disease detection and risk factors extraction',\n",
       "  'abstract': 'Abstract Efficiently treating cardiac patients before the onset of a heart attack relies on the precise prediction of heart disease. Identifying and detecting the risk factors for heart disease such as diabetes mellitus, Coronary Artery Disease (CAD), hyperlipidemia, hypertension, smoking, familial CAD history, obesity, and medications is critical for developing effective preventative and management measures. Although Electronic Health Records (EHRs) have emerged as valuable resources for identifying these risk factors, their unstructured format poses challenges for cardiologists in retrieving relevant information. This research proposed employing transfer learning techniques to automatically extract heart disease risk factors from EHRs. Leveraging transfer learning, a deep learning technique has demonstrated a significant performance in various clinical natural language processing (NLP) applications, particularly in heart disease risk prediction. This study explored the application of transformer-based language models, specifically utilizing pre-trained architectures like BERT (Bidirectional Encoder Representations from Transformers), RoBERTa, BioClinicalBERT, XLNet, and BioBERT for heart disease detection and extraction of related risk factors from clinical notes, using the i2b2 dataset. These transformer models are pre-trained on an extensive corpus of medical literature and clinical records to gain a deep understanding of contextualized language representations. Adapted models are then fine-tuned using annotated datasets specific to heart disease, such as the i2b2 dataset, enabling them to learn patterns and relationships within the domain. These models have demonstrated superior performance in extracting semantic information from EHRs, automating high-performance heart disease risk factor identification, and performing downstream NLP tasks within the clinical domain. This study proposed fine-tuned five widely used transformer-based models, namely BERT, RoBERTa, BioClinicalBERT, XLNet, and BioBERT, using the 2014 i2b2 clinical NLP challenge dataset. The fine-tuned models surpass conventional approaches in predicting the presence of heart disease risk factors with impressive accuracy. The RoBERTa model has achieved the highest performance, with micro F1-scores of 94.27%, while the BERT, BioClinicalBERT, XLNet, and BioBERT models have provided competitive performances with micro F1-scores of 93.73%, 94.03%, 93.97%, and 93.99%, respectively. Finally, a simple ensemble of the five transformer-based models has been proposed, which outperformed the most existing methods in heart disease risk fan, achieving a micro F1-Score of 94.26%. This study demonstrated the efficacy of transfer learning using transformer-based models in enhancing risk prediction and facilitating early intervention for heart disease prevention.'},\n",
       " '10.1016/j.eswa.2024.123917': {'title': 'Relation guided and attention enhanced multi-head selection for relational facts extraction',\n",
       "  'abstract': 'Multi-head selection is a reasonable way of extracting relational facts. Though effective, it ignores the interdependencies of relations and disregards the contextual information. In this paper, we propose a relation guided and attention enhanced approach to address the above challenges. Specifically, we predict the relations existing in the input sentence to guide multi-head selection. This strategy helps to model dependencies of relations. Moreover, we use an attention mechanism to leverage the sentential context. The experimental results demonstrate that our approach significantly outperforms the baselines.'},\n",
       " '10.1007/s40747-023-01321-y': {'title': 'Genre: generative multi-turn question answering with contrastive learning for entity–relation extraction',\n",
       "  'abstract': 'Abstract Extractive approaches have been the mainstream paradigm for identifying overlapping entity–relation extraction. However, limited by their inherently methodological flaws, which hardly deal with three issues: hierarchical dependent entity–relations, implicit entity–relations, and entity normalization. Recent advances have proposed an effective solution based on generative language models, which cast entity–relation extraction as a sequence-to-sequence text generation task. Inspired by the observation that humans learn by getting to the bottom of things, we propose a novel framework, namely GenRE, Generative multi-turn question answering with contrastive learning for entity–relation extraction. Specifically, a template-based question prompt generation first is designed to answer in different turns. We then formulate entity–relation extraction as a generative question answering task based on the general language model instead of span-based machine reading comprehension. Meanwhile, the contrastive learning strategy in fine-tuning is introduced to add negative samples to mitigate the exposure bias inherent in generative models. Our extensive experiments demonstrate that GenRE performs competitively on two public datasets and a custom dataset, highlighting its superiority in entity normalization and implicit entity–relation extraction. (The code is available at https://github.com/lovelyllwang/GenRE ).'},\n",
       " '10.1016/j.eswa.2023.123000': {'title': 'A recollect-tuning method for entity and relation extraction',\n",
       "  'abstract': 'Fine-tuning and mask-tuning (or prompt tuning) are two approaches to construct deep neural networks for entity and relation extraction. Fine-tuning based models optimize neural networks with task-relevant objective, in which pre-trained language models (PLMs) are mainly used as external resources to support word embedding. In mask-tuning models, neural networks is optimized by the same pre-training objective in a PLM, which directly outputs verbalized entity type representations. It is effective to utilize potential knowledge of PLMs. In this paper, we propose a recollect-tuning approach, which jointly makes full use of the mechanisms of both fine-tuning and mask-tuning. In this approach, the recollect-tuning iteratively masks tokens in a possible entity span. The classification is based on both the masked token representation and the entity span representation. It is the same as the process to make a decision based on incomplete information. In the training process, the deep network is optimized by task-relevant objective, which strengthens the semantic representation of each entity span. It is effective to learn entity noise-invariant features and take full advantage of potential knowledge of PLMs. Our method is evaluated on three public benchmarks (the ACE 2004, ACE 2005 and SciERC datasets) for the entity and relation extraction task. The result shows significant improvement in the two tasks, outperforming the state-of-the-art performance on ACE04, ACE05 and SciERC by +0.4%, +0.6%, and +0.5%, respectively.'},\n",
       " '10.1016/j.eswa.2023.122007': {'title': 'An effective relation-first detection model for relational triple extraction',\n",
       "  'abstract': 'Relational triple extraction is a crucial task in the field of information extraction, which attempts to identify all triples from natural language text. Existing methods primarily focus on addressing the issue of overlapping triples. However, the majority of studies need to perform the same operation on all predefined relations when solving this problem, which will lead to relation redundancy. In addition, most methods have the problem of error propagation. During training, they use the ground truth labels as a priori knowledge to predict at different stages, while during inference, they must use the labels predicted in the previous stage to predict in the following stages. To address these problems, we propose an effective relation-first detection model for relational triple extraction (ERFD-RTE). The proposed model first detects the potential relations in the sentence and then performs entity recognition for each specific relation, which aims to solve the overlapping triples issue and avoid additional calculations for redundant relations. We design a random label error strategy for the error propagation problem in the training phase, which balances the difference between training and inference. Experiment results demonstrate that ERFD-RTE is superior to other baselines by improving the F1 score to 92.7% (+0.7%) on NYT-P and NYT-E, 92.9% (+0.3%) on WebNLG-P, 89.3% (+0.9%) on WebNLG-E and 83.71% (+1.5%) on ADE. Additional analysis shows that ERFD-RTE can effectively extract overlapping triples.'},\n",
       " '10.1016/j.eswa.2023.121561': {'title': 'Entity–relation triple extraction based on relation sequence information',\n",
       "  'abstract': 'Data overlap is a significant challenge in the task of entity–relation triple extraction. This task includes two research lines, line one first identifies entities and then predicts relations while line two completely shuffles the order. The methods in line two are more conducive to the optimization of the data overlap problem. Recent works have made breakthroughs in dealing with overlapping data, but there are still some defects such as difficulty in convergence and poor performance on datasets with numerous relations. To solve the above problems, we adopt a two-step strategy of first extracting subjects, and then predicting relation–object pairs. Considering the absence of connectivity between the two steps in the conventional method, we adopt the relation sequence as input in both steps and propose the TERS model. The relation sequence can connect two steps and improve the single-step and comprehensive extraction capability of the model. The TERS model consists of two modules. The first module performs information interaction and filters invalid subjects through the Text Relation Attention method. The second module implements multiple iterations of information interaction through the Information Flow method. The combination of these two modules contributes to the strong entity–relation triple extraction capability of our model. We evaluate our method on three public datasets. Extensive experiments show that our TERS model outperforms previous state-of-the-art models in triple extraction and overlapping data processing. Compared with other two-step extraction models, the advantages of our model are more obvious.'},\n",
       " '10.1016/j.heliyon.2023.e19265': {'title': \"Using transfer learning-based causality extraction to mine latent factors for Sjögren's syndrome from biomedical literature\",\n",
       "  'abstract': \"Understanding causality is a longstanding goal across many different domains. Different articles, such as those published in medical journals, disseminate newly discovered knowledge that is often causal. In this paper, we use this intuition to build a model that leverages causal relations to unearth factors related to Sjögren's syndrome from biomedical literature. Sjögren's syndrome is an autoimmune disease affecting up to 3.1 million Americans. Due to the uncommon nature of the illness, symptoms across different specialties coupled with common symptoms of other autoimmune conditions such as rheumatoid arthritis, it is difficult for clinicians to diagnose the disease timely. Due to the lack of a dedicated dataset for causal relationships built from biomedical literature, we propose a transfer learning-based approach, where the relationship extraction model is trained on a wide variety of datasets. We conduct an empirical analysis of numerous neural network architectures and data transfer strategies for causal relation extraction. By conducting experiments with various contextual embedding layers and architectural components, we show that an ELECTRA-based sentence-level relation extraction model generalizes better than other architectures across varying web-based sources and annotation strategies. We use this empirical observation to create a pipeline for identifying causal sentences from literature text, extracting the causal relationships from causal sentences, and building a causal network consisting of latent factors related to Sjögren's syndrome. We show that our approach can retrieve such factors with high precision and recall values. Comparative experiments show that this approach leads to 25% improvement in retrieval F1-score compared to several state-of-the-art biomedical models, including BioBERT and Gram-CNN. We apply this model to a corpus of research articles related to Sjögren's syndrome collected from PubMed to create a causal network for Sjögren's syndrome. The proposed causal network for Sjögren's syndrome will potentially help clinicians with a holistic knowledge base for faster diagnosis.\"},\n",
       " '10.1007/s13278-023-01095-8': {'title': 'Relation extraction: advancements through deep learning and entity-related features',\n",
       "  'abstract': 'Capturing semantics and structure surrounding the target entity pair is crucial for relation extraction. The task is challenging due to the limited semantic elements and structural features of the target entity pair within a sentence. To tackle this problem, this paper introduces an approach that fuses entity-related features under convolutional neural networks and graph convolution neural networks. Our approach combines the unit features of the target entity pair to generate corresponding fusion features and applies the deep learning framework to extract high-order abstract features for relation extraction. Experimental results from three public datasets (ACE05 English, ACE05 Chinese, and SanWen) indicate that the proposed approach achieves F1-scores of 77.70%, 90.12%, and 68.84%, respectively, highlighting its effectiveness and robustness. This paper provides a comprehensive description of the approach and experimental results.'},\n",
       " '10.1007/978-3-031-46846-9_10': {'title': 'Beyond Rule-Based Named Entity Recognition and Relation Extraction for Process Model Generation from Natural Language Text',\n",
       "  'abstract': 'Process-aware information systems offer extensive advantages to companies, facilitating planning, operations, and optimization of day-to-day business activities. However, the time-consuming but required step of designing formal business process models often hampers the potential of these systems. To overcome this challenge, automated generation of business process models from natural language text has emerged as a promising approach to expedite this step. Generally two crucial subtasks have to be solved: extracting process-relevant information from natural language and creating the actual model. Approaches towards the first subtask are rule based methods, highly optimized for specific domains, but hard to adapt to related applications. To solve this issue, we present an extension to an existing pipeline, to make it entirely data driven. We demonstrate the competitiveness of our improved pipeline, which not only eliminates the substantial overhead associated with feature engineering and rule definition, but also enables adaptation to different datasets, entity and relation types, and new domains. Additionally, the largest available dataset (PET) for the first subtask, contains no information about linguistic references between mentions of entities in the process description. Yet, the resolution of these mentions into a single visual element is essential for high quality process models. We propose an extension to the PET dataset that incorporates information about linguistic references and a corresponding method for resolving them. Finally, we provide a detailed analysis of the inherent challenges in the dataset at hand.'},\n",
       " '10.1016/j.eswa.2023.120441': {'title': 'Boundary regression model for joint entity and relation extraction',\n",
       "  'abstract': 'Joint extraction of named entities and their relations has the advantage of avoiding cascading failures caused by falsely recognized named entities. Recent studies have focused on span classification modes to support end-to-end multiobjective learning. However, the enumeration of a large number of inaccurate entity spans creates a serious data imbalance and incurs high computational complexity. In this study, we propose a boundary regression model for joint entity and relation extraction, where a boundary regression mechanism is adopted to learn the offset of a possible named entity relevant to a true named entity. Instead of exhaustively enumerating all possible entity spans, this model receives only a small number of coarse entities with inaccurate boundaries as inputs. It can locate named entities and extract relations between them simultaneously. Experiments demonstrated that our boundary regression model outperforms state-of-the-art models in terms of the F1 score by +2.5%, +0.4%, +2.1%, and +1.3% on ADE, ACE05, ACE04, and CoNLL04 benchmark datasets respectively. Analytical experiments further confirmed the effectiveness of our model for refining entity boundaries and learning accurate span representations.'},\n",
       " '10.1007/s40747-023-01004-8': {'title': 'NEDORT: a novel and efficient approach to the data overlap problem in relational triples',\n",
       "  'abstract': 'Abstract Relation triple extraction is a combination of named entity recognition and relation prediction. Early works ignore the problem of data overlap when extracting triples, resulting in poor extraction performance. Subsequent works improve the capability of the model to extract overlapping triples through generative and extractive methods. These works achieve considerable performance but still suffer from some defects, such as poor extraction capability for individual triplets and inappropriate spatial distribution of the data. To solve the above problems, we perform sequence-to-matrix transformation and propose the NEDORT model. NEDORT predicts all subjects in the sentence and then completes the extraction of relation–object pairs. There are overlapping parts between relation–object pairs, so we conduct the conversion of sequence to matrix. We design the Differential Amplified Multi-head Attention method to extract subjects. This method highlights the locations of entities and captures sequence features from multiple dimensions. When performing the extraction of relation–object pairs, we fuse subject and sequence information through the Biaffine method and generate relation–sequence matrices. In addition, we design a multi-layer U-Net network to optimize the matrix representation and improve the extraction performance of the model. Experimental results on two public datasets show that our model outperforms other baseline models on triples of all categories'},\n",
       " '10.1016/j.ipm.2023.103352': {'title': 'Planarized sentence representation for nested named entity recognition',\n",
       "  'abstract': 'One strategy to recognize nested entities is to enumerate overlapped entity spans for classification. However, current models independently verify every entity span, which ignores the semantic dependency between spans. In this paper, we first propose a planarized sentence representation to represent nested named entities. Then, a bi-directional two-dimensional recurrent operation is implemented to learn semantic dependencies between spans. Our method is evaluated on seven public datasets for named entity recognition. It achieves competitive performance in named entity recognition. The experimental results show that our method is effective to resolve nested named entities and learn semantic dependencies between them.'},\n",
       " '10.1186/s12911-023-02127-1': {'title': 'Subsequence and distant supervision based active learning for relation extraction of Chinese medical texts',\n",
       "  'abstract': 'In recent years, relation extraction on unstructured texts has become an important task in medical research. However, relation extraction requires a large amount of labeled corpus, manually annotating sequences is time consuming and expensive. Therefore, efficient and economical methods for annotating sequences are required to ensure the performance of relational extraction. This paper proposes a method of subsequence and distant supervision based active learning. The method is annotated by selecting information-rich subsequences as a sampling unit instead of the full sentences in traditional active learning. Additionally, the method saves the labeled subsequence texts and their corresponding labels in a dictionary which is continuously updated and maintained, and pre-labels the unlabeled set through text matching based on the idea of distant supervision. Finally, the method combines a Chinese-RoBERTa-CRF model for relation extraction in Chinese medical texts. Experimental results test on the CMeIE dataset achieves the best performance compared to existing methods. And the best F1 value obtained between different sampling strategies is 55.96%.'},\n",
       " '10.1049/cim2.12073': {'title': 'A framework and prototype system in support of workflow collaboration and knowledge mining for manufacturing value chains',\n",
       "  'abstract': 'Abstract In the field of industrial design and manufacture, computer‐supported collaborative work (CSCW) systems have been widely deployed for better teamwork. However, the traditional CSCW systems have a main drawback in effectively processing and utilising knowledge across different industrial workflows. To bridge this gap, we propose a framework for collaboration between members across the manufacturing value chains to increase efficiency and reduce duplication in team cooperation. The framework contains three parts, namely workflow, knowledge mining, and services. Specifically, the workflow part provides a collaborative environment for multiple users. The knowledge mining part, as the core of the framework, extracts in‐context knowledge from workflows. The part of services can interact with users with different users in each workflow, including information recommendation they need in the future or information retrieval they want to know from other workflows. Furthermore, we develop a prototype system for supporting multiple value chains collaboration to verify the effectiveness and efficiency of the framework.'},\n",
       " '10.1038/s41598-022-26116-y': {'title': 'A novel knowledge extraction method based on deep learning in fruit domain',\n",
       "  'abstract': 'Knowledge extraction aims to identify entities and extract relations between them from unstructured text, which are in the form of triplets. Analysis of the fruit nutrition domain corpus revealed many overlapping triplets, that is, multiple correspondences between a subject and multiple objects or the same subject and object. The current relevant methods mainly target the extraction of ordinary triplets, which cannot accurately identify overlapping triplets. To solve this problem, a deep learning based model for overlapping triplet extraction is proposed in this study. The relation is modeled as a function that maps a subject to an object. The hybrid information of the subject is entered into the relation-object extraction model to detect the object and relation. The experimental results show this model outperforms existing extraction models and achieves state-of-the-art performance on the manually labeled fruit nutrition domain dataset. In terms of application value, the proposed work can obtain a high-quality and structured fruit nutrition knowledge base, which provides application fundamentals for downstream applications of nutrition matching.'},\n",
       " '10.1016/j.knosys.2022.109129': {'title': 'Boundary assembling method for joint entity and relation extraction',\n",
       "  'abstract': 'In recent years, a paradigm shift has occurred in the field of joint entity and relation extraction from token tagging to span classification, because the latter can handle nested named entities in a sentence and better utilize the global features of a possible named entity. Because relation extraction should verify every entity pair in a sentence, the performance of joint entity and relation extraction significantly depends on the quality of the entity span proposals. Most models enumerate numerous inaccurate entity spans, causing a severe data imbalance problem and high computational complexity. To address these problems, we propose a boundary assembling model for joint entity and relation extraction, in which entity boundaries are assembled to enumerate entity spans. Entity boundaries have small granularity and are less ambiguous, hence, the proposed model can benefit from accurate entity spans. Furthermore, boundary detection, span classification, and relation extraction are integrated into an end-to-end framework; thus, our model can share model parameters for multi-objective learning, which enhances the discriminability of a neural network. Experiments show that our boundary assembling model outperforms existing state-of-the-art models on four evaluation datasets: SciERC, ADE, ACE05, and CoNLL04.'},\n",
       " '10.1016/j.neucom.2022.04.059': {'title': 'A pattern-first pipeline approach for entity and relation extraction',\n",
       "  'abstract': 'Entity-relation extraction is the task of extracting entities and their semantic relations from a piece of unstructured text. In recent studies, Machine Reading Comprehension (MRC) based methods have been applied to this task and achieved significant results. As a pipelined approach, these methods always extract head entities first, and then identify related tail entities by enumerating each relationship. These entity-first methods will lead to the entity redundancy problem. They also suffer from the error propagation issue, which is an inherent issue of the multi-step inference process. Moreover, most existing MRC-based models, which use tagging-based methods for entity recognition, could not deal with overlapping entities. To address these, we propose Patti, a Pattern-First Pipeline Approach for Entity and Relation Extraction. Firstly, Patti leverages a novel MRC-based pattern classifier to identify relation patterns. Next, a span-based method was introduced to extract entities under the guidance of questions parameterized by the patterns yield in the first step. Finally, to alleviate the error propagation issue, Patti employs an additional MRC-based classifier to remove falsely extracted candidate entity-relation triples. Experiment results show that our approach significantly outperforms the entity-first baseline models on CoNLL04 and ACE05 datasets.'},\n",
       " '10.1016/j.simpa.2022.100294': {'title': 'Connecting the dots in clinical document understanding with Relation Extraction at scale',\n",
       "  'abstract': '<h2>Abstract</h2> We present a text mining framework based on top of the Spark NLP library - comprising of Named Entity Recognition (NER) and Relation Extraction (RE) models, which expands on previous work in three main ways. First, we release new RE model architectures that obtain state-of-the-art F1 scores on 5 out of 7 benchmark datasets. Second, we introduce a modular approach to train and stack multiple models in a single nlp pipeline in a production grade library with little coding. Third, we apply these models in practical applications including knowledge graph generation, prescription parsing, and robust ontology mapping.'},\n",
       " '10.1016/j.knosys.2022.108825': {'title': 'A novel bundling learning paradigm for named entity recognition',\n",
       "  'abstract': 'Multi-task learning (MTL) takes advantage of the information gained from multiple related NLP tasks in order to improve performance across these tasks. MTL-based models for named entity recognition (NER) have traditionally included relation extraction and (or) coreference resolution, which requires additional data annotations in NER corpora, whereas these annotations are often unavailable. Indeed, we generally model the NER task using either a sequence labeling-based or span-based approach. Motivated by MTL, we propose a novel Bundling Learning (BL) paradigm for the NER task, which is achieved by bundling sequence labeling-based and span-based NER models together, thus allowing us to model the task from both token- and span-level perspectives. In addition, BL does not require additional data annotations compared to MTL. In experiments on NER and RE tasks, it is shown that BL consistently improves the performance of the two tasks across several benchmark datasets. Detailed analyses further confirm the effectiveness of BL.'},\n",
       " '10.1016/j.compag.2022.106776': {'title': 'CG-ANER: Enhanced contextual embeddings and glyph features-based agricultural named entity recognition',\n",
       "  'abstract': 'In recent years, deep learning has greatly improved the performance of named entity recognition models in various fields, especially in the agricultural domain. However, most existing works only utilize word embedding models to generate the context-independent embeddings, which is limited in modeling polysemous words. Moreover, the abundant morphological information in agricultural texts has not been fully utilized. Besides, the local context information needs to be further extracted. To solve the aforementioned issues, a novel enhanced contextual embeddings and glyph features-based model was proposed. First, the contextual embeddings were dynamically generated by the fine-tuned Bidirectional Encoder Representation from Transformers (BERT) on the domain-specific corpus (e.g., agricultural texts), and then the multi-granularity information was obtained from the layers of BERT. Thus, the contextual embeddings not only contain domain-specific knowledge but also include multi-grained semantic information. Second, a novel 3-dimension convolutional neural network-based framework was designed to capture the contextual glyph features for each character from the image perspective. Third, a channel-wised fusion architecture was also introduced to further improve the ability of the convolutional neural network layer to capture local context features. Experimental results showed that our proposed model achieved the best F1-scores of 95.02% and 96.51% on AgCNER and Resume datasets, which indicated the effectiveness and generalization of our model to identify the entities in cross-domain texts. The ablation study in many aspects also demonstrated the better performance of the proposed model.'},\n",
       " '10.1016/j.jii.2021.100301': {'title': 'Improved strategies of relation extraction based on graph convolutional model on tree structure for web information processing',\n",
       "  'abstract': 'In the Industry 4.0/5.0 era, information integration is employed to fuse information from different companies to facilitate interoperation. However, information extraction is an important preprocessing phase that must be performed prior to integrating data from different contexts. Relation extraction, which is an element of information extraction, is typically the basis of many upper-level applications, e.g., information visualization and inference. Some current models may not fully consider the complementary effect of information at different levels of granularity featured by different neural networks. In this paper, two improvement relation extraction strategies based on the graph convolutional model on tree structure (GCNTree) are proposed. The first strategy integrates a hierarchical attention mechanism and correlation analysis between subjects and objects to generate sentence and entity vectors, respectively. The second strategy merges a named-entity recognition subnetwork with GCNTree to realize joint learning of relation and entity extraction. Experimental results demonstrate that the proposed strategies are comparable to state-of-the-art methods.1'},\n",
       " '10.1007/978-3-030-88483-3_37': {'title': 'An Effective System for Multi-format Information Extraction',\n",
       "  'abstract': 'The multi-format information extraction task in the 2021 Language and Intelligence Challenge is designed to comprehensively evaluate information extraction from different dimensions. It consists of an multiple slots relation extraction subtask and two event extraction subtasks that extract events from both sentence-level and document-level. Here we describe our system for this multi-format information extraction competition task. Specifically, for the relation extraction subtask, we convert it to a traditional triple extraction task and design a voting based method that makes full use of existing models. For the sentence-level event extraction subtask, we convert it to a NER task and use a pointer labeling based method for extraction. Furthermore, considering the annotated trigger information may be helpful for event extraction, we design an auxiliary trigger recognition model and use the multi-task learning mechanism to integrate the trigger features into the event extraction model. For the document-level event extraction subtask, we design an Encoder-Decoder based method and propose a Transformer-alike decoder. Finally, our system ranks No.4 on the test set leader-board of this multi-format information extraction task, and its F1 scores for the subtasks of relation extraction, event extractions of sentence-level and document-level are 79.887%, 85.179%, and 70.828% respectively. The codes of our model are available at https://github.com/neukg/MultiIE.'},\n",
       " '10.1007/978-981-99-6207-5_15': {'title': 'Enhancing Ontology Knowledge for Domain-Specific Joint Entity and Relation Extraction',\n",
       "  'abstract': 'Pre-trained language models (PLMs) have been widely used in entity and relation extraction methods in recent years. However, due to the semantic gap between general-domain text used for pre-training and domain-specific text, these methods encounter semantic redundancy and domain semantics insufficiency when it comes to domain-specific tasks. To mitigate this issue, we propose a low-cost and effective knowledge-enhanced method to facilitate domain-specific semantics modeling in joint entity and relation extraction. Precisely, we use ontology and entity type descriptions as domain knowledge sources, which are encoded and incorporated into the downstream entity and relation extraction model to improve its understanding of domain-specific information. We construct a dataset called SSUIE-RE for Chinese entity and relation extraction in space science and utilization domain of China Manned Space Engineering, which contains a wealth of domain-specific knowledge. The experimental results on SSUIE-RE demonstrate the effectiveness of our method, achieving a 1.4% absolute improvement in relation F1 score over previous best approach.'},\n",
       " '10.1007/978-981-16-5188-5_2': {'title': 'Systematic Analysis of Joint Entity and Relation Extraction Models in Identifying Overlapping Relations',\n",
       "  'abstract': 'Named entity recognition and relation extraction are two fundamental tasks in the domain of natural language processing. Joint entity and relation extraction models have attracted more and more attention due to the performance advantage. However, there are difficulties in identifying overlapping relations among the models. To investigate the differences of structures and performances of joint extraction models, this paper implements a list of state-of-the-art joint extraction models and compares their difference in identifying overlapping relations. Experiment results show that the models by separating entity features and relation features work better than the models with feature fusion in identifying overlapping relations on three publicly available datasets.'},\n",
       " '10.1007/978-3-030-93733-1_23': {'title': 'Automated ESG Report Analysis by Joint Entity and Relation Extraction',\n",
       "  'abstract': 'The banking industry has lately been under pressure, notably from regulators and NGOs, to report various Environmental, Societal and Governance (ESG) metrics (e.g., the carbon footprint of loans). For years at Crédit Agricole, a specialized division examined ESG and Corporate Social Responsibility (CSR) reports to ensure, e.g., the bank’s commitment to de-fund coal activities, and companies with social or environmental issues. With both an intensification of the aforementioned exterior pressure, and of the number of companies making such reports publicly available, the tedious process of going through each report has become unsustainable.In this work, we present two adaptations of previously published models for joint entity and relation extraction. We train them on a private dataset consisting in ESG and CSR reports annotated internally at Crédit Agricole. We show that we are able to effectively detect entities such as coal activities and environmental or social issues, as well as relations between these entities, thus enabling the financial industry to quickly grasp the creditworthiness of clients and prospects w.r.t. ESG criteria. The resulting model is provided at https://github.com/adimajo/renard_joint.'},\n",
       " '10.1007/978-3-540-74690-4_56': {'title': 'Multi-dimensional Recurrent Neural Networks',\n",
       "  'abstract': 'Recurrent neural networks (RNNs) have proved effective at one dimensional sequence learning tasks, such as speech and online handwriting recognition. Some of the properties that make RNNs suitable for such tasks, for example robustness to input warping, and the ability to access contextual information, are also desirable in multi-dimensional domains. However, there has so far been no direct way of applying RNNs to data with more than one spatio-temporal dimension. This paper introduces multi-dimensional recurrent neural networks, thereby extending the potential applicability of RNNs to vision, video processing, medical imaging and many other areas, while avoiding the scaling problems that have plagued other multi-dimensional models. Experimental results are provided for two image segmentation tasks.'},\n",
       " '10.1016/j.jeconom.2019.10.014': {'title': 'Overlap in observational studies with high-dimensional covariates',\n",
       "  'abstract': 'Estimating causal effects under exogeneity hinges on two key assumptions: unconfoundedness and overlap. Researchers often argue that unconfoundedness is more plausible when more covariates are included in the analysis. Less discussed is the fact that covariate overlap is more difficult to satisfy in this setting. In this paper, we explore the implications of overlap in observational studies with high-dimensional covariates and formalize curse-of-dimensionality argument, suggesting that these assumptions are stronger than investigators likely realize. Our key innovation is to explore how strict overlap restricts global discrepancies between the covariate distributions in the treated and control populations. Exploiting results from information theory, we derive explicit bounds on the average imbalance in covariate means under strict overlap and show that these bounds become more restrictive as the dimension grows large. We discuss how these implications interact with assumptions and procedures commonly deployed in observational causal inference, including sparsity and trimming.'},\n",
       " '10.1007/978-3-319-50496-4_34': {'title': 'Discovering Concept-Level Event Associations from a Text Stream',\n",
       "  'abstract': 'We study an open text mining problem – discovering concept-level event associations from a text stream. We investigate the importance and challenge of this task and propose a novel solution by using event sequential patterns. The proposed approach can discover important event associations implicitly expressed. The discovered event associations are general and useful as knowledge for applications such as event prediction.'},\n",
       " '10.1007/978-3-319-41259-7_8': {'title': 'Semiparametric Theory and Empirical Processes in Causal Inference',\n",
       "  'abstract': 'In this paper we review important aspects of semiparametric theory and empirical processes that arise in causal inference problems. We begin with a brief introduction to the general problem of causal inference, and go on to discuss estimation and inference for causal effects under semiparametric models, which allow parts of the data-generating process to be unrestricted if they are not of particular interest (i.e., nuisance functions). These models are very useful in causal problems because the outcome process is often complex and difficult to model, and there may only be information available about the treatment process (at best). Semiparametric theory gives a framework for benchmarking efficiency and constructing estimators in such settings. In the second part of the paper we discuss empirical process theory, which provides powerful tools for understanding the asymptotic behavior of semiparametric estimators that depend on flexible nonparametric estimators of nuisance functions. These tools are crucial for incorporating machine learning and other modern methods into causal inference analyses. We conclude by examining related extensions and future directions for work in semiparametric causal inference.'},\n",
       " '10.1007/978-3-642-29449-5_1': {'title': 'Local Characterizations of Causal Bayesian Networks',\n",
       "  'abstract': 'The standard definition of causal Bayesian networks (CBNs) invokes a global condition according to which the distribution resulting from any intervention can be decomposed into a truncated product dictated by its respective mutilated subgraph. We analyze alternative formulations which emphasizes local aspects of the causal process and can serve therefore as more meaningful criteria for coherence testing and network construction. We first examine a definition based on “modularity” and prove its equivalence to the global definition. We then introduce two new definitions, the first interprets the missing edges in the graph, and the second interprets “zero direct effect” (i.e., ceteris paribus). We show that these formulations are equivalent but carry different semantic content.'},\n",
       " '10.1016/S0010-0285(03)00036-7': {'title': 'Models of causation and the semantics of causal verbs',\n",
       "  'abstract': 'This research examines the relationship between the concept of CAUSE as it is characterized in psychological models of causation and the meaning of causal verbs, such as the verb cause itself. According to focal set models of causation (; ), the concept of CAUSE should be more similar to the concepts of ENABLE and PREVENT than either is to each other. According to a model based on theory of force dynamics, the force dynamic model, the concepts of CAUSE, ENABLE, and PREVENT should be roughly equally similar to one another. The relationship between these predictions and the meaning of causal verbs was examined by having participants sort causal verbs and rate them with respect to the dimensions specified by the two models. The results from five experiments indicated that the force dynamic model provides a better account of the meaning of causal verbs than do focal set models of causation. Implications for causal inference and induction are discussed.'},\n",
       " '10.1016/B978-0-12-108550-6.50014-8': {'title': 'THE STRUCTURE OF EPISODES IN MEMORY',\n",
       "  'abstract': 'This chapter discusses that the process of understanding is, in large part, the assigning of new input conceptualizations to causal sequences and the inference of remembered conceptualizations that will allow for complete causal chains. Information is organized within episodic sequences and these episodic sequences serve to organize understanding. The simplest kind of episodic sequence is the script that organizes information about everyday causal chains that are part of a shared knowledge of the world. Human understanding, then, is a process by which new information gets treated in terms of the old information already present in memory. The chapter presents an argument for a combination of the notions of semantic memory and episodic memory. The basis of human memory is the conceptualization. Internally, the conceptualization is action-based with certain specified associative links between actions and objects. Externally, conceptualizations can relate to other conceptualizations within a context or episodic sequence.'},\n",
       " '10.1016/0749-596X(85)90049-X': {'title': 'Causal thinking and the representation of narrative events',\n",
       "  'abstract': 'The basis for representing narrative events in memory was investigated in reanalyses of the stories and data of R. C. Omanson (1982b, Journal of Verbal Learning and Verbal Behavior, 21, 326–337) and N. L. Stein and C. G. Glenn (1979, In New Directions in Discourse Processing, Hillsdale, NJ, Erlbaum). Causal network representations of the stories were derived for prediction of data on immediate and delayed recall, summarization, and judged importance of events. Properties of the networks were compared in multiple regression analyses with other factors, notably the story-grammar categories of the events. Whether or not an event was in a causal chain and the number of its causal connections were both found to account for substantial proportions of common and unique variance in all four measures. The story-grammar category of events also contributed unique variance but overlapped substantially with the causal factors. The concreteness, serial position, and argument overlap of an event failed to account uniquely for the data. A recursive transition network model is discussed that integrates story grammar, causal chain, causal network, and hierarchical problem-solving approaches to story representation.'},\n",
       " '10.1016/0749-596X(85)90048-8': {'title': 'Causal relatedness and importance of story events',\n",
       "  'abstract': 'The question of what makes a statement \"important\" in a story was studied. Causal relations were identified between all pairs of events in six folktales, using context-dependent, logical criteria of necessity, and counterfactual tests of the form: If event A had not occurred, then, in the circumstances of the story, event B would not have occurred. Causal networks were derived from these identifications for each story and two properties of them were found to predict judgments of importance: (1) the number of direct causal connections and (2) whether or not an event was in a causal chain from the opening to the closing of the story. The judged importance of a statement increased with the number of causal connections and causal chain membership. Regression analyses showed that substantial proportions of variance were accounted for jointly by both properties and uniquely by causal connections. The importance of a statement, whether identified by structural analysis or judged by naive subjects, seems to be determined by analogous assessments of the statement\\'s causal and logical relations to other statements in the text.'},\n",
       " '10.1016/0304-422X(80)90021-2': {'title': 'Story understanding as problem-solving',\n",
       "  'abstract': \"We investigated how people understand and recall simple stories. After discussing our general framework for investigating memory, we examined story grammars considered as theories of readers' memory of a story. Story grammars were found to be inadequate as grammars, as recognition devices for stories, and as predictors of recall probabilities of different statements in three test stories. An alternative approach views a story as a problem-solving protocol and analyzes it into a hierarchical state transition (HST) network; actions were viewed as succeeding or failing to bring about state changes, with actions perhaps being decomposed into subactions. We hypothesized that successful actions, and those higher in the action hierarchy, would be remembered better. Recall evidence supported these hypotheses. First, they predicted recall of statements within our three test stories. Second, people recalled action sequences that were completed, or that succeeded in attaining a goal, better than ones that were begun but abandoned before completion or because they failed. Third, superordinate actions were recalled more than subordinate ones. Fourth, setting information that enabled plot actions was recalled more than unused setting information; moreover, used settings tended to be misrecalled near actions they enabled. Finally we discussed incompletenesses of the HST approach. It requires a processing theory. We suggested some of its components and some story phenomena it must encompass.\"},\n",
       " '10.1016/0010-0285(79)90009-4': {'title': 'Scripts in memory for text',\n",
       "  'abstract': \"These experiments investigate people's knowledge of routine activities (e.g., eating in a restaurant, visiting a dentist) and how that knowledge is organized and used to understand and remember narrative texts. We use the term script to refer to these action stereotypes. Two studies collected script norms: people described what goes on in detail during familiar activities. They largely agreed on the nature of the characters, props, actions, and the order of the actions. They also agreed on how to segment the low-level action sequences into constituent “scenes,” suggesting a hierarchical organization in memory of the activity. Other studies investigated memory for a text narrating actions from a script. Subjects tended to confuse in memory actions that were stated with unstated actions implied by the script. This tendency increased as more related script instances were studied. Subjects also preferred to recall script actions in their familiar order; a scrambled text that presented some script actions out of order tended to be recalled in canonical order. We also investigated whether the reading time for adjacent statements in a text varied with their distance apart in the underlying script. A statement at a one-step distance was read faster than one at a two- or three-step distance; statements in the second half of a script were read faster than those in the first half. A final experiment found that goal-relevant deviations from a script were remembered better than script actions. The role of script knowledge in text memory was discussed, as was the relation of scripts to schema memory in general.\"},\n",
       " '10.1016/B978-1-4832-1446-7.50018-2': {'title': 'A FRAMEWORK FOR REPRESENTING KNOWLEDGE',\n",
       "  'abstract': 'Briefly describes frame systems as a formalism for representing knowledge and then concentrates on the issue of what the content of knowledge should be in specific domains. Argues that vision should be viewed symbolically with an emphasis on forming expectations and then using details to fill in slots in those expectations. Discusses the enormous problem of the volume of background common sense knowledge required to understand even very simple natural language texts and suggests that networks of frames are a reasonable approach to represent such knowledge. Discusses the concept of expectation further including ways to adapt to and understand expectation failures. Argues that numerical approaches to knowledge representation are inherently limited.'},\n",
       " '10.1016/j.ipm.2022.103033': {'title': 'Identification of Chinese dark jargons in Telegram underground markets using context-oriented and linguistic features',\n",
       "  'abstract': 'When cybercriminals communicate with their customers in underground markets, they tend to use secure and customizable instant messaging (IM) software, i.e. Telegram. It is a popular IM software with over 700 million monthly active users (MAU) up to June 2022. In recent years, more and more dark jargons (i.e. an innocent-looking replacement of sensitive terms) appear frequently on Telegram. Therefore, jargons identification is one of the most significant research perspectives to track online underground markets and cybercrimes. This paper proposes a novel Chinese Jargons Identification Framework (CJI-Framework) to identify dark jargons. Firstly, we collect chat history from Telegram groups that are related to the underground market and construct the corpus TUMCC (Telegram Underground Market Chinese Corpus), which is the first Chinese corpus in jargons identification research field. Secondly, we extract seven brand-new features which can be classified into three categories: Vectors-based Features (VF), Lexical analysis-based Features (LF), and Dictionary analysis-based Features (DF), to identify Chinese dark jargons from commonly-used words. Based on these features, we then run a statistical outlier detection to decide whether a word is a jargon. Furthermore, we employ a word vector projection method and a transfer learning method to improve the effect of the framework. Experimental results show that CJI-Framework achieves a remarkable performance with an F1-score of 89.66%. After adaptation for English, it performs better than state-of-the-art English jargons identification method as well. Our built corpus and code have been publicly released to facilitate the reproduction and extension of our work.'},\n",
       " '10.1016/J.NEUNET.2005.06.042': {'title': 'Framewise phoneme classification with bidirectional LSTM and other neural network architectures',\n",
       "  'abstract': 'In this paper, we present bidirectional Long Short Term Memory (LSTM) networks, and a modified, full gradient version of the LSTM learning algorithm. We evaluate Bidirectional LSTM (BLSTM) and several other network architectures on the benchmark task of framewise phoneme classification, using the TIMIT database. Our main findings are that bidirectional networks outperform unidirectional ones, and Long Short Term Memory (LSTM) is much faster and also more accurate than both standard Recurrent Neural Nets (RNNs) and time-windowed Multilayer Perceptrons (MLPs). Our results support the view that contextual information is crucial to speech processing, and suggest that BLSTM is an effective architecture with which to exploit it.'},\n",
       " '10.1016/j.ipm.2023.103546': {'title': 'Multi-granularity cross-modal representation learning for named entity recognition on social media',\n",
       "  'abstract': 'With social media posts tending to be multimodal, Multimodal Named Entity Recognition (MNER) for the text with its accompanying image is attracting more and more attention since it plays an important role for various applications such as intention understanding and user recommendation. However, there are two drawbacks in existing approaches: (1) Meanings of the text and its accompanying image do not match always, so the text information still plays a major role. However, social media posts are usually shorter and more informal compared with other normal contents, which easily causes incomplete semantic description and the data sparsity problem. (2) Although the visual representations are already used, existing methods ignore either fine-grained semantic correspondence between objects in images and words in text or the objective fact that there are misleading objects or no objects in some images . In this work, we solve the above two problems by introducing the multi-granularity cross-modal representation learning . To resolve the first problem, we enhance the representation by semantic augmentation for each word in text. As for the second issue, we perform the cross-modal semantic interaction between text and vision at the different vision granularity to get the most effective multimodal guidance representation for every word . The experiments show that our results on TWITTER-2015 (74.57%) and TWITTER-2017 (86.09%) outperform the current performances. The code, data and the best performing models are available at : https://github.com/LiuPeiP-CS/IIE4MNER.'},\n",
       " '10.1007/s40747-022-00742-5': {'title': 'AttenSy-SNER: software knowledge entity extraction with syntactic features and semantic augmentation information',\n",
       "  'abstract': 'Abstract Software knowledge community contains a large scale of software knowledge entity information, complex structure and rich semantic correlations. It is significant to recognize and extract software knowledge entity from software knowledge community, as it has great impact on entity-centric tasks such as software knowledge graph construction, software document generation and expert recommendation. Since the texts of the software knowledge community are unstructured by user-generated texts, it is difficult to apply the traditional entity extraction method in the domain of the software knowledge community due to the problems of entity variation, entity sparsity, entity ambiguity, out-of-vocabulary (OOV) words and the lack of annotated data sets. This paper proposes a novel software knowledge entity extraction model, named AttenSy-SNER, which integrates syntactic features and semantic augmentation information, to extract fine-grained software knowledge entities from unstructured user-generated content. The input representation layer utilizes Bidirectional Encoder Representations from Transformers (BERT) model to extract the feature representation of the input sequence. The contextual coding layer leverages the Bidirectional Long Short-Term Memory (BiLSTM) network and Graph Convolutional Network (GCN) for contextual information and syntactic dependency information, and a semantic augmentation strategy based on attention mechanism is introduced to enrich the semantic feature representation of sequences as well. The tag decoding layer leverages Conditional Random Fields (CRF) to solve the dependency between the output tags and obtain the global optimal label sequence. The results of model comparison experiments show that the proposed model has better performance than the benchmark model in software engineering domain.'},\n",
       " '10.1016/j.knosys.2022.109178': {'title': 'LELNER: A Lightweight and Effective Low-resource Named Entity Recognition model',\n",
       "  'abstract': 'Named entity recognition aims to find the target entity from the input sentence and determine the category it belongs to. Low-resource means that the training data used by the model is scarce. In order to improve the performance of the model with a small quantity of labeled data, previous works propose the concept of the trigger and introduce trigger information. Despite their excellent performance, these methods still have shortcomings in trigger representation generation, information fusion and model training. To remedy these deficiencies, this paper proposes the LELNER model including information interaction module and information fusion network. The information interaction module realizes the interaction between trigger and sentence, which leads to trigger representation containing more entity information. The information fusion network perfectly merges the trigger representation into the sentence sequence. As a result, the network has a better fusion effect than previous nonlinear fusion methods. In terms of model training, this paper designs a one-step training method to replace the two-step training method used in previous models, which provides convenience for the entire training process. Experimental results show that the proposed LELNER model achieves state-of-the-art results on three public datasets BC5CDR, CONLL and SemEval-lap.1'},\n",
       " '10.1016/j.aiopen.2022.12.002': {'title': 'CAILIE 1.0: A dataset for Challenge of AI in Law - Information Extraction V1.0',\n",
       "  'abstract': 'Legal information extraction requires identifying and classifying legal elements from specific legal documents. Considering that information extraction is mostly regarded as the first step in natural language understanding (NLU), the quality of legal information extraction results certainly has a great impact on the performance of various legal AI downstream tasks. However, due to the particularity of legal documents, Chinese judicial information extraction datasets are very scarce. In response to this situation, we constructed a dataset for Callenge of AI in Law - Information Extraction V1.0 (CAILIE 1.0). The following two features of CAILIE are worth mentioning: 1) The entity definition focuses on more fine-grained theft document information, providing more interpretability for downstream legal AI. 2) To meet the needs of Chinese judicial practice, we define entity labels with judicial attributes based on natural attribute labels. We implement some classic models on this dataset. The experimental results show that legal information extraction is still challenging and additional research is required for this task to be solved.'},\n",
       " '10.1007/978-3-031-10986-7_17': {'title': 'CLINER: Clinical Interrogation Named Entity Recognition',\n",
       "  'abstract': 'The automatic generation of electronic medical record (EMR) data aims to create EMRs from raw medical text (e.g., doctor-patient interrogation dialog text) without human efforts. A critical problem is how to accurately locate the medical entities mentioned in the doctor-patient interrogation text, as well as identify the state of each clinical entity (e.g., whether a patient genuinely suffers from the mentioned disease). Such precisely extracted medical entities and their states can facilitate clinicians to trace the whole interrogation process for medical decision-making. In this work, we annotate and release an online clinical dialog NER dataset that contains 72 types of clinical items and 3 types of states. Existing conventional named entity recognition (NER) methods only take a candidate entity’s surrounding context information into consideration. However, identifying the state of a clinical entity mentioned in a doctor-patient dialog turn requires the information across the whole dialog rather than only the current turn. To bridge the gap, we further propose CLINER, a CLinical Interrogation NER model, which exploits both fine-grained and coarse-grained information for each dialog turn to facilitate the extraction of entities and their corresponding states. Extensive experiments on the medical dialog information extraction (MIE) task and clinical interrogation named entity recognition task show that our approach shows significant performance improvement (3.72 on NER F1 and 6.12 on MIE F1) over the state-of-art on both tasks.'},\n",
       " '10.1007/978-981-16-7512-6_2': {'title': 'SAU’S Submission for CCMT 2021 Quality Estimation Task',\n",
       "  'abstract': 'This paper describes our submissions to CCMT 2021 quality estimation sentence-level task for both Chinese-to-English (ZH-EN) and English-to-Chinese (EN-ZH). In this task. We follow TransQuest framework which is based on cross-lingual transformers (XLM-R). In order to make the model pay more attention to key words, we use the attention mechanism and gate module to fuse the last hidden state and pooler output of XLM-R model to generate more accurate prediction. In addition, we use the Predictor-Estimator architecture model to integrate with our model to improve the results. Experiments show that this is a simple and effective ensemble method.'},\n",
       " '10.1007/978-981-16-7476-1_30': {'title': 'Chinese Named Entity Recognition Incorporating Multi-scale Features',\n",
       "  'abstract': 'Deep learning technology has been widely used in the field of natural language processing, making the deep learning-based Chinese Social Media Named Entity Recognition (NER) method is becoming more and more important. However, the public datasets in the field of Chinese Social Media are small in size, which cannot allow deep learning models to fully learn, resulting in low accuracy of model recognition. At the same time, Chinese Social Media has more new words and abbreviations, which contains a lot of noise. To solve the above problems, we propose a Chinese Social Media NER model based on multi-scale features BiLSTM-CRF, which combines character features, word segmentation features, radical features and pinyin features at the embedding layer to obtain multi-scale semantics information. Then, the acquired features are transferred to the BiLSTM network (CIFG Cell) for encoding, and finally the encoded tags are decoded through the CRF layer to obtain the prediction results. Experimental results prove that the BiLSTM-CRF model based on multi-scale features can improve the accuracy of the model when performing Chinese social media named entity recognition. At the same time, we use CIFG Cell to have higher recognition efficiency than Basic LSTM Cell in network coding. When the model is trained, we use the gradient truncation method and the Dropout layer to further avoid problems such as gradient explosion and model over-fitting.'},\n",
       " '10.1186/s13638-022-02182-8': {'title': 'A multi-task learning framework for efficient grammatical error correction of textual messages in mobile communications',\n",
       "  'abstract': 'Abstract In mobile communications, plenty of textual messages need to be transmitted and processed rapidly. However, messages usually contain noise, which will affect the performance of related applications. Thus, we investigate grammatical error correction (GEC) to correct errors in messages. Unlike recent works, we focus on improving the efficiency of GEC because low time delay is significant in mobile communications. We propose a novel multi-task learning approach to GEC by detecting errors first and then making corrections. Two classifiers are used to serially detect sentence-level and token-level errors, so the correct content can be free from correction operations. We adapt a non-autoregressive decoder to parallelly generate corrected tokens, making the correction stage efficient. Experiments show that our approach is ten times faster than the traditional approach and can achieve a comparable GEC performance.'},\n",
       " '10.1007/978-3-319-99501-4_41': {'title': 'Overview of the NLPCC 2018 Shared Task: Grammatical Error Correction',\n",
       "  'abstract': 'In this paper, we present an overview of the Grammatical Error Correction task in the NLPCC 2018 shared tasks. We give detailed descriptions of the task definition and the data for training as well as evaluation. We also summarize the approaches investigated by the participants of this task. Such approaches demonstrate the state-of-the-art of Grammatical Error Correction for Mandarin Chinese. The data set and evaluation tool used by this task is available at https://github.com/zhaoyyoo/NLPCC2018_GEC .'},\n",
       " '10.1016/j.eswa.2023.120041': {'title': 'KitchenScale: Learning to predict ingredient quantities from recipe contexts',\n",
       "  'abstract': 'Determining proper quantities for ingredients is an essential part of cooking practice from the perspective of enriching tastiness and promoting healthiness. We introduce KitchenScale, a fine-tuned Pre-trained Language Model (PLM) that predicts a target ingredient’s quantity and measurement unit given its recipe context. To effectively train our KitchenScale model, we formulate an ingredient quantity prediction task that consists of three sub-tasks which are ingredient measurement type classification, unit classification, and quantity regression task. Furthermore, we utilized transfer learning of cooking knowledge from recipe texts to PLMs. We adopted the Discrete Latent Exponent (DExp) method to cope with high variance of numerical scales in recipe corpora. Experiments with our newly constructed dataset and recommendation examples demonstrate KitchenScale’s understanding of various recipe contexts and generalizability in predicting ingredient quantities. We implemented a web application for KitchenScale to demonstrate its functionality in recommending ingredient quantities expressed in numerals (e.g., 2) with units (e.g., ounce).'},\n",
       " '10.1007/3-540-36124-3_77': {'title': 'Open Mind Common Sense: Knowledge Acquisition from the General Public',\n",
       "  'abstract': 'Open Mind Common Sense is a knowledge acquisition system designed to acquire commonsense knowledge from the general public over the web. We describe and evaluate our first fielded system, which enabled the construction of a 450,000 assertion commonsense knowledge base. We then discuss how our second-generation system addresses weaknesses discovered in the first. The new system acquires facts, descriptions, and stories by allowing participants to construct and fill in natural language templates. It employs word-sense disambiguation and methods of clarifying entered knowledge, analogical inference to provide feedback, and allows participants to validate knowledge and in turn each other.'},\n",
       " '10.1016/j.knosys.2024.111662': {'title': 'KMc-ToD: Structure knowledge enhanced multi-copy network for task-oriented dialogue system',\n",
       "  'abstract': 'Task-oriented dialogue (ToD) system aims to assist users in completing various tasks, which has attracted great interest from researchers. However, the current models introduce delexicalization prepossessing to improve the generalization ability of the models, which makes it difficult to integrate dialogue slots into response generation, resulting in unsatisfactory performance for users. In this paper, we propose a structure knowledge-enhanced multi-copy network (KMc-ToD) for the ToD system, which uses the multi-copy mechanism to selectively copy dialogue slots from the dialogue history and schema graph into the response. Furthermore, to select the appropriate slots, we design the schema graph that helps the model understand the relation between different slots. Specifically, this graph adjusts the weights between nodes according to different utterances to prevent introducing noise. Experimental results on the MultiWOZ datasets show that our model achieves promising performance.'},\n",
       " '10.1016/j.neucom.2023.126252': {'title': 'A graph attention network utilizing multi-granular information for emotion-cause pair extraction',\n",
       "  'abstract': 'Emotion-cause pair extraction (ECPE) aims to extract emotion and cause clauses underlying a text and pair them. Most of the recent approaches to this problem adopt deep neural networks to model the inter-clause dependency, without making full use of information at word level and document level. In this paper, we propose a model that utilizes multi-granular information, including word-level, clause-level, and document-level information, to facilitate emotion-cause pair extraction. Our model consists of two fully-connected clause graphs, including emotion graph and cause graph, and graph attention is applied to learn emotion-specific and cause-specific representations which are then used to generate document-level representations. To exploit the mutual indication between emotion and cause, a cross-graph co-attention mechanism is proposed. Moreover, external knowledge of emotional and causal cues is incorporated to provide word-level indicative information for emotion-cause pair extraction. The proposed model is tested on both Chinese [1] and English [2] datasets, and the results show that our model achieves the state-of-the-art performance on both datasets.'},\n",
       " '10.1016/j.knosys.2022.109822': {'title': 'An exploration of mutual information based on emotion–cause pair extraction',\n",
       "  'abstract': 'Emotion–cause pair extraction task (ECPE) aims to extract the emotions and causes from an unannotated text. The previous works are mostly limited to using deep networks to model the relation between the emotion clause and cause clause and lack exploration of the statistical dependence between them, such as the effects of emotion–cause causality on the mutual information of two clauses. In this paper, we preliminarily explore the difference between emotion–cause pairs and non emotion–cause pairs in their mutual information and further probe the relations among mutual information, emotion–cause pair, and their relative distance. Additionally, we find that mutual information can be used to measure the dependence strength of an emotion–cause causality on the context. Specifically, we formalize the ECPE as a probability problem and derive the joint distribution of the emotion clause and cause clause using the total probability formula. Based on the joint distribution, we estimate the mutual information (MI) between the emotion clause and cause clause, and further quantify the trend of mutual information in the training process. We conduct various experiments, and the experimental results show that our preliminary exploration is practical and effective. Meanwhile, we also prove our conjecture on the emotion–cause causality and mutual information.'},\n",
       " '10.1016/J.ASOC.2021.107818': {'title': 'Order-guided deep neural network for emotion-cause pair prediction',\n",
       "  'abstract': 'Emotion-Cause Pair Extraction (ECPE) is a prediction task aiming to extract the emotions and their corresponding causes in a target document. The existing methods for this problem mainly focus on modeling the dependence between emotion clauses and related cause clauses and the interaction among emotion-cause pairs. However, these methods ignore the order information between emotion clauses and their cause clauses, which can be proved useful for the ECPE task. In this paper, we propose an order-guided deep predictive model, which integrates different orders between emotion clauses and their cause clauses into an end-to-end framework to tackle this task. Specifically, we build an order-guided clause encoder with a three-level long-short term memory (LSTM) network to learn the different orders from forward LSTM, backward LSTM and Bi-LSTM, respectively. In this way, the deep networks with different directions can effectively capture different orders, and therefore improve the performance of our model in this prediction task. Additionally, the previous methods use only a shared word encoder to capture word-level emotion and cause information, resulting in paying more attention to emotion information and lacking the ability to capture cause information. In order to overcome this deficiency, we design both an emotion-aware word encoder and a cause-aware word encoder to enhance the ability to capture the emotion and cause information. The experiment results illustrate that our method outperforms the other baselines on two real-world datasets, and demonstrate the effectiveness of the proposed method.'},\n",
       " '10.1007/978-3-031-17120-8_45': {'title': 'Learning Emotion-Aware Contextual Representations for Emotion-Cause Pair Extraction',\n",
       "  'abstract': 'Emotion-Cause Pair Extraction (ECPE) focuses on analyzing emotions and its corresponding causes in a document. Two reasons have made ECPE a more challenging, but more applicable task than the previous Emotion-Cause Extraction (ECE) task: 1) an ECPE model needs to identify both emotions and their corresponding causes without the annotation of emotions. 2) the ECPE task involves finding causes for multiple emotions in a document, while ECE is for one emotion. However, existing ECPE methods fail to meet the second challenge, since they are evaluated on a dataset which exhibits a bias that nearly 90% of documents have only one emotion-cause pair. Thus, we reconstruct the dataset to better meet ECPE settings. We observe that previous SOTA approaches suffer from performance degradation in extracting multiple emotion-cause pairs due to the use of shared context encoder in the joint learning process. In this work, we propose a new pipelined approach that builds on two independent models with unshared context encoders, in which the emotion extraction model only provides input features for the cause extraction model. Experimental results demonstrate that our model can learn distinct contextual representations specific to each emotion, reaching state-of-the-art performance on both datasets and showing robustness in the analysis of more complex document context.'},\n",
       " '10.1016/j.neucom.2020.03.105': {'title': 'Joint multi-level attentional model for emotion detection and emotion-cause pair extraction',\n",
       "  'abstract': 'Emotion detection (ED) and emotion-cause pair extraction (ECPE) have drawn extensive research interests due to their wide applications in real-world scenarios. However, existing work fails to capture the implicit connection between two tasks. This limits the performances of these tasks. To address this issue, we propose a novel joint framework to take full advantage of the clause-level and word-level information about ED and ECPE tasks. Specifically, we explore a multi-level attentional module to model the relationship between two clauses in an emotion-cause pair. Results on two benchmark datasets show that our proposed model achieves the current best performance, outperforming the previous methods and strong neural baselines by a large margin. Our code is available at https://github.com/tomsonsgs/LVE-joint-MANN-master.'},\n",
       " '10.1016/J.KNOSYS.2019.03.008': {'title': 'Context-aware emotion cause analysis with multi-attention-based neural network',\n",
       "  'abstract': 'Emotion cause analysis has elicited wide interest in both academia and industry, and aims to identify the reasons behind certain emotions expressed in text. Most of the current studies on emotion cause analysis do not consider two types of information: i) the context of the emotional word, which can provide rich emotional details, and ii) the interaction between the candidate clause and the emotional clause (containing the emotional word). The above information is able to provide important clues in emotion cause analysis. In this paper, we propose a multi-attention-based neural network model to address this issue. First, our model encodes the clause via bidirectional long short-term memory, which can incorporate the contextual information of the word. Second, a multi-attention mechanism is designed to capture the mutual influences between the emotion clause and each candidate clause, and then generate the representations for the above two clauses separately. With this design, our model creates better-distributed representations of the emotion expressions and clauses. Finally, these representations are fed into a convolutional neural network to model the emotion cause clause. The experimental results show that our proposed approach outperforms the state-of-the-art baseline methods by a significant margin.'},\n",
       " '10.1016/j.aiopen.2024.01.003': {'title': 'An ecosystem for personal knowledge graphs: A survey and research roadmap',\n",
       "  'abstract': 'This paper presents an ecosystem for personal knowledge graphs (PKG), commonly defined as resources of structured information about entities related to an individual, their attributes, and the relations between them. PKGs are a key enabler of secure and sophisticated personal data management and personalized services. However, there are challenges that need to be addressed before PKGs can achieve widespread adoption. One of the fundamental challenges is the very definition of what constitutes a PKG, as there are multiple interpretations of the term. We propose our own definition of a PKG, emphasizing the aspects of (1) data ownership by a single individual and (2) the delivery of personalized services as the primary purpose. We further argue that a holistic view of PKGs is needed to unlock their full potential, and propose a unified framework for PKGs, where the PKG is a part of a larger ecosystem with clear interfaces towards data services and data sources. A comprehensive survey and synthesis of existing work is conducted, with a mapping of the surveyed work into the proposed unified ecosystem. Finally, we identify open challenges and research opportunities for the ecosystem as a whole, as well as for the specific aspects of PKGs, which include population, representation and management, and utilization.'},\n",
       " '10.1007/978-3-319-72926-8_28': {'title': 'Age and Gender Classification of Tweets Using Convolutional Neural Networks',\n",
       "  'abstract': 'Determining age and gender from a series of texts is useful for areas such as business intelligence and digital forensics. We explore the use of convolutional neural networks together with word2vec word embeddings for this task in comparison to handcrafted features. The network constructed consists of five layers and is trained using adadelta. It starts with an embedding layer where a word is represented by a vector, followed by a convolutional layer composed of three filters, each with 100 feature maps. It is followed by a max-over-time pooling layer which is done on each map and the resulting features are concatenated before a dropout layer and a softmax layer. The network was trained to classify age and gender for English and Spanish tweets. The predictions per tweet were aggregated using the majority prediction as the final prediction for the user who gave the tweets. The results outperform previous experiments. The highest English age and gender classification accuracy obtained are 49.6% and 72.1% respectively. The highest Spanish age and gender classification accuracy obtained on the other hand are 56.0% and 69.3% respectively.'},\n",
       " '10.1007/978-3-642-22362-4_1': {'title': 'Analyzing User Modeling on Twitter for Personalized News Recommendations',\n",
       "  'abstract': 'How can micro-blogging activities on Twitter be leveraged for user modeling and personalization? In this paper we investigate this question and introduce a framework for user modeling on Twitter which enriches the semantics of Twitter messages (tweets) and identifies topics and entities (e.g. persons, events, products) mentioned in tweets. We analyze how strategies for constructing hashtag-based, entity-based or topic-based user profiles benefit from semantic enrichment and explore the temporal dynamics of those profiles. We further measure and compare the performance of the user modeling strategies in context of a personalized news recommendation system. Our results reveal how semantic enrichment enhances the variety and quality of the generated user profiles. Further, we see how the different user modeling strategies impact personalization and discover that the consideration of temporal profile patterns can improve recommendation quality.'},\n",
       " '10.1016/j.neunet.2018.07.011': {'title': 'A systematic study of the class imbalance problem in convolutional neural networks',\n",
       "  'abstract': 'In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.'},\n",
       " '10.1201/B10440-6': {'title': 'Efficient Inference with Poor Instruments: A General Framework',\n",
       "  'abstract': 'This quote from Ragnar Frisch’s Editor’s Note in the first issue of Econometrica in 1933 has never seemed more timely. The phrase “data rich, information\\npoor” is often used to characterize the current state of our digitized world.\\nOver recent decades, data storage and availability has been growing at an\\nexponential rate, and currently, data sets on the order of terabytes are not\\nuncommon. While a portion of this new data is in the form of numerical or\\ncategorical data in well-structured databases, the vast majority is in the form\\nof unstructured textual data. These news stories, government reports, blog\\nentries, e-mails, Web pages, and the like are the medium of information flowof Empiricalthroughout the world. It is this unstructured data that most decision-makers\\nturn to for information.'},\n",
       " '10.1186/s41039-018-0082-z': {'title': 'Automatic distractor generation for multiple-choice English vocabulary questions',\n",
       "  'abstract': 'The use of automated systems in second-language learning could substantially reduce the workload of human teachers and test creators. This study proposes a novel method for automatically generating distractors for multiple-choice English vocabulary questions. The proposed method introduces new sources for collecting distractor candidates and utilises semantic similarity and collocation information when ranking the collected candidates. We evaluated the proposed method by administering the questions to real English learners. We further asked an expert to judge the quality of the distractors generated by the proposed method, a baseline method and humans. The results show that the proposed method produces fewer problematic distractors than the baseline method. Furthermore, the generated distractors have a quality that is comparable with that of human-made distractors.'},\n",
       " '10.1007/3-540-44581-1_7': {'title': 'Ultraconservative Online Algorithms for Multiclass Problems',\n",
       "  'abstract': 'In this paper we study online classification algorithms for multiclass problems in the mistake bound model. The hypotheses we use maintain one prototype vector per class. Given an input instance, a multiclass hypothesis computes a similarity-score between each prototype and the input instance and then sets the predicted label to be the index of the prototype achieving the highest similarity. To design and analyze the learning algorithms in this paper we introduce the notion of ultraconservativeness. Ultraconservative algorithms are algorithms that update only the prototypes attaining similarity-scores which are higher than the score of the correct label’s prototype. We start by describing a family of additive ultraconservative algorithms where each algorithm in the family updates its prototypes by finding a feasible solution for a set of linear constraints that depend on the instantaneous similarity-scores. We then discuss a specific online algorithm that seeks a set of prototypes which have a small norm. The resulting algorithm, which we term MIRA (for Margin Infused Relaxed Algorithm) is ultraconservative as well. We derive mistake bounds for all the algorithms and provide further analysis of MIRA using a generalized notion of the margin for multiclass problems.'},\n",
       " '10.1016/s0378-2166(98)00098-8': {'title': 'On mitigation',\n",
       "  'abstract': 'If saying is doing it must be an effective doing. Mitigation (or ‘downgrading’, German Abschwächung) is a cover-term for a set of strategies, rooted in a metapragmatic awareness, by which people try to make their saying-doing more effective. The notion of mitigation - outlined in Rhetorica ad Herennium (86-82 b.C.) and landed in pragmatics in the eigthies (Fraser, 1980), lends itself easily to connecting different fields (e.g. pragmatics and classical rhetoric), different categories (e.g. illocution and perlocution), and different perspectives (e.g. sociolinguistic and psycholinguistic approaches to communication). The aim of the present paper is to recast the issue of mitigation, which is defined as the result of the weakening of one of the interactional parameters, in a broad, integrated pragmatic framework by connecting different approaches to interaction, in particular rhetorical and psychological approaches. In the present work, which takes its data from a corpus of transcripts of doctor-patient and psychotherapeutic conversations in Italian, different kinds of mitigators and mitigation strategies will be discussed along with the potential effects they release both with regard to their instrumental adequacy and the psychological distance they project between the interactants.'},\n",
       " '10.1016/J.DCM.2014.08.006': {'title': 'Languaging when contexts collapse: Audience design in social networking',\n",
       "  'abstract': 'This paper examines strategies of language choice in social networking interactions among multilingual young people on Facebook. In media studies the term “context collapse” describes the process by which online social networks bring together people from various social contexts, thereby creating a diverse networked audience. In online social networks that involve participants from different countries and language communities, language choice becomes a pertinent issue. This paper draws on empirical data from social networks among young multilingual people on Facebook to examine strategies of language choice and negotiation. Drawing on the sociolinguistic framework of audience design, the sociolinguistics of multilingualism and computer-mediated discourse analysis, the analysis examines language choice in initiating and responding contributions, metapragmatic negotiations of language style and the role of English as a resource among networked writers.'},\n",
       " '10.1016/0010-0277(80)90009-8': {'title': 'Polite responses to polite requests',\n",
       "  'abstract': \"Indirect requests vary in politeness; for example, Can you tell me where Jordan Hall is? is more polite than Shouldn't you tell me where Jordan Hall is? By one theory, the more the literal meaning of a request implies personal benefits for the listener, within reason, the more polite is the request. This prediction was confirmed in Experiment 1. Responses to indirect requests also vary in politeness. For Can you tell me where Jordan Hall is?, the response Yes, I can — it's up the street is more polite than It's up the street. By an extension of that theory, the more attentive the responder is to all of the requester's meaning, the more polite is the response. This prediction was confirmed in Experiments 2, 3 and 4. From this evidence, we argued that people ordinarily compute both the literal and the indirect meanings of indirect requests. They must if they are to recognize when the speaker is and isn't being polite, and if they are to respond politely, impolitely, or even neutrally. Les demandes indirectes peuvent être formulées de façon plus ou moins polie. Par example “Can you tell me where Jordan Hall is?” (Pouvez-vous me dire oú se trouve Jordan Hall?) est plus poli que “Shouldn't you tell me where Jordan Hall is?” (Ne devriez-vous pas me dire oú se trouve Jordan Hall?). Une approche théorique propose que plus le sens littéral de la demande implique d'advantages personnels pour l'auditeur, dans les limites du raisonnable, plus polie est la demande. Cette prédiction est confirmée par l'Expérience 1. Les résponses aux demandes indirectes varient aussi en politesse. Pour “Can you tell me where Jordan Hall is?” (Pouvez-vous me dire oú se trouve Jordan Hall?) la résponse “Yes, I can — it's up the street” (Oui, je peux vous le dire, il se trouve en haut de la rue) est plus polie que “It's up the street” (C'est en haut de la rue). Une extension de la théorie permet de prédire que plus celui qui répond fait attention à tous les sens impliqués par la requête, plus la résponse est polie. Les Expériences 2, 3 et 4 confirment cette prédiction. Avec ces preuves, nous proposons que les gens calculent les sens directs et indirects des demandes indirectes. Cela est nécessaire pour reconnaître quand le locuteur est polî ou ne l'est pas, et pour pouvoir réspondre poliment, impoliment ou de façon neutre.\"},\n",
       " '10.1002/9781118584194.CH14': {'title': 'Interactional Sociolinguistics <i>A Personal Perspective</i>',\n",
       "  'abstract': \"Interactional Sociolinguistics (IS) is an approach to discourse analysis that has its origin in the search for replicable methods of qualitative analysis that account for our ability to interpret what participants intend to convey in everyday communicative practice. A main IS theme is the inherent linguistic and cultural diversity of today's communicative environments. For the purpose of analysis, talk is treated as constituted by sequentially organized strings of speaking turns, such that by means of these turns conversationalists indicate the meaning of their actions and their understanding of prior actions. Apart from focusing on interpretations as such, IS analysis attempts to illustrate how these tasks are accomplished. It is for this reason that the analysis places so much stress on contextualization processes. A part of this chapter presents a more detailed discussion of the electrician's interview, but first, more background on basic IS assumptions.\"},\n",
       " '10.1016/j.ctim.2004.07.042': {'title': 'Conversation analysis',\n",
       "  'abstract': 'Conversation analysis (CA) is well established as a means of exploring the interactional detail of conventional healthcare encounters. It is also becoming increasingly popular in action to CAM. This article outlines the main features of CA, how it can be used in a CAM context, and the type of information it can be expected to reveal. Examples of original CA data obtained from CAM consultations are presented to illustrate the CA method.'},\n",
       " '10.1016/S0022-1031(75)80025-4': {'title': 'Disclosing oneself to a stranger: Reciprocity and its limits',\n",
       "  'abstract': \"Two experiments explored the determinants of self-disclosure between strangers in airport departure lounges. Experiment I focused on the effects of demand characteristics on self-disclosure reciprocity. Subjects were asked to provide either “handwriting samples” or written “self-descriptions.” More intimate and longer disclosures were provided in the self-description condition. Subjects in the self-description condition also tended to reciprocate the intimacy level of the experimenter's prior disclosure to a greater degree. These results were attributed to a process of modeling, in response to the demand characteristics of the situation. Experiment II employed the handwriting paradigm to probe the limits of self-disclosure reciprocity. The experimenter first disclosed himself at either a low, medium, or high level of intimacy, and he did so either nonpersonalistically (he simply copied a standard measage) or personalistically (he pretended to create the message specifically for the subject). It was predicted that in the nonpersonalistic conditions subjects would again model the experimenter's level of intimacy. In the personalistic conditions, however, considerations of trust were expected to supplement or supplant the modeling mechanism. In particular, the personalistic, high intimacy message was expected to give rise to suspicion rather than trust and, as a result, to elicit a reduced degree of self-disclosure. The results with respect to the length of the subjects' messages conformed closely to the predicted pattern. On a qualitative measure of intimacy, there was a less perfect fit between predictions and results. Other results from both studies concerned the impact of sex roles upon patterns of self-disclosure. In Experiment II it was also found that out-of-town visitors wrote longer messages than did local residents, suggesting the operation of a “passing stranger” effect.\"},\n",
       " '10.1007/s10115-023-02053-8': {'title': 'Sentiment analysis of tweets using text and graph multi-views learning',\n",
       "  'abstract': 'Abstract With the surge of deep learning framework, various studies have attempted to address the challenges of sentiment analysis of tweets (data sparsity, under-specificity, noise, and multilingual content) through text and network-based representation learning approaches. However, limited studies on combining the benefits of textual and structural (graph) representations for sentiment analysis of tweets have been carried out. This study proposes a multi-view learning framework ( end-to-end and ensemble-based ) that leverages both text-based and graph-based representation learning approaches to enrich the tweet representation for sentiment classification. The efficacy of the proposed framework is evaluated over three datasets using suitable baseline counterparts. From various experimental studies, it is observed that combining both textual and structural views can achieve better performance of sentiment classification tasks than its counterparts.'},\n",
       " '10.1016/j.ipm.2022.103095': {'title': 'Investigating the COVID-19 vaccine discussions on Twitter through a multilayer network-based approach',\n",
       "  'abstract': 'Modeling discussions on social networks is a challenging task, especially if we consider sensitive topics, such as politics or healthcare. However, the knowledge hidden in these debates helps to investigate trends and opinions and to identify the cohesion of users when they deal with a specific topic. To this end, we propose a general multilayer network approach to investigate discussions on a social network. In order to prove the validity of our model, we apply it on a Twitter dataset containing tweets concerning opinions on COVID-19 vaccines. We extract a set of relevant hashtags (i.e., gold-standard hashtags) for each line of thought (i.e., pro-vaxxer, neutral, and anti-vaxxer). Then, thanks to our multilayer network model, we figure out that the anti-vaxxers tend to have ego networks denser (+14.39%) and more cohesive (+64.2%) than the ones of pro-vaxxer, which leads to a higher number of interactions among anti-vaxxers than pro-vaxxers (+393.89%). Finally, we report a comparison between our approach and one based on single networks analysis. We prove the effectiveness of our model to extract influencers having ego networks with more nodes (+40.46%), edges (+39.36%), and interactions with their neighbors (+28.56%) with respect to the other approach. As a result, these influential users are much more important to analyze and can provide more valuable information.'},\n",
       " '10.1016/j.ipm.2024.103662': {'title': 'Deconstructing cultural appropriation in online communities: A multilayer network analysis approach',\n",
       "  'abstract': 'In this study, we introduce a novel multilayer network model designed to analyze complex social phenomena in online communities. The model captures intricate relationships between users, content, and specific aspects of social phenomena, providing a comprehensive framework for understanding these interactions. We applied this model to a dataset of over 1 million Reddit comments from January to April 2022, filtered for cultural appropriation-related keywords. Our quantitative analyses, based on Social Network Analysis techniques, revealed significant findings. For instance, a subreddit exhibited the highest user interaction, indicating a substantial level of engagement on this topic. Furthermore, the distribution of key contents across different subreddits was non-uniform, suggesting diverse levels of engagement across communities. The results of this research underscore the potential of our approach in providing a nuanced understanding of social phenomena in online communities, thereby contributing to future research in this field.'},\n",
       " '10.1016/j.eswa.2019.113090': {'title': 'Leveraging deep graph-based text representation for sentiment polarity applications',\n",
       "  'abstract': 'Over the last few years, machine learning over graph structures has manifested a significant enhancement in text mining applications such as event detection, opinion mining, and news recommendation. One of the primary challenges in this regard is structuring a graph that encodes and encompasses the features of textual data for the effective machine learning algorithm. Besides, exploration and exploiting of semantic relations is regarded as a principal step in text mining applications. However, most of the traditional text mining methods perform somewhat poor in terms of employing such relations. In this paper, we propose a sentence-level graph-based text representation which includes stop words to consider semantic and term relations. Then, we employ a representation learning approach on the combined graphs of sentences to extract the latent and continuous features of the documents. Eventually, the learned features of the documents are fed into a deep neural network for the sentiment classification task. The experimental results demonstrate that the proposed method substantially outperforms the related sentiment analysis approaches based on several benchmark datasets. Furthermore, our method can be generalized on different datasets without any dependency on pre-trained word embeddings.'},\n",
       " '10.1007/978-981-10-8438-6_2': {'title': 'A Deep Neural Architecture for Sentence-Level Sentiment Classification in Twitter Social Networking',\n",
       "  'abstract': 'This paper introduces a novel deep learning framework including a lexicon-based approach for sentence-level prediction of sentiment label distribution. We propose to first apply semantic rules and then use a Deep Convolutional Neural Network (DeepCNN) for character-level embeddings in order to increase information for word-level embedding. After that, a Bidirectional Long Short-Term Memory network (Bi-LSTM) produces a sentence-wide feature representation from the word-level embedding. We evaluate our approach on three twitter sentiment classification datasets. Experimental results show that our model can improve the classification accuracy of sentence-level sentiment analysis in Twitter social networking.'},\n",
       " '10.1016/j.datak.2017.06.001': {'title': 'Learning multiple layers of knowledge representation for aspect based sentiment analysis',\n",
       "  'abstract': 'Sentiment Analysis is the task of automatically discovering the exact sentimental ideas about a product (or service, social event, etc.) from customer textual comments (i.e. reviews) crawled from various social media resources. Recently, we can see the rising demand of aspect-based sentiment analysis, in which we need to determine sentiment ratings and importance degrees of product aspects. In this paper we propose a novel multi-layer architecture for representing customer reviews. We observe that the overall sentiment for a product is composed from sentiments of its aspects, and in turn each aspect has its sentiments expressed in related sentences which are also the compositions from their words. This observation motivates us to design a multiple layer architecture of knowledge representation for representing the different sentiment levels for an input text. This representation is then integrated into a neural network to form a model for prediction of product overall ratings. We will use the representation learning techniques including word embeddings and compositional vector models, and apply a back-propagation algorithm based on gradient descent to learn the model. This model consequently generates the aspect ratings as well as aspect weights (i.e. aspect importance degrees). Our experiment is conducted on a data set of reviews from hotel domain, and the obtained results show that our model outperforms the well-known methods in previous studies.'},\n",
       " '10.1016/j.knosys.2017.02.030': {'title': 'Learning representations from heterogeneous network for sentiment classification of product reviews',\n",
       "  'abstract': 'There have been increasing interests in natural language processing to explore effective methods in learning better representations of text for sentiment classification in product reviews. However, most existing methods do not consider subtle interplays among words appeared in review text, authors of reviews and products the reviews are associated with. In this paper, we make use of a heterogeneous network to model the shared polarity in product reviews and learn representations of users, products they commented on and words they used simultaneously. The basic idea is to first construct a heterogeneous network which links users, products, words appeared in product reviews, as well as the polarities of the words. Based on the constructed network, representations of nodes are learned using a network embedding method, which are subsequently incorporated into a convolutional neural network for sentiment analysis. Evaluations on the product reviews, including IMDB, Yelp 2013 and Yelp 2014 datasets, show that the proposed approach achieves the state-of-the-art performance.'},\n",
       " '10.1016/j.eswa.2016.10.065': {'title': 'Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN',\n",
       "  'abstract': 'Different types of sentences express sentiment in very different ways. Traditional sentence-level sentiment classification research focuses on one-technique-fits-all solution or only centers on one special type of sentences. In this paper, we propose a divide-and-conquer approach which first classifies sentences into different types, then performs sentiment analysis separately on sentences from each type. Specifically, we find that sentences tend to be more complex if they contain more sentiment targets. Thus, we propose to first apply a neural network based sequence model to classify opinionated sentences into three types according to the number of targets appeared in a sentence. Each group of sentences is then fed into a one-dimensional convolutional neural network separately for sentiment classification. Our approach has been evaluated on four sentiment classification datasets and compared with a wide range of baselines. Experimental results show that: (1) sentence type classification can improve the performance of sentence-level sentiment analysis; (2) the proposed approach achieves state-of-the-art results on several benchmarking datasets.'},\n",
       " '10.1016/j.joi.2009.01.003': {'title': 'Sentiment analysis: A combined approach',\n",
       "  'abstract': 'Sentiment analysis is an important current research area. This paper combines rule-based classification, supervised learning and machine learning into a new combined method. This method is tested on movie reviews, product reviews and MySpace comments. The results show that a hybrid classification can improve the classification effectiveness in terms of micro- and macro-averaged F1. F1 is a measure that takes both the precision and recall of a classifier’s effectiveness into account. In addition, we propose a semi-automatic, complementary approach in which each classifier can contribute to other classifiers to achieve a good level of effectiveness.'},\n",
       " '10.1016/S0169-7552(98)00110-X': {'title': 'The anatomy of a large-scale hypertextual Web search engine',\n",
       "  'abstract': 'In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The prototype with a full text and hyperlink database of at least 24 million pages is available at http://google.stanford.edu/ To engineer a search engine is a challenging task. Search engines index tens to hundreds of millions of Web pages involving a comparable number of distinct terms. They answer tens of millions of queries every day. Despite the importance of large-scale search engines on the Web, very little academic research has been done on them. Furthermore, due to rapid advance in technology and Web proliferation, creating a Web search engine today is very different from three years ago. This paper provides an in-depth description of our large-scale Web search engine — the first such detailed public description we know of to date. Apart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better search results. This paper addresses this question of how to build a practical large-scale system which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want.'},\n",
       " '10.1016/j.dss.2013.08.002': {'title': 'Sentiment classification: The contribution of ensemble learning',\n",
       "  'abstract': 'With the rapid development of information technologies, user-generated contents can be conveniently posted online. While individuals, businesses, and governments are interested in evaluating the sentiments behind this content, there are no consistent conclusions on which sentiment classification technologies are best. Recent studies suggest that ensemble learning methods may have potential applicability in sentiment classification. In this study, we conduct a comparative assessment of the performance of three popular ensemble methods (Bagging, Boosting, and Random Subspace) based on five base learners (Naive Bayes, Maximum Entropy, Decision Tree, K Nearest Neighbor, and Support Vector Machine) for sentiment classification. Moreover, ten public sentiment analysis datasets were investigated to verify the effectiveness of ensemble learning for sentiment analysis. Based on a total of 1200 comparative group experiments, empirical results reveal that ensemble methods substantially improve the performance of individual base learners for sentiment classification. Among the three ensemble methods, Random Subspace has the better comparative results, although it was seldom discussed in the literature. These results illustrate that ensemble learning methods can be used as a viable method for sentiment classification.'},\n",
       " '10.1016/j.neunet.2023.11.031': {'title': 'Grounding spatial relations in text-only language models',\n",
       "  'abstract': 'This paper shows that text-only Language Models (LM) can learn to ground spatial relations like left of or below if they are provided with explicit location information of objects and they are properly trained to leverage those locations. We perform experiments on a verbalized version of the Visual Spatial Reasoning (VSR) dataset, where images are coupled with textual statements which contain real or fake spatial relations between two objects of the image. We verbalize the images using an off-the-shelf object detector, adding location tokens to every object label to represent their bounding boxes in textual form. Given the small size of VSR, we do not observe any improvement when using locations, but pretraining the LM over a synthetic dataset automatically derived by us improves results significantly when using location tokens. We thus show that locations allow LMs to ground spatial relations, with our text-only LMs outperforming Vision-and-Language Models and setting the new state-of-the-art for the VSR dataset. Our analysis show that our text-only LMs can generalize beyond the relations seen in the synthetic dataset to some extent, learning also more useful information than that encoded in the spatial rules we used to create the synthetic dataset itself.'},\n",
       " '10.1038/s41593-022-01026-4': {'title': 'Shared computational principles for language processing in humans and deep language models',\n",
       "  'abstract': 'Departing from traditional linguistic models, advances in deep learning have resulted in a new type of predictive (autoregressive) deep language models (DLMs). Using a self-supervised next-word prediction task, these models generate appropriate linguistic responses in a given context. In the current study, nine participants listened to a 30-min podcast while their brain responses were recorded using electrocorticography (ECoG). We provide empirical evidence that the human brain and autoregressive DLMs share three fundamental computational principles as they process the same natural narrative: (1) both are engaged in continuous next-word prediction before word onset; (2) both match their pre-onset predictions to the incoming word to calculate post-onset surprise; (3) both rely on contextual embeddings to represent words in natural contexts. Together, our findings suggest that autoregressive DLMs provide a new and biologically feasible computational framework for studying the neural basis of language.'},\n",
       " '10.1186/s40537-021-00492-0': {'title': 'Text Data Augmentation for Deep Learning',\n",
       "  'abstract': 'Natural Language Processing (NLP) is one of the most captivating applications of Deep Learning. In this survey, we consider how the Data Augmentation training strategy can aid in its development. We begin with the major motifs of Data Augmentation summarized into strengthening local decision boundaries, brute force training, causality and counterfactual examples, and the distinction between meaning and form. We follow these motifs with a concrete list of augmentation frameworks that have been developed for text data. Deep Learning generally struggles with the measurement of generalization and characterization of overfitting. We highlight studies that cover how augmentations can construct test sets for generalization. NLP is at an early stage in applying Data Augmentation compared to Computer Vision. We highlight the key differences and promising ideas that have yet to be tested in NLP. For the sake of practical implementation, we describe tools that facilitate Data Augmentation such as the use of consistency regularization, controllers, and offline and online augmentation pipelines, to preview a few. Finally, we discuss interesting topics around Data Augmentation in NLP such as task-specific augmentations, the use of prior knowledge in self-supervised learning versus Data Augmentation, intersections with transfer and multi-task learning, and ideas for AI-GAs (AI-Generating Algorithms). We hope this paper inspires further research interest in Text Data Augmentation.'},\n",
       " '10.1016/j.tins.2021.04.005': {'title': 'Deep learning and the Global Workspace Theory',\n",
       "  'abstract': 'Recent advances in deep learning have allowed artificial intelligence (AI) to reach near human-level performance in many sensory, perceptual, linguistic, and cognitive tasks. There is a growing need, however, for novel, brain-inspired cognitive architectures. The Global Workspace Theory (GWT) refers to a large-scale system integrating and distributing information among networks of specialized modules to create higher-level forms of cognition and awareness. We argue that the time is ripe to consider explicit implementations of this theory using deep-learning techniques. We propose a roadmap based on unsupervised neural translation between multiple latent spaces (neural networks trained for distinct tasks, on distinct sensory inputs and/or modalities) to create a unique, amodal Global Latent Workspace (GLW). Potential functional advantages of GLW are reviewed, along with neuroscientific implications.'},\n",
       " '10.1016/S0364-0213(01)00061-1': {'title': 'Learning words from sights and sounds: a computational model',\n",
       "  'abstract': 'This paper presents an implemented computational model of word acquisition which learns directly from raw multimodal sensory input. Set in an information theoretic framework, the model acquires a lexicon by finding and statistically modeling consistent cross-modal structure. The model has been implemented in a system using novel speech processing, computer vision, and machine learning algorithms. In evaluations the model successfully performed speech segmentation, word discovery and visual categorization from spontaneous infant-directed speech paired with video images of single objects. These results demonstrate the possibility of using state-of-the-art techniques from sensory pattern recognition and machine learning to implement cognitive models which can process raw sensor data without the need for human transcription or labeling.'},\n",
       " '10.1007/978-3-030-89820-5_10': {'title': 'Nahuatl Neural Machine Translation Using Attention Based Architectures: A Comparative Analysis for RNNs and Transformers as a Mobile Application Service',\n",
       "  'abstract': 'Machine Translation is a problem that consists of automating the task of translating a sentence into another target language done by a computer, and is still in research, especially with low-resource languages. The neoteric introduction of attention techniques inside the Natural Language Processing (NLP) field in coalescence with a broader disposal of word-segmentation and Web Scrapping techniques; including the lack of a proper online tool translation for Nahuatl dialect, inspired this work in an effort to produce such a tool. Once availability of suitable corpus via Web Scrapping is searched for with scrutiny, therefore, doubling the state of the art in parallel phrases; several vocabulary files were produced using two sorts of word segmentation tools in order to extract the morphemes and break down the agglutination Nahuatl contains. By performing a comparative analysis between Recurrent Neural Networks (RNNs) and Transformers, incorporating two segmentation techniques and two different corpus, it is possible to improve the state of the art regarding Nahuatl by more than four times the BLEU score (66.45) with second validation by using a Fuzzy similarity library. Such experiments confirmed the hypothesis that by increasing the corpus size by double, using transformers and sub-word segmentation, a translation from Spanish to Nahuatl is the best approach that can be accomplished so far with the current tools; outperforming many times Statistical Machine Translation (SMT) and RNNs which do not contain attention, plus the deployment of an application that serves as a platform for the language.'},\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
