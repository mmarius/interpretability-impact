{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f6d26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173e3acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e641c178bc44b8be0f06812faa87ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83a91409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>semantic_scholar_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main.1004</td>\n",
       "      <td>AnswerFact: Fact Checking in Product Question ...</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.188</td>\n",
       "      <td>Product-related question answering platforms n...</td>\n",
       "      <td>4c61df1b4b9a164fec1a34587b4fffae029cd18c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main.1006</td>\n",
       "      <td>Knowledge-Grounded Dialogue Generation with Pr...</td>\n",
       "      <td>Dialog and Interactive Systems</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.272</td>\n",
       "      <td>We study knowledge-grounded dialogue generatio...</td>\n",
       "      <td>3447a432f724aa36595643446acda5b78943db19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main.1009</td>\n",
       "      <td>BiST: Bi-directional Spatio-Temporal Reasoning...</td>\n",
       "      <td>Dialog and Interactive Systems</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.145</td>\n",
       "      <td>Video-grounded dialogues are very challenging ...</td>\n",
       "      <td>f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main.1010</td>\n",
       "      <td>A Knowledge-Aware Sequence-to-Tree Network for...</td>\n",
       "      <td>NLP Applications</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.579</td>\n",
       "      <td>With the advancements in natural language proc...</td>\n",
       "      <td>24ed85ad966823868c1694a19385d01c6ad71008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main.1011</td>\n",
       "      <td>Knowledge Association with Hyperbolic Knowledg...</td>\n",
       "      <td>Information Extraction</td>\n",
       "      <td>EMNLP</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.18653/v1/2020.emnlp-main.460</td>\n",
       "      <td>Capturing associations for knowledge graphs (K...</td>\n",
       "      <td>3d61a28b9429fc8f7047fc379a0134a3765edbcb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>T4773</td>\n",
       "      <td>Rank-Aware Negative Training for Semi-Supervis...</td>\n",
       "      <td>Machine Learning for NLP</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1162/tacl_a_00574</td>\n",
       "      <td>Abstract Semi-supervised text classification-b...</td>\n",
       "      <td>79a502caa0b12573f56a7e8948459722aa891479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9251</th>\n",
       "      <td>T4777</td>\n",
       "      <td>Transparency Helps Reveal When Language Models...</td>\n",
       "      <td>Linguistic Theories, Cognitive Modeling, and P...</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1162/tacl_a_00565</td>\n",
       "      <td>Many current NLP systems are built from langua...</td>\n",
       "      <td>eee70790ced38b0fcf50351dbb3dcbdb582467e8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9252</th>\n",
       "      <td>T4803</td>\n",
       "      <td>Design Choices for Crowdsourcing Implicit Disc...</td>\n",
       "      <td>Discourse and Pragmatics</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1162/tacl_a_00586</td>\n",
       "      <td>Abstract Disagreement in natural language anno...</td>\n",
       "      <td>bf65a1b637e0f253abb8402fc9d0ab80db79aa92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>T4929</td>\n",
       "      <td>Time-and-Space-Efficient Weighted Deduction</td>\n",
       "      <td>Semantics: Sentence-level Semantics, Textual I...</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1162/tacl_a_00588</td>\n",
       "      <td>Abstract Many NLP algorithms have been describ...</td>\n",
       "      <td>f1803d124e5af7263ce656f7ccf3219eacc62b1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>T5043</td>\n",
       "      <td>Collective Human Opinions in Semantic Textual ...</td>\n",
       "      <td>Semantics: Sentence-level Semantics, Textual I...</td>\n",
       "      <td>ACL</td>\n",
       "      <td>2023</td>\n",
       "      <td>10.1162/tacl_a_00584</td>\n",
       "      <td>Abstract Despite the subjective nature of sema...</td>\n",
       "      <td>1fc4e904ed92da4b9af30e2eb5224ebe29e470b3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9255 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              title  \\\n",
       "0     main.1004  AnswerFact: Fact Checking in Product Question ...   \n",
       "1     main.1006  Knowledge-Grounded Dialogue Generation with Pr...   \n",
       "2     main.1009  BiST: Bi-directional Spatio-Temporal Reasoning...   \n",
       "3     main.1010  A Knowledge-Aware Sequence-to-Tree Network for...   \n",
       "4     main.1011  Knowledge Association with Hyperbolic Knowledg...   \n",
       "...         ...                                                ...   \n",
       "9250      T4773  Rank-Aware Negative Training for Semi-Supervis...   \n",
       "9251      T4777  Transparency Helps Reveal When Language Models...   \n",
       "9252      T4803  Design Choices for Crowdsourcing Implicit Disc...   \n",
       "9253      T4929        Time-and-Space-Efficient Weighted Deduction   \n",
       "9254      T5043  Collective Human Opinions in Semantic Textual ...   \n",
       "\n",
       "                                                   area source  year  \\\n",
       "0                                    Question Answering  EMNLP  2020   \n",
       "1                        Dialog and Interactive Systems  EMNLP  2020   \n",
       "2                        Dialog and Interactive Systems  EMNLP  2020   \n",
       "3                                      NLP Applications  EMNLP  2020   \n",
       "4                                Information Extraction  EMNLP  2020   \n",
       "...                                                 ...    ...   ...   \n",
       "9250                           Machine Learning for NLP    ACL  2023   \n",
       "9251  Linguistic Theories, Cognitive Modeling, and P...    ACL  2023   \n",
       "9252                           Discourse and Pragmatics    ACL  2023   \n",
       "9253  Semantics: Sentence-level Semantics, Textual I...    ACL  2023   \n",
       "9254  Semantics: Sentence-level Semantics, Textual I...    ACL  2023   \n",
       "\n",
       "                                  doi  \\\n",
       "0     10.18653/v1/2020.emnlp-main.188   \n",
       "1     10.18653/v1/2020.emnlp-main.272   \n",
       "2     10.18653/v1/2020.emnlp-main.145   \n",
       "3     10.18653/v1/2020.emnlp-main.579   \n",
       "4     10.18653/v1/2020.emnlp-main.460   \n",
       "...                               ...   \n",
       "9250             10.1162/tacl_a_00574   \n",
       "9251             10.1162/tacl_a_00565   \n",
       "9252             10.1162/tacl_a_00586   \n",
       "9253             10.1162/tacl_a_00588   \n",
       "9254             10.1162/tacl_a_00584   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     Product-related question answering platforms n...   \n",
       "1     We study knowledge-grounded dialogue generatio...   \n",
       "2     Video-grounded dialogues are very challenging ...   \n",
       "3     With the advancements in natural language proc...   \n",
       "4     Capturing associations for knowledge graphs (K...   \n",
       "...                                                 ...   \n",
       "9250  Abstract Semi-supervised text classification-b...   \n",
       "9251  Many current NLP systems are built from langua...   \n",
       "9252  Abstract Disagreement in natural language anno...   \n",
       "9253  Abstract Many NLP algorithms have been describ...   \n",
       "9254  Abstract Despite the subjective nature of sema...   \n",
       "\n",
       "                           semantic_scholar_id  \n",
       "0     4c61df1b4b9a164fec1a34587b4fffae029cd18c  \n",
       "1     3447a432f724aa36595643446acda5b78943db19  \n",
       "2     f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16  \n",
       "3     24ed85ad966823868c1694a19385d01c6ad71008  \n",
       "4     3d61a28b9429fc8f7047fc379a0134a3765edbcb  \n",
       "...                                        ...  \n",
       "9250  79a502caa0b12573f56a7e8948459722aa891479  \n",
       "9251  eee70790ced38b0fcf50351dbb3dcbdb582467e8  \n",
       "9252  bf65a1b637e0f253abb8402fc9d0ab80db79aa92  \n",
       "9253  f1803d124e5af7263ce656f7ccf3219eacc62b1c  \n",
       "9254  1fc4e904ed92da4b9af30e2eb5224ebe29e470b3  \n",
       "\n",
       "[9255 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cl_papers.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d2ca3e-8ebd-4d9d-9008-c9da5f116018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "def get_abstract_with_acl_anthology(doi):\n",
    "    url_path = doi.split('/')[-1]\n",
    "    url = 'https://aclanthology.org/' + url_path\n",
    "    r = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    css_selector = \"#main > div.row.acl-paper-details > div.col.col-lg-10.order-2 > div > div > span\"\n",
    "    element = soup.select_one(css_selector)\n",
    "    abstract = element.text\n",
    "    return abstract\n",
    "\n",
    "def get_abstract_from_semantic_scholar(paper_id):\n",
    "    query = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}\"\n",
    "    fields = \"abstract\"\n",
    "    response = requests.get(query, headers={\"x-api-key\": API_KEY}, params={\"fields\": fields})\n",
    "    paper_dict = response.json()\n",
    "\n",
    "    assert type(paper_dict['abstract']) == str\n",
    "    return paper_dict['abstract']\n",
    "\n",
    "\n",
    "def get_abstract_from_crossref(doi):\n",
    "    url = 'https://api.crossref.org/works/' + doi\n",
    "    r = requests.get(url)\n",
    "    response = r.json()\n",
    "    soup = bs4.BeautifulSoup(response['message']['abstract'], 'html.parser')\n",
    "    return soup.find('jats:p').text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b75f6d-158c-45d5-99f8-5589acc2b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstract(row):\n",
    "    doi = row['doi']\n",
    "    semantic_scholar_id = row['semantic_scholar_id']\n",
    "\n",
    "    try:\n",
    "        if not pd.isna(semantic_scholar_id):\n",
    "            abstract = get_abstract_from_semantic_scholar(semantic_scholar_id)\n",
    "            return abstract\n",
    "    except Exception as e:\n",
    "        print('failed to abstract from semantic scholar for', semantic_scholar_id)\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        if not pd.isna(doi):\n",
    "            abstract = get_abstract_with_acl_anthology(doi)\n",
    "            return abstract\n",
    "    except Exception as e:\n",
    "        print('failed to abstract from acl anthology for', doi)\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        if not pd.isna(doi):\n",
    "            abstract = get_abstract_from_crossref(doi)\n",
    "            return abstract\n",
    "    except Exception as e:\n",
    "        print('failed to abstract from semantic scholar for', doi)\n",
    "        print(e)\n",
    "\n",
    "    print('no source has the abstract for', doi)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bf7f13b-8fd2-4500-a533-4462f75769dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtAugment: Intent Detection Meta-Learning through Unsupervised Diverse Paraphrasing\n",
      "Multi-Source Multi-Type Knowledge Exploration and Exploitation for Dialogue Generation\n",
      "DUMB: A Dutch Model Benchmark\n",
      "`Don't Get Too Technical with Me': A Discourse Structure-Based Framework for Automatic Science Journalism\n",
      "A Framework for Vision-Language Warm-up Tasks in Multimodal Dialogue Models\n",
      "Exploring Linguistic Probes for Morphological Inflection\n",
      "It Ain't Over: A Multi-aspect Diverse Math Word Problem Dataset\n",
      "PhenotypeCLIP: Phenotype-based Contrastive Learning for Medical Imaging Report Generation\n",
      "Improving Author Attribute Prediction by Retrofitting Linguistic Representations with Homophily\n",
      "Identifying the narrative styles of YouTubeâ€™s vloggers\n",
      "Card-660: A Reliable Evaluation Framework for Rare Word Representation Models\n",
      "Personalized Microblog Sentiment Classification via Adversarial Cross-lingual learning\n",
      "Bootstrapping Transliteration with Guided Discovery for Low-Resource Languages\n",
      "XNLI: Cross-lingual Sentence Understanding through Inference\n"
     ]
    }
   ],
   "source": [
    "### some papers did not have their abstract by any of the sources\n",
    "### these abstracts where added manually\n",
    "\n",
    "title_to_doi = {\n",
    "\"ProtAugment: Intent Detection Meta-Learning through Unsupervised Diverse Paraphrasing\": '10.18653/v1/2021.acl-long.191',\n",
    "\"Multi-Source Multi-Type Knowledge Exploration and Exploitation for Dialogue Generation\": '10.18653/v1/2023.emnlp-main.771',\n",
    "\"DUMB: A Dutch Model Benchmark\": '10.18653/v1/2023.emnlp-main.447',\n",
    "\"`Don't Get Too Technical with Me': A Discourse Structure-Based Framework for Automatic Science Journalism\": '10.18653/v1/2023.emnlp-main.76',\n",
    "\"A Framework for Vision-Language Warm-up Tasks in Multimodal Dialogue Models\": '10.18653/v1/2023.emnlp-main.167',\n",
    "\"Exploring Linguistic Probes for Morphological Inflection\": '10.18653/v1/2023.emnlp-main.552',\n",
    "\"It Ain't Over: A Multi-aspect Diverse Math Word Problem Dataset\": '10.18653/v1/2023.emnlp-main.927',\n",
    "\"PhenotypeCLIP: Phenotype-based Contrastive Learning for Medical Imaging Report Generation\": '10.18653/v1/2023.emnlp-main.989',\n",
    "\"Improving Author Attribute Prediction by Retrofitting Linguistic Representations with Homophily\": '10.18653/v1/D18-1070',\n",
    "\"Identifying the narrative styles of YouTubeâ€™s vloggers\": '10.18653/v1/D18-1394',\n",
    "\"Card-660: A Reliable Evaluation Framework for Rare Word Representation Models\": '10.18653/v1/D18-1169',\n",
    "\"Personalized Microblog Sentiment Classification via Adversarial Cross-lingual learning\": '10.18653/v1/D18-1031',\n",
    "\"Bootstrapping Transliteration with Guided Discovery for Low-Resource Languages\": '10.18653/v1/D18-1046',\n",
    "\"XNLI: Cross-lingual Sentence Understanding through Inference\": '10.18653/v1/D18-1269',\n",
    "}\n",
    "\n",
    "for title, doi in title_to_doi.items():\n",
    "    print(title)\n",
    "    assert len(df[df['title'] == title]) == 1\n",
    "    df.loc[df['title'] == title, 'doi'] = doi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee448a78-2e53-4670-830a-276b1ac79ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                      | 5205/9255 [00:00<00:00, 52044.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to abstract from semantic scholar for c981f606740220fcac476a552d9353a825ea4aa9\n",
      "\n",
      "failed to abstract from semantic scholar for d240ea959f383411983a536089aeeab6bdf0163d\n",
      "\n",
      "failed to abstract from semantic scholar for 74fe9a7742c362e4235af69fab75c7f0e381a5e0\n",
      "\n",
      "failed to abstract from semantic scholar for 8106093c872e3818bfcd9001ed1f0a0ae1965e02\n",
      "\n",
      "failed to abstract from semantic scholar for 7b95148986fe48e09cfe80df5518e466a42d4e4c\n",
      "\n",
      "failed to abstract from semantic scholar for 3759c5853d4b26c011d70c0bb290a00e1015a610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9255/9255 [00:11<00:00, 837.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    if pd.isna(df.iloc[i]['abstract']):\n",
    "        abstract = get_abstract(df.iloc[i])\n",
    "        df.iloc[i, df.columns.get_loc('abstract')] = abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eabd6ba3-7798-42dd-ba6b-89c634abce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/cl_papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0599a9c3-bcad-46ac-b94e-0f4df9cff7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>semantic_scholar_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, title, area, source, year, doi, abstract, semantic_scholar_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['abstract'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc56fe48-62f2-464b-b0de-c4c5389e060e",
   "metadata": {},
   "source": [
    "# Computing the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3775373c-71d7-4c8b-90c5-3268ec959a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3dfe5fa72b45db96d9bb8077a2c044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9282/9282 [14:28<00:00, 10.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from adapters import AutoAdapterModel\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/specter2_base')\n",
    "\n",
    "model = AutoAdapterModel.from_pretrained(\"allenai/specter2_base\")\n",
    "adapter_name = model.load_adapter(\"allenai/specter2_classification\", source=\"hf\", set_active=True)\n",
    "\n",
    "def get_embedding(paper_row):\n",
    "    text = paper_row['title'] + tokenizer.sep_token + paper_row['abstract']\n",
    "    inputs = tokenizer(text,\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\",\n",
    "                       return_token_type_ids=False,\n",
    "                       max_length=2048)\n",
    "    output = model(**inputs)\n",
    "    embeddings = output.last_hidden_state[:, 0, :][0].detach().numpy()\n",
    "    return embeddings\n",
    "\n",
    "processed_df['embedding'] = processed_df.progress_apply(get_embedding, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb96294a-6ffd-4f6a-80db-ed01dddcfbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>interpretability</th>\n",
       "      <th>doi</th>\n",
       "      <th>source</th>\n",
       "      <th>working_doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main.8</td>\n",
       "      <td>Large Scale Multi-Actor Generative Dialog Mode...</td>\n",
       "      <td>Dialogue and Interactive Systems</td>\n",
       "      <td>False</td>\n",
       "      <td>10.18653/v1/2020.acl-main.8</td>\n",
       "      <td>ACL2020</td>\n",
       "      <td>True</td>\n",
       "      <td>Non-goal oriented dialog agents (i.e. chatbots...</td>\n",
       "      <td>[-0.55811894, -0.12536883, -0.06339799, -1.815...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main.52</td>\n",
       "      <td>CDL: Curriculum Dual Learning for Emotion-Cont...</td>\n",
       "      <td>Dialogue and Interactive Systems</td>\n",
       "      <td>False</td>\n",
       "      <td>10.18653/v1/2020.acl-main.52</td>\n",
       "      <td>ACL2020</td>\n",
       "      <td>True</td>\n",
       "      <td>Emotion-controllable response generation is an...</td>\n",
       "      <td>[-1.1278496, -0.5229794, 0.0056311972, -1.3223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main.46</td>\n",
       "      <td>Emergence of Syntax Needs Minimal Supervision</td>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Ma...</td>\n",
       "      <td>False</td>\n",
       "      <td>10.18653/v1/2020.acl-main.46</td>\n",
       "      <td>ACL2020</td>\n",
       "      <td>True</td>\n",
       "      <td>This paper is a theoretical contribution to th...</td>\n",
       "      <td>[0.26176804, 0.8106163, 0.27426642, -1.174295,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main.359</td>\n",
       "      <td>Selecting Backtranslated Data from Multiple So...</td>\n",
       "      <td>Machine Translation</td>\n",
       "      <td>False</td>\n",
       "      <td>10.18653/v1/2020.acl-main.359</td>\n",
       "      <td>ACL2020</td>\n",
       "      <td>True</td>\n",
       "      <td>Machine translation (MT) has benefited from us...</td>\n",
       "      <td>[-0.43927717, 1.0674063, 0.08589529, -0.437168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main.417</td>\n",
       "      <td>ParaCrawl: Web-Scale Acquisition of Parallel C...</td>\n",
       "      <td>Resources and Evaluation</td>\n",
       "      <td>False</td>\n",
       "      <td>10.18653/v1/2020.acl-main.417</td>\n",
       "      <td>ACL2020</td>\n",
       "      <td>True</td>\n",
       "      <td>We report on methods to create the largest pub...</td>\n",
       "      <td>[-0.3593886, 0.33652788, -0.026537634, -0.7595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9277</th>\n",
       "      <td>889</td>\n",
       "      <td>Multimodal Transformer for Unaligned Multimoda...</td>\n",
       "      <td>Vision, Robotics, Multimodal, Grounding and Sp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P19-1656</td>\n",
       "      <td>ACL2019</td>\n",
       "      <td>True</td>\n",
       "      <td>Human language is often multimodal, which comp...</td>\n",
       "      <td>[-0.25314885, -0.08230631, -0.3357741, -1.7636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9278</th>\n",
       "      <td>2155</td>\n",
       "      <td>Show, Describe and Conclude: On Exploiting the...</td>\n",
       "      <td>Vision, Robotics, Multimodal, Grounding and Sp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P19-1657</td>\n",
       "      <td>ACL2019</td>\n",
       "      <td>True</td>\n",
       "      <td>Chest X-Ray (CXR) images are commonly used for...</td>\n",
       "      <td>[-0.488766, -0.30718938, -1.3068513, -0.397652...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9279</th>\n",
       "      <td>384</td>\n",
       "      <td>Visual Story Post-Editing</td>\n",
       "      <td>Vision, Robotics, Multimodal, Grounding and Sp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P19-1658</td>\n",
       "      <td>ACL2019</td>\n",
       "      <td>True</td>\n",
       "      <td>We introduce the first dataset for human edits...</td>\n",
       "      <td>[-0.63484645, -0.21893704, 0.09538727, -0.8349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9280</th>\n",
       "      <td>1891</td>\n",
       "      <td>Multimodal Abstractive Summarization for How2 ...</td>\n",
       "      <td>Vision, Robotics, Multimodal, Grounding and Sp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P19-1659</td>\n",
       "      <td>ACL2019</td>\n",
       "      <td>True</td>\n",
       "      <td>In this paper, we study abstractive summarizat...</td>\n",
       "      <td>[-0.9391148, -0.115553305, -0.06912733, -1.159...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>2118</td>\n",
       "      <td>Learning to Relate from Captions and Bounding ...</td>\n",
       "      <td>Vision, Robotics, Multimodal, Grounding and Sp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P19-1660</td>\n",
       "      <td>ACL2019</td>\n",
       "      <td>True</td>\n",
       "      <td>In this work, we propose a novel approach that...</td>\n",
       "      <td>[-0.4750144, 0.19817561, -0.35619363, -0.61330...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9282 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "0       main.8  Large Scale Multi-Actor Generative Dialog Mode...   \n",
       "1      main.52  CDL: Curriculum Dual Learning for Emotion-Cont...   \n",
       "2      main.46      Emergence of Syntax Needs Minimal Supervision   \n",
       "3     main.359  Selecting Backtranslated Data from Multiple So...   \n",
       "4     main.417  ParaCrawl: Web-Scale Acquisition of Parallel C...   \n",
       "...        ...                                                ...   \n",
       "9277       889  Multimodal Transformer for Unaligned Multimoda...   \n",
       "9278      2155  Show, Describe and Conclude: On Exploiting the...   \n",
       "9279       384                          Visual Story Post-Editing   \n",
       "9280      1891  Multimodal Abstractive Summarization for How2 ...   \n",
       "9281      2118  Learning to Relate from Captions and Bounding ...   \n",
       "\n",
       "                                                   area interpretability  \\\n",
       "0                      Dialogue and Interactive Systems            False   \n",
       "1                      Dialogue and Interactive Systems            False   \n",
       "2     Theory and Formalism in NLP (Linguistic and Ma...            False   \n",
       "3                                   Machine Translation            False   \n",
       "4                              Resources and Evaluation            False   \n",
       "...                                                 ...              ...   \n",
       "9277  Vision, Robotics, Multimodal, Grounding and Sp...              NaN   \n",
       "9278  Vision, Robotics, Multimodal, Grounding and Sp...              NaN   \n",
       "9279  Vision, Robotics, Multimodal, Grounding and Sp...              NaN   \n",
       "9280  Vision, Robotics, Multimodal, Grounding and Sp...              NaN   \n",
       "9281  Vision, Robotics, Multimodal, Grounding and Sp...              NaN   \n",
       "\n",
       "                                doi   source  working_doi  \\\n",
       "0       10.18653/v1/2020.acl-main.8  ACL2020         True   \n",
       "1      10.18653/v1/2020.acl-main.52  ACL2020         True   \n",
       "2      10.18653/v1/2020.acl-main.46  ACL2020         True   \n",
       "3     10.18653/v1/2020.acl-main.359  ACL2020         True   \n",
       "4     10.18653/v1/2020.acl-main.417  ACL2020         True   \n",
       "...                             ...      ...          ...   \n",
       "9277           10.18653/v1/P19-1656  ACL2019         True   \n",
       "9278           10.18653/v1/P19-1657  ACL2019         True   \n",
       "9279           10.18653/v1/P19-1658  ACL2019         True   \n",
       "9280           10.18653/v1/P19-1659  ACL2019         True   \n",
       "9281           10.18653/v1/P19-1660  ACL2019         True   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     Non-goal oriented dialog agents (i.e. chatbots...   \n",
       "1     Emotion-controllable response generation is an...   \n",
       "2     This paper is a theoretical contribution to th...   \n",
       "3     Machine translation (MT) has benefited from us...   \n",
       "4     We report on methods to create the largest pub...   \n",
       "...                                                 ...   \n",
       "9277  Human language is often multimodal, which comp...   \n",
       "9278  Chest X-Ray (CXR) images are commonly used for...   \n",
       "9279  We introduce the first dataset for human edits...   \n",
       "9280  In this paper, we study abstractive summarizat...   \n",
       "9281  In this work, we propose a novel approach that...   \n",
       "\n",
       "                                              embedding  \n",
       "0     [-0.55811894, -0.12536883, -0.06339799, -1.815...  \n",
       "1     [-1.1278496, -0.5229794, 0.0056311972, -1.3223...  \n",
       "2     [0.26176804, 0.8106163, 0.27426642, -1.174295,...  \n",
       "3     [-0.43927717, 1.0674063, 0.08589529, -0.437168...  \n",
       "4     [-0.3593886, 0.33652788, -0.026537634, -0.7595...  \n",
       "...                                                 ...  \n",
       "9277  [-0.25314885, -0.08230631, -0.3357741, -1.7636...  \n",
       "9278  [-0.488766, -0.30718938, -1.3068513, -0.397652...  \n",
       "9279  [-0.63484645, -0.21893704, 0.09538727, -0.8349...  \n",
       "9280  [-0.9391148, -0.115553305, -0.06912733, -1.159...  \n",
       "9281  [-0.4750144, 0.19817561, -0.35619363, -0.61330...  \n",
       "\n",
       "[9282 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd1c114c-5560-411a-b87a-c1d346dff6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv('../data/new_classifier_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
