{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from acl_anthology import Anthology\n",
    "# Instantiate the Anthology from the official repository\n",
    "# This will download the Anthology once at the beginning\n",
    "anthology = Anthology.from_repo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9788\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/parsed_data.csv\", sep=\",\", index_col=0)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>interpretability</th>\n",
       "      <th>doi</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>Pre-training Multi-party Dialogue Models with ...</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.acl-long.533</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>Dual-Gated Fusion with Prefix-Tuning for Multi...</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.findings-acl.572</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>Aerial Vision-and-Dialog Navigation</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.findings-acl.190</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Fixing MoE Over-Fitting on Low-Resource Langua...</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.findings-acl.897</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>A Survey of Deep Learning for Mathematical Rea...</td>\n",
       "      <td>Posters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.acl-long.817</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title            area  \\\n",
       "0  21  Pre-training Multi-party Dialogue Models with ...  Virtual Poster   \n",
       "1  23  Dual-Gated Fusion with Prefix-Tuning for Multi...  Virtual Poster   \n",
       "2  25                Aerial Vision-and-Dialog Navigation  Virtual Poster   \n",
       "3  34  Fixing MoE Over-Fitting on Low-Resource Langua...  Virtual Poster   \n",
       "4  35  A Survey of Deep Learning for Mathematical Rea...         Posters   \n",
       "\n",
       "  interpretability                                doi   source  \n",
       "0              NaN      10.18653/v1/2023.acl-long.533  ACL2023  \n",
       "1              NaN  10.18653/v1/2023.findings-acl.572  ACL2023  \n",
       "2              NaN  10.18653/v1/2023.findings-acl.190  ACL2023  \n",
       "3              NaN  10.18653/v1/2023.findings-acl.897  ACL2023  \n",
       "4              NaN      10.18653/v1/2023.acl-long.817  ACL2023  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>interpretability</th>\n",
       "      <th>doi</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104</td>\n",
       "      <td>Investigating Glyph-Phonetic Information for C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>286</td>\n",
       "      <td>Do Androids Laugh at Electric Sheep? Humor \"Un...</td>\n",
       "      <td>Posters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>366</td>\n",
       "      <td>A  Set Prediction Network For Extractive Summa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>415</td>\n",
       "      <td>Do Large Language Models Know What They Don't ...</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>807</td>\n",
       "      <td>Bridging the Domain Gaps in Context Representa...</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title            area  \\\n",
       "21   104  Investigating Glyph-Phonetic Information for C...             NaN   \n",
       "78   286  Do Androids Laugh at Electric Sheep? Humor \"Un...         Posters   \n",
       "110  366  A  Set Prediction Network For Extractive Summa...             NaN   \n",
       "127  415  Do Large Language Models Know What They Don't ...  Virtual Poster   \n",
       "276  807  Bridging the Domain Gaps in Context Representa...  Virtual Poster   \n",
       "\n",
       "    interpretability  doi   source  \n",
       "21               NaN  NaN  ACL2023  \n",
       "78               NaN  NaN  ACL2023  \n",
       "110              NaN  NaN  ACL2023  \n",
       "127              NaN  NaN  ACL2023  \n",
       "276              NaN  NaN  ACL2023  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_doi = df[df['doi'].isna()]\n",
    "print(len(df_no_doi))\n",
    "df_no_doi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>interpretability</th>\n",
       "      <th>doi</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>Pre-training Multi-party Dialogue Models with ...</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.acl-long.533</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>Dual-Gated Fusion with Prefix-Tuning for Multi...</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.findings-acl.572</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>Aerial Vision-and-Dialog Navigation</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.findings-acl.190</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Fixing MoE Over-Fitting on Low-Resource Langua...</td>\n",
       "      <td>Virtual Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.findings-acl.897</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>A Survey of Deep Learning for Mathematical Rea...</td>\n",
       "      <td>Posters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/2023.acl-long.817</td>\n",
       "      <td>ACL2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title            area  \\\n",
       "0  21  Pre-training Multi-party Dialogue Models with ...  Virtual Poster   \n",
       "1  23  Dual-Gated Fusion with Prefix-Tuning for Multi...  Virtual Poster   \n",
       "2  25                Aerial Vision-and-Dialog Navigation  Virtual Poster   \n",
       "3  34  Fixing MoE Over-Fitting on Low-Resource Langua...  Virtual Poster   \n",
       "4  35  A Survey of Deep Learning for Mathematical Rea...         Posters   \n",
       "\n",
       "  interpretability                                doi   source  \n",
       "0              NaN      10.18653/v1/2023.acl-long.533  ACL2023  \n",
       "1              NaN  10.18653/v1/2023.findings-acl.572  ACL2023  \n",
       "2              NaN  10.18653/v1/2023.findings-acl.190  ACL2023  \n",
       "3              NaN  10.18653/v1/2023.findings-acl.897  ACL2023  \n",
       "4              NaN      10.18653/v1/2023.acl-long.817  ACL2023  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doi = df[df['doi'].notna()]\n",
    "print(len(df_doi))\n",
    "df_doi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(df_no_doi[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Investigating Glyph-Phonetic Information for Chinese Spell Checking: What Works and What's Next?\",\n",
       " 'Do Androids Laugh at Electric Sheep? Humor \"Understanding\" Benchmarks from The New Yorker Caption Contest',\n",
       " 'A  Set Prediction Network For Extractive Summarization',\n",
       " \"Do Large Language Models Know What They Don't Know?\",\n",
       " 'Bridging the Domain Gaps in Context Representations for $k$-Nearest Neighbor Neural Machine Translation',\n",
       " \"Where's the Point? Self-Supervised Multilingual Punctuation-Agnostic Sentence Segmentation\",\n",
       " 'On \"Scientific Debt\" in NLP: A Case for More Rigour in Language Model Pre-Training Research',\n",
       " \"CDA: A Contrastive Data Augmentation Method for Alzheimer's Disease Detection\",\n",
       " 'Coarse-to-Fine Contribution Network for Multimodal Summarization',\n",
       " 'Rethinking Document-Level Relation Extraction:  A Reality Check']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 36/436 [01:58<25:29,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Shu ̄o Wén Jiˇe Zì: Rethinking Dictionaries and Glyphs for Chinese Language Pre-training\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 70/436 [04:28<26:34,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Mapping Text to Knowledge Graph Entities by Vector Space Transformation\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Mapping Text to Knowledge Graph Entities by Vector Space Transformation\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Mapping Text to Knowledge Graph Entities by Vector Space Transformation\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 72/436 [04:54<45:53,  7.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Deep and Wide Reader: Effective Memory Augmenting Method for Large-Scale Reading Comprehension\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Deep and Wide Reader: Effective Memory Augmenting Method for Large-Scale Reading Comprehension\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Deep and Wide Reader: Effective Memory Augmenting Method for Large-Scale Reading Comprehension\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 75/436 [05:31<52:01,  8.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Learning Neural Embeddings for CLIR with Adversarial Framework\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 76/436 [05:39<51:23,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Improving Author Attribute Prediction by Retrofitting Linguistic Representations with Homophily\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Improving Author Attribute Prediction by Retrofitting Linguistic Representations with Homophily\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Improving Author Attribute Prediction by Retrofitting Linguistic Representations with Homophily\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Improving Author Attribute Prediction by Retrofitting Linguistic Representations with Homophily\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 78/436 [06:18<1:14:38, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Part-of-Speech Tagging for Twitter by Different Expression Styles\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Part-of-Speech Tagging for Twitter by Different Expression Styles\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Part-of-Speech Tagging for Twitter by Different Expression Styles\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 81/436 [06:42<49:33,  8.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Modeling Inter-Aspect Relation in Aspect-Based Sentiment Analysis\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 86/436 [07:05<25:30,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Interpretable Emoji Prediction via Multi-Attention LSTMs\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 87/436 [07:12<31:10,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Variational Sequential Labelers for Semi-Supervised Sequence Labeling\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 88/436 [07:21<37:23,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Card-660: A Reliable Evaluation Framework for Rare Word Representation Models\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Card-660: A Reliable Evaluation Framework for Rare Word Representation Models\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Card-660: A Reliable Evaluation Framework for Rare Word Representation Models\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 89/436 [07:46<1:08:45, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Context-Attentive Embeddings for Improved Sentence Representations\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 91/436 [07:58<49:21,  8.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Spider: A Large-Scale Complex Human-Labeled SQL Corpus for Semantic Parsing and Text-to-SQL Generation\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Spider: A Large-Scale Complex Human-Labeled SQL Corpus for Semantic Parsing and Text-to-SQL Generation\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 95/436 [08:27<33:33,  5.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Process Paragraph Comprehension using World Knowledge\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Process Paragraph Comprehension using World Knowledge\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Process Paragraph Comprehension using World Knowledge\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Process Paragraph Comprehension using World Knowledge\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 97/436 [08:51<46:34,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: TwoWingOS: Claim Entailment with Precise Evidence via a Two-Wing Optimization Strategy\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: TwoWingOS: Claim Entailment with Precise Evidence via a Two-Wing Optimization Strategy\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: TwoWingOS: Claim Entailment with Precise Evidence via a Two-Wing Optimization Strategy\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: TwoWingOS: Claim Entailment with Precise Evidence via a Two-Wing Optimization Strategy\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 99/436 [09:30<1:10:51, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Neural Latent Relational Analysis to Capture Lexical Semantic Relation\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 100/436 [09:40<1:05:37, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Commonsense Action Explanation in Human-Agent Communication\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Commonsense Action Explanation in Human-Agent Communication\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Commonsense Action Explanation in Human-Agent Communication\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 101/436 [10:00<1:19:29, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Text, Visual and Acoustic are Friends! A Multi-Modal Attention Framework for Utterance-Level Sentiment Prediction\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Text, Visual and Acoustic are Friends! A Multi-Modal Attention Framework for Utterance-Level Sentiment Prediction\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Text, Visual and Acoustic are Friends! A Multi-Modal Attention Framework for Utterance-Level Sentiment Prediction\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Text, Visual and Acoustic are Friends! A Multi-Modal Attention Framework for Utterance-Level Sentiment Prediction\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 102/436 [10:43<2:07:30, 22.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Sentence Editing under Quantifiable Guidance\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 106/436 [10:59<46:30,  8.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Multi-Reference Training with Pseudo-Reference Generation for Text Generation\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 111/436 [11:22<24:14,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Task Oriented Parsing\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Task Oriented Parsing\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 113/436 [11:32<25:30,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Crosslingual Sense Embeddings in One Space\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Crosslingual Sense Embeddings in One Space\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Crosslingual Sense Embeddings in One Space\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 117/436 [11:56<24:50,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Adaptive Multi-pass Decoder for Neural Machine Translation with Reinforcement Learning\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 118/436 [12:08<35:38,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: XNLI: Cross-lingual Sentence Understanding through Inference\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: XNLI: Cross-lingual Sentence Understanding through Inference\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: XNLI: Cross-lingual Sentence Understanding through Inference\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 119/436 [12:30<1:00:05, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: The Importance of Joint Multilingual Supervision for Cross-lingual Entity Linking\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 121/436 [12:44<46:37,  8.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Training RNNs as Fast as CNNs\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Training RNNs as Fast as CNNs\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Training RNNs as Fast as CNNs\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Training RNNs as Fast as CNNs\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 123/436 [13:02<42:53,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Modeling Game-Based Video-Context Dialogue\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 125/436 [13:09<28:55,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Noise Contrastive Estimation for Conditional Models: Consistency and Statistical Efficiency\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 127/436 [13:23<30:34,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find a paper with title: Natural Language Processing Not-At-All from Scratch: Evaluating The Utility of Hand-crafted Features in Deep Learning\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Natural Language Processing Not-At-All from Scratch: Evaluating The Utility of Hand-crafted Features in Deep Learning\n",
      "Reducing similarity threshold.\n",
      "Couldn't find a paper with title: Natural Language Processing Not-At-All from Scratch: Evaluating The Utility of Hand-crafted Features in Deep Learning\n",
      "Reducing similarity threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 133/436 [14:21<32:41,  6.48s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paper_found:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m anthology\u001b[38;5;241m.\u001b[39mpapers():\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msimilar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[1;32m      9\u001b[0m             paper_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m             updated_titles\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(paper\u001b[38;5;241m.\u001b[39mtitle))\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36msimilar\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilar\u001b[39m(a, b):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSequenceMatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mratio()\n",
      "File \u001b[0;32m~/miniconda3/envs/semanticscholarapi/lib/python3.11/difflib.py:182\u001b[0m, in \u001b[0;36mSequenceMatcher.__init__\u001b[0;34m(self, isjunk, a, b, autojunk)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautojunk \u001b[38;5;241m=\u001b[39m autojunk\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seqs\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/semanticscholarapi/lib/python3.11/difflib.py:194\u001b[0m, in \u001b[0;36mSequenceMatcher.set_seqs\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set the two sequences to be compared.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m>>> s = SequenceMatcher()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m0.75\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_seq1(a)\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seq2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/semanticscholarapi/lib/python3.11/difflib.py:248\u001b[0m, in \u001b[0;36mSequenceMatcher.set_seq2\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatching_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopcodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfullbcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__chain_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/semanticscholarapi/lib/python3.11/difflib.py:281\u001b[0m, in \u001b[0;36mSequenceMatcher.__chain_b\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2j \u001b[38;5;241m=\u001b[39m b2j \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, elt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(b):\n\u001b[0;32m--> 281\u001b[0m     indices \u001b[38;5;241m=\u001b[39m b2j\u001b[38;5;241m.\u001b[39msetdefault(elt, [])\n\u001b[1;32m    282\u001b[0m     indices\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# Purge junk elements\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "updated_titles, missing_dois = [], []\n",
    "\n",
    "for idx, title in enumerate(tqdm(titles)):\n",
    "    paper_found = False\n",
    "    threshold = 0.9\n",
    "    while not paper_found:\n",
    "        for paper in anthology.papers():\n",
    "            if similar(title, str(paper.title)) >= threshold:\n",
    "                paper_found = True\n",
    "                updated_titles.append(str(paper.title))\n",
    "                missing_dois.append(str(paper.doi))\n",
    "                break\n",
    "        if not paper_found:\n",
    "            print(f\"Couldn't find a paper with title: {title}\")\n",
    "            print(\"Reducing similarity threshold.\")\n",
    "            threshold -= 0.1\n",
    "    # if idx > 5:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10.18653/v1/2023.findings-acl.1',\n",
       " '10.18653/v1/2023.acl-long.41',\n",
       " '10.18653/v1/2023.findings-acl.293',\n",
       " '10.18653/v1/2023.findings-acl.551',\n",
       " '10.18653/v1/2023.acl-long.321',\n",
       " '10.18653/v1/2023.acl-long.398',\n",
       " '10.18653/v1/2023.acl-long.477',\n",
       " '10.18653/v1/2023.findings-acl.114',\n",
       " '10.18653/v1/2023.acl-long.476',\n",
       " '10.18653/v1/2023.findings-acl.353',\n",
       " '10.18653/v1/2023.acl-long.244',\n",
       " '10.18653/v1/2023.findings-acl.895',\n",
       " '10.18653/v1/2023.findings-acl.352',\n",
       " '10.18653/v1/2023.findings-acl.426',\n",
       " '10.18653/v1/2023.acl-long.270',\n",
       " '10.18653/v1/2023.findings-acl.58',\n",
       " '10.18653/v1/2023.findings-acl.843',\n",
       " '10.18653/v1/2023.acl-long.469',\n",
       " '10.18653/v1/2023.findings-acl.771',\n",
       " '10.18653/v1/2023.findings-acl.165',\n",
       " '10.18653/v1/2023.findings-acl.550',\n",
       " '10.18653/v1/2023.acl-long.523',\n",
       " '10.18653/v1/2023.acl-long.697',\n",
       " '10.18653/v1/2023.findings-acl.280',\n",
       " '10.18653/v1/2023.findings-acl.892',\n",
       " '10.18653/v1/2023.findings-acl.100',\n",
       " '10.18653/v1/2023.acl-long.111',\n",
       " '10.18653/v1/2023.findings-acl.69',\n",
       " '10.18653/v1/2023.acl-short.70',\n",
       " '10.18653/v1/2023.acl-long.780',\n",
       " '10.18653/v1/2023.findings-acl.737',\n",
       " '10.18653/v1/2023.acl-long.309',\n",
       " '10.18653/v1/2023.acl-long.280',\n",
       " '10.18653/v1/2023.acl-long.489',\n",
       " '10.18653/v1/2023.findings-acl.641',\n",
       " '10.18653/v1/2023.acl-long.237',\n",
       " '10.18653/v1/2023.findings-acl.70',\n",
       " '10.18653/v1/2023.acl-long.23',\n",
       " '10.18653/v1/2023.findings-acl.23',\n",
       " '10.18653/v1/2023.findings-acl.560',\n",
       " '10.18653/v1/2023.acl-long.524',\n",
       " '10.18653/v1/2023.acl-long.472',\n",
       " '10.18653/v1/2023.findings-acl.527',\n",
       " '10.18653/v1/2023.acl-long.328',\n",
       " '10.18653/v1/2023.acl-long.98',\n",
       " '10.18653/v1/2023.acl-long.496',\n",
       " '10.18653/v1/2023.findings-acl.365',\n",
       " '10.18653/v1/2023.findings-acl.337',\n",
       " '10.18653/v1/2023.findings-acl.81',\n",
       " '10.18653/v1/2023.acl-long.598',\n",
       " '10.18653/v1/2023.findings-acl.822',\n",
       " '10.18653/v1/2023.findings-acl.448',\n",
       " '10.18653/v1/2023.findings-acl.515',\n",
       " '10.18653/v1/2023.findings-acl.819',\n",
       " '10.18653/v1/2023.acl-long.359',\n",
       " '10.18653/v1/2023.acl-long.781',\n",
       " '10.18653/v1/2023.acl-long.839',\n",
       " '10.18653/v1/2023.acl-long.1',\n",
       " '10.18653/v1/2023.acl-long.616',\n",
       " '10.18653/v1/2023.acl-long.150',\n",
       " '10.18653/v1/2023.findings-acl.90',\n",
       " '10.18653/v1/2023.acl-long.530',\n",
       " '10.18653/v1/2023.acl-long.166',\n",
       " '10.18653/v1/P18-2125',\n",
       " '10.18653/v1/P18-1256',\n",
       " '10.18653/v1/P18-1198',\n",
       " '10.18653/v1/P18-1105',\n",
       " '10.18653/v1/D18-1018',\n",
       " '10.18653/v1/D18-1517',\n",
       " '10.18653/v1/D18-1518',\n",
       " '10.18653/v1/D18-1221',\n",
       " '10.18653/v1/D18-1228',\n",
       " '10.18653/v1/W18-2603',\n",
       " '10.18653/v1/D18-1246',\n",
       " '10.18653/v1/D18-1495',\n",
       " '10.18653/v1/D18-1212',\n",
       " 'None',\n",
       " '10.18653/v1/D18-1272',\n",
       " 'None',\n",
       " '10.18653/v1/D18-1373',\n",
       " '10.18653/v1/D18-1375',\n",
       " '10.18653/v1/N18-2043',\n",
       " '10.18653/v1/D18-1394',\n",
       " '10.18653/v1/D18-1004',\n",
       " '10.18653/v1/D18-1467',\n",
       " '10.18653/v1/D18-1373',\n",
       " '10.18653/v1/D18-1508',\n",
       " '10.18653/v1/D18-1020',\n",
       " '10.18653/v1/D18-1169',\n",
       " '10.18653/v1/D18-1176',\n",
       " '10.18653/v1/D18-1193',\n",
       " '10.18653/v1/D18-1425',\n",
       " '10.18653/v1/D18-1195',\n",
       " '10.18653/v1/D18-1198',\n",
       " '10.18653/v1/D18-1210',\n",
       " 'None',\n",
       " '10.18653/v1/D18-1008',\n",
       " '10.18653/v1/D18-1010',\n",
       " '10.18653/v1/D18-1414',\n",
       " '10.18653/v1/D18-1058',\n",
       " '10.18653/v1/D19-6013',\n",
       " 'None',\n",
       " '10.18653/v1/D18-1420',\n",
       " '10.18653/v1/D18-1422',\n",
       " '10.18653/v1/D18-1438',\n",
       " '10.18653/v1/D18-1206',\n",
       " '10.18653/v1/D18-1357',\n",
       " '10.18653/v1/D18-1464',\n",
       " '10.18653/v1/D18-1466',\n",
       " '10.18653/v1/D18-1422',\n",
       " '10.18653/v1/D18-1297',\n",
       " '10.3115/980491.980538',\n",
       " '10.18653/v1/D18-1115',\n",
       " '10.18653/v1/P16-1157',\n",
       " '10.18653/v1/D18-1028',\n",
       " '10.18653/v1/D18-1031',\n",
       " '10.18653/v1/D18-1046',\n",
       " '10.18653/v1/D18-1048',\n",
       " '10.18653/v1/N18-1101',\n",
       " '10.18653/v1/D18-1270',\n",
       " '10.18653/v1/D18-1512',\n",
       " '10.3115/981967.982013',\n",
       " '10.18653/v1/D18-1482',\n",
       " '10.18653/v1/D18-1012',\n",
       " 'None',\n",
       " '10.18653/v1/D18-1405',\n",
       " '10.18653/v1/D18-1407',\n",
       " '10.18653/v1/D18-1310',\n",
       " '10.18653/v1/D18-1114',\n",
       " '10.18653/v1/2021.findings-emnlp.34',\n",
       " '10.18653/v1/2021.findings-emnlp.254',\n",
       " '10.18653/v1/2021.emnlp-main.789',\n",
       " '10.18653/v1/2021.emnlp-main.790']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Investigating Glyph-Phonetic Information for Chinese Spell Checking: What Works and What’s Next?',\n",
       " 'Do Androids Laugh at Electric Sheep? Humor “Understanding” Benchmarks from The New Yorker Caption Contest',\n",
       " 'A Set Prediction Network For Extractive Summarization',\n",
       " 'Do Large Language Models Know What They Don’t Know?',\n",
       " 'Bridging the Domain Gaps in Context Representations for k-Nearest Neighbor Neural Machine Translation',\n",
       " 'Where’s the Point? Self-Supervised Multilingual Punctuation-Agnostic Sentence Segmentation',\n",
       " 'On “Scientific Debt” in NLP: A Case for More Rigour in Language Model Pre-Training Research',\n",
       " 'CDA: A Contrastive Data Augmentation Method for Alzheimer’s Disease Detection',\n",
       " 'CFSum Coarse-to-Fine Contribution Network for Multimodal Summarization',\n",
       " 'Rethinking Document-Level Relation Extraction: A Reality Check',\n",
       " 'On Second Thought, Let’s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning',\n",
       " 'On the Expressivity Role of LayerNorm in Transformers’ Attention',\n",
       " 'Know What I don’t Know: Handling Ambiguous and Unknown Questions for Text-to-SQL',\n",
       " '“Low-Resource” Text Classification: A Parameter-Free Classification Method with Compressors',\n",
       " 'Don’t Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments',\n",
       " 'Structured Mean-Field Variational Inference for Higher-Order Span-Based Semantic Role Labeling',\n",
       " 'Don’t Lose Yourself! Empathetic Response Generation via Explicit Self-Other Awareness',\n",
       " 'Don’t Parse, Choose Spans! Continuous and Discontinuous Constituency Parsing via Autoregressive Span Selection',\n",
       " 'Efficient Document Embeddings via Self-Contrastive Bregman Divergence Learning',\n",
       " 'Together We Make Sense–Learning Meta-Sense Embeddings',\n",
       " 'Solving Cosine Similarity Underestimation between High Frequency Words by ℓ2 Norm Discounting',\n",
       " 'Log-linear Guardedness and its Implications',\n",
       " 'What’s the Meaning of Superhuman Performance in Today’s NLU?',\n",
       " 'Debiasing should be Good and Bad: Measuring the Consistency of Debiasing Techniques in Language Models',\n",
       " '“A Little is Enough”: Few-Shot Quality Estimation based Corpus Filtering improves Machine Translation',\n",
       " '2*n is better than n2: Decomposing Event Coreference Resolution into Two Tractable Problems',\n",
       " 'Tailoring Instructions to Student’s Learning Levels Boosts Knowledge Distillation',\n",
       " 'CLIPText: A New Paradigm for Zero-shot Text Classification',\n",
       " 'Counterfactual reasoning: Testing language models’ understanding of hypothetical scenarios',\n",
       " 'Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker',\n",
       " 'Know Where You’re Going: Meta-Learning for Parameter-Efficient Fine-Tuning',\n",
       " 'Won’t Get Fooled Again: Answering Questions with False Premises',\n",
       " 'Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to Pre-trained Language Models’ Memories',\n",
       " 'What does the Failure to Reason with “Respectively” in Zero/Few-Shot Settings Tell Us about Language Models?',\n",
       " 'NewsMet : A ‘do it all’ Dataset of Contemporary Metaphors in News Headlines',\n",
       " 'REDFM: a Filtered and Multilingual Relation Extraction Dataset',\n",
       " 'Rethinking Dictionaries and Glyphs for Chinese Language Pre-training',\n",
       " 'What about “em”? How Commercial Machine Translation Fails to Handle (Neo-)Pronouns',\n",
       " 'G3R: A Graph-Guided Generate-and-Rerank Framework for Complex and Cross-domain Text-to-SQL Generation',\n",
       " 'It is a Bird Therefore it is a Robin: On BERT’s Internal Consistency Between Hypernym Knowledge and Logical Words',\n",
       " 'Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM’s Translation Capability',\n",
       " '(QA)2: Question Answering with Questionable Assumptions',\n",
       " 'What In-Context Learning “Learns” In-Context: Disentangling Task Recognition and Task Learning',\n",
       " 'Learning “O” Helps for Learning More: Handling the Unlabeled Entity Problem for Class-incremental NER',\n",
       " 'Why Aren’t We NER Yet? Artifacts of ASR Errors in Named Entity Recognition in Spontaneous Speech Transcripts',\n",
       " 'SLUE Phase-2: A Benchmark Suite of Diverse Spoken Language Understanding Tasks',\n",
       " 'It’s not Sexually Suggestive; It’s Educative | Separating Sex Education from Suggestive Content on TikTok videos',\n",
       " 'TextObfuscator: Making Pre-trained Language Model a Privacy Protector via Obfuscating Word Representations',\n",
       " 'Risks and NLP Design: A Case Study on Procedural Document QA',\n",
       " 'A dynamic programming algorithm for span-based nested named-entity recognition in O(n2)',\n",
       " 'Theory of Mind in Freely-Told Children’s Narratives: A Classification Approach',\n",
       " 'Knowledge Graph Embeddings using Neural Ito Process: From Multiple Walks to Stochastic Trajectories',\n",
       " 'Computer says “No”: The Case Against Empathetic Conversational AI',\n",
       " 'Using Collostructional Analysis to evaluate BERT’s representation of linguistic constructions',\n",
       " 'Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event Chains of Children’s Fairy Tales',\n",
       " 'Don’t Retrain, Just Rewrite: Countering Adversarial Perturbations by Rewriting Text',\n",
       " 'Don’t Forget Your ABC’s: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems',\n",
       " 'One Cannot Stand for Everyone! Leveraging Multiple User Simulators to train Task-oriented Dialogue Systems',\n",
       " 'Your spouse needs professional help: Determining the Contextual Appropriateness of Messages through Modeling Social Relationships',\n",
       " 'Symbolic Chain-of-Thought Distillation: Small Models Can Also “Think” Step-by-Step',\n",
       " 'Towards Zero-Shot Persona Dialogue Generation with In-Context Learning',\n",
       " 'Ideology Prediction from Scarce and Biased Supervision: Learn to Disregard the “What” and Focus on the “How”!',\n",
       " 'Helping a Friend or Supporting a Cause? Disentangling Active and Passive Cosponsorship in the U.S. Congress',\n",
       " '‘Lighter’ Can Still Be Dark: Modeling Comparative Color Descriptions',\n",
       " 'Let’s do it “again”: A First Computational Approach to Detecting Adverbial Presupposition Triggers',\n",
       " 'What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties',\n",
       " 'Taylor’s law for Human Linguistic Sequences',\n",
       " 'Using Linguistic Features to Improve the Generalization Capability of Neural Coreference Resolvers',\n",
       " 'Similar but not the Same: Word Sense Disambiguation Improves Event Detection via Neural Representation Matching',\n",
       " 'Learning Word Representations with Cross-Sentence Dependency for End-to-End Co-reference Resolution',\n",
       " 'Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs',\n",
       " 'Annotation of a Large Clinical Entity Corpus',\n",
       " 'A Multi-Stage Memory Augmented Neural Network for Machine Reading Comprehension',\n",
       " 'N-ary Relation Extraction using Graph-State LSTM',\n",
       " 'GraphBTM: Graph Enhanced Autoencoded Variational Inference for Biterm Topic Model',\n",
       " 'Learning Neural Representation for CLIR with Adversarial Framework',\n",
       " 'Improving Word Sense Induction by Exploiting Semantic Relevance',\n",
       " 'WECA: A WordNet-Encoded Collocation-Attention Network for Homographic Pun Recognition',\n",
       " 'Part-of-Speech Tagging for Twitter: Annotation, Features, and Experiments',\n",
       " 'LRMM: Learning to Recommend with Missing Modalities',\n",
       " 'A Genre-Aware Attention Model to Improve the Likability Prediction of Books',\n",
       " 'Modeling Inter-Aspect Dependencies for Aspect-Based Sentiment Analysis',\n",
       " 'Identifying the sentiment styles of YouTube’s vloggers',\n",
       " 'It’s going to be okay: Measuring Access to Support in Online Communities',\n",
       " 'Making “fetch” happen: The influence of social and linguistic context on nonstandard word growth and decline',\n",
       " 'LRMM: Learning to Recommend with Missing Modalities',\n",
       " 'Interpretable Emoji Prediction via Label-Wise Attention LSTMs',\n",
       " 'Variational Sequential Labelers for Semi-Supervised Learning',\n",
       " 'Card-660: Cambridge Rare Word Dataset - a Reliable Benchmark for Infrequent Word Representation Models',\n",
       " 'Dynamic Meta-Embeddings for Improved Sentence Representations',\n",
       " 'SyntaxSQLNet: Syntax Tree Networks for Complex and Cross-Domain Text-to-SQL Task',\n",
       " 'Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task',\n",
       " 'Learning to Learn Semantic Parsers from Natural Language Supervision',\n",
       " 'Better Transition-Based AMR Parsing with a Refined Search Space',\n",
       " 'Learning Context-Sensitive Convolutional Filters for Text Processing',\n",
       " 'Word Maturity: Computational Modeling of Word Knowledge',\n",
       " 'Textual Analogy Parsing: What’s Shared and What’s Compared among Analogous Facts',\n",
       " 'TwoWingOS: A Two-Wing Optimization Strategy for Evidential Claim Verification',\n",
       " 'Semantic Role Labeling for Learner Chinese: the Importance of Syntactic Parsing and L2-L1 Parallel Data',\n",
       " 'Neural Latent Relational Analysis to Capture Lexical Semantic Relations in a Vector Space',\n",
       " 'Commonsense inference in human-robot communication',\n",
       " 'A Position-aware Bidirectional Attention Network for Aspect-level Sentiment Analysis',\n",
       " 'QuaSE: Sequence Editing under Quantifiable Guidance',\n",
       " 'Operation-guided Neural Networks for High Fidelity Data-To-Text Generation',\n",
       " 'Abstractive Text-Image Summarization Using Multi-Modal Attentional Hierarchical RNN',\n",
       " 'Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization',\n",
       " 'Multi-Reference Training with Pseudo-References for Neural Translation and Text Generation',\n",
       " 'A Neural Local Coherence Model for Text Quality Assessment',\n",
       " 'Getting to “Hearer-old”: Charting Referring Expressions Across Time',\n",
       " 'Operation-guided Neural Networks for High Fidelity Data-To-Text Generation',\n",
       " 'Towards Less Generic Responses in Neural Conversation Models: A Statistical Re-weighting Method',\n",
       " 'Entity-Oriented Parsing',\n",
       " 'Conversational Decision-Making Model for Predicting the King’s Decision in the Annals of the Joseon Dynasty',\n",
       " 'Cross-lingual Models of Word Embeddings: An Empirical Comparison',\n",
       " 'WikiAtomicEdits: A Multilingual Corpus of Wikipedia Edits for Modeling Language and Discourse',\n",
       " 'Personalized Microblog Sentiment Classification via Adversarial Cross-lingual Multi-task Learning',\n",
       " 'Bootstrapping Transliteration with Constrained Discovery for Low-Resource Languages',\n",
       " 'Adaptive Multi-pass Decoder for Neural Machine Translation',\n",
       " 'A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference',\n",
       " 'Joint Multilingual Supervision for Cross-lingual Entity Linking',\n",
       " 'Has Machine Translation Achieved Human Parity? A Case for Document-level Evaluation',\n",
       " 'Information States as First Class Citizens',\n",
       " 'Word Mover’s Embedding: From Word2Vec to Document Embedding',\n",
       " 'Game-Based Video-Context Dialogue',\n",
       " 'Tuning for Neural Machine Translation',\n",
       " 'Noise Contrastive Estimation and Negative Sampling for Conditional Models: Consistency and Statistical Efficiency',\n",
       " 'Pathologies of Neural Models Make Interpretations Difficult',\n",
       " 'Evaluating the Utility of Hand-crafted Features in Sequence Labelling',\n",
       " 'Neural-Davidsonian Semantic Proto-role Labeling',\n",
       " 'WHOSe Heritage: Classification of UNESCO World Heritage Statements of \"Outstanding Universal Value” with Soft Labels',\n",
       " 'LMSOC: An Approach for Socially Sensitive Pretraining',\n",
       " '“So You Think You’re Funny?”: Rating the Humour Quotient in Standup Comedy',\n",
       " '“Was it “stated” or was it “claimed”?: How linguistic bias affects generative language models']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semanticscholarapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
