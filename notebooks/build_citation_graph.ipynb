{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"09ybTvNroM4eXDl0QwNy71O6ncKaNHSc4HIijpfa\" \n",
    "\n",
    "def get_all_citations(paper: dict, max_retries: int = 10) -> dict:\n",
    "    # get papers that cite a paper \n",
    "    paper_id = paper[\"paperId\"] if \"paperId\" in paper.keys() else paper[\"doi\"]\n",
    "    query = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/citations\"\n",
    "    fields = \"title,isInfluential,intents,year,venue,citationCount,influentialCitationCount,url\"\n",
    "    # TODO(mm): adding authors will make issues when saving to .gexf as it doesn't like lists as attributes \n",
    "    # fields = \"title,isInfluential,intents,year,venue,citationCount,influentialCitationCount,url,authors\" \n",
    "\n",
    "    retrieved_all_papers = False\n",
    "    offset = 0\n",
    "    all_citing_papers = []\n",
    "    while not retrieved_all_papers: \n",
    "        \n",
    "        # define query params\n",
    "        params = {\"fields\": fields, \"offset\": f\"{offset}\", \"limit\": 1000} # 1000 is the limit of the API\n",
    "    \n",
    "        # query Semantic Scholar API\n",
    "        response = requests.get(\n",
    "            query, \n",
    "            headers={\"x-api-key\": API_KEY}, \n",
    "            params=params\n",
    "        )\n",
    "        \n",
    "        # try again if query fails\n",
    "        retries = 1\n",
    "        while response.status_code != 200: # 200 means success\n",
    "            # try again\n",
    "            print(f\"Status code={response.status_code}. Trying again ...\", )\n",
    "            response = requests.get(query, headers={\"x-api-key\": API_KEY}, params=params)\n",
    "\n",
    "            retries += 1\n",
    "            if retries > max_retries:\n",
    "                break\n",
    "        \n",
    "        # query successfull\n",
    "        response_json = response.json()\n",
    "        papers = []\n",
    "        for paper in response_json[\"data\"]:\n",
    "            if \"intents\" in paper.keys():\n",
    "                intents_dict = {intent: True if intent in paper[\"intents\"] else False for intent in [\"background\", \"method\", \"results\"]}\n",
    "                updated_paper = {**intents_dict, **paper} # merge dicts\n",
    "                del updated_paper[\"intents\"]\n",
    "                papers.append(updated_paper)\n",
    "        \n",
    "        all_citing_papers += papers\n",
    "\n",
    "        # decide whether to continue\n",
    "        if \"next\" in response_json.keys():\n",
    "            offset = response_json[\"next\"]\n",
    "            print(f\"Continuing with offset={offset}\")\n",
    "        else:\n",
    "            retrieved_all_papers = True\n",
    "\n",
    "    return all_citing_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021\n"
     ]
    }
   ],
   "source": [
    "# read the clean data frame\n",
    "df = pd.read_csv(\"../data/clean_data_semantic_scholar.csv\", sep=\"\\t\")\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>interpretability</th>\n",
       "      <th>doi</th>\n",
       "      <th>source</th>\n",
       "      <th>working_doi</th>\n",
       "      <th>classifier_interpretability_prediction</th>\n",
       "      <th>paperId</th>\n",
       "      <th>url</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>influentialCitationCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187</td>\n",
       "      <td>Probabilistic FastText for Multi-Sense Word Em...</td>\n",
       "      <td>Word Semantics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P18-1001</td>\n",
       "      <td>ACL2018</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>812580f6800bf0db4df0f48af6893b5ff1970fb3</td>\n",
       "      <td>https://www.semanticscholar.org/paper/812580f6...</td>\n",
       "      <td>Annual Meeting of the Association for Computat...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1520</td>\n",
       "      <td>A La Carte Embedding: Cheap but Effective Indu...</td>\n",
       "      <td>Word Semantics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P18-1002</td>\n",
       "      <td>ACL2018</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>542b9b17bb6273ee68281b7f29994b2b29d038b8</td>\n",
       "      <td>https://www.semanticscholar.org/paper/542b9b17...</td>\n",
       "      <td>Annual Meeting of the Association for Computat...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>707</td>\n",
       "      <td>Unsupervised Learning of Distributional Relati...</td>\n",
       "      <td>Word Semantics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P18-1003</td>\n",
       "      <td>ACL2018</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5fc80b69bfd3fe63ae2c55f4b7d8f961ceac48e1</td>\n",
       "      <td>https://www.semanticscholar.org/paper/5fc80b69...</td>\n",
       "      <td>Annual Meeting of the Association for Computat...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1553</td>\n",
       "      <td>Explicit Retrofitting of Distributional Word V...</td>\n",
       "      <td>Word Semantics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P18-1004</td>\n",
       "      <td>ACL2018</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>165a74c246d7942efd1829b4316aa5120d1ebf12</td>\n",
       "      <td>https://www.semanticscholar.org/paper/165a74c2...</td>\n",
       "      <td>Annual Meeting of the Association for Computat...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>Unsupervised Neural Machine Translation with W...</td>\n",
       "      <td>Machine Translation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18653/v1/P18-1005</td>\n",
       "      <td>ACL2018</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5206960404cbe05162e9f95067c56c3d0bd6f81b</td>\n",
       "      <td>https://www.semanticscholar.org/paper/52069604...</td>\n",
       "      <td>Annual Meeting of the Association for Computat...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title  \\\n",
       "0   187  Probabilistic FastText for Multi-Sense Word Em...   \n",
       "1  1520  A La Carte Embedding: Cheap but Effective Indu...   \n",
       "2   707  Unsupervised Learning of Distributional Relati...   \n",
       "3  1553  Explicit Retrofitting of Distributional Word V...   \n",
       "4    76  Unsupervised Neural Machine Translation with W...   \n",
       "\n",
       "                  area interpretability                   doi   source  \\\n",
       "0       Word Semantics              NaN  10.18653/v1/P18-1001  ACL2018   \n",
       "1       Word Semantics              NaN  10.18653/v1/P18-1002  ACL2018   \n",
       "2       Word Semantics              NaN  10.18653/v1/P18-1003  ACL2018   \n",
       "3       Word Semantics              NaN  10.18653/v1/P18-1004  ACL2018   \n",
       "4  Machine Translation              NaN  10.18653/v1/P18-1005  ACL2018   \n",
       "\n",
       "   working_doi  classifier_interpretability_prediction  \\\n",
       "0         True                                   False   \n",
       "1         True                                   False   \n",
       "2         True                                   False   \n",
       "3         True                                   False   \n",
       "4         True                                   False   \n",
       "\n",
       "                                    paperId  \\\n",
       "0  812580f6800bf0db4df0f48af6893b5ff1970fb3   \n",
       "1  542b9b17bb6273ee68281b7f29994b2b29d038b8   \n",
       "2  5fc80b69bfd3fe63ae2c55f4b7d8f961ceac48e1   \n",
       "3  165a74c246d7942efd1829b4316aa5120d1ebf12   \n",
       "4  5206960404cbe05162e9f95067c56c3d0bd6f81b   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.semanticscholar.org/paper/812580f6...   \n",
       "1  https://www.semanticscholar.org/paper/542b9b17...   \n",
       "2  https://www.semanticscholar.org/paper/5fc80b69...   \n",
       "3  https://www.semanticscholar.org/paper/165a74c2...   \n",
       "4  https://www.semanticscholar.org/paper/52069604...   \n",
       "\n",
       "                                               venue    year  citationCount  \\\n",
       "0  Annual Meeting of the Association for Computat...  2018.0          112.0   \n",
       "1  Annual Meeting of the Association for Computat...  2018.0           79.0   \n",
       "2  Annual Meeting of the Association for Computat...  2018.0           25.0   \n",
       "3  Annual Meeting of the Association for Computat...  2018.0           72.0   \n",
       "4  Annual Meeting of the Association for Computat...  2018.0          118.0   \n",
       "\n",
       "   influentialCitationCount  \n",
       "0                      13.0  \n",
       "1                      17.0  \n",
       "2                       3.0  \n",
       "3                      11.0  \n",
       "4                      13.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # look at some papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8599\n",
      "8599\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(len(df[\"paperId\"].unique()))\n",
    "print(len(df[\"doi\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpretability_papers = df[df[\"interpretability\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 100\n",
    "# head = interpretability_papers.head(n).drop(\"Unnamed: 0\", axis=1)\n",
    "# # head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9021"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to list of dictionaries (each paper becomes one dict in the list)\n",
    "papers = df.to_dict(orient=\"records\")\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '187',\n",
       "  'title': 'Probabilistic FastText for Multi-Sense Word Embeddings',\n",
       "  'area': 'Word Semantics',\n",
       "  'interpretability': nan,\n",
       "  'doi': '10.18653/v1/P18-1001',\n",
       "  'source': 'ACL2018',\n",
       "  'working_doi': True,\n",
       "  'classifier_interpretability_prediction': False,\n",
       "  'paperId': '812580f6800bf0db4df0f48af6893b5ff1970fb3',\n",
       "  'url': 'https://www.semanticscholar.org/paper/812580f6800bf0db4df0f48af6893b5ff1970fb3',\n",
       "  'venue': 'Annual Meeting of the Association for Computational Linguistics',\n",
       "  'year': 2018.0,\n",
       "  'citationCount': 112.0,\n",
       "  'influentialCitationCount': 13.0},\n",
       " {'id': '1520',\n",
       "  'title': 'A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors',\n",
       "  'area': 'Word Semantics',\n",
       "  'interpretability': nan,\n",
       "  'doi': '10.18653/v1/P18-1002',\n",
       "  'source': 'ACL2018',\n",
       "  'working_doi': True,\n",
       "  'classifier_interpretability_prediction': False,\n",
       "  'paperId': '542b9b17bb6273ee68281b7f29994b2b29d038b8',\n",
       "  'url': 'https://www.semanticscholar.org/paper/542b9b17bb6273ee68281b7f29994b2b29d038b8',\n",
       "  'venue': 'Annual Meeting of the Association for Computational Linguistics',\n",
       "  'year': 2018.0,\n",
       "  'citationCount': 79.0,\n",
       "  'influentialCitationCount': 17.0}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[:2] # look at the first two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build citation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph() # create graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding nodes to graph: 100%|██████████| 9021/9021 [00:00<00:00, 897883.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# add all papers from our clean data frame as nodes to graph\n",
    "for paper in tqdm(papers, desc=\"Adding nodes to graph\"):\n",
    "    G.add_node(paper[\"paperId\"], **paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812580f6800bf0db4df0f48af6893b5ff1970fb3\n",
      "{'id': '187', 'title': 'Probabilistic FastText for Multi-Sense Word Embeddings', 'area': 'Word Semantics', 'interpretability': nan, 'doi': '10.18653/v1/P18-1001', 'source': 'ACL2019', 'working_doi': True, 'classifier_interpretability_prediction': False, 'paperId': '812580f6800bf0db4df0f48af6893b5ff1970fb3', 'url': 'https://www.semanticscholar.org/paper/812580f6800bf0db4df0f48af6893b5ff1970fb3', 'venue': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2018.0, 'citationCount': 112.0, 'influentialCitationCount': 13.0}\n",
      "542b9b17bb6273ee68281b7f29994b2b29d038b8\n",
      "{'id': '1520', 'title': 'A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors', 'area': 'Word Semantics', 'interpretability': nan, 'doi': '10.18653/v1/P18-1002', 'source': 'ACL2019', 'working_doi': True, 'classifier_interpretability_prediction': False, 'paperId': '542b9b17bb6273ee68281b7f29994b2b29d038b8', 'url': 'https://www.semanticscholar.org/paper/542b9b17bb6273ee68281b7f29994b2b29d038b8', 'venue': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2018.0, 'citationCount': 79.0, 'influentialCitationCount': 17.0}\n",
      "5fc80b69bfd3fe63ae2c55f4b7d8f961ceac48e1\n",
      "{'id': '707', 'title': 'Unsupervised Learning of Distributional Relation Vectors', 'area': 'Word Semantics', 'interpretability': nan, 'doi': '10.18653/v1/P18-1003', 'source': 'ACL2019', 'working_doi': True, 'classifier_interpretability_prediction': False, 'paperId': '5fc80b69bfd3fe63ae2c55f4b7d8f961ceac48e1', 'url': 'https://www.semanticscholar.org/paper/5fc80b69bfd3fe63ae2c55f4b7d8f961ceac48e1', 'venue': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2018.0, 'citationCount': 25.0, 'influentialCitationCount': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# inspect some nodes\n",
    "for idx, (nid, attributes) in enumerate(G.nodes.data()):\n",
    "    print(nid)\n",
    "    print(attributes)\n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:   0%|          | 31/8599 [00:18<1:13:41,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n",
      "Continuing with offset=3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:   1%|▏         | 116/8599 [01:06<1:34:48,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:   3%|▎         | 299/8599 [02:29<1:02:11,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:   4%|▍         | 351/8599 [02:53<1:15:38,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:   5%|▍         | 396/8599 [03:13<47:14,  2.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:   7%|▋         | 620/8599 [04:50<41:47,  3.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n",
      "Continuing with offset=3000\n",
      "Continuing with offset=4000\n",
      "Continuing with offset=5000\n",
      "Continuing with offset=6000\n",
      "Continuing with offset=7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  11%|█▏        | 980/8599 [07:58<51:01,  2.49it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  13%|█▎        | 1104/8599 [09:05<39:12,  3.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n",
      "Continuing with offset=3000\n",
      "Continuing with offset=4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  14%|█▍        | 1210/8599 [10:14<1:12:27,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  23%|██▎       | 1963/8599 [15:23<51:49,  2.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  26%|██▌       | 2225/8599 [17:37<37:26,  2.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  26%|██▋       | 2262/8599 [17:54<39:06,  2.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  28%|██▊       | 2444/8599 [19:24<38:38,  2.65it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  33%|███▎      | 2868/8599 [22:25<40:23,  2.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  35%|███▍      | 2997/8599 [23:18<28:25,  3.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  42%|████▏     | 3575/8599 [27:07<27:24,  3.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  45%|████▍     | 3867/8599 [28:54<24:33,  3.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  86%|████████▌ | 7398/8599 [46:15<05:49,  3.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  87%|████████▋ | 7442/8599 [46:35<06:42,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  88%|████████▊ | 7545/8599 [47:12<06:38,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  88%|████████▊ | 7569/8599 [47:24<05:37,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n",
      "Continuing with offset=3000\n",
      "Continuing with offset=4000\n",
      "Continuing with offset=5000\n",
      "Continuing with offset=6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  89%|████████▉ | 7683/8599 [48:27<05:02,  3.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  91%|█████████ | 7843/8599 [49:27<03:11,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  91%|█████████▏| 7856/8599 [49:37<06:01,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  96%|█████████▌| 8235/8599 [51:48<02:01,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations:  97%|█████████▋| 8313/8599 [52:18<01:09,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with offset=1000\n",
      "Continuing with offset=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving citations: 100%|██████████| 8599/8599 [54:10<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# for each node in our graph (i.e., a paper), get all the papers that cite it\n",
    "# NOTE: running this will take some time (~1:30h on my Macbook Pro M1)\n",
    "citing_papers = {}\n",
    "for nid, attributes in tqdm(G.nodes.data(), desc=\"retrieving citations\"):\n",
    "    citing_papers[nid] = get_all_citations(attributes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8599\n"
     ]
    }
   ],
   "source": [
    "print(len(citing_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'id': '187',\n",
    "#  'title': 'Probabilistic FastText for Multi-Sense Word Embeddings',\n",
    "#  'area': 'Word Semantics',\n",
    "#  'interpretability': nan,\n",
    "#  'doi': '10.18653/v1/P18-1001',\n",
    "#  'source': 'ACL2019',\n",
    "#  'working_doi': True,\n",
    "#  'classifier_interpretability_prediction': False,\n",
    "#  'paperId': '812580f6800bf0db4df0f48af6893b5ff1970fb3',\n",
    "#  'url': 'https://www.semanticscholar.org/paper/812580f6800bf0db4df0f48af6893b5ff1970fb3',\n",
    "#  'venue': 'Annual Meeting of the Association for Computational Linguistics',\n",
    "#  'year': 2018,\n",
    "#  'citationCount': 112,\n",
    "#  'influentialCitationCount': 13,\n",
    "#  'value': '812580f6800bf0db4df0f48af6893b5ff1970fb3',\n",
    "#  'name': '812580f6800bf0db4df0f48af6893b5ff1970fb3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(mm): handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding citations to the graph: 100%|██████████| 8599/8599 [00:02<00:00, 3819.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# add citing papers to the graph\n",
    "for key, values in tqdm(citing_papers.items(), desc=\"Adding citations to the graph\"):\n",
    "    for paper in values:\n",
    "        paper_info = paper[\"citingPaper\"]\n",
    "        if paper_info[\"paperId\"] is not None:\n",
    "            # TODO(mm): figure out how to best handle None attributes\n",
    "            cleaned_paper_info = {k: v if v is not None else \"None\" for k,v in paper_info.items()}\n",
    "            G.add_node(cleaned_paper_info[\"paperId\"], **cleaned_paper_info)\n",
    "            G.add_edge(key, paper_info[\"paperId\"], isInfluential=paper[\"isInfluential\"], background=paper[\"background\"], results=paper[\"results\"], method=paper[\"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110934"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for edge in G.edges.data():\n",
    "#     print(edge)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # update node attributes\n",
    "# for nid, attributes in G.nodes.data():\n",
    "#     # get edges for a specific node\n",
    "#     edges = G.edges([nid])\n",
    "#     # update attributes \n",
    "#     attributes[\"citationCount\"] = len(edges)\n",
    "#     nx.set_node_attributes(G, {nid:attributes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot graph\n",
    "\n",
    "# # get unique groups\n",
    "# groups = set(nx.get_node_attributes(G,'citationCount').values())\n",
    "# mapping = dict(zip(sorted(groups), count()))\n",
    "# nodes = G.nodes()\n",
    "# # colors = [mapping[G.nodes[n]['citationCount'] if \"citationCount\" in G.nodes[n] else 0] for n in nodes]\n",
    "# colors = [mapping[G.nodes[n]['citationCount']] for n in nodes]\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=1, dpi=120)\n",
    "\n",
    "# # nx.draw(G, with_labels=False, font_weight='bold', node_color=\"red\", node_size=5, width=0.5)\n",
    "\n",
    "# # draw nodes and edges seperately\n",
    "# pos = nx.spring_layout(G)\n",
    "# ec = nx.draw_networkx_edges(G, pos, alpha=0.2, width=1)\n",
    "# nc = nx.draw_networkx_nodes(G, pos, nodelist=G.nodes(), node_color=colors, node_size=5, cmap=plt.cm.jet)\n",
    "# # nc = nx.draw_networkx_nodes(G, pos, nodelist=G.nodes(), node_color=\"red\", node_size=5)\n",
    "\n",
    "# plt.colorbar(nc, label=\"number of citations\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph to json\n",
    "G_json = nx.cytoscape_data(G)  \n",
    "\n",
    "with open('../citationgraph/graph.json', 'w') as f:\n",
    "    json.dump(G_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "with open('../citationgraph/graph.json') as f:\n",
    "    GG = json.load(f)\n",
    "GG = nx.cytoscape_graph(GG)\n",
    "\n",
    "assert G.number_of_nodes() == GG.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph to gephi format\n",
    "nx.write_gexf(G, '../citationgraph/graph.gexf', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot graph\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=1, dpi=120)\n",
    "\n",
    "# # nx.draw(G, with_labels=False, font_weight='bold', node_color=\"red\", node_size=5, width=0.5)\n",
    "\n",
    "# # draw nodes and edges seperately\n",
    "# pos = nx.spring_layout(G)\n",
    "# ec = nx.draw_networkx_edges(G, pos, alpha=0.2, width=1)\n",
    "# nc = nx.draw_networkx_nodes(G, pos, nodelist=G.nodes(), node_color=colors, node_size=5, cmap=plt.cm.jet)\n",
    "# # nc = nx.draw_networkx_nodes(G, pos, nodelist=G.nodes(), node_color=\"red\", node_size=5)\n",
    "\n",
    "# # plt.colorbar(nc, label=\"number of citations\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4682"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nx.dominating_set(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semanticscholarapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
